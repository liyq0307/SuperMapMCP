_jsuperpy_env_locale = {
    "iobjectspy._jsuperpy.env": """""",

    "iobjectspy._jsuperpy.env.Env": """
    Environment setting class, the configuration file is the env.json file in the current directory
    """,

    "iobjectspy._jsuperpy.env.Env.get_iobjects_java_bin_path": """""",

    "iobjectspy._jsuperpy.env.Env.get_omp_num_threads": """
        Get the number of threads used in parallel computing

        :rtype: int
        """,

    "iobjectspy._jsuperpy.env.Env.is_auto_close_output_datasource": """
        Whether to automatically close the result datasource object. When processing data or analysis, if the result datasource information set is automatically opened by the program (that is, the datasource does not exist in the current workspace), by default,
        The application closes automatically after completing a single functdataion. The user can make the result datasource not automatically closed by setting :py:meth: 'set_auto_close_output_datasource', so that the result datasource will exist in the current workspace.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.env.Env.is_use_analyst_memory_mode": """
        Whether to use memory mode for spatial analysis

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.env.Env.load": """
        Read all settings from the env.json settings file

        :param bool force_load: Whether to force loading.
        """,

    "iobjectspy._jsuperpy.env.Env.set_analyst_memory_mode": """
        Set whether to enable memory mode for spatial analysis.

        :param bool is_use_memory: Enable the memory mode to set True, otherwise set to False
        """,

    "iobjectspy._jsuperpy.env.Env.set_auto_close_output_datasource": """
        Set whether to close the result datasource object. When processing data or analysis, if the set result datasource information is automatically opened by the program (it is not opened by the user calling the open datasource interface, that is, the datasource does not exist in the current workspace), by default,
        The application closes automatically after completing a single function. The user can set auto_close to False through this interface so that the result datasource will not be closed automatically, so that the result datasource will exist in the current workspace.

        :param bool auto_close: Whether to automatically close the datasource object opened in the program.
        """,

    "iobjectspy._jsuperpy.env.Env.set_iobjects_java_bin_path": """""",

    "iobjectspy._jsuperpy.env.Env.set_omp_num_threads": """
        Set the number of threads used for parallel computing

        :param int num_threads: the number of threads used in parallel computing
        """,

    "iobjectspy._jsuperpy.env.get_iobjects_java_path": """
    Get the Bin directory address of the iObjects Java component set. Only the directory address that is actively set or saved in the env.json file can be obtained. The default value is None.

    :rtype: str
    """,

    "iobjectspy._jsuperpy.env.get_omp_num_threads": """
    Get the number of threads used in parallel computing

    :rtype: int
    """,

    "iobjectspy._jsuperpy.env.is_auto_close_output_datasource": """
    Whether to automatically close the result datasource object. When processing data or analysis, if the result datasource information set is automatically opened by the program (that is, the datasource does not exist in the current workspace), by default
    The application closes automatically after completing a single function. The user can make the result datasource not automatically closed by setting :py:meth: 'set_auto_close_output_datasource', so that the result datasource will exist in the current workspace.

    :rtype: bool
    """,

    "iobjectspy._jsuperpy.env.is_use_analyst_memory_mode": """
    Whether to use memory mode for spatial analysis

    :rtype: bool
    """,

    "iobjectspy._jsuperpy.env.set_analyst_memory_mode": """
    Set whether to enable memory mode for spatial analysis.

    :param bool is_use_memory: Enable the memory mode to set True, otherwise set to False
    """,

    "iobjectspy._jsuperpy.env.set_auto_close_output_datasource": """
    Set whether to close the result datasource object. When processing data or analysis, if the set result datasource information is automatically opened by the program (it is not opened by the user calling the open datasource interface, that is, the datasource does not exist in the current workspace), by default,
    The application closes automatically after completing a single function. The user can set auto_close to False through this interface so that the result datasource will not be closed automatically, so that the result datasource will exist in the current workspace.

    :param bool auto_close: Whether to automatically close the datasource object opened in the program.
    """,

    "iobjectspy._jsuperpy.env.set_iobjects_java_path": """
    Set the Bin directory address of the iObjects Java component. The set Bin directory address will be saved in the env.json file.

    :param str bin_path: iObjects Java component Bin directory address
    :param bool is_copy_jars: Whether to copy the jars of the iObjects Java component to the iObjectsPy directory at the same time.
    """,

    "iobjectspy._jsuperpy.env.set_omp_num_threads": """
    Set the number of threads used for parallel computing

    :param int num_threads: the number of threads used in parallel computing
    """,
"iobjectspy._jsuperpy.env.Env.get_show_features_count" :
    """ 
    The maximum number of records displayed in vector dataset printing

        :rtype: int
    """,
"iobjectspy._jsuperpy.env.Env.set_show_features_count" :
    """ 
    Set the maximum number of records displayed in vector dataset printing

        :param int number_features: The maximum number of records displayed in vector dataset printing
    """,
}

_jsuperpy_data_locale = {
    "iobjectspy._jsuperpy.data.step": """""",

    "iobjectspy._jsuperpy.data.step.StepEvent": """
    An event that indicates a progress bar. This event is triggered when the target progress of the listener changes.
    Some functions can return the progress information of the current task execution. The progress information is returned through StepEvent, and the user can get the status of the current task from the StepEvent.

    For example, the user can define a function to display the progress information of the buffer analysis.

    >>> def progress_function(step_event):
            print('%s-%s'% (step_event.title, step_event.message))
    >>>
    >>> ds = Workspace().open_datasource('E:/data.udb')
    >>> dt = ds['point'].query('SmID <1000')
    >>> buffer_dt = create_buffer(dt, 10, 10, progress=progress_function)

    """,

    "iobjectspy._jsuperpy.data.step.StepEvent.is_cancel": """bool: the cancellation status of the event""",

    "iobjectspy._jsuperpy.data.step.StepEvent.message": """str: information about the operation in progress""",

    "iobjectspy._jsuperpy.data.step.StepEvent.percent": """int: the percentage of the current operation completed""",

    "iobjectspy._jsuperpy.data.step.StepEvent.remain_time": """int: The estimated remaining time to complete the current operation, in seconds""",

    "iobjectspy._jsuperpy.data.step.StepEvent.set_cancel": """
        Set the cancellation status of the event. If the operation is set to cancel, the task will be interrupted.

        :param bool value: The state of event cancellation, if true, the execution will be interrupted
        """,

    "iobjectspy._jsuperpy.data.step.StepEvent.title": """str: title of the progress information""",

    "iobjectspy._jsuperpy.data.ex.title": """""",

    "iobjectspy._jsuperpy.data.ex.DatasourceCreatedFailedError": """datasource creation failed exception""",

    "iobjectspy._jsuperpy.data.ex.DatasourceOpenedFailedError": """datasource open failed exception""",

    "iobjectspy._jsuperpy.data.ex.DatasourceReadOnlyError": """
    Exception when the datasource is read-only. Some functions need to write data to the datasource or modify the data in the datasource, and the exception information will be returned when the datasource is read-only.
    """,

    "iobjectspy._jsuperpy.data.ex.ObjectDisposedError": """
    The abnormal object after the object is released. This exception will be thrown after checking that the java object bound in the Python instance is released.
    """,

    "iobjectspy._jsuperpy.data._jvm": """""",

    "iobjectspy._jsuperpy.data._jvm.JVMBase": """""",

    "iobjectspy._jsuperpy.data._util": """""",

    "iobjectspy._jsuperpy.data._util.check_output_datasource": """""",

    "iobjectspy._jsuperpy.data._util.convert_value_to_java": """""",

    "iobjectspy._jsuperpy.data._util.convert_value_to_python": """""",

    "iobjectspy._jsuperpy.data._util.create_geometry_buffer": """""",

    "iobjectspy._jsuperpy.data._util.create_result_datasaet": """""",

    "iobjectspy._jsuperpy.data._util.field_default_value_to_java": """""",

    "iobjectspy._jsuperpy.data._util.from_value_get_field_type": """""",

    "iobjectspy._jsuperpy.data._util.get_dataset_type_from_geometry_type": """""",

    "iobjectspy._jsuperpy.data._util.get_input_dataset": """""",

    "iobjectspy._jsuperpy.data._util.get_output_datasource": """""",

    "iobjectspy._jsuperpy.data._util.java_field_infos_to_list": """""",

    "iobjectspy._jsuperpy.data._util.java_field_infos_to_map": """""",

    "iobjectspy._jsuperpy.data._util.java_point2ds_to_list": """""",

    "iobjectspy._jsuperpy.data._util.to_java_dataset_array": """""",

    "iobjectspy._jsuperpy.data._util.to_java_datasetgrid_array": """""",

    "iobjectspy._jsuperpy.data._util.to_java_datasetimage_array": """""",

    "iobjectspy._jsuperpy.data._util.to_java_datasetvector_array": """""",

    "iobjectspy._jsuperpy.data._util.to_java_geoline_array": """""",

    "iobjectspy._jsuperpy.data._util.to_java_geometry_array": """""",

    "iobjectspy._jsuperpy.data._util.to_java_point2d_array": """""",

    "iobjectspy._jsuperpy.data._util.to_java_point2ds": """""",

    "iobjectspy._jsuperpy.data._util.to_java_point3ds": """""",

    "iobjectspy._jsuperpy.data._util.to_java_recordset_array": """""",

    "iobjectspy._jsuperpy.data._util.to_java_stattype_array": """""",

    "iobjectspy._jsuperpy.data._util.try_close_output_datasource": """""",

    "iobjectspy._jsuperpy.data.style": """""",

    "iobjectspy._jsuperpy.data.style.Color": """
    To define an RGB color object, the user can specify the RGB color value by specifying a three-element tuple, or use a four-element tuple to specify the RGBA color value.
    By default, the Alpha value is 255.

    .. image:: ../image/Colors.png

    """,

    "iobjectspy._jsuperpy.data.style.Color.A": """int: Get the A value of Color""",

    "iobjectspy._jsuperpy.data.style.Color.B": """int: Get the B value of Color""",

    "iobjectspy._jsuperpy.data.style.Color.G": """int: Get the G value of Color""",

    "iobjectspy._jsuperpy.data.style.Color.R": """int: Get the R value of Color""",

    "iobjectspy._jsuperpy.data.style.Color.__init__": """
        Construct a Color through tuple

        :param seq: the specified RGB or RGBA color value
        :type seq: tuple[int,int,int] or tuple[int,int,int,int]
        """,

    "iobjectspy._jsuperpy.data.style.Color.aliceblue": """
        Construct color value (240, 248, 255)

        :return: color value (240, 248, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.antiquewhite": """
        Construct color value (250, 235, 215)

        :return: color value (250, 235, 215)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.aqua": """
        Construct color value (0, 255, 255)

        :return: color value (0, 255, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.aquamarine": """
        Construct color value (127, 255, 212)

        :return: color value (127, 255, 212)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.azure": """
        Construct color value (240, 255, 255)

        :return: color value (240, 255, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.beige": """
        Construct color value (245, 245, 220)

        :return: color value (245, 245, 220)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.bisque": """
        Construct color value (255,228,196)

        :return: color value (255,228,196)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.black": """
        Construct color value (0, 0, 0)

        :return: color value (0, 0, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.blanchedalmond": """
        Construct color value (255,235,205)

        :return: color value (255,235,205)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.blue": """
        Construct color value (0, 0, 255)

        :return: color value (0, 0, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.blueviolet": """
        Construct color value (138, 43, 226)

        :return: color value (138, 43, 226)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.burlywood": """
        Construct color value (222, 184, 135)

        :return: color value (222, 184, 135)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.cadetblue": """
        Construct color value (95, 158, 160)

        :return: color value (95, 158, 160)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.chartreuse": """
        Construct color value (127, 255, 0)

        :return: color value (127, 255, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.chocolate": """
        Construct color value (210, 105, 30)

        :return: color value (210, 105, 30)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.coral": """
        Construct color value (255, 127, 80)

        :return: color value (255, 127, 80)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.cornflowerblue": """
        Construct color value (100, 149, 237)

        :return: color value (100, 149, 237)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.cornsilk": """
        Construct color value (255, 248, 220))

        :return: color value (255, 248, 220))
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.crimson": """
        Construct color value (220, 20, 60)

        :return: color value (220, 20, 60)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.cyan": """
        Construct color value (0, 255, 255

        :return: color value (0, 255, 255
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkblue": """
        Construct color value (0, 0, 139)

        :return: color value (0, 0, 139)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkcyan": """
        Construct color value (0, 139, 139)

        :return: color value (0, 139, 139)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkgoldenrod": """
        Construct color value (184, 134, 11)

        :return: color value (184, 134, 11)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkgray": """
        Construct color value (64, 64, 64)

        :return: color value (64, 64, 64)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkgreen": """
        Construct color value (0, 100, 0)

        :return: color value (0, 100, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkkhaki": """
        Construct color value (189, 183, 107)

        :return: color value (189, 183, 107)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkmagena": """
        Construct color value (139, 0, 139)

        :return: color value (139, 0, 139)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkolivegreen": """
        Construct color value (85, 107, 47)

        :return: color value (85, 107, 47)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkorange": """
        Construct color value (255, 140, 0)

        :return: color value (255, 140, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkorchid": """
        Construct color value (153, 50, 204)

        :return: color value (153, 50, 204)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkred": """
        Construct color value (139, 0, 0)

        :return: color value (139, 0, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darksalmon": """
        Construct color value (233, 150, 122)

        :return: color value (233, 150, 122)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkseagreen": """
        Construct color value (143, 188, 143)

        :return: color value (143, 188, 143)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkslateblue": """
        Construct color value (72, 61, 139)

        :return: color value (72, 61, 139)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkturquoise": """
        Construct color value (0, 206, 209)

        :return: color value (0, 206, 209)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.darkviolet": """
        Construct color value (148, 0, 211)

        :return: color value (148, 0, 211)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.deeppink": """
        Construct color value (255, 20, 147)

        :return: color value (255, 20, 147)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.deepskyblue": """
        Construct color value (0, 191, 255)

        :return: color value (0, 191, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.dimgray": """
        Construct color values (105, 105, 105)

        :return: color value (105, 105, 105)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.dodgerblue": """
        Construct color value (30, 144, 255)

        :return: color value (30, 144, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.firebrick": """
        Construct color value (178, 34, 34)

        :return: color value (178, 34, 34)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.floralwhite": """
        Construct color value (255, 250, 240)

        :return: color value (255, 250, 240)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.forestgreen": """
        Construct color value (34, 139, 34)

        :return: color value (34, 139, 34)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.fuschia": """
        Construct color value (255, 0, 255)

        :return: color value (255, 0, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.gainsboro": """
        Construct color value (220, 220, 220)

        :return: color value (220, 220, 220)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.ghostwhite": """
        Construct color value (248, 248, 255)

        :return: color value (248, 248, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.gold": """
        Construct color value (255, 215, 0)

        :return: color value (255, 215, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.goldenrod": """
        Construct color value (218, 165, 32)

        :return: color value (218, 165, 32)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.gray": """
        Construct color value (128, 128, 128)

        :return: color value (128, 128, 128)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.green": """
        Construct color value (0, 128, 0)

        :return: color value (0, 128, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.greenyellow": """
        Construct color value (173, 255, 47)

        :return: color value (173, 255, 47)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.honeydew": """
        Construct color value (240, 255, 240)

        :return: color value (240, 255, 240)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.hotpink": """
        Construct color value (255, 105, 180)

        :return: color value (255, 105, 180)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.indianred": """
        Construct color value (205, 92, 92)

        :return: color value (205, 92, 92)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.indigo": """
        Construct color value (75, 0, 130)

        :return: color value (75, 0, 130)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.ivory": """
        Construct color value (255, 240, 240)

        :return: color value (255, 240, 240)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.khaki": """
        Construct color value (240, 230, 140)

        :return: color value (240, 230, 140)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lavender": """
        Construct color values (230, 230, 250)

        :return: color value (230, 230, 250)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lavenderblush": """
        Construct color value (255, 240, 245)

        :return: color value (255, 240, 245)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lawngreen": """
        Construct color value (124, 252, 0)

        :return: color value (124, 252, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lemonchiffon": """
        Construct color value (255, 250, 205)

        :return: color value (255, 250, 205)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightblue": """
        Construct color value (173, 216, 230)

        :return: color value (173, 216, 230)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightcoral": """
        Construct color value (240, 128, 128)

        :return: color value (240, 128, 128)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightcyan": """
        Construct color value (224, 255, 255)

        :return: color value (224, 255, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightgoldenrodyellow": """
        Construct color value (250, 250, 210)

        :return: color value (250, 250, 210)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightgray": """
        Construct color value (211, 211, 211)

        :return: color value (211, 211, 211)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightgreen": """
        Construct color value (144, 238, 144)

        :return: color value (144, 238, 144)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightpink": """
        Construct color value (255, 182, 193)

        :return: color value (255, 182, 193)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightsalmon": """
        Construct color value (255, 160, 122)

        :return: color value (255, 160, 122)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightseagreen": """
        Construct color value (32, 178, 170)

        :return: color value (32, 178, 170)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightskyblue": """
        Construct color value (135, 206, 250)

        :return: color value (135, 206, 250)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightslategray": """
        Construct color value (119, 136, 153)

        :return: color value (119, 136, 153)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightsteelblue": """
        Construct color value (176, 196, 222)

        :return: color value (176, 196, 222)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lightyellow": """
        Construct color value (255, 255, 224)

        :return: color value (255, 255, 224)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.lime": """
        Construct color value (0, 255, 0)

        :return: color value (0, 255, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.limegreen": """
        Construct color value (50, 205, 50)

        :return: color value (50, 205, 50)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.linen": """
        Construct color value (250, 240, 230)

        :return: color value (250, 240, 230)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.magenta": """
        Construct color value (255, 0, 255)

        :return: color value (255, 0, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.make": """
        Construct a Color object

        :param value: The value used to construct the Color object. If it is str, it can be concatenated with',', for example: '0,255,232' or '0,255,234,54'
        :type value: Color or str or tuple[int,int,int] or tuple[int,int,int,int]
        :return: color object
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.maroon": """
        Construct color value (128, 0, 0)

        :return: color value (128, 0, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.medium_sea_green": """
        Construct color value (60, 179, 113)

        :return: color value (60, 179, 113)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.mediumaquamarine": """
        Construct color value (102, 205, 170)

        :return: color value (102, 205, 170)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.mediumblue": """
        Construct color value (0, 0, 205)

        :return: color value (0, 0, 205)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.mediumorchid": """
        Construct color value (186, 85, 211)

        :return: color value (186, 85, 211)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.mediumpurple": """
        Construct color values (147, 112, 219)

        :return: color value (147, 112, 219)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.mediumslateblue": """
        Construct color value (123, 104, 238)

        :return: color value (123, 104, 238)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.mediumspringgreen": """
        Construct color value (0, 250, 154)

        :return: color value (0, 250, 154)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.mediumturquoise": """
        Construct color value (72, 209, 204)

        :return: color value (72, 209, 204)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.mediumvioletred": """
        Construct color value (199, 21, 112)

        :return: color value (199, 21, 112)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.midnightblue": """
        Construct color value (25, 25, 112)

        :return: color value (25, 25, 112)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.mintcream": """
        Construct color value (245, 255, 250)

        :return: color value (245, 255, 250)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.mistyrose": """
        Construct color value (255, 228, 225)

        :return: color value (255, 228, 225)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.moccasin": """
        Construct color value (255, 228, 181)

        :return: color value (255, 228, 181)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.navajowhite": """
        Construct color value (255, 222, 173)

        :return: color value (255, 222, 173)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.navy": """
        Construct color value (0, 0, 128)

        :return: color value (0, 0, 128)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.oldlace": """
        Construct color value (253, 245, 230)

        :return: color value (253, 245, 230)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.olive": """
        Construct color value (128, 128, 0)

        :return: color value (128, 128, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.olivedrab": """
        Construct color value (107, 142, 45)

        :return: color value (107, 142, 45)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.orange": """
        Construct color value (255, 165, 0)

        :return: color value (255, 165, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.orangered": """
        Construct color value (255, 69, 0)

        :return: color value (255, 69, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.orchid": """
        Construct color value (218, 112, 214)

        :return: color value (218, 112, 214)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.pale_goldenrod": """
        Construct color value (238, 232, 170)

        :return: color value (238, 232, 170)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.palegreen": """
        Construct color value (152, 251, 152)

        :return: color value (152, 251, 152)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.paleturquoise": """
        Construct color value (175, 238, 238)

        :return: color value (175, 238, 238)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.palevioletred": """
        Construct color value (219, 112, 147)

        :return: color value (219, 112, 147)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.papayawhip": """
        Construct color value (255, 239, 213)

        :return: color value (255, 239, 213)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.peachpuff": """
        Construct color value (255, 218, 155

        :return: color value (255, 218, 155
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.peru": """
        Construct color value (205, 133, 63)

        :return: color value (205, 133, 63)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.pink": """
        Construct color value (255, 192, 203)

        :return: color value (255, 192, 203)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.plum": """
        Construct color value (221, 160, 221)

        :return: color value (221, 160, 221)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.powderblue": """
        Construct color value (176, 224, 230)

        :return: color value (176, 224, 230)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.purple": """
        Construct color value (128, 0, 128)

        :return: color value (128, 0, 128)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.red": """
        Construct color value (255, 0, 0)

        :return: color value (255, 0, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.rgb": """
        Construct a Color object by specifying R, G, B, and A values

        :param int red: Red value
        :param int green: Green value
        :param int blue: Blue value
        :param int alpha: Alpha value
        :return: color object
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.rosybrown": """
        Construct color value (188, 143, 143)

        :return: color value (188, 143, 143)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.royalblue": """
        Construct color value (65, 105, 225)

        :return: color value (65, 105, 225)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.saddlebrown": """
        Construct color value (244, 164, 96)

        :return: color value (244, 164, 96)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.sandybrown": """
        Construct color value (244, 144, 96)

        :return: color value (244, 144, 96)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.seagreen": """
        Construct color value (46, 139, 87)

        :return: color value (46, 139, 87)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.seashell": """
        Construct color value (255, 245, 238)

        :return: color value (255, 245, 238)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.sienna": """
        Construct color value (160, 82, 45)

        :return: color value (160, 82, 45)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.silver": """
        Construct color value (192, 192, 192)

        :return: color value (192, 192, 192)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.skyblue": """
        Construct color value (135, 206, 235)

        :return: color value (135, 206, 235)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.slateblue": """
        Construct color value (106, 90, 205)

        :return: color value (106, 90, 205)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.slategray": """
        Construct color value (106, 90, 205)

        :return: color value (106, 90, 205)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.snow": """
        Construct color value (255, 250, 250)

        :return: color value (255, 250, 250)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.springgreen": """
        Construct color value (0, 255, 127)

        :return: color value (0, 255, 127)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.steelblue": """
        Construct color value (70, 130, 180)

        :return: color value (70, 130, 180)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.tan": """
        Construct color value (210, 180, 140)

        :return: color value (210, 180, 140)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.teal": """
        Construct color value (0, 128, 128)

        :return: color value (0, 128, 128)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.thistle": """
        Construct color value (216, 191, 216)

        :return: color value (216, 191, 216)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.tomato": """
        Construct color value (253, 99, 71)

        :return: color value (253, 99, 71)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.turquoise": """
        Construct color value (64, 224, 208)

        :return: color value (64, 224, 208)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.violet": """
        Construct color value (238, 130, 238)

        :return: color value (238, 130, 238)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.wheat": """
        Construct color value (245, 222, 179)

        :return: color value (245, 222, 179)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.white": """
        Construct color value (255, 255, 255)

        :return: color value (255, 255, 255)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.white_smoke": """
        Construct color value (245, 245, 245)

        :return: color value (245, 245, 245)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.yellow": """
        Construct color value (255, 255, 0)

        :return: color value (255, 255, 0)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.Color.yellowgreen": """
        Construct color value (154, 205, 50)

        :return: color value (154, 205, 50)
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle": """
    Geometric style class. Used to define point symbols, line symbols, fill symbols and their related settings. For text objects, only text style can be set, not geometric style.
    Except for composite dataset (CAD dataset), other types of dataset do not store the style information of geometric objects.
    The filling mode is divided into normal filling mode and gradient filling mode. In normal filling mode, you can use pictures or vector symbols for filling; in gradient filling mode, there are four types of gradients to choose from: linear gradient filling, radial gradient filling, conical gradient filling and four-corner gradient filling
    """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.fill_back_color": """Color: The background color of the fill symbol. When the fill mode is gradient fill, this color is the fill end color. The default value Color(255,255,255,255)""",

    "iobjectspy._jsuperpy.data.style.GeoStyle.fill_fore_color": """Color: The foreground color of the fill symbol. When the fill mode is gradient fill, this color is the starting color of the gradient fill. The default value Color(189,235,255,255)""",

    "iobjectspy._jsuperpy.data.style.GeoStyle.fill_gradient_angle": """float: The rotation angle of the gradient fill, the unit is 0.1 degrees, and the counterclockwise direction is the positive direction.""",

    "iobjectspy._jsuperpy.data.style.GeoStyle.fill_gradient_mode": """FillGradientMode: Return the gradient type of the gradient fill style. For the definition of each gradient fill type, please refer to: py:class:`FillGradientMode` """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.fill_gradient_offset_ratio_x": """float: Return the percentage of the horizontal offset of the center point of the gradient fill relative to the center point of the filled area. Set the coordinates of the center point of the filled area be (x0,y0 ), 
        the coordinates of the filling center point are (x, y), the width of the filled area is a, and the horizontal offset percentage is dx, then x=x0 + a*dx/100. The percentage can be negative. When it is negative, the filling center point is
        offset to the negative direction of the X-axis relative to the filling area center point. This method is effective for radial gradient, cone gradient, four-corner gradient and linear gradient fill. """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.fill_gradient_offset_ratio_y": """float: Return the vertical offset percentage of the filling center point relative to the center point of the filling area. Set the coordinates of the center point of the filling area to (x0,y0), the coordinates of the filling center point are
        (x, y), the height of the filled area is b, and the vertical offset percentage is dy, then y=y0 + b*dy/100. The percentage can be negative. When it is negative, the filling center point is
        offset to the negative direction of the X-axis relative to the filling area center point. This method is effective for radial gradient, cone gradient, four-corner gradient and linear gradient fill. """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.fill_opaque_rate": """int: Return the opaqueness of the fill. The legal value is 0-100. Its value is 0 means completely transparent; if its value is 100, it means completely opaque. Assignment If it is less than 0, it will be treated as 0, and if it is greater than 100, it will be treated as 100. """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.fill_symbol_id": """int: Return the code of the filling symbol. This code is used to uniquely identify the filling symbol of each common filling style. The filling symbol can be user-defined or the system can be used Built-in symbol library. """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.from_xml": """
        Construct GeoStyle object according to xml description information

        :param str xml: Describe the xml information of GeoStyle. Specific reference: py:meth:`to_xml`
        :return: geometric object style
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.is_fill_back_opaque": """bool: Whether the current filled background is opaque. If the current filled background is opaque, it is True, otherwise it is False.""",

    "iobjectspy._jsuperpy.data.style.GeoStyle.line_color": """Color: Line symbol style or color of dot symbol. """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.line_style": """
        Object style for constructing a line object

        :param int line_id: The code of the line symbol. This code is used to uniquely identify each linear symbol. Linear symbols can be customized by users, or you can use the system's own symbol library.
        :param float line_width: The width of the line symbol. The unit is millimeter and the accuracy is 0.1.
        :param color: parametric style
        :type color: Color or tuple[int,int,int] or tuple[int,int,int,int]
        :return: the object style of the line object
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.line_symbol_id": """int: the code of the line symbol. This code is used to uniquely identify each line symbol. The line symbol can be customized by the user or can be used by the system Symbol library. """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.line_width": """float: The width of the line symbol. The unit is millimeters and the precision is 0.1. """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.marker_angle": """float: The rotation angle of the dot symbol, in degrees, accurate to 0.1 degrees. And the counterclockwise direction is the positive direction. This angle can be used as a normal filling style. This angle can be used as the rotation angle of the fill symbol in the normal fill style.""",

    "iobjectspy._jsuperpy.data.style.GeoStyle.marker_size": """tuple[float,float]: The size of the dot symbol, in millimeters, accurate to 0.1 mm.""",

    "iobjectspy._jsuperpy.data.style.GeoStyle.marker_symbol_id": """int: The code of the dot symbol. This code is used to uniquely identify each dot symbol. The dot symbol can be customized by the user or the system itself Symbol library. """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.point_style": """
        Object style for constructing a point object

        :param int marker_id: The code of the dot symbol. This code is used to uniquely identify each dot symbol. Point symbols can be customized by users, or you can use the system's own symbol library. The ID value of the specified symbol must be an ID value that already exists in the symbol library.
        :param float marker_angle: The rotation angle of the dot symbol. The unit is degree, accurate to 0.1 degree, and the counterclockwise direction is the positive direction. This angle can be used as the rotation angle of the fill symbol in the normal fill style.
        :param marker_size: The size of the dot, in millimeters, with an accuracy of 0.1 mm. Its value must be greater than or equal to 0. If it is 0, it means no display; if it is less than 0, an exception will be thrown.
        :type marker_size: tuple[int,int]
        :param color: The color of the dot symbol.
        :type color: Color or tuple[int,int,int] or tuple[int,int,int,int]
        :return: the object style of the point object
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_fill_back_color": """
        Set the background color of the fill symbol. When the fill mode is gradient fill, this color is the end color of the gradient fill.

        :param value: Used to set the background color of the fill symbol.
        :type value: Color or tuple[int,int,int] or tuple[int,int,int,int]
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_fill_back_opaque": """
        Set whether the current filled background is opaque.

        :param bool value: Whether the current filled background is transparent, true means opaque.
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_fill_fore_color": """
        Set the foreground color of the fill symbol. When the fill mode is gradient fill, this color is the starting color of the gradient fill.

        :param value: used to set the foreground color of the fill symbol
        :type value: Color or tuple[int,int,int] or tuple[int,int,int,int]
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_fill_gradient_angle": """
        Set the rotation angle of the gradient fill, the unit is 0.1 degrees, and the counterclockwise direction is the positive direction. For the definition of each gradient fill style, please refer to FillGradientMode.
        For different gradient fills, the rotated effects are different, but they are all rotated counterclockwise with the center of the smallest bounding rectangle as the center of rotation:

        * Linear gradient

         When the set angle is from 0 to 360 degrees, the line passing through the starting point and ending point is rotated counterclockwise with the center of the smallest enclosing rectangle as the center of rotation, and the gradient style rotates accordingly, it is still a linear gradient from the beginning of the line to the end. 
         The following are the gradient styles at special angles:

        -When the gradient fill angle is set to 0 degrees or 360 degrees, then the gradient fill style is a linear gradient from left to right from the start color to the end color, as shown in the figure, the start color is yellow and the end color is pink ï¼›

            .. image: ./image/Fill_360.png

        -When the gradient fill angle is set to 180 degrees, the gradient fill style is exactly the opposite of the style described in 1, that is, from right to left, a linear gradient from the start color to the end color;

            .. image: ./image/Fill_180.png

        -When the gradient fill angle is set to 90 degrees, the gradient fill style is a linear gradient from bottom to top, starting color to ending color;

            .. image: ./image/Fill_90.png

        -When the gradient fill angle is set to 270 degrees, the gradient fill style is exactly the opposite of the style described in 3, that is, from top to bottom, the starting color to the ending color is linearly gradient.

            .. image: ./image/Fill_270.png

        * Radiation gradient

         When the gradient filling angle is set to any angle (not exceeding the normal range), the circle that defines the radial gradient will be rotated according to the set angle. Since the circle is symmetric about
         the center point of the smallest enclosing rectangle that fills the range, the style of the gradient filling after the rotation is always the same, that is, the radial gradient from the center point to the boundary of the filling range, from the foreground color to the background color.

        * Conical gradient

         When the gradient angle is set to any angle between 0-360 degrees, all the generatrices of the cone will rotate, taking the center point of the cone, that is, the center of the smallest bounding rectangle of the filled area as the center of rotation,
         rotate counterclockwise. In the example shown in the figure, the rotation angle is 90 degrees, and all the buses are rotated from the starting position (the position where the rotation angle is zero) to the specified angle. Take the bus passing the starting point as an example, it starts from the 0 degree position Rotate to 90 degree position.


            .. image: ./image/GeoS_Angle1.png

            .. image: ./image/GeoS_Angle2.png

        * Four-corner gradient

         According to the given gradient filling angle, the gradient square will be rotated with the center of the filled area as the center. All squares are rotated from their initial position,
         the default position with zero rotation Angle. The gradient is still a gradient from the starting color to the ending color from the inner square to the outer square.

        :param float value: to set the rotation angle of the gradient fill
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_fill_gradient_mode": """
        Set the gradient type of the gradient fill style

        :param value: The gradient type of the gradient fill style.
        :type value: FillGradientMode or str
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_fill_gradient_offset_ratio_x": """
        Set the horizontal offset percentage of the gradient fill center point relative to the center point of the filled area. Suppose the coordinates of the center point of the filling area are (x0, y0), and the coordinates of the filling center point are (x, y),
        The width of the filled area is a, and the horizontal offset percentage is dx, then x=x0 + a*dx/100. The percentage can be negative, when it is negative, the center of the filling is relative to the filled area
        The center point is offset in the negative direction of the x-axis. This method is effective for radial gradient, cone gradient, four-corner gradient and linear gradient fill.

        :param float value: The value used to set the horizontal offset of the filling center point.
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_fill_gradient_offset_ratio_y": """
        Set the vertical offset percentage of the filling center point relative to the center point of the filled area. Suppose the coordinates of the center point of the filling area are (x0, y0), and the coordinates of the filling center point are (x, y),
        The height of the filled area is b, and the vertical offset percentage is dy, then y=y0 + b*dy/100 The percentage can be negative. When it is negative, the center of the filling is relative to the filled area
        The center point is offset in the negative direction of the y-axis. This method is effective for radial gradient, cone gradient, four-corner gradient and linear gradient fill.

        :param float value: The value used to set the vertical offset of the filling center point.
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_fill_opaque_rate": """
        Set the fill opacity, the legal value is 0-100. A value of 0 means empty filling; a value of 100 means completely opaque. If the value is less than 0, it will be treated as 0, and if it is greater than 100, it will be treated as 100.

        :param int value: The integer value used to set the opacity of the fill.
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_fill_symbol_id": """
        Set the code of the fill symbol. This code is used to uniquely identify the fill symbols of each common fill style. Filling symbols can be customized by users, or you can use the symbol library that comes with the system. The ID value of the specified filling symbol must be an ID value that already exists in the symbol library.

        :param int value: An integer is used to set the code of the filling symbol.
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_line_color": """
        Set the style of linear symbols or the color of dot symbols

        :param value: A Color object is used to set the style of linear symbols or the color of dot symbols.
        :type value: Color or tuple[int,int,int] or tuple[int,int,int,int]
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_line_symbol_id": """
        Set the encoding of the linear symbol. This code is used to uniquely identify each linear symbol. Linear symbols can be customized by users, or you can use the system's own symbol library. The ID value of the specified line symbol must be an ID value that already exists in the symbol library .

        :param int value: An integer value used to set the encoding of the line symbol.
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_line_width": """
        Set the width of the linear symbol. The unit is millimeter and the accuracy is 0.1.

        :param float value:
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_marker_angle": """
        Set the rotation angle of the dot symbol, in degrees, accurate to 0.1 degrees, and counterclockwise is the positive direction. This angle can be used as the rotation angle of the fill symbol in the normal fill style.

        :param float value: The rotation angle of the dot symbol.
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_marker_size": """
        Set the size of the dot symbol in millimeters, accurate to 0.1 mm. Its value must be greater than or equal to 0. If it is 0, it means no display, if it is less than 0, an exception will be thrown.

        When setting the style of the dot vector layer, if the dot symbol used is a TrueType font, when specifying the width and height of the dot symbol, it is not supported to set the symbol size with unequal width and height values, that is, the aspect ratio of the symbol is always 1:1. When the user sets a symbol size with unequal width and height values, the system automatically takes the width and height values of the symbol size to be equal and equal to the height value specified by the user.

        :param float width: width
        :param float height: height
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.set_marker_symbol_id": """
        Set the code of the dot symbol. This code is used to uniquely identify each dot symbol. Point symbols can be customized by users, or you can use the system's own symbol library. The ID value of the specified line symbol must be an ID value that already exists in the symbol library.

        :param int value: The code of the point symbol.
        :return: object itself
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.style.GeoStyle.to_xml": """
        Return the XML string representing the GeoStyle object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo": """""",

    "iobjectspy._jsuperpy.data.geo.Feature": """
    Feature element object. Feature element object can be used to describe spatial information and attribute information, or it can only be used to describe attribute information.
    """,

    "iobjectspy._jsuperpy.data.geo.Feature.__init__": """

        :param Geometry geometry: geometric object information
        :param values: The attribute field value of the feature object.
        :type values: list or tuple or dict
        :param str id_value: feature object ID
        :param list[FieldInfo] field_infos: attribute field information of feature element object con
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.add_field_info": """
        Add an attribute field. After adding an attribute field, if there is no attribute field without a default value, the attribute value will be set to None

        :param FieldInfo field_info: attribute field information
        :return: return True if added successfully, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.bounds": """Rectangle: Get the geographic extent of the geometric object. If the geometric object is empty, return empty """,

    "iobjectspy._jsuperpy.data.geo.Feature.clone": """
        Copy the current object

        :rtype: Feature
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.feature_id": """str: Return Feature ID""",

    "iobjectspy._jsuperpy.data.geo.Feature.field_infos": """list[FieldInfo]: Return all field information of feature objects""",

    "iobjectspy._jsuperpy.data.geo.Feature.from_json": """
        Read information from json string to construct feature feature object

        :param dict value: json string containing feature feature object information
        :rtype: Feature
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.geometry": """Geometry: return geometric object""",

    "iobjectspy._jsuperpy.data.geo.Feature.get_field_info": """
        Get the field information of the specified name and serial number

        :param item: field name or serial number
        :type item: str or int
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.get_value": """
        Get the field value of the specified attribute field in the current object

        :param item: field name or serial number
        :type item: str or int
        :rtype: int or float or str or datetime.datetime or bytes or bytearray
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.get_values": """
        Get the property field value of the current object.

        :param bool exclude_system: Whether to include system fields. All fields beginning with "Sm" are system fields. The default is True
        :param bool is_dict: Whether to return in the form of a dict. If a dict is returned, the key of the dict is the field name and value is the attribute field value. Otherwise, the field value is returned as a list. The default is False
        :return: attribute field value
        :rtype: dict or list
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.remove_field_info": """
        Delete the field with the specified field name or serial number. After deleting the field, the field value will also be deleted

        :param name: field name or serial number
        :type name: int or str
        :return: Return True if the deletion is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.set_feature_id": """
        Set Feature ID

        :param str fid: feature ID value, generally used to represent the unique ID value of a feature object
        :return:
        :rtype:
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.set_field_infos": """
        Set attribute field information

        :param list[FieldInfo] field_infos: attribute field information
        :return: self
        :rtype: Feature
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.set_geometry": """
        Set geometric objects

        :param Geometry geo: geometry object
        :return: self
        :rtype: Feature
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.set_value": """
        Set the field value of the specified attribute field in the current object

        :param item: field name or serial number
        :type item: str or int
        :param value: field value
        :type value: int or float or str or datetime.datetime or bytes or bytearray
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.set_values": """
        Set the field value.

        :param dict values: The attribute field values to be written. Must be a dict, the key value of dict is the field name, and the value of dict is the field value
        :return: Return the number of successfully written fields
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.Feature.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo": """
    Field information class. The field information class is used to store related information such as the name, type, default value, and length of the field. Each field corresponds to a FieldInfo. For each field of the vector dataset, only the field
    The alias (caption) can be modified, and the modification of other attributes depends on whether the specific engine supports it.
    """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.__init__": """
        Construct field information object

        :param str name: field name. The name of a field can only consist of numbers, letters and underscores, but cannot start with numbers or underscores; When the user creates a new field, the field name cannot start with SM,
                          because all SuperMap system fields are prefixed with SM. In addition, the field name cannot exceed 30 characters, and the field name is not case sensitive. 
                          The name is used to uniquely identify the field, so the field cannot have the same name.
        :param field_type: field type
        :type field_type: FieldType or str
        :param int max_length: The maximum length of the field value, only valid for text fields
        :param default_value: the default value of the field
        :type default_value: int or float or datetime.datetime or str or bytes or bytearray
        :param str caption: field alias
        :param bool is_required: Is it a required field
        :param bool is_zero_length_allowed: Whether to allow zero length. Only valid for text type (TEXT, WTEXT, CHAR) fields
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.caption": """str: field alias """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.clone": """
        Copy a new FieldInfo object

        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.default_value": """ int or float or datetime.datetime or str or bytes or bytearray: the default value of the field """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.from_dict": """
        Read field information from the dict object

        :param dict values: dict object containing FieldInfo field information
        :return: self
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.from_json": """
        Construct FieldInfo object from json string

        :param str value: json string
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.is_required": """bool: Whether the field is required""",

    "iobjectspy._jsuperpy.data.geo.FieldInfo.is_system_field": """
        Determine whether the current object is a system field. All fields beginning with SM (not case sensitive) are system systems.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.is_zero_length_allowed": """bool: Whether to allow zero length. Only valid for text type (TEXT, WTEXT, CHAR) fields""",

    "iobjectspy._jsuperpy.data.geo.FieldInfo.make_from_dict": """
        Construct a new FieldInfo object from the dict object

        :param dict values: dict object containing FieldInfo field information
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.max_length": """int: the maximum length of the field value, only valid for text fields""",

    "iobjectspy._jsuperpy.data.geo.FieldInfo.name": """str: field name, the field name can only consist of numbers, letters and underscores, but cannot start with numbers or underscores; when the user creates a new field, the field name Cannot use SM as the prefix, all SuperMap system fields
            are prefixed with SM. In addition, the field name cannot exceed 30 characters and the field name is not case sensitive. The name is used to uniquely identify the field, so the field cannot have the same name. """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.set_caption": """
        Set the alias of this field. The alias can be non-unique, that is, different fields can have the same alias, and the name is used to uniquely identify a field, so the name cannot be duplicated

        :param str value: Field alias.
        :return: self
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.set_default_value": """
        Set the default value of the field. When adding a record, if the field is not assigned a value, the default value is used as the value of the field.

        :param value: the default value of the field
        :type value: bool or int or float or datetime.datetime or str or bytes or bytearray
        :return: self
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.set_max_length": """
        The maximum length of the returned field value, which is only valid for text fields. Unit: Byte

        :param int value: the maximum length of the field value
        :return: self
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.set_name": """
        Set the field name. The name of the field can only consist of numbers, letters and underscores, but cannot start with numbers or underscores; when creating a new field, the field name cannot be prefixed with SM and all SuperMap system 
        fields are prefixed with SM. In addition, the field name cannot exceed 30 characters, and the field name is not case sensitive. The name is used to uniquely identify the field, so the field cannot have the same name.

        :param str value: field name
        :return: self
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.set_required": """
        Set whether the field is required

        :param str value: field name
        :return: self
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.set_type": """
        Set field type

        :param value: field type
        :type value: FieldType or str
        :return: self
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.set_zero_length_allowed": """
        Set whether the field allows zero length. Only valid for text fields.

        :param bool value: Whether the field allows zero length. Allow field zero length to be set to True, otherwise it is False. The default value is True.
        :return: self
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.to_dict": """
        Output the current object to the dict object

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.FieldInfo.type": """FieldType: Field Type""",

    "iobjectspy._jsuperpy.data.geo.GeoBox": """
    Cuboid geometric object class
    """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object degenerates to a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of its right boundary Value. 
        The upper boundary coordinate value is equal to the lower boundary coordinate value, which is the x coordinate and y coordinate of the point.""",

    "iobjectspy._jsuperpy.data.geo.GeoBox.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.convertToGeoModel3D": """
        Convert 3D geometric objects to 3D model objects
        :param bLonLat: Specify whether the vertex or interpolation point of the model is latitude and longitude
        :param slice:
        :return: The converted 3D model object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.get_rotate": """""",

    "iobjectspy._jsuperpy.data.geo.GeoBox.get_scale": """
        The zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance.  That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. 
        Returns true if they intersect; Otherwise, it Return False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.position": """Get and set the position of the 3D geometric object""",

    "iobjectspy._jsuperpy.data.geo.GeoBox.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoBox.set_height": """""",

    "iobjectspy._jsuperpy.data.geo.GeoBox.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.set_length": """""",

    "iobjectspy._jsuperpy.data.geo.GeoBox.set_position": """
        Set the position of the 3D geometric object.
        The coordinate value of this position is the three-dimensional coordinate value of the center point of the base surface of the cuboid connected to the three-dimensional geometry object.
        The center point is used to control the placement of 3D geometric objects on the earth
        :param value:
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.set_rotate": """
        Set the rotation angle of the 3D geometric object along the X, Y, Z axis, the unit is degree
        :param x: the rotation angle along the X axis
        :param y: the rotation angle along the Y axis
        :param z: rotation angle along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.set_scale": """
        Set the zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :param x: zoom ratio along the X axis
        :param y: zoom ratio along the Y axis
        :param z: zoom ratio along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.set_style3D": """""",

    "iobjectspy._jsuperpy.data.geo.GeoBox.set_width": """""",

    "iobjectspy._jsuperpy.data.geo.GeoBox.style3D": """Get the style of 3D geometric objects""",

    "iobjectspy._jsuperpy.data.geo.GeoBox.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.translate": """
        Offset according to the center point of the object
        :param dx: offset in x direction
        :param dy: offset in y direction
        :param dz: offset in z direction
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoBox.type": """GeometryType: Return the geometry object type""",

    "iobjectspy._jsuperpy.data.geo.GeoBox.volume": """Get the volume of a 3D geometric object in cubic meters.""",

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D": """
    3D circular geometry object class
    """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object degenerates to a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of its right boundary Value, the upper boundary coordinate value is equal to its
        The coordinate values of the lower boundary are the x coordinate and y coordinate of the point. """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.convertToGeoModel3D": """
        Convert 3D geometric objects to 3D model objects
        :param bLonLat: Specify whether the vertex or interpolation point of the model is latitude and longitude
        :param slice:
        :return: The converted 3D model object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.get_rotate": """""",

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.get_scale": """
        The zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. If so,
        It Return True; otherwise, it Return False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.position": """Get and set the position of the 3D geometric object""",

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.set_position": """
        Set the position of the 3D geometric object.
       The coordinate value of this position is the three-dimensional coordinate value of the center point of the base surface of the cuboid connected to the three-dimensional geometry object.
        The center point is used to control the placement of 3D geometric objects on the earth
        :param value:
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.set_radius": """""",

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.set_rotate": """
        Set the rotation angle of the 3D geometric object along the X, Y, Z axis, the unit is degree
        :param x: the rotation angle along the X axis
        :param y: the rotation angle along the Y axis
        :param z: rotation angle along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.set_scale": """
        Set the zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :param x: zoom ratio along the X axis
        :param y: zoom ratio along the Y axis
        :param z: zoom ratio along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.set_style3D": """""",

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.style3D": """Get the style of 3D geometric objects""",

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.translate": """
        Offset according to the center point of the object
        :param dx: offset in x direction
        :param dy: offset in y direction
        :param dz: offset in z direction
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.type": """GeometryType: Return the geometric object type""",

    "iobjectspy._jsuperpy.data.geo.GeoCircle3D.volume": """Gets the volume of a 3D geometric object in cubic meters.""",

    "iobjectspy._jsuperpy.data.geo.GeoCylinder": """
    The geometric object class of the truncated cone, which is inherited from the Geometry3D class.
    If the radius of the bottom circle is equal to the radius of the top circle, it is a cylindrical geometry object.
    """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object degenerates to a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of its right boundary Value, the upper boundary coordinate value is equal to its
        The coordinate values of the lower boundary are the x coordinate and y coordinate of the point. """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.convertToGeoModel3D": """
        Convert 3D geometric objects to 3D model objects
        :param bLonLat: Specify whether the vertex or interpolation point of the model is latitude and longitude
        :param slice:
        :return: The converted 3D model object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.get_rotate": """""",

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.get_scale": """
        The zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. If so,
        It Return True; otherwise, it Return False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.position": """Get the position of the 3D geometric object""",

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.set_bottomRadius": """""",

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.set_height": """""",

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.set_position": """
        Set the position of the 3D geometric object.
        The coordinate value of this position is the three-dimensional coordinate value of the center point of the base surface of the cuboid connected to the three-dimensional geometry object.
        The center point is used to control the placement of 3D geometric objects on the earth
        :param value:
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.set_rotate": """
        Set the rotation angle of the 3D geometric object along the X, Y, Z axis, the unit is degree
        :param x: the rotation angle along the X axis
        :param y: the rotation angle along the Y axis
        :param z: rotation angle along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.set_scale": """
        Set the zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :param x: zoom ratio along the X axis
        :param y: zoom ratio along the Y axis
        :param z: zoom ratio along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.set_style3D": """""",

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.set_topRadius": """""",

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.style3D": """Get the style of 3D geometric objects""",

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.translate": """
        Offset according to the center point of the object
        :param dx: offset in x direction
        :param dy: offset in y direction
        :param dz: offset in z direction
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.type": """GeometryType: Return the geometry object type """,

    "iobjectspy._jsuperpy.data.geo.GeoCylinder.volume": """Gets the volume of a 3D geometric object in cubic meters.""",

    "iobjectspy._jsuperpy.data.geo.GeoLine": """
    The line geometry object class.
    This class is used to describe linear geographic entities, such as rivers, roads, contours, etc., and is generally represented by one or more ordered coordinate point sets. The direction of the line is determined by the order of the coordinate points. You can also call 'reverse'
    method to change the direction of the line. A line object is composed of one or more parts, each part is called a sub-object of the line object, and each sub-object is represented by an ordered set of coordinate points. You can add, delete,
    modify and other operations to the sub-objects.

    """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.__init__": """
        Construct a line geometry object

        :param points: objects containing point string information, can be list[Point2D], tuple[Point2D], GeoLine, GeoRegion and Rectangle
        :type points: list[Point2D] or tuple[Point2D] or GeoLine or GeoRegion or Rectangle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.add_part": """
        Add a sub-object to this line geometry object. The serial number of the added sub-object is returned successfully.

        :param list[Point2D] points: an ordered set of points
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object is a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of the right boundary value,
        the coordinate value of the upper boundary is equal to the coordinate value of the lower boundary, which is the x and y coordinates of the point, respectively. """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.clone": """
        Copy object

        :rtype: GeoLine
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.convert_to_region": """
        Convert current line object to area geometry object
        -For unclosed line objects, the beginning and the ending points will be automatically connected
        -If the number of points of a sub-object of the GeoLine object instance is less than 3, it will fail

        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.create_buffer": """
        Construct the buffer object of the current line object. The round head full buffer of the line object will be constructed.

        :param float distance: The radius of the buffer. If prj and unit are set, the unit of unit will be used as the unit of buffer radius.
        :param PrjCoordSys prj: Describe the projection information of the point geometry object
        :param unit: buffer radius unit
        :type unit: Unit or str
        :return: buffer radius
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.find_point_on_line_by_distance": """
        Find a point on the line at a specified distance, and the starting point of the search is the starting point of the line.
        -When 'distance' is greater than 'Length', the end of the last sub-object of the line is returned.
        -When 'distance=0', return the starting point of the line geometry object;
        -When a line geometry object has multiple sub-objects, search according to the sequence number of the sub-objects

        :param float distance: the distance to find the point
        :return: If search succeeds, return the point you are looking for, otherwise it Return None
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.get_part": """
        Return the sub-object of the specified sequence number in this line geometry object, and Return the sub-object in the form of an ordered point collection. When the two-dimensional line object is a simple line object, if the parameter 0 is passed in, the set of nodes of this line object will be obtained.

        :param int item: The serial number of the sub-object.
        :return: the node of the sub-object
        :rtype: list[Point2D]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.get_part_count": """
        Get the number of sub-objects

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.get_parts": """
        Get all point coordinates of the current geometric object. Each sub-object uses a list storage

        >>> points = [Point2D(1,2),Point2D(2,3)]
        >>> geo = GeoLine(points)
        >>> geo.add_part([Point2D(3,4),Point2D(4,5)])
        >>> print(geo.get_parts())
        [[(1.0, 2.0), (2.0, 3.0)], [(3.0, 4.0), (4.0, 5.0)]]

        :return: contains a list of all point coordinates
        :rtype: list[list[Point2D]]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object.
        Return True if they intersect; otherwise, it Return False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.insert_part": """
        Insert a sub-object at the specified position in the geometric object of this line. Return True if successful, otherwise False

        :param int item: insert position
        :param list[Point2D] points: inserted ordered set of points
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.length": """float: return the length of the line object""",

    "iobjectspy._jsuperpy.data.geo.GeoLine.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.remove_part": """
        Delete the sub-object of the specified number in the geometric object of this line.

        :param int item: the serial number of the specified sub-object
        :return: Return true if successful, otherwise false
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoLine.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.to_json": """
        Output the current object as a Simple Json string

        >>> points = [Point2D(1,2), Point2D(2,3), Point2D(1,5), Point2D(1,2)]
        >>> geo = GeoLine(points)
        >>> print(geo.to_json())
        {"Line": [[[1.0, 2.0], [2.0, 3.0], [1.0, 5.0], [1.0, 2.0]]], "id": 0}

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine.type": """GeometryType: Return the type of geometry object""",

    "iobjectspy._jsuperpy.data.geo.GeoLine3D": """
    The line geometry object class.
    This class is used to describe linear geographic entities, such as rivers, roads, contours, etc., and is generally represented by one or more ordered coordinate point sets. The direction of the line is determined by the order of the ordered coordinate points. You can also call reverse
    method to change the direction of the line. A line object is composed of one or more parts, each part is called a sub-object of the line object, and each sub-object is represented by an ordered set of coordinate points. You can add, delete,
    modify and other operations to the sub-objects.

    """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.__init__": """
        Construct a line geometry object

        :param points: objects containing point string information, can be list[Point3D], tuple[Point3D], GeoLine3D, GeoRegion3D
        :type points: list[Point3D] or tuple[Point3D] or GeoLine3d or GeoRegion
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.add_part": """
        Add a sub-object to this line geometry object. The serial number of the added sub-object is returned successfully.

        :param list[Point3D] points: an ordered set of points
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object degenerates to a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of its right boundary Value, the upper boundary coordinate value is equal to its
        The coordinate values of the lower boundary are the x coordinate and y coordinate of the point. """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.clone": """
        Copy object

        :rtype: GeoLine
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.convertToGeoModel3D": """
        Convert 3D geometric objects to 3D model objects
        :param bLonLat: Specify whether the vertex or interpolation point of the model is latitude and longitude
        :param slice:
        :return: The converted 3D model object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.convert_to_region": """
        Convert current line object to area geometry object
        -For unclosed line objects, the beginning and the ending points will be automatically connected
        -If the number of points of a sub-object of the GeoLine object instance is less than 3, it will fail

        :rtype: GeoRegion3D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.get_part": """
        Return the sub-object of the specified sequence number in this line geometry object, and Return the sub-object in the form of an ordered point collection. When the two-dimensional line object is a simple line object, if the parameter 0 is passed in, the set of nodes of this line object will be obtained.

        :param int item: The serial number of the sub-object.
        :return: the node of the sub-object
        :rtype: list[Point2D]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.get_part_count": """
        Get the number of sub-objects

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.get_parts": """
        Get all point coordinates of the current geometric object. Each sub-object uses a list storage

        >>> points = [Point3D(1,2,0),Point3D(2,3,0)]
        >>> geo = GeoLine3D(points)
        >>> geo.add_part([Point3D(3,4,0),Point3D(4,5,0)])
        >>> print(geo.get_parts())
        [[(1.0, 2.0, 0.0), (2.0, 3.0, 0.0)], [(3.0, 4.0, 0.0), (4.0, 5.0, 0.0)]]

        :return: contains a list of all point coordinates
        :rtype: list[list[Point3D]]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.get_rotate": """""",

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.get_scale": """
        The zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. If so,
        It Return True; otherwise, it Return False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.insert_part": """
        Insert a sub-object at the specified position in the geometric object of this line. Return True if successful, otherwise False

        :param int item: insert position
        :param list[Point2D] points: inserted ordered set of points
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.length": """float: Return the length of the line object""",

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.position": """Get the position of the 3D geometric object""",

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.remove_part": """
        Delete the sub-object of the specified number in the geometric object of this line.

        :param int item: the serial number of the specified sub-object
        :return: Return true if successful, otherwise false
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.set_position": """
        Set the position of the 3D geometric object.
        The coordinate value of this position is the three-dimensional coordinate value of the center point of the bottom surface of the cuboid circumscribed by the three-dimensional geometric object.
        The center point is used to control the placement of 3D geometric objects on the earth
        :param value:
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.set_rotate": """
        Set the rotation angle of the 3D geometric object along the X, Y, Z axis, the unit is degree
        :param x: the rotation angle along the X axis
        :param y: the rotation angle along the Y axis
        :param z: rotation angle along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.set_scale": """
        Set the zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :param x: zoom ratio along the X axis
        :param y: zoom ratio along the Y axis
        :param z: zoom ratio along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.set_style3D": """""",

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.style3D": """Get the style of 3D geometric objects""",

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.to_json": """
        Output the current object as a Simple Json string

        >>> points = [Point3D(1,2,0), Point3D(2,3,0), Point3D(1,5,0), Point3D(1,2,0)]
        >>> geo = GeoLine(points)
        >>> print(geo.to_json())
        {"Line3D": [[[1.0, 2.0, 0.0], [2.0, 3.0, 0.0], [1.0, 5.0, 0.0], [1.0, 2.0, 0.0]]], "id": 0}

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.translate": """
        Offset according to the center point of the object
        :param dx: offset in x direction
        :param dy: offset in y direction
        :param dz: offset in z direction
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.type": """GeometryType: Return the geometry object type """,

    "iobjectspy._jsuperpy.data.geo.GeoLine3D.volume": """Gets the volume of a 3D geometric object in cubic meters.""",

    "iobjectspy._jsuperpy.data.geo.GeoLineM": """
    Route object. It is a set of linear feature objects composed of points with X, Y coordinates and linear measurement values. The M value is the so-called Measure value, which is often used in traffic network analysis
    to mark the distance between different points of a route and a certain point. For example, milestones on highways. Traffic control departments often use milestones on highways to mark and manage highway conditions,
    vehicle speed limits and high-speed accident points, etc.
    """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.__init__": """
        Construct a route object

        :param points: objects containing point string information, can be list[PointM], tuple[PointM], GeoLineM
        :type points: list[PointM], tuple[PointM], GeoLineM
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.add_part": """
        Append a sub-object to the current object. The serial number of the added sub-object is returned successfully.

        :param list[PointM] points: an ordered set of points
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object degenerates to a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of the right boundary Value, the upper boundary coordinate value is equal to its
        The coordinate values of the lower boundary are the x coordinate and y coordinate of the point. """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.clone": """
        Copy object

        :rtype: GeoLineM
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.convert_to_line": """
        Convert the routing object into a two-dimensional line geometry object, and return the line geometry object successfully.

        :rtype: GeoLine
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.convert_to_region": """
        Convert current object to area geometry object
        -For objects that are not closed, the beginning and the ending will be automatically connected when converted to area objects
        -If the number of points of a sub-object of the GeoLineM object instance is less than 3, it will fail

        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.find_point_on_line_by_distance": """
        Find a point on the line at a specified distance, and the starting point of the search is the starting point of the line.
        -When 'distance' is greater than 'Length', the end of the last sub-object of the line is returned.
        -When 'distance=0', return the starting point of the line geometry object;
        -When a line geometry object has multiple sub-objects, search according to the sequence number of the sub-objects

        :param float distance: the distance to find the point
        :return: If search succeeds, return the point you are looking for, otherwise it Return None
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.get_distance_at_measure": """
        Return the distance from the point object corresponding to the specified M value to the starting point of the specified route sub-object.

        :param float measure: The value of M specified.
        :param bool is_ignore_gap: Specify whether to ignore the distance between sub-objects.
        :param int sub_index: The index value of the specified route sub-object. If it is -1, start counting from the first sub-object, otherwise start counting from the specified sub-object
        :return: Specify the distance from the point object corresponding to the M value to the starting point of the specified route sub-object. The unit is the same as the unit of the dataset to which the route object belongs.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.get_max_measure": """
        Return the maximum linear metric value

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.get_measure_at_distance": """
        Return the M value of the point object at the specified distance.

        :param float distance: The specified distance. The distance refers to the distance to the starting point of the route. The unit is the same as the unit of the dataset to which the route object belongs.
        :param bool is_ignore_gap: Whether to ignore the distance between sub-objects.
        :param int sub_index: The sequence number of the route sub-object to be returned. If it is -1, the calculation starts from the first object, otherwise the calculation starts from the specified sub-object.
        :return: The M value of the point object at the specified distance.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.get_measure_at_point": """
        Return the M value at the specified point of the route object.

        :param Point2D point: The specified point object.
        :param float tolerance: tolerance value. It is used to judge whether the specified point is on the routing object. If the distance from the point to the routing object is greater than this value, the specified point is considered invalid
                                Do not return. The unit is the same as the unit of the dataset to which the route object belongs.
        :param bool is_ignore_gap: Whether to ignore the gap between sub-objects.
        :return: The M value at the specified point of the route object.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.get_min_measure": """
        Return the smallest linear metric value.

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.get_part": """
        Return the sub-object of the specified sequence number in the current object, and Return the sub-object in an ordered point collection. When the current object is a simple routing object and the 0 is passed in,
        the result is a collection of nodes of this object.

        :param int item: The serial number of the subobject.
        :return: the node of the sub-object
        :rtype: list[PointM]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.get_part_count": """
        Get the number of sub-objects

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.get_parts": """
        Get all point coordinates of the current object. Each sub-object uses a list storage

        :return: contains a list of all point coordinates
        :rtype: list[list[PointM]]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object.
        It returns True if they intersect; otherwise, it returns False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.insert_part": """
        Insert a sub-object at the specified position in the current pair. Return True if successful, otherwise False

        :param int item: insert position
        :param list[PointM] points: inserted ordered set of points
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.length": """float: Return the length of the current object""",

    "iobjectspy._jsuperpy.data.geo.GeoLineM.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.remove_part": """
        Delete the sub-object of the specified serial number in this object.

        :param int item: the serial number of the specified sub-object
        :return: Return true if successful, otherwise false
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.set_empty": """Empties the spatial data in the geometric object , but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoLineM.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.to_json": """
        Output the current object as a Simple Json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoLineM.type": """GeometryType: Return the type of geometry object""",

    "iobjectspy._jsuperpy.data.geo.GeoModel3D": """
    3D model object class
    """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.Mirror": """
        :Mirror
        :param plane: mirror plane
        :return: return self's model object about plane mirroring
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.SetMatrix": """
        Model transformation
        :param basePoint: reference point
        :param matrix: transformation matrix
        :return: GeoModel3D after matrix transformation
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.__init__": """
        : Construct 3D model objects from vertices and vertex indexes
        :param poin3dValues: vertex package
        :param faceIndices: Face index collection, it should be noted that each element of the vertex index should be a list with a number greater than or equal to 4 (the first and last are the same)
        That is, the connection order of each Face vertex. It should be noted that Face should be a plane
        :return 3D model object
        For example, build a 3D model of a box with a center point at the origin
        8 vertices
        point3ds = [Point3D(-1,-1,-1), Point3D(1,-1,-1), Point3D(1,-1,1), Point3D(-1,-1,1),Point3D(- 1,1,-1), Point3D(1, 1, -1), Point3D(1, 1, 1), Point3D(-1, 1, 1)]
        6 sides
        faceIndices=[
                    [3,2,1,0,3],#front
                    [0,1,5,4,0],#bottom
                    [0,4,7,3,0],#right
                    [1,5,6,2,1],#left
                    [2,3,7,6,2],#top
                    [5,4,7,6,5] #back
                    ]
        geo=GeoModel3D(point3ds, faceIndices)

        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object degenerates to a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of its right boundary Value.
            The coordinate value of the upper boundary is equal to the coordinate value of the lower boundary, which is the x and y coordinates of the point, respectively.""",

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.convertToGeoModel3D": """
        Convert 3D geometric objects to 3D model objects
        :param bLonLat: Specify whether the vertex or interpolation point of the model is latitude and longitude
        :param slice:
        :return: The converted 3D model object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.get_rotate": """""",

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.get_scale": """
        The zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. If so,
        It returns True if they intersect; otherwise, it Return False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.max_z": """Get the maximum value in the z direction of the model""",

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.min_z": """Get the minimum value in the z direction of the model""",

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.position": """Get the position of the 3D geometric object""",

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.set_color": """
        Set the model material color, all skeletons are of this color
        :param value: material color
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.set_position": """
        Set the position of the 3D geometric object.
        The coordinate value of this position is the three-dimensional coordinate value of the center point of the base surface of the cuboid connected to the three-dimensional geometry object.
        The center point is used to control the placement of 3D geometric objects on the earth
        :param value:
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.set_rotate": """
        Set the rotation angle of the 3D geometric object along the X, Y, Z axis, the unit is degree
        :param x: the rotation angle along the X axis
        :param y: the rotation angle along the Y axis
        :param z: rotation angle along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.set_scale": """
        Set the zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :param x: zoom ratio along the X axis
        :param y: zoom ratio along the Y axis
        :param z: zoom ratio along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.set_style3D": """""",

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.style3D": """Get the style of 3D geometric objects""",

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.translate": """
        Model translation
        :param x: translation amount in X direction
        :param y: Y direction translation
        :param z: translation amount in Z direction
        :return: return the translated model
        """,

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.type": """GeometryType: Return the type of geometry object""",

    "iobjectspy._jsuperpy.data.geo.GeoModel3D.volume": """Gets the volume of a 3D geometric object in cubic meters.""",

    "iobjectspy._jsuperpy.data.geo.GeoPoint": """
        Point geometry object class.
        This class is generally used to describe point geographic entities. Both Point2D and GeoPoint can be used to represent two-dimensional points. The difference is that GeoPoint describes a ground object, while Point2D describes a position.
        When given to GeoPoint with different geometric styles, it can be used to represent different ground objects, while Point2D is a coordinate point widely used for positioning
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.__init__": """
        Construct a point geometry object.

        :param point: point object
        :type point: Point2D or GeoPoint or tuple[float] or list[float]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.bounds": """
        Rectangle: Get the geographic range of the point geometry object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.create_buffer": """
        Construct a buffer object at the current location

        :param float distance: The radius of the buffer. If prj and unit are set, the unit of unit will be used as the unit of buffer radius.
        :param PrjCoordSys prj: Describe the projection information of the point geometry object
        :param unit: buffer radius unit
        :type unit: Unit or str
        :return: buffer radius
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.get_x": """
        Get the X coordinate value of the point geometry object

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.get_y": """
        Get the Y coordinate value of the point geometry object

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. If so,
        It returns True when they intersect; otherwise, it returns False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.point": """
        Return the geographic location of the point geometry object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoPoint.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.set_point": """
        Set the geographic location of the point geometry object

        :param Point2D point: the geographic location of the point geometric object
        :return: self
        :rtype: GeoPoint
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.set_x": """
        Set the X coordinate of the point geometry object

        :param float x: X coordinate value
        :return: self
        :rtype: GeoPoint
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.set_y": """
        Set the Y coordinate of the point geometry object

        :param float y: Y coordinate value
        :return: self
        :rtype: GeoPoint
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.to_json": """
        Return the current point object in simple json format.

        E.g.::

            >>> geo = GeoPoint((10,20))
            >>> print(geo.to_json())
            {"Point": [10.0, 20.0], "id": 0}

        :return: simple json format string
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint.type": """GeometryType: Return the type of geometry object""",

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D": """
    Point geometry object class.
    This class is generally used to describe point geographic entities. Both Point3D and GeoPoint3D can be used to represent three-dimensional points. The difference is that GeoPoint3D describes a ground object, while Point3D describes a position point.
    When different geometric styles are given to GeoPoint3D, it can be used to represent different ground objects, while Point3D is a coordinate point widely used for positioning
    """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.__init__": """
        Construct a point geometry object.

        :param point: point object
        :type point: Point3D or GeoPoint3D or tuple[float] or list[float]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.bounds": """
        Rectangle: Get the geographic range of the point geometry object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, the original data of the geometric object is cleared first, and then the geometric object is reconstructed according to the incoming XML string .
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.get_x": """
        Get the X coordinate value of the point geometry object

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.get_y": """
        Get the Y coordinate value of the point geometry object

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.get_z": """
        Get the Z coordinate value of the point geometry object

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance.  That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. If so,
        It returns True when they intersect; otherwise, it Return False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.point": """
        Return the geographic location of the point geometry object

        :rtype: Point3D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.set_point": """
        Set the geographic location of the point geometry object

        :param Point3D point: the geographic location of the point geometric object
        :return: self
        :rtype: GeoPoint
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.set_x": """
        Set the X coordinate of the point geometry object

        :param float x: X coordinate value
        :return: self
        :rtype: GeoPoint3D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.set_y": """
        Set the Y coordinate of the point geometry object

        :param float y: Y coordinate value
        :return: self
        :rtype: GeoPoint3D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.set_z": """
        Set the z coordinate of the point geometry object

        :param float z: Z coordinate value
        :return: self
        :rtype: GeoPoint3D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.to_json": """
        Return the current point object in simple json format.

        E.g.::

            >>> geo = GeoPoint3D((10,20,15))
            >>> print(geo.to_json())
            {"Point3D": [10.0, 20.0], "id": 0}

        :return: simple json format string
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoPoint3D.type": """GeometryType: Return the geometric object type """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion": """
    The surface geometry object class, derived from the Geometry class.

    This class is used to describe planar geographic entities, such as administrative regions, lakes, residential areas, etc., and is generally represented by one or more ordered coordinate point sets. A surface geometry object is composed of one or more parts, and each part is called a
    a sub-object of the image, each sub-object is represented by an ordered set of coordinate points, and its start point and end point coincide. You can add, delete, and modify sub-objects.
    """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.__init__": """
        Construct a surface geometry object

        :param points: objects containing point string information, can be list[Point2D], tuple[Point2D], GeoLine, GeoRegion and Rectangle
        :type points: list[Point2D] or tuple[Point2D] or GeoLine or GeoRegion or Rectangle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.add_part": """
        Add a sub-object to this geometry object. The serial number of the added sub-object is returned successfully.

        :param list[Point2D] points: an ordered set of points
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.area": """float: Return the area of the region""",

    "iobjectspy._jsuperpy.d ata.geo.GeoRegion.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object is a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of its right boundary Value, the upper boundary coordinate value is equal to its
        The coordinate values of the lower boundary are the x coordinate and y coordinate of the point. """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.contains": """
        Determine whether the point is in the plane

        :param point: the two-dimensional point object to be judged
        :type point: Point2D or GeoPoint
        :return: Return True if the point is inside the surface, otherwise it Return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.convert_to_line": """
        Convert current area object to line object

        :rtype: GeoLine
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.create_buffer": """
        Build the buffer object of the current face object

        :param float distance: The radius of the buffer. If prj and unit are set, the unit of unit will be used as the unit of buffer radius.
        :param PrjCoordSys prj: Describe the projection information of the point geometry object
        :param unit: buffer radius unit
        :type unit: Unit or str
        :return: buffer radius
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.get_part": """
        Return the sub-object of the specified sequence number in this geometry object, and Return the sub-object in the form of an ordered point collection.

        :param int item: The serial number of the sub-object.
        :return: the node of the sub-object
        :rtype: list[Point2D]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.get_part_count": """
        Get the number of sub-objects

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.get_parts": """
        Get all point coordinates of the current geometric object. Each sub-object uses a list storage


        >>> points = [Point2D(1,2), Point2D(2,3), Point2D(1,5), Point2D(1,2)]
        >>> geo = GeoRegion(points)
        >>> geo.add_part([Point2D(2,3), Point2D(4,3), Point2D(4,2), Point2D(2,3)])
        >>> geo.get_parts()
        [[(1.0, 2.0), (2.0, 3.0), (1.0, 5.0), (1.0, 2.0)],
        [(2.0, 3.0), (4.0, 3.0), (4.0, 2.0), (2.0, 3.0)]]


        :return: contains a list of all point coordinates
        :rtype: list[list[Point2D]]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.get_parts_topology": """
       Determine the island - hole relationship between the children of the face object. The island hole relational array is composed of two values, 1 and -1. The size of the array is the same as that of the sub-objects of the face object. Where, 1 means that the sub-object is an island and -1 means that the sub-object is a hole.

        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.get_precise_area": """
        Accurately calculate the area of the polygon under the projection reference system

        :param prj: Specified projected coordinate system
        :type prj: PrjCoordSys
        :return: the area of the 2D surface geometry object
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object.
        It returns True if they intersect; otherwise, it returns False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.insert_part": """
        Insert a sub-object at the specified position in this geometric object. Return True if successful, otherwise False

        :param int item: insert position
        :param list[Point2D] points: inserted ordered set of points
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.is_counter_clockwise": """
        Determine the direction of the sub-object of the face object. true means the direction is counterclockwise, and false means the direction is clockwise.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.perimeter": """float: Return the perimeter of the region""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion.protected_decompose": """
        Protective decomposition of surface object. Different from the simple decomposition of the sub-objects of the combined object, the protective decomposition decomposes the complex area object with multiple nested islands and caves into the area object with only one level of nesting relationship.
        The rationality of decomposition cannot be guaranteed if there are subobjects partially overlapped in the surface object.

        :return: The object obtained after protective decomposition.
        :rtype: list[GeoRegion]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.remove_part": """
        Delete the sub-objects of the specified sequence number in this geometry object.

        :param int item: the serial number of the specified sub-object
        :return: Return true if successful, otherwise false
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.to_json": """
        Output the current object as a Simple Json string

        >>> points = [Point2D(1,2), Point2D(2,3), Point2D(1,5), Point2D(1,2)]
        >>> geo = GeoRegion(points)
        >>> print(geo.to_json())
        {"Region": [[[1.0, 2.0], [2.0, 3.0], [1.0, 5.0], [1.0, 2.0]]], "id": 0}

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.to_xml": """
        According to the GML 3.0 specification, the spatial data of this geometry object is output as an XML string. Note: The XML string output from the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion.type": """GeometryType: Return the geometry object type""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D": """
    The surface geometry object class, derived from the Geometry3D class.

    This class is used to describe planar geographic entities, such as administrative regions, lakes, residential areas, etc., and is generally represented by one or more ordered coordinate point sets. A surface geometry object is composed of one or more parts, and each part is called a 
    sub-object of the surface geometry object, each sub-object is represented by an ordered set of coordinate points, and its start point and end point coincide. You can add, delete, and modify sub-objects.
    """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.__init__": """
        Construct a surface geometry object

        :param points: objects containing point string information, can be list[Point2D], tuple[Point2D], GeoLine, GeoRegion and Rectangle
        :type points: list[Point2D] or tuple[Point2D] or GeoLine or GeoRegion or Rectangle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.add_part": """
        Add a sub-object to this geometry object. The serial number of the added sub-object is returned successfully.

        :param list[Point2D] points: an ordered set of points
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.area": """float: Return the area of the region object""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object degenerates to a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of the right boundary Value, the upper boundary coordinate value is equal to its
        The coordinate values of the lower boundary are the x coordinate and y coordinate of the point. """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.contains": """
        Determine whether the point is in the plane
        :param point: point object to be judged
        :type point: Point3D or GeoPoint3D
        :return: Return True if the point is inside the surface, otherwise it Return False
        :return type: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.convertToGeoModel3D": """
        Convert 3D geometric objects to 3D model objects
        :param bLonLat: Specify whether the vertex or interpolation point of the model is latitude and longitude
        :param slice:
        :return: The converted 3D model object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.get_part": """
        Return the sub-object of the specified sequence number in this geometry object, and Return the sub-object in the form of an ordered point collection.

        :param int item: The serial number of the sub-object.
        :return: the node of the sub-object
        :rtype: list[Point3D]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.get_part_count": """
        Get the number of sub-objects
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.get_parts": """
        Get all point coordinates of the current geometric object. Each sub-object uses a list storage

        >>> points = [Point3D(1,2,0), Point3D(2,3,0), Point3D(1,5,0), Point3D(1,2,0)]
        >>> geo = GeoRegion(points)
        >>> geo.add_part([Point3D(2,3,0), Point3D(4,3,0), Point3D(4,2,0), Point3D(2,3,0)])
        >>> geo.get_parts()
        :return: contains a list of all point coordinates
        :rtype: list[list[Point2D]]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.get_rotate": """""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.get_scale": """
        The zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. It used to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. If so,
        it returns True; otherwise, it returns False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.insert_part": """
        Insert a sub-object at the specified position in this geometric object. Return True if successful, otherwise False
        :param int item: insert position
        :param list[Point3D] points: inserted ordered set of points
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.perimeter": """float: Return the perimeter of the region""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.position": """Get the position of the 3D geometric object""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.remove_part": """
        Delete the sub-objects of the specified sequence number in this geometry object.
        :param int item: the serial number of the specified sub-object
        :return: Return true if successful, otherwise false
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.set_position": """
        Set the position of the 3D geometric object.
        The coordinate value of this position is the three-dimensional coordinate value of the center point of the bottom surface of the cuboid circumscribed by the three-dimensional geometric object.
        The center point is used to control the placement of 3D geometric objects on the earth
        :param value:
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.set_rotate": """
        Set the rotation angle of the 3D geometric object along the X, Y, Z axis, the unit is degree
        :param x: the rotation angle along the X axis
        :param y: the rotation angle along the Y axis
        :param z: rotation angle along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.set_scale": """
        Set the zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :param x: scale ratio along the X axis
        :param y: scale ratio along the Y axis
        :param z: scale ratio along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.set_style3D": """""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.style3D": """Get the style of 3D geometric objects""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.to_json": """
        Output the current object as a Simple Json string

        >>> points = [Point2D(1,2), Point2D(2,3), Point2D(1,5), Point2D(1,2)]
        >>> geo = GeoRegion(points)
        >>> print(geo.to_json())
        {"Region": [[[1.0, 2.0], [2.0, 3.0], [1.0, 5.0], [1.0, 2.0]]], "id": 0}

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output from the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.translate": """
        Offset the area object, add the offset to each point in the area
        :param dx: offset in X direction
        :param dy: Y direction offset
        :param dz: Z direction offset
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.type": """GeometryType: Return the geometric object type""",

    "iobjectspy._jsuperpy.data.geo.GeoRegion3D.volume": """Gets the volume of a 3D geometric object in cubic meters.""",

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D": """
    The style class of geometric objects in the 3D scene. This class is mainly used to set the display style of geometric objects in the 3D scene
    """,

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.clone": """
        Copy object

        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.from_dict": """
        Read style information from dict
        :param dict values: dict containing style information
        :return: self
        :rtype: GeoStyle3D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.from_json": """
        Construct GeoStyle3D object from json string
        :param str value:
        :rtype: GeoStyle3D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.make_from_dict": """
        Read text style information from dict to construct GeoStyle3D
        :param dict values: a dict containing text style information
        :rtype: GeoStyle3D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.set_fillForeColor": """""",

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.set_lineColor": """""",

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.set_lineWidth": """""",

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.set_markerColor": """""",

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.set_markerSize": """""",

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.to_dict": """
        Output current object as dict
        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.geo.GeoStyle3D.to_json": """
        Output as json string
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText": """
    Text class, derived from Geometry class. This category is mainly used to identify features and necessary notes. A text object is composed of one or more parts, and each part is called a sub-object of the text object.
    Each sub-object is an instance of TextPart. All sub-objects of the same text object use the same style, that is, use the text style of the text object for display.

    """,

    "iobjectspy._jsuperpy.data.geo.GeoText.__init__": """
        Construct a text object

        :param TextPart text_part: Text sub-object.
        :param TextStyle text_style: the style of the text object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.add_part": """
        Add a text subobject

        :param TextPart text_part: text sub-object
        :return: Return the serial number of the sub-object when the addition is successful, and Return -1 when it fails.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object degenerates to a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of the right boundary Value, the upper boundary coordinate value is equal to its
        The coordinate values of the lower boundary are the x coordinate and y coordinate of the point. """,

    "iobjectspy._jsuperpy.data.geo.GeoText.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.get_part": """
        Get the specified text subobject

        :param int index: the serial number of the text subobject
        :return:
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.get_part_count": """
        Get the number of text sub-objects

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.get_parts": """
        Get all text sub-objects of the current text object

        :rtype: list[TextPart]
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.get_text": """
        The content of the text object. If the object has multiple sub-objects, its value is the sum of the sub-object strings.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. If so,
        It Return True; otherwise, it Return False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.GeoText.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.remove_part": """
        Delete the text sub-object of the specified serial number of this text object.

        :param int index:
        :return: Return True if the deletion is successful, otherwise Return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.GeoText.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.set_part": """
        Modify the sub-object of the specified number of this text object, that is, replace the original text sub-object with the new text sub-object.

        :param int index: text sub-object number
        :param TextPart text_part: text sub-object
        :return: Return True if the setting is successful, otherwise return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.set_text_style": """
        Set the text style of the text object. The text style is used to specify the font, width, height and color of the text object when it is displayed.

        :param TextStyle text_style: The text style of the text object.
        :return: self
        :rtype: GeoText
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.text_style": """TextStyle: The text style of the text object. The text style is used to specify the font, width, height and color of the text object when it is displayed.""",

    "iobjectspy._jsuperpy.data.geo.GeoText.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.GeoText.type": """GeometryType: Return the geometry object type""",

    "iobjectspy._jsuperpy.data.geo.Geometry": """
    The base class of geometric objects, used to represent the spatial characteristics of geographic entities, and provide related processing methods. According to the different spatial characteristics of geographic entities, they are described by points (GeoPoint), lines (GeoLine), regions (GeoRegion), etc.
    """,

    "iobjectspy._jsuperpy.data.geo.Geometry.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object degenerates into a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of the right boundary Value, the upper boundary coordinate value is equal to its
        The coordinate values of the lower boundary are the x coordinate and y coordinate of the point. """,

    "iobjectspy._jsuperpy.data.geo.Geometry.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. If so,
        it returns True; otherwise, it returns False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.Geometry.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.Geometry.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry.type": """GeometryType: Return the type of geometry object""",

    "iobjectspy._jsuperpy.data.geo.Geometry3D": """
    The base class of all 3D geometry classes provides the properties and methods of the basic 3D geometry classes.
    Through this class, the posture of 3D geometric objects can be controlled, including the position, rotation angle, zoom ratio and interior point of the object;
    You can also offset the 3D geometric objects; you can also get the 3D model geometric objects
    """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.bounds": """Rectangle: Return the minimum bounding rectangle of a geometric object. The minimum bounding rectangle of a point object degenerates to a point, that is, the coordinate value of the left boundary of the rectangle is equal to the coordinate of its right boundary Value, the upper boundary coordinate value is equal to its
        The coordinate values of the lower boundary are the x coordinate and y coordinate of the point. """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.clone": """
        Copy object

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.convertToGeoModel3D": """
        Convert 3D geometric objects to 3D model objects
        :param bLonLat: Specify whether the vertex or interpolation point of the model is latitude and longitude
        :param slice:
        :return: The converted 3D model object
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.from_geojson": """
        Read information from geojson to construct a geometric object

        :param str geojson: geojson string
        :return: geometric object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.from_json": """
        Construct a geometric object from json. Reference: py:meth:`to_json`

        :param str value: json string
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.from_xml": """
        Reconstruct the geometric object based on the incoming XML string. The XML must conform to the GML3.0 specification.
        When calling this method, first clear the original data of the geometric object, and then reconstruct the geometric object according to the incoming XML string.
        GML (Geography Markup Language) is a geographic markup language. GML can represent spatial data and non-spatial attribute data of geographic spatial objects. GML is an XML-based spatial information encoding
        standard, proposed by the OpenGIS Consortium (OGC), has been strongly supported by many companies, such as Oracle, Galdos, MapInfo, CubeWerx, etc.
        As a spatial data coding specification, GML provides a set of basic tags, a common data model, and a mechanism for users to construct GML Application Schemas.

        :param str xml: string in XML format
        :return: Return True if the construction is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.get_inner_point": """
        Get the inner point of a geometric object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.get_rotate": """""",

    "iobjectspy._jsuperpy.data.geo.Geometry3D.get_scale": """
        The zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.get_style": """
        Get the object style of the geometric object

        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.hit_test": """
        Test whether the specified point is within the range of the geometric object within the allowable range of the specified tolerance. That is to judge whether the circle with the test point as the center of the circle and the specified tolerance as the radius has an intersection with the geometric object. If so,
        It Return True; otherwise, it Return False.

        :param Point2D point: test point
        :param float tolerance: tolerance value, the unit is the same as the unit of the dataset
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.id": """int: Return the ID of the geometric object """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.is_empty": """
        Judge whether a geometric object is null. Different geometric objects have different conditions for null.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.linear_extrude": """
        Linear stretch, support 2D and 3D vector faces, 2D and 3D circles, GeoRectangle
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param bLonLat: Whether it is latitude and longitude
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.offset": """
        Offset this geometric object by the specified amount.

        :param float dx: the amount to offset the X coordinate
        :param float dy: the amount to offset the Y coordinate
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.position": """Get and set the position of the 3D geometric object""",

    "iobjectspy._jsuperpy.data.geo.Geometry3D.resize": """
        Scale this geometric object to make its minimum enclosing rectangle equal to the specified rectangular object.
        For geometric points, this method only changes its position and moves it to the center point of the specified rectangle; for text objects, this method will scale the text size.

        :param Rectangle rc: The range of the geometric object after resizing.
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.rotate": """
        Use the specified point as the base point to rotate this geometric object by the specified angle, the counterclockwise direction is the positive direction, and the angle is in degrees.

        :param Point2D base_point: The base point of the rotation.
        :param float angle: the angle of rotation, in degrees
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.rotate_extrude": """
        Rotational extrusion, supports two-dimensional and three-dimensional vector faces, must be constructed in a plane coordinate system and cannot cross the Y axis
        :param angle: rotation angle
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.set_empty": """Empties the spatial data in the geometric object, but the identifier and geometric style of the geometric object remain unchanged.""",

    "iobjectspy._jsuperpy.data.geo.Geometry3D.set_id": """
        Set the ID value of the geometric object

        :param int value: ID value.
        :return: self
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.set_position": """
        Set the position of the 3D geometric object.
        The coordinate value of this position is the three-dimensional coordinate value of the center point of the bottom surface of the cuboid circumscribed by the three-dimensional geometric object.
        The center point is used to control the placement of 3D geometric objects on the earth
        :param value:
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.set_rotate": """
        Set the rotation angle of the 3D geometric object along the X, Y, Z axis, the unit is degree
        :param x: the rotation angle along the X axis
        :param y: the rotation angle along the Y axis
        :param z: rotation angle along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.set_scale": """
        Set the zoom ratio of 3D geometric objects along the X, Y, and Z axes
        :param x: scale ratio along the X axis
        :param y: scale ratio along the Y axis
        :param z: scale ratio along the Z axis
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.set_style": """
        Set the style of geometric objects

        :param GeoStyle style: geometric object style
        :return: return the object itself
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.set_style3D": """""",

    "iobjectspy._jsuperpy.data.geo.Geometry3D.style3D": """Get the style of 3D geometric objects""",

    "iobjectspy._jsuperpy.data.geo.Geometry3D.to_geojson": """
        Return the current object information in geojson format. Only point, line and area objects are supported.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.to_xml": """
        According to the GML 3.0 specification, the spatial data of the geometric object is output as an XML string. Note: The XML string output by the geometric object only contains the geographic coordinate value of the geometric object, and does not contain the style and ID of the geometric object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.translate": """
        Offset according to the center point of the object
        :param dx: offset in x direction
        :param dy: offset in y direction
        :param dz: offset in z direction
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.Geometry3D.type": """GeometryType: Return the type of geometry object""",

    "iobjectspy._jsuperpy.data.geo.Geometry3D.volume": """Gets the volume of a 3D geometric object in cubic meters.""",

    "iobjectspy._jsuperpy.data.geo.Matrix": """
    4X4 matrix type, mainly used for 3D model matrix transformation
    If you need continuous transformation, you should use the static method Multiply to multiply
    """,

    "iobjectspy._jsuperpy.data.geo.Matrix.multiply": """
        : Matrix multiplication, the first parameter can be Point3D or Matrix
        :param value: can be Point3D or 4X4 matrix,
        :param matrix: matrix
        :return: When the first parameter is Point3D, the return value is Point3D; when it is Matrix, the return value is Matrix
        """,

    "iobjectspy._jsuperpy.data.geo.Matrix.rotate": """
        : Rotation, unit: degree
        :param rotationX: the angle of rotation around the X axis
        :param rotationY: the angle of rotation around the Y axis
        :param rotationZ: the angle of rotation around the Z axis
        :return: return a new matrix with rotationX, rotationY, rotationZ scaling
        """,

    "iobjectspy._jsuperpy.data.geo.Matrix.scale": """
        : Zoom
        :param scaleX: zoom in X direction
        :param scaleY: zoom in Y direction
        :param scaleZ:Z-direction zoom
        :return: return a new matrix with scaleX, scaleY, scaleZ
        """,

    "iobjectspy._jsuperpy.data.geo.Matrix.set_ArrayValue": """
        : Set matrix
        :param value: an array of length 16
        """,

    "iobjectspy._jsuperpy.data.geo.Matrix.translate": """
        : Pan
        :param translateX: translation in X direction
        :param translateY: Y direction translation
        :param translateZ:Z direction translation
        :return: return a new matrix with translateX, translateY, translateZ translation
        """,

    "iobjectspy._jsuperpy.data.geo.Plane": """
    Flat object class. This plane is an infinitely extending plane in the mathematical sense, which is mainly used for cross-sectional projection and plane projection of 3D models
    usage:
    p1 = Point3D(1, 1, 1)
    p2 = Point3D(0, 3, 4)
    p3 = Point3D(7, 4, 3)
    plane = Plane([p1, p2, p3])
    or:
    plane = Plane(PlaneType.PLANEXY)
    """,

    "iobjectspy._jsuperpy.data.geo.Plane.get_normal": """
         Get the normal vector of the face
        :return: return normal vector Point3D
        """,

    "iobjectspy._jsuperpy.data.geo.Plane.set_normal": """
        Set the normal vector of the face
        :param p: Normal vector, can be Point3D, tuple[float,float,float] or list[float,float,float]
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.Plane.set_type": """
        Set plane type
        :param planeType:
        :return:
        """,

    "iobjectspy._jsuperpy.data.geo.Point2D": """
    A two-dimensional point object, using two floating-point numbers to represent the positions of the x and y axes respectively.
    """,

    "iobjectspy._jsuperpy.data.geo.Point2D.__init__": """
        Use the x and y values to construct a two-dimensional point object.

        :param float x: x axis value
        :param float y: y coordinate value
        """,

    "iobjectspy._jsuperpy.data.geo.Point2D.clone": """
        Copy the current object and return a new object

        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.Point2D.distance_to": """
        Calculate the distance between the current point and the specified point

        :param Point2D other: target point
        :return: Return the geometric distance between two points
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.Point2D.equal": """
        Determine whether the current point and the specified point are equal within the tolerance range

        :param Point2D other: point to be judged
        :param float tolerance: tolerance
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Point2D.from_dict": """
        Read point information from dict

        :param dict value: a dict containing x and y values
        :return: self
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.Point2D.from_json": """
        Construct two-dimensional point coordinates from json string

        :param str value: json string
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.Point2D.make": """
        Construct a two-dimensional point object

        :param p: x and y values
        :type p: tuple[float,float] or list[float,float] or GeoPoint or Point2D or dict
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.Point2D.make_from_dict": """
        Read point information from dict to construct two-dimensional point object

        :param dict value: a dict containing x and y values
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.geo.Point2D.to_dict": """output as a dict object

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.geo.Point2D.to_json": """
        Output the current two-dimensional point object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.Point3D": """""",

    "iobjectspy._jsuperpy.data.geo.Point3D.clone": """
        Copy the current object

        :rtype: Point3D
        """,

    "iobjectspy._jsuperpy.data.geo.Point3D.from_dict": """
        Read point information from dict

        :param dict value: a dict containing x, y and z values
        :return: self
        :rtype: Point3D
        """,

    "iobjectspy._jsuperpy.data.geo.Point3D.from_json": """
        Construct 3D point coordinates from json string

        :param str value: json string
        :rtype: Point3D
        """,

    "iobjectspy._jsuperpy.data.geo.Point3D.make": """
        Construct a 3D point object

        :param p: x, y and z values
        :type p: tuple[float,float,float] or list[float,float,float] or GeoPoint3D or Point3D or dict
        :rtype: Point3D
        """,

    "iobjectspy._jsuperpy.data.geo.Point3D.make_from_dict": """
        Read point information from dict to construct 3D point coordinates

        :param dict value: a dict containing x, y and z values
        :return: self
        :rtype: Point3D
        """,

    "iobjectspy._jsuperpy.data.geo.Point3D.to_dict": """output as a dict object

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.geo.Point3D.to_json": """
        Output current 3D point object as json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.PointM": """""",

    "iobjectspy._jsuperpy.data.geo.PointM.clone": """
        Copy the current object

        :rtype: PointM
        """,

    "iobjectspy._jsuperpy.data.geo.PointM.from_dict": """
        Read point information from dict

        :param dict value: a dict containing x, y and m values
        :return: self
        :rtype: PointM
        """,

    "iobjectspy._jsuperpy.data.geo.PointM.from_json": """
        Construct routing point coordinates from json string

        :param str value: json string
        :rtype: PointM
        """,

    "iobjectspy._jsuperpy.data.geo.PointM.make": """
        Construct a routing point object

        :param p: x, y and m values
        :type p: tuple[float,float,float] or list[float,float,float] or PointM or dict
        :rtype: PointM
        """,

    "iobjectspy._jsuperpy.data.geo.PointM.make_from_dict": """
        Read point information from dict to construct routing point coordinates

        :param dict value: a dict containing x, y and m values
        :return: self
        :rtype: PointM
        """,

    "iobjectspy._jsuperpy.data.geo.PointM.to_dict": """output as a dict object

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.geo.PointM.to_json": """
        Output the current route point object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle": """
        The rectangle object uses four floating point numbers to represent the extent of a rectangle. Where left represents the minimum value in the x direction, top represents the maximum value in the y direction,
        right represents the maximum value in the x direction, and bottom represents the minimum value in the y direction. When a rectangle is used to represent a geographic range, usually left represents the minimum longitude,
        right represents the maximum value of longitude, top represents the maximum value of latitude, and bottom represents the minimum value of latitude
        This type of object is usually used to determine the range, which can be used to represent the minimum bounding rectangle of a geometric object, the visible range of the map window, the range of the dataset, etc. In addition, this type of object is also used in rectangle selection, rectangle query, etc.
    """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.__eq__": """
        Determine whether the current rectangular object is the same as the specified rectangular object. Only when the upper, lower, left, and right boundaries are exactly the same can it be judged as the same.

        :param Rectangle other: The rectangle object to be judged.
        :return: If the current object is the same as the rectangle object, return True, otherwise return False
        :rtype: bool 
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.__getitem__": """
        When the rectangular object uses four two-dimensional coordinate points to describe the specific coordinate position, the point coordinate value is returned.

        :param int item: 0, 1, 2, 3 value
        :return: According to the value of item, return the upper left point, upper right point, lower right point, and lower left point respectively
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.__len__": """
        :return: When the rectangular object uses four two-dimensional coordinate points to describe the specific coordinate position, the number of points is returned. Fixed at 4.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.bottom": """
        float: Return the coordinate value of the lower boundary of the current rectangular object
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.center": """ Point2D: Return the center point of the current rectangle object """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.clone": """
        Copy the current object

        :rtype: Rectangle
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.contains": """
        Determine whether a point object or rectangular rectangle is inside the current rectangular object

        :param Point2D item: Two-dimensional point object (contains x and y attributes) or rectangular object. The rectangle object must be non-empty (whether the rectangle object is empty, please refer to @Rectangle.is_empty)
        :return: The object to be judged Return True within the current rectangle, otherwise False
        :rtype: bool

        >>> rect = Rectangle(1.0, 20, 2.0, 3)
        >>> rect.contains(Point2D(1.1,10))
        True
        >>> rect.contains(Point2D(0,0))
        False
        >>> rect.contains(Rectangle(1.0,10,1.5,5))
        True

        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.from_dict": """
        Read the boundary value of the rectangular object from a dictionary object. After reading successfully, the existing value of the rectangular object will be overwritten.

        :param dict value: dictionary object, the keys of the dictionary object must have'left','top','right','bottom'
        :return: return the current object, self
        :rtype: Rectangle
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.from_json": """
        Construct a rectangle object from the json string.

        :param str value: json string
        :return: rectangle object
        :rtype: Rectangle

        >>> s ='{"rectangle": [1.0, 1.0, 2.0, 2.0]}'
        >>> Rectangle.from_json(s)
        (1.0, 1.0, 2.0, 2.0)

        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.has_intersection": """
        Judge whether a two-dimensional point, rectangular object or spatial geometric object intersects the current rectangular object. As long as the object to be judged has an intersection area or contact with the current rectangular object, it will be an intersection.

        : param Point2D item: a two-dimensional point is determined to be an object, and the rectangle geometry object space, the space several HE supporting point line objects and text objects.
        :return: return True if the intersection is judged, otherwise return False
        :rtype: bool

        >>> rc = Rectangle(1,2,2,1)
        >>> rc.has_intersection(Rectangle(0,1.5,1.5,0))
        True
        >>> rc.has_intersection(GeoLine([Point2D(0,0),Point2D(3,3)]))
        True
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.height": """ float: Return the height value of the current rectangle object """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.inflate": """
        Scale the current rectangular object vertically (y direction) and horizontally (x direction). After scaling, the current object will change the top and bottom or left and right values, but the center point remains unchanged.

        :param float dx: zoom amount in horizontal direction
        :param float dy: vertical zoom
        :return: self
        :rtype: Rectangle

        >>> rc = Rectangle(1,2,2,1)
        >>> rc.inflate(3,None)
        (-2.0, 1.0, 5.0, 2.0)
        >>> rc.left == -2
        True
        >>> rc.right == 5
        True
        >>> rc.top == 2
        True
        >>> rc.inflate(0, 2)
        (-2.0, -1.0, 5.0, 4.0)
        >>> rc.left == -2
        True
        >>> rc.top == 4
        True

        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.intersect": """
        Specify the intersection of the rectangular object and the current object, and change the current rectangular object.

        :param Rectangle rc: the rectangle used for intersection operation
        :return: current object, self
        :rtype: Rectangle

        >>> rc = Rectangle(1,1,2,2)
        >>> rc.intersect(Rectangle(0,0,1.5,1.5))
        (1.0, 1.0, 1.5, 1.5)

        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.is_empty": """
        Determine whether the rectangle object is empty. When one of the upper, lower, left, and right boundary values of the rectangle is None, the rectangle is empty. The rectangle is empty when one of the upper, lower, right, and left bounds
        is -1.7976931348623157e+308.

        :return: If the rectangle is empty, return True, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.left": """
        float: Return the coordinate value of the left boundary of the current rectangular object
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.make": """
        Construct a two-dimensional rectangular object

        :param value: contains the left, bottom, right and top information of a two-dimensional rectangular object
        :type value: Rectangle or list or str or dict
        :return:
        :rtype:
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.make_from_dict": """
        Construct a rectangular object from a dictionary object.

        :param value: dictionary object, the keys of the dictionary object must have'left','top','right','bottom'
        :rtype: Rectangle

        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.offset": """
        Translate this rectangle by dx in the x direction and dy in the y direction. This method will change the current object.

        :param float dx: The amount to offset the position horizontally.
        :param float dy: The amount to offset the position vertically.
        :return: self
        :rtype: Rectangle

        >>> rc = Rectangle(1,2,2,1)
        >>> rc.offset(2,3)
        (3.0,4.0, 4.0, 5.0)
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.points": """
        tuple[Point2D]: Get the coordinates of the four vertices of the rectangle and return a tuple of 4 two-dimensional points (Point2D). The first point represents the upper left point, the second point represents the upper right point, the third point represents the lower right point, and the fourth point represents the lower left point.

        >>> rect = Rectangle(1.0, 3, 2.0, 20)
        >>> points = rect.points
        >>> len(points)
        4
        >>> points[0] == Point2D(1.0,20)
        True
        >>> points[2] == Point2D(2.0,3)
        True
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.right": """
        float: Return the coordinate value of the right boundary of the current rectangular object
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.set_bottom": """
        Set the lower boundary value of the current rectangular object. If the upper and lower boundary values are both valid, and the lower boundary value is greater than the upper boundary value, the upper and lower boundary values will be swapped

        :param float value: lower boundary value
        :return: self
        :rtype: Rectangle
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.set_left": """
        Set the left boundary value of the current rectangular object. If the left and right boundary values are both valid, and the left boundary value is greater than the right boundary value, the left and right boundary values will be swapped

        :param float value: left boundary value
        :return: self
        :rtype: Rectangle
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.set_right": """
        Set the right boundary value of the current rectangular object. If the left and right boundary values are both valid, and the left boundary value is greater than the right boundary value, the left and right boundary values will be swapped

        :param float value: right boundary value
        :return: self
        :rtype: Rectangle

        >>> rc = Rectangle(left=10).set_right(5.0)
        >>> rc.right, rc.left
        (10.0, 5.0)

        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.set_top": """
        Set the upper boundary value of the current rectangular object. If the upper and lower boundary values are both valid, and the lower boundary value is greater than the upper boundary value, the upper and lower boundary values will be swapped

        :param float value: upper boundary value
        :return: self
        :rtype: Rectangle

        >>> rc = Rectangle(bottom=10).set_top(5.0)
        >>> rc.top, rc.bottom
        (10.0, 5.0)

        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.to_dict": """
        Return the rectangle object as a dictionary object

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.to_json": """
        Get the json string form of the rectangle object

        :rtype: str

        >>> Rectangle(1,1,2,2).to_json()
        '{"rectangle": [1.0, 1.0, 2.0, 2.0]}'

        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.to_region": """
        Use a geometric area object to represent the range of a rectangular object. The point coordinate order of the returned area object is: the first point represents the upper left point, the second point represents the upper right point, and the third point represents the lower right point.
        The fourth point represents the lower left point, and the fifth point has the same coordinates as the first point.

        :return: Return the geometric region object represented by the rectangle range
        :rtype: GeoRegion

        >>> rc = Rectangle(2.0, 20, 3.0, 10)
        >>> geoRegion = rc.to_region()
        >>> print(geoRegion.area)
        10.0
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.to_tuple": """
        Get a tuple object, the elements of the tuple object are the left, bottom, right, and top of the rectangle

        :rtype: tuple
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.top": """
        float: Return the coordinate value of the upper boundary of the current rectangular object
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.union": """
        The current rectangular object merges the specified rectangular object. After the merge is completed, the range of the rectangle will be the union of the rectangle before the merge and the specified rectangular object.

        :param Rectangle rc: the specified rectangle object for merging
        :return: self
        :rtype: Rectangle

        >>> rc = Rectangle(1,1,2,2)
        >>> rc.union(Rectangle(0,-2,1,0))
        (0.0, -2.0, 2.0, 2.0)
        """,

    "iobjectspy._jsuperpy.data.geo.Rectangle.width": """float: Return the width value of the current rectangle object """,

    "iobjectspy._jsuperpy.data.geo.Size2D": """""",

    "iobjectspy._jsuperpy.data.geo.TextPart": """
    Text sub-object class. Used to represent a text object: py: class: `GeoText` the sub-object, the sub-object that stores the text of the present, the rotation angle, and to provide other information sub-anchor object associated method for processing performed.
    """,

    "iobjectspy._jsuperpy.data.geo.TextPart.__init__": """
        Construct a text sub-object.

        :param str text: The text content of the text sub-object instance.
        :param Point2D anchor_point: The anchor point of the text sub-object instance.
        :param float rotation: The rotation angle of the text sub-object, in degrees, counterclockwise is the positive direction.
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.anchor_point": """The anchor point of the text sub-object instance. The alignment of the anchor point and the text together determines the display position of the text sub-object. Regarding the alignment of the anchor point and the text How to determine the display position of the text sub-object,
        See :py:class:`TextAlignment` class. """,

    "iobjectspy._jsuperpy.data.geo.TextPart.clone": """
        Copy object

        :rtype: TextPart
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.from_dict": """
        Read information about text sub-objects from dict

        :param dict values: text sub-object
        :return: self
        :rtype: TextPart
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.from_json": """
        Read information from json string to construct text sub-object

        :param str value: json string
        :rtype: TextPart
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.make_from_dict": """
        Read information from dict to construct text sub-object

        :param dict values: text sub-object
        :rtype: TextPart
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.rotation": """The rotation angle of the text sub-object, in degrees, counterclockwise is the positive direction.""",

    "iobjectspy._jsuperpy.data.geo.TextPart.set_anchor_point": """
        Set the anchor point of this text sub-object. The alignment of the anchor point and the text together determines the display position of the text sub-object. For how the alignment of the anchor point and the text determines the display position of the text sub-object, please refer to the :py:class:`TextAlignment` class.

        :param Point2D value: the anchor point of the text subobject
        :return: self
        :rtype: TextPart
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.set_rotation": """
        Set the rotation angle of this text sub-object. Counterclockwise is the positive direction and the unit is degree.
        The rotation angle returned by the text sub-object after being stored by the data engine has an accuracy of 0.1 degree; for the text sub-object directly constructed by the constructor, the accuracy of the returned rotation angle remains unchanged.

        :param float value: the rotation angle of the text sub-object
        :return: self
        :rtype: TextPart
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.set_text": """
        Set the text sub-content of the text sub-object

        :param str value: text sub-content of text sub-object
        :return: self
        :rtype: TextPart
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.set_x": """
        Set the abscissa of the anchor point of this text sub-object

        :param float value: the abscissa of the anchor point of this text subobject
        :return: self
        :rtype: TextPart
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.set_y": """
        Set the ordinate of the anchor point of the text sub-object

        :param float value: the ordinate of the anchor point of the text object
        :return: self
        :rtype: TextPart
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.text": """str: the text content of this text sub-object """,

    "iobjectspy._jsuperpy.data.geo.TextPart.to_dict": """
        Output current sub-object as dict

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.to_json": """
        Output the current sub-object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.TextPart.x": """float: the abscissa of the anchor point of the text sub-object, the default value is 0""",

    "iobjectspy._jsuperpy.data.geo.TextPart.y": """float: the vertical coordinate of the anchor point of the text sub-object, the default value is 0""",

    "iobjectspy._jsuperpy.data.geo.TextStyle": """
    The text style class. Used to set the style of: py:class:`GeoText` class object
    """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.alignment": """TextAlignment: The alignment of the text.""",

    "iobjectspy._jsuperpy.data.geo.TextStyle.back_color": """tuple: the background color of the text, the default color is black""",

    "iobjectspy._jsuperpy.data.geo.TextStyle.border_spacing_width": """int: Return the distance between the edge of the text background rectangle and the edge of the text, in pixels """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.clone": """
        Copy object

        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.font_height": """float: The height of the text font. When the size is fixed, the unit is 1 mm, otherwise the geographic coordinate unit is used. The default value is 6. """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.font_name": """str: Return the name of the text font. If a certain font is specified for the text layer in the map under the Windows platform, and the map data needs to be in Linux Application under the platform , then please make sure you
        the same font also exists under the Linux platform, otherwise, the font display effect of the text layer will be problematic. The default value of the name of the text font is "Times New Roman". """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.font_scale": """float: the scale of the annotation font""",

    "iobjectspy._jsuperpy.data.geo.TextStyle.font_width": """float: The width of the text. The width of the font is based on English characters, because one Chinese character is equivalent to two English characters. The unit is 1 when the size is fixed Millimeters, otherwise use geographic coordinate units.""",

    "iobjectspy._jsuperpy.data.geo.TextStyle.fore_color": """tuple: The foreground color of the text, the default color is black. """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.from_dict": """
        Read text style information from dict

        :param dict values: a dict containing text style information
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.from_json": """
        Construct TextStyle object from json string

        :param str value:
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.is_back_opaque": """bool: Whether the text background is opaque, True means the text background is opaque. The default opaque """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.is_bold": """bool: Return whether the text is bold, True means bold """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.is_italic": """bool: Whether the text is italicized, True means italicized """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.is_outline": """bool: Return whether to display the background of the text in an outline way""",

    "iobjectspy._jsuperpy.data.geo.TextStyle.is_shadow": """bool: Whether the text has a shadow. True means to add a shadow to the text """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.is_size_fixed": """bool : .false text size is fixed, the table shows the size of the text is not fixed to the text """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.is_strikeout": """bool: Whether the text font should be strikethrough. True means strikethrough.""",

    "iobjectspy._jsuperpy.data.geo.TextStyle.is_underline": """bool: Whether the text font should be underlined. True means underline.""",

    "iobjectspy._jsuperpy.data.geo.TextStyle.italic_angle": """float: Return the font tilt angle, between positive and negative degrees, in degrees, accurate to 0.1 degrees. When the tilt angle is 0 degrees, it is the system default The font slant style.
        Positive and negative degrees refer to the vertical axis as the starting zero degree line, the left side of the vertical axis is positive, and the right side is negative. The maximum allowable angle is 60, and the minimum is -60. More than 60 will be treated as 60, and less than -60 will be treated as -60. """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.make_from_dict": """
        Read text style information from dict to construct TextStyle

        :param dict values: a dict containing text style information
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.opaque_rate": """int: Set the opaqueness of the annotation text. The range of opacity is 0-100. """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.outline_width": """float: The width of the text outline, the unit of the value is: pixel, the value range is any integer from 0 to 5.""",

    "iobjectspy._jsuperpy.data.geo.TextStyle.rotation": """float: The angle of text rotation. The counterclockwise direction is the positive direction, and the unit is degree. """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_alignment": """
        Set the alignment of the text

        :param value: the alignment of the text
        :type value: TextAlignment or str
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_back_color": """
        Set the background color of the text.

        :param value: background color of the text
        :type value: int or tuple
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_back_opaque": """
        Set whether the text background is opaque, True means the text background is opaque

        :param bool value: Whether the text background is opaque
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_bold": """
        Set whether the text is bold, True means bold

        :param bool value: whether the text is bold
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_border_spacing_width": """
        Set the distance between the edge of the text background rectangle and the edge of the text, in pixels.

        :param int value:
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_font_height": """
        Set the height of the text font. When the size is fixed, the unit is 1 mm, otherwise the geographic coordinate unit is used.

        :param float value: the height of the text font
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_font_name": """
        Set the name of the text font. If a certain font is specified for the text layer in the map under the Windows platform, and the map data needs to be applied under the Linux platform, please make sure
        the same font exists on your Linux platform, otherwise, the font display effect of the text layer will be problematic.

        :param str value: The name of the text font. The default value of the name of the text font is "Times New Roman".
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_font_scale": """
        Set the zoom ratio of the annotation font

        :param float value: The zoom ratio of the annotation font
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_font_width": """
        Set the width of the text. The width of the font is based on English characters, because one Chinese character is equivalent to two English characters. When the size is fixed, the unit is 1 mm, otherwise the geographic coordinate unit is used.

        :param float value: the width of the text
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_fore_color": """
        Set the foreground color of the text

        :param value: the foreground color of the text
        :type value: int or tuple
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_italic": """
        Set whether the text is in italics, true means italics.

        :param bool value: whether the text is in italics
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_italic_angle": """
        Set the font tilt angle, between positive and negative degrees, in degrees, accurate to 0.1 degrees. When the tilt angle is 0 degrees, it is the default font tilt style of the system.
        Positive and negative degrees refer to the vertical axis as the starting zero degree line, the left side of the vertical axis is positive, and the right side is negative. The maximum allowable angle is 60, and the minimum is -60. More than 60 will be treated as 60, and less than -60 will be treated as -60.

        :param float value: The tilt angle of the font, between positive and negative degrees, in degrees, accurate to 0.1 degrees
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_opaque_rate": """
        Set the opacity of the annotation text. The range of opacity is 0-100.

        :param int value: The opacity of the annotation text
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_outline": """
        Set whether to display the background of the text in outline. false, which means that the background of the text is not displayed as an outline.

        :param bool value: Whether to display the background of the text in an outline way
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_outline_width": """
        Set the width of the text outline, the unit of the value is pixels, the value range is any integer from 0 to 5, where a value of 0 means no outline. Must pass method: py:meth:`is_outline` as
        True, the width setting of the text outline is valid.

        :param int value: The width of the text outline, the unit of the value is: pixel, the value range is any integer from 0 to 5, where a value of 0 means no outline.
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_rotation": """
        Set the angle of text rotation. The counterclockwise direction is the positive direction and the unit is degree.

        :param float value: the angle of text rotation
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_shadow": """
        Set whether the text has a shadow. True means to add shadow to the text

        :param bool value: whether the text has a shadow
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_size_fixed": """
        Set whether the text size is fixed. False, indicating that the text is of non-fixed size.

        :param bool value: Whether the text size is fixed. False, indicating that the text is of non-fixed size.
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_strikeout": """
        Set whether to add strikethrough in text font.

        :param bool value: Whether to add strikethrough in text font.
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_string_alignment": """
        Set the typesetting of the text, you can set left, right, center, and both ends of multi-line text

        :param value: How to format the text
        :type value: StringAlignment
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_underline": """
        Set whether the text font is underlined. True means underline

        :param bool value: Whether the text font is underlined. True means underline
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.set_weight": """
        Set the point size of the text font to indicate the specific value of bold. The value range is a whole hundred from 0 to 900. For example, 400 means normal display, 700 means bold, please refer to Microsoft MSDN help about
        Introduction to the LOGFONT class

        :param int value: The point size of the text font.
        :return: self
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.string_alignment": """StringAlignment: How the text is formatted""",

    "iobjectspy._jsuperpy.data.geo.TextStyle.to_dict": """
        Output current object as dict

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.to_json": """
        Output as json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.geo.TextStyle.weight": """float: The point size of the text font, representing the specific value of bold. The value range is a whole hundred from 0-900, such as 400 Normal display, 700 is in bold, please refer to Microsoft MSDN help
        An introduction to the LOGFONT class. The default value is 400""",

    "iobjectspy._jsuperpy.data.prj.weight": """""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter": """
    Projection conversion reference system conversion parameter class, usually including translation, rotation and scale factor.

    When performing projection conversion, if the geographic coordinate systems of the source and target projections are different, a reference system conversion is required. SuperMap provides six commonly used reference system conversion methods, see CoordSysTransMethod
    for more details. Different reference system conversion methods need to specify different conversion parameters:

    -Three-parameter conversion method (GeocentricTranslation), Molodensky conversion method (Molodensky), simplified Molodensky conversion method (MolodenskyAbridged) are the
      conversion methods with low accuracy, which can generally be used when the data accuracy requirement is not very high. These three conversion methods require three translation conversion parameters: X axis coordinate offset (set_translate_x), Y axis
      coordinate offset (set_translate_y) and Z axis coordinate offset (set_translate_z).
    -Position vector method (PositionVector), seven-parameter conversion method based on the center of the earth (CoordinateFrame), Bursa method (BursaWolf) are several conversion methods with higher precision. Need seven
      parameters for adjustment and conversion, including the three translation conversion parameters mentioned above, but also three rotation conversion parameters (X-axis rotation angle (set_rotate_x), Y-axis rotation angle (set_rotate_y), 
      Z axis rotation angle (set_rotate_z)), and projection scale difference parameter (set_scale_difference).

    """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.clone": """
        Copy object

        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.from_xml": """
        Construct a CoordSysTransParameter object based on the XML string, and return True successfully

        :param str xml:
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.rotate_x": """float: X axis rotation angle""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.rotate_y": """float: Y-axis rotation angle""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.rotate_z": """float: Z-axis rotation angle""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.rotation_origin_x": """float: X coordinate of the origin of rotation""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.rotation_origin_y": """float: the amount of Y coordinate of the origin of rotation""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.rotation_origin_z": """float: the amount of Z coordinate of the origin of rotation""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.scale_difference": """float: Projection scale difference. The unit is one part per million. It is used to convert between different geodetic reference systems""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.set_rotate_x": """
        Set the rotation angle of the X axis. Used for conversion between different geodetic reference systems. The unit is radians.

        :param float value: Rotation angle of X axis
        :return: self
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.set_rotate_y": """
        Set the rotation angle of the Y axis. Used for conversion between different geodetic reference systems. The unit is radians.

        :param float value: Y-axis rotation angle
        :return: self
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.set_rotate_z": """
        Set the rotation angle of the Z axis. Used for conversion between different geodetic reference systems. The unit is radians.

        :param float value: Rotation angle of Z axis
        :return: self
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.set_rotation_origin_x": """
        Set the amount of X coordinate of the origin of rotation

        :param float value: The amount of X coordinate of the origin of rotation
        :return: self
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.set_rotation_origin_y": """
        Set the amount of Y coordinate of the origin of rotation

        :param float value: The amount of Y coordinate of the origin of rotation
        :return: self
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.set_rotation_origin_z": """
        Set the amount of Z coordinate of the rotation origin

        :param float value: the amount of Z coordinate of the origin of rotation
        :return: self
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.set_scale_difference": """
        Set the projection scale difference. The unit is one part per million. Used for conversion between different geodetic reference systems

        :param float value: projection scale difference
        :return: self
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.set_translate_x": """
        Set the coordinate offset of the X axis. The unit is meters

        :param float value: X axis coordinate offset
        :return: self
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.set_translate_y": """
        Set the coordinate offset of the Y axis. The unit is meters

        :param float value: Y-axis coordinate offset
        :return: self
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.set_translate_z": """
        Set the coordinate offset of the Z axis. The unit is meters

        :param float value: coordinate offset of Z axis
        :return: self
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.to_xml": """
        Output the CoordSysTransParameter object as an XML string.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.translate_x": """float: Return the coordinate offset of the X axis. The unit is meters""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.translate_y": """float: Return the coordinate offset of the Y axis. The unit is meters""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTransParameter.translate_z": """float: Return the coordinate offset of the Z axis. The unit is meters""",

    "iobjectspy._jsuperpy.data.prj.CoordSysTranslator": """
    Projection conversion class. Mainly used for conversion between projection coordinates and projection coordinate systems.

    Projection transformation generally has three working methods: the transformation between geographic (latitude and longitude) coordinates and projection coordinates uses the forward() method, the transformation between projection coordinates and geographic (latitude and longitude) coordinates uses the inverse() method,
    the conversion between the two projected coordinate systems uses the convert() method.

    Note: The current version does not support the projection conversion of raster data. That is, in the same datasource, the projection transformation only transforms the vector data part. Geographic coordinate system (Geographic coordinate system) is also called geographic
    coordinate system, which uses latitude and longitude as the storage unit of the map. Obviously, the geographic coordinate system is a spherical coordinate system. If the digital information on the earth is stored in a spherical coordinate system, it is necessary to have such an ellipsoid with
    the following features: It can be quantified and calculated, with Semimajor Axis, Semiminor Axis, Flattening, prime meridian and datum.

    The projection coordinate system is essentially a plane coordinate system, and the map unit is usually meters. The process of converting spherical coordinates into plane coordinates is called projection. So every
    projected coordinate systems must have geographic coordinate system (Geographic Coordinate System) parameters. Therefore, there is a conversion between projection coordinates and a conversion between projection coordinate systems.

    When performing projection conversion, the text object (GeoText) has also been projected and converted, the character height and angle of the text object will be converted accordingly. If the user does not need such changes, the character height and angle of the converted text object need to be corrected.

    """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTranslator.convert": """
        The input data is projected and transformed according to the source projection coordinate system and the target projection coordinate system. According to whether valid result datasource information has been setted, you can directly modify the source data or store the converted result data in the result datasource.

        :param source_data: The data to be converted. Directly convert dataset, geometric objects, two-dimensional point sequences and geometric object sequences.
        :type source_data: DatasetVector or Geometry or list[Point2D] or list[Geometry]
        :param PrjCoordSys target_prj_coordsys: target projected coordinate system object.
        :param CoordSysTransParameter coordsys_trans_parameter:
        :type coordsys_trans_parameter: Projected coordinate system transform0a tion parameter. Including the coordinate translation, rotation angle, and projection scale difference. For details, please refer to the :py:class:`CoordSysTransParameter` class.
        :param coord_sys_trans_method: Method of projection transformation. For details, see: py:class:`CoordSysTransMethod`. When performing projection conversion, if the geographic coordinate system of the source projection and the target projection are the same, the setting of this parameter has no effect.
        :type coord_sys_trans_method: CoordSysTransMethod
        :param PrjCoordSys source_prj_coordsys: Source projected coordinate system object. When the converted data is a dataset object, this parameter is invalid and the projection coordinate system information of the dataset will be used.
        :param out_data: result datasource. When the result datasource is valid, the converted result will be stored in the new result dataset, otherwise the point coordinates of the original data will be directly modified.
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param out_dataset_name: The name of the result dataset. Only works when out_datasource is valid
        :type out_dataset_name: str
        :return: According to whether the result datasource object is set:

                -If the result datasource object is set and the conversion is successful, the converted result will be written to the result dataset and the result dataset name or result dataset object will be returned. If the conversion fails, None is returned.
                -If the result datasource object is not set and the conversion is successful, it will directly modify the point coordinates of the input source data and return True, otherwise return False.

        :rtype: DatasetVector or str bool
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTranslator.forward": """
        In the same geographic coordinate system, this method is used to convert the two-dimensional point object in the specified Point2D list from geographic coordinates to projection coordinates

        :param data: a list of 2D points to be converted
        :type data: list[Point2D] or tuple[Point2D]
        :param prj_coordsys: the projected coordinate system where the two-dimensional point object is located
        :type prj_coordsys: PrjCoordSys
        :param out_data: The result datasource object, you can choose to save the converted points to the datasource. If it is empty, it will return a list of points obtained after conversion
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param out_dataset_name: the name of the result dataset, it will work only when out_datasource is valid
        :type out_dataset_name: str
        :return: Return None if the conversion fails. If the conversion is successful, if a valid out_datasource is set, the result dataset or the name of the dataset will be returned; otherwise, the list of points obtained after the conversion will be returned.
        :rtype: DatasetVector or str or list[Point2D]
        """,

    "iobjectspy._jsuperpy.data.prj.CoordSysTranslator.inverse": """
        In the same projected coordinate system, this method is used to convert the two-dimensional point objects in the specified Point2D list from projected coordinates to geographic coordinates.

        :param data: a list of 2D points to be converted
        :type data: list[Point2D] or tuple[Point2D]
        :param prj_coordsys: the projected coordinate system where the two-dimensional point object is located
        :type prj_coordsys: PrjCoordSys
        :param out_data: The result datasource object, you can choose to save the converted points to the datasource. If it is empty, it will return a list of points obtained after conversion
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param out_dataset_name: the name of the result dataset, it will work only when out_datasource is valid
        :type out_dataset_name: str
        :return: Return None if the conversion fails. If the conversion is successful, if a valid out_datasource is set, the result dataset or the name of the dataset will be returned; otherwise, the list of points after the conversion will be returned.
        :rtype: DatasetVector or str or list[Point2D]
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys": """
    The geographic coordinate system class.

    The geographic coordinate system is composed of a geodetic reference system, a central meridian, and coordinate units. In the geographic coordinate system, the unit is generally expressed in degrees, but also in degrees, minutes and seconds. The east-west (horizontal direction) range is -180 degrees to 180
    degree. The north-south direction (vertical direction) ranges from -90 degrees to 90 degrees.

    Geographical coordinates are spherical coordinates that use latitude and longitude to indicate the location of ground points. In a spherical system, the circle intercepted by the intersection of the parallel plane of the equatorial plane and the ellipsoidal surface of the earth is called the circle of latitude, also called the line of latitude, which represents the east-west direction. 
    The circle that intersects the surface of the ellipsoid through the earth's axis of rotation is the meridian circle, also known as the longitude line, which indicates the north-south direction. These grids surrounding the earth are called latitude and longitude grids.

    The latitude and longitude lines are generally expressed in degrees (and also in degrees, minutes and seconds when necessary). Longitude refers to the dihedral angle formed by the meridian of a certain point on the ground and the prime meridian. The longitude of the prime meridian is defined as 0 degrees. 
    From prime meridian 0 to 180 degrees east is "east longitude", represented by "E"; Westward 0 to -180 degrees is the "West longitude", represented by the letter "W". Latitude refers to the connection between a point on the ground and the center of the earth's sphere The line-face angle formed by the line and the equatorial plane,
    the latitude of the equator is set at 0 degrees, from the equator to the north from 0 to 90 degrees is "north latitude", which is represented by the letter "N", and from 0 to -90 degrees to the south is "south latitude", which is represented by the letter "S".

    """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.clone": """
        Copy object

        :rtype: GeoCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.coord_unit": """
        Unit: Return the unit of the geographic coordinate system. The default value is DEGREE
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.from_xml": """
        Construct an object of geographic coordinate system class from the specified XML string, and return True successfully

        :param str xml: XML string
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.geo_datum": """
        GeoDatum: Return the object of the geodetic reference system
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.geo_prime_meridian": """
        GeoPrimeMeridian: Return the central meridian object
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.geo_spatial_ref_type": """
        GeoSpatialRefType: Return the type of spatial coordinate system.
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.name": """
        str: Return the name of the geographic coordinate system object
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.set_coord_unit": """
        Set the unit of the geographic coordinate system.

        :param unit: the unit of the geographic coordinate system
        :type unit: Unit or str
        :return: self
        :rtype: GeoCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.set_geo_datum": """
        Set the geodetic reference system object

        :param GeoDatum datum:
        :return: self
        :rtype: GeoCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.set_geo_prime_meridian": """
        Set the central meridian object

        :param GeoPrimeMeridian prime_meridian:
        :return: self
        :rtype: GeoCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.set_geo_spatial_ref_type": """
        Set the type of spatial coordinate system.

        :param spatial_ref_type: spatial coordinate system type
        :type spatial_ref_type: GeoSpatialRefType or str
        :return: self
        :rtype: GeoCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.set_name": """
        Set the name of the geographic coordinate system object

        :param str name: the name of the geographic coordinate system object
        :return: self
        :rtype: GeoCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.set_type": """
        Set geographic coordinate system type

        :param coord_type: geographic coordinate system type
        :type coord_type: GeoCoordSysType or str
        :return: self
        :rtype: GeoCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.to_xml": """
        Convert the object of the geographic coordinate system into a string in XML format.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.prj.GeoCoordSys.type": """
        GeoCoordSysType: Return the type of geographic coordinate system
        """,

    "iobjectspy._jsuperpy.data.prj.GeoDatum": """
    Geodetic reference system class.
    This class contains the parameters of the earth ellipsoid.
    The earth ellipsoid only describes the size and shape of the earth. In order to more accurately describe the specific location of the features on the earth, a geodetic reference system needs to be introduced. The geodetic reference system determines the position of the earth ellipsoid relative to the center of the earth's sphere, provides a frame of reference for the measurement of surface features, and determines the origin and direction of the latitude and longitude grid lines on the surface. The geodetic reference system takes the center of the earth ellipsoid as the origin. The earth ellipsoid of the geodetic reference system in a region is more or less offset from the true center of the earth, and the coordinates of the surface features are relative to the center of the ellipsoid. At present, WGS84 is widely used, which is used as the basic frame of geodetic survey. Different geodetic reference systems are suitable for different countries and regions, and one geodetic reference system is not suitable for all regions.
    """,

    "iobjectspy._jsuperpy.data.prj.GeoDatum.__init__": """
        Construct a geodetic reference system object

        :param datum_type: type of geodetic reference system
        :type datum_type: GeoDatumType or str
        """,

    "iobjectspy._jsuperpy.data.prj.GeoDatum.clone": """
        Copy object

        :rtype: GeoDatum
        """,

    "iobjectspy._jsuperpy.data.prj.GeoDatum.from_xml": """
        Construct a GeoDatum object based on the XML string, and return True if it succeeds.

        :param str xml:
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.prj.GeoDatum.geo_spheroid": """GeoSpheroid: Earth ellipsoid object""",

    "iobjectspy._jsuperpy.data.prj.GeoDatum.name": """str: the name of the geodetic reference system object """,

    "iobjectspy._jsuperpy.data.prj.GeoDatum.set_geo_spheroid": """
        Set the earth ellipsoid object. It can be set only when the geodetic reference system type is a custom type.
        People usually use a sphere or ellipsoid to describe the shape and size of the earth. Sometimes for the convenience of calculation, the earth can be regarded as a sphere, but more often it is regarded as an ellipsoid. Generally in the map scale
        when it is less than 1:1,000,000, suppose the shape of the earth is a sphere, because the difference between a sphere and an ellipsoid is almost indistinguishable at this scale; 
        At large scales with accuracy of 1:1,000,000 or more, an ellipsoid is needed to approach the earth. The ellipsoid is based on an ellipse, so two axes are used to express the size of the earth sphere, namely the major axis (equatorial radius) and the minor axis (polar radius).

        :param GeoSpheroid geo_spheroid: Earth ellipsoid object
        :return: self
        :rtype: GeoSpheroid
        """,

    "iobjectspy._jsuperpy.data.prj.GeoDatum.set_name": """
        Set the name of the geodetic reference system object

        :param str name: the name of the geodetic reference system object
        :return: self
        :rtype: GeoDatum
        """,

    "iobjectspy._jsuperpy.data.prj.GeoDatum.set_type": """
        Set the type of geodetic reference system.
        When the geodetic reference system is customized, the user needs to specify the ellipsoid parameters separately; other values are predefined by the system, and the user does not need to specify the ellipsoid parameters. See: py:class:`GeoDatumType`.

        :param datum_type: type of geodetic reference system
        :type datum_type: GeoDatumType or str
        :return: self
        :rtype: GeoDatum
        """,

    "iobjectspy._jsuperpy.data.prj.GeoDatum.to_xml": """
        Convert the object of the geodetic reference system into a string in XML format

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.prj.GeoDatum.type": """GeoDatumType: Type of geodetic reference system""",

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian": """
    The central meridian class.
    This object is mainly used in the geographic coordinate system. The geographic coordinate system consists of three parts: the central meridian, the reference system or Datum and the angle unit.

    """,

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian.__init__": """
        Construct a central meridian object

        :param meridian_type: central meridian type
        :type meridian_type: GeoPrimeMeridianType or str
        """,

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian.clone": """
        Copy object

        :rtype: GeoPrimeMeridian
        """,

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian.from_xml": """
        The specified XML string constructs a GeoPrimeMeridian object

        :param str xml: XML string
        :return:
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian.longitude_value": """float : warp central value of a single bit of the""",

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian.name": """str: The name of the central meridian object """,

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian.set_longitude_value": """
        Set the central meridian value in degrees

        :param float value: Central meridian value in degrees
        :return: self
        :rtype: GeoPrimeMeridian
        """,

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian.set_name": """
        Set the name of the central meridian object

        :param str name: the name of the central meridian object
        :return: self
        :rtype: GeoPrimeMeridian
        """,

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian.set_type": """
        Set the central warp type

        :param meridian_type: central meridian type
        :type meridian_type: GeoPrimeMeridianType or str
        :return: self
        :rtype: GeoPrimeMeridian
        """,

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian.to_xml": """
        Return an XML string representing a GeoPrimeMeridian object

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.prj.GeoPrimeMeridian.type": """GeoPrimeMeridianType: Central meridian type""",

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid": """
    The parameter class of the earth ellipsoid. This category is mainly used to describe the long radius and oblateness of the earth.

    People usually use a sphere or ellipsoid to describe the shape and size of the earth. Sometimes for the convenience of calculation, the earth can be regarded as a sphere, but more often it is regarded as an ellipsoid. In general, when the scale of the map is
    less than 1:1,000,000, assuming that the earth is a sphere shape, since in this case the difference between the ball and the dimensions of the ellipsoid not almost impossible to distinguish; in 1: 1,000,000 for greater accuracy even large scale,
    you need to use an ellipsoid to approach the earth. The ellipsoid is based on an ellipse, so two axes are used to express the size of the earth sphere, namely the major axis (equatorial radius) and the minor axis (polar radius).

    Because the same projection method, different ellipsoid parameters, and the same data projection results may be very different, it is necessary to select the appropriate ellipsoid parameters. Earth ellipsoid parameters used in different ages, countries and regions
    may be different. At present, China mainly uses Krasovsky ellipsoid parameters; North American continent and Britain and France mainly use Clark ellipsoid parameters.
    """,

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.__init__": """
        Constructs the parameter class object of the earth ellipsoid

        :param spheroid_type: the type of the earth spheroid parameter object
        :type spheroid_type: GeoSpheroidType or str
        """,

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.axis": """float: Return the long radius of the earth ellipsoid""",

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.clone": """
        Copy object

        :rtype: GeoSpheroid
        """,

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.flatten": """float: Return the flatness of the earth ellipsoid""",

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.from_xml": """
        Construct an object of the earth ellipsoid parameter class from the specified XML string.

        :param str xml: XML string
        :return: return True if the build is successful, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.name": """str: the name of the earth ellipsoid object""",

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.set_axis": """
        Set the major radius of the earth ellipsoid. The long radius of the earth ellipsoid is also called the earth's equatorial radius, and the polar radius, first eccentricity, second eccentricity and so on of the earth ellipsoid can be obtained through it and the flatness of the earth. Only when
        the type of the earth ellipsoid is a custom type, the long radius can be set.

        :param float value: the long radius of the earth ellipsoid
        :return: self
        :rtype: GeoSpheroid
        """,

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.set_flatten": """
        Set the oblateness of the earth ellipsoid. The oblateness can be set only when the type of the earth ellipsoid is a custom type. The flatness of the earth ellipsoid reflects the roundness of the earth ellipsoid, Generally, it is the ratio of the difference
        between the length and length of the semi-axis of the earth..

        :param float value:
        :return: self
        :rtype: GeoSpheroid
        """,

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.set_name": """
        Set the name of the earth ellipsoid object

        :param str name: the name of the earth ellipsoid object
        :return: self
        :rtype: GeoSpheroid
        """,

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.set_type": """
        Set the type of the earth ellipsoid. When the earth ellipsoid type is a custom type, the user needs to additionally specify the major radius and oblateness of the ellipsoid; the remaining values are predefined by the system, user does not need to specify the major radius and oblateness.
        See also the earth ellipsoid:py:class:`GeoSpheroidType` enumeration class.

        :param spheroid_type:
        :type spheroid_type: GeoSpheroidType or str
        :return: self
        :rtype: GeoSpheroid
        """,

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.to_xml": """
        Convert the object of the earth ellipsoid parameter class to a string in XML format.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.prj.GeoSpheroid.type": """GeoSpheroidType: Return the type of the earth ellipsoid""",

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys": """
        The projected coordinate system class. The projection coordinate system is composed of map projection method, projection parameters, coordinate unit and geographic coordinate system. SuperMap Objects Java provides many predefined projection systems. Users can
        use it directly, in addition, users can customize their own projection system. The projected coordinate system is defined on a two-dimensional plane. Unlike the geographic coordinate system, which uses latitude and longitude to locate ground points, the projected coordinate system uses X and Y coordinates to locate.
        Each projected coordinate system is based on a geographic coordinate system.
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.__init__": """
        Construct projected coordinate system objects

        :param prj_type: Projected coordinate system type
        :type prj_type: PrjCoordSysType or str
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.clone": """
        Copy an object

        :rtype: PrjCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.coord_unit": """
        Unit: Return the coordinate unit of the projection system. The coordinate unit of the projection system can be different from the distance unit (distance_unit). For example, the coordinate unit under the latitude and longitude coordinates is degrees, and the distance unit can be meters,
        Kilometers, etc.; even if they are ordinary plane coordinates or projected coordinates, these two units can also be different.
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.distance_unit": """Unit: Distance (length) unit""",

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.from_epsg_code": """
        Construct projected coordinate system objects from EPSG coding

        :param int code: EPSG code
        :rtype: PrjCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.from_file": """
        Read projection coordinate information from xml file or prj file

        :param str file_path: file path
        :return: Return True if the build is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.from_wkt": """
        Construct projected coordinate system objects from WKT strings

        :param str wkt: WKT string
        :rtype: PrjCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.from_xml": """
        Read projection information from xml string

        :param str xml: xml string
        :return: Return True if the construction is successful, otherwise Return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.geo_coordsys": """GeoCoordSys: the geographic coordinate system object of the projected coordinate system""",

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.make": """
        Construct PrjCoordSys object, support constructing from epsg code, PrjCoordSysType type, xml or wkt, or projection information file. Note that if you pass in an integer value,
        It must be epsg encoding and cannot be an integer value of type PrjCoordSysType.

        :param prj: projection information
        :type prj: int or str or PrjCoordSysType
        :return: Projection object
        :rtype: PrjCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.name": """str: the name of the projected coordinate system object """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.prj_parameter": """PrjParameter: the projection parameter of the projected coordinate system object""",

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.projection": """Projection: Projection method of the projection coordinate system. Projection methods such as equiangular conic projection, equidistant azimuth projection, etc. """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.set_geo_coordsys": """
        Set the geographic coordinate system object of the projected coordinate system. Each projection system depends on a geographic coordinate system. This method is only valid when the coordinate system type is a custom projection coordinate system and a custom geographic coordinate system.

        :param GeoCoordSys geo_coordsys:
        :return: self
        :rtype: PrjCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.set_name": """Set the name of the projected coordinate system object

        :param str name: the name of the projected coordinate system object
        :return: self
        :rtype: PrjCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.set_prj_parameter": """
        Set the projection parameters of the projection coordinate system object.

        :param PrjParameter parameter: the projection parameter of the projection coordinate system object
        :return: self
        :rtype: PrjCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.set_projection": """
        Set the projection method of the projection coordinate system. Projection methods such as equiangular conic projection, equidistant azimuth projection and so on.

        :param Projection projection:
        :return: self
        :rtype: PrjCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.set_type": """
        Set the type of projected coordinate system

        :param prj_type: Projected coordinate system type
        :type prj_type: PrjCoordSysType or str
        :return: self
        :rtype: PrjCoordSys
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.to_epsg_code": """
        Return the EPSG code of the current object

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.to_file": """Output projection coordinate information to a file. Only supports output as xml file.

        :param str file_path: The full path of the XML file.
        :return: Return True if the export is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.to_wkt": """
        Output current projection information as WKT string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.to_xml": """
        Convert the object of the projected coordinate system class to a string in XML format.

        :return: XML string representing the object of the projected coordinate system class
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.prj.PrjCoordSys.type": """PrjCoordSysType: Projected coordinate system type""",

    "iobjectspy._jsuperpy.data.prj.PrjParameter": """
    The map projection parameter class. Map projection parameters, such as the central longitude, the origin latitude, the first and second latitudes of the double standard latitude, etc.
    """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.azimuth": """float: azimuth angle""",

    "iobjectspy._jsuperpy.data.prj.PrjParameter.central_meridian": """float: central meridian angle value. Unit: degree. The value range is -180 degrees to 180 degrees""",

    "iobjectspy._jsuperpy.data.prj.PrjParameter.central_parallel": """float: Return the latitude value corresponding to the origin of the coordinate. Unit: degree. The value range is -90 degrees to 90 degrees. In conic projection, the projection area is usually the most The latitude value of the southern end.""",

    "iobjectspy._jsuperpy.data.prj.PrjParameter.clone": """
        Copy object

        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.false_easting": """float: coordinate horizontal offset. Unit: meter""",

    "iobjectspy._jsuperpy.data.prj.PrjParameter.false_northing": """float: coordinate vertical offset""",

    "iobjectspy._jsuperpy.data.prj.PrjParameter.first_point_longitude": """float: Return the longitude of the first point. Used for azimuth projection or oblique projection. Unit: degree """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.from_xml": """
        Construct a PrjParameter object based on the incoming XML string

        :param str xml:
        :return: return True if the build is successful, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.rectified_angle": """float: Return the corrected angle in the parameter of the ProjectionType.RectifiedSkewedOrthomorphic, in radians """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.scale_factor": """float: Return the scale factor of the projection conversion. Used to reduce the error of the projection transformation. The values of Mercator, Gauss-KrÃ¼ger and UTM projections are normal Is 0.9996""",

    "iobjectspy._jsuperpy.data.prj.PrjParameter.second_point_longitude": """float: Return the longitude of the second point. Used for azimuth projection or oblique projection. Unit: degree """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_azimuth": """
        Set the azimuth angle. Mainly used for oblique axis projection. Unit: Degree

        :param float value: azimuth
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_central_meridian": """
        Set the central meridian angle value. Unit: degree. The value range is -180 degrees to 180 degrees.

        :param float value: The angle value of the central meridian. Unit: Degree
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_central_parallel": """
        Set the latitude value corresponding to the origin of the coordinate. Unit: degree. The value range is -90 degrees to 90 degrees. In conic projection, it is usually the latitude value of the southernmost point of the projection area.

        :param float value: The latitude value corresponding to the origin of the coordinate
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_false_easting": """
        Set the horizontal offset of the coordinate. Unit: m. The parameter value of this method is an offset added to avoid negative values of the system coordinates . Usually used in Gauss-KrÃ¼ger, UTM and Mercator projections. The general value is 500,000 meters.

        :param float value: The horizontal offset of the coordinate. Unit: m.
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_false_northing": """
        Set the vertical offset of the coordinate. Unit: m. The parameter value of this method is an offset added to avoid negative values of the system coordinates. Usually used in Gauss-KrÃ¼ger, UTM and Mercator projections. The general value is 1,000,000 meters.

        :param float value: The vertical offset of the coordinate. Unit: m
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_first_point_longitude": """
        Set the longitude of the first point. Used for azimuth projection or oblique projection. Unit: Degree

        :param float value: The longitude of the first point. Unit: Degree
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_rectified_angle": """
        Set the corrected angle in the parameter of ProjectionType.RectifiedSkewedOrthomorphic, in radians.

        :param float value: The corrected angle in the parameter of the ProjectionType.RectifiedSkewedOrthomorphic, the unit is radians
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_scale_factor": """
        Set the scale factor for projection conversion. Used to reduce the error of projection transformation. The values of Mercator, Gauss-KrÃ¼ger, and UTM projections are generally 0.9996.

        :param float value: the scale factor of the projection conversion
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_second_point_longitude": """
        Set the longitude of the second point. Used for azimuth projection or oblique projection. Unit: degree.

        :param float value: The longitude of the second point. Unit: Degree
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_standard_parallel1": """
        Set the latitude value of the first standard parallel. Unit: degree. Mainly used in conic projection. If it is a single standard latitude, the latitude values of the first standard latitude and the second standard latitude are the same.

        :param float value: The latitude value of the first standard parallel
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.set_standard_parallel2": """
        Set the latitude value of the second standard parallel. Unit: degree. Mainly used in conic projection. If it is a single standard latitude, the latitude value of the first standard latitude is the same as that of the second standard latitude; if it is a double standard latitude, then
        its value cannot be the same as the value of the first standard parallel.

        :param float value: The latitude value of the second standard parallel. Unit: degree.
        :return: self
        :rtype: PrjParameter
        """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.standard_parallel1": """float: Return the latitude value of the first standard parallel. Unit: degree. Mainly used in conic projection. If it is a single standard parallel, then the first standard parallel Same as the latitude value of the second standard parallel.""",

    "iobjectspy._jsuperpy.data.prj.PrjParameter.standard_parallel2": """float: Return the latitude value of the second standard parallel. Unit: degree. Mainly used in conic projection. If it is a single standard parallel, then the first standard parallel Same as the latitude value of the second standard latitude; If it is a double standard parallel, 
        its value cannot be the same as that of the first standard parallel. """,

    "iobjectspy._jsuperpy.data.prj.PrjParameter.to_xml": """
        Return the XML string representation of the PrjParameter object

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.prj.Projection": """
        The projection coordinate system map projection class. Map projection is the process of converting spherical coordinates into plane coordinates.

        Generally speaking, map projection can be divided into equal-angle projection, equal-distance projection and equal-area projection according to the deformation properties, which are suitable for different purposes. If it is a nautical chart, the isometric projection is very common. And then there are other kinds of deformation between them, 
        which is generally used for reference purposes and as instructional maps. Map projections can also be divided into two categories according to their composition methods, namely geometric projections and non-geometric projections. Geometric projection is the projection of a network of longitude and latitude lines on an ellipsoid onto
        a geometric surface, and then expand the geometric surface into a plane. it includes azimuth projection, cylindrical projection and conic projection; non-geometric projection does not rely on geometric surfaceã€‚ According to some conditions, the functional relationship of point to point between sphere and plane can be determined by mathematical analysis, 
        including pseudo-azimuth projection, pseudo-cylindrical projection, pseudo-conic projection and poly-conic projection. For more information about the projection method type, please refer to: py:class:`ProjectionType`
        """,

    "iobjectspy._jsuperpy.data.prj.Projection.__init__": """

        :param projection_type:
        :type projection_type: ProjectionType or str
        """,

    "iobjectspy._jsuperpy.data.prj.Projection.clone": """
        Copy object

        :rtype: Projection
        """,

    "iobjectspy._jsuperpy.data.prj.Projection.from_xml": """
        Construct a projection coordinate method object based on the XML string, and return True if it succeeds.

        :param str xml: the specified XML string
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.prj.Projection.name": """str: the name of the projection method object """,

    "iobjectspy._jsuperpy.data.prj.Projection.set_name": """
        Name of your custom projection setting

        :param str name: the name of the custom projection
        :return: self
        :rtype: Projection
        """,

    "iobjectspy._jsuperpy.data.prj.Projection.set_type": """
        Set the type of projection method of the projection coordinate system.

        :param projection_type: the type of projection method of the projection coordinate system
        :type projection_type: ProjectionType or str
        :return: self
        :rtype: Projection
        """,

    "iobjectspy._jsuperpy.data.prj.Projection.to_xml": """
        Return the XML string representation of the projection method object.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.prj.Projection.type": """ProjectionType: the type of projection method of the projection coordinate system""",

    "iobjectspy._jsuperpy.data.op.type": """""",

    "iobjectspy._jsuperpy.data.op.GeometriesRelation": """
    The difference between the geometric object relationship judgment class and the spatial query is that this class is used for the judgment of geometric objects, not the dataset, and the realization principle is the same as the spatial query.

    The following sample code shows the function of querying points by region. By inserting multiple regions (regions) into GeometriesRelation, you can determine which region object contains each point object.
    Then, all point objects contained in each area object can be obtained. When a large number of point objects need to be processed, this method has better performance::

    >>> geos_relation = GeometriesRelation()
    >>> for index in range(len(regions))
    >>> geos_relation.insert(regions[index], index)
    >>> results = dict()
    >>> for point in points:
    >>> region_values = geos_relation.matches(point,'Contain')
    >>> for region_value in region_values:
    >>> region = regions[region_value]
    >>> if region in results:
    >>> results[region].append(point)
    >>> else:
    >>> results[region] = [point]
    >>> del geos_relation
    """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.__init__": """

        :param float tolerance: node tolerance
        :param gridding_level: The gridding level of the area object.
        :type gridding_level: GriddingLevel or str
        """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.get_bounds": """
        Get the geographic range of all inserted geometric objects in GeometriesRelation

        :rtype: Rectangle
        """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.get_gridding": """
        Get the grid level of the area object. Do not grid grid by default

        :rtype: GriddingLevel
        """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.get_sources_count": """
        Get the number of geometric objects inserted in GeometriesRelation

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.get_tolerance": """
        Get node tolerance

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.insert": """
        Insert a geometric object to be matched. The matched object is a query object in the spatial query mode. For example, to query a polygon containing point object, you need to insert a polygon object to
        In GeometriesRelation, then match in turn to obtain the surface objects that satisfy the containment relationship with the point objects.

        :param data: The geometric object to be matched must be a point, line or surface, or point, line, and surface record set or dataset
        :type data: Geometry or Point2D or Rectangle, Recordset, DatasetVector
        :param value: The matched value is a unique value and must be greater than or equal to 0, such as the ID of a geometric object. If the incoming is Recordset or DatasetVector,
                      Then value is the name of a field with a unique integer value representing the object and the value is greater than or equal to 0. If it is None, the SmID value of the object is used.
        :type value: int
        :return: Return True if the insert is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.intersect_extents": """
        Return all objects that intersect the specified rectangular range, that is, the rectangular range of the object intersects.

        :param rc: the specified rectangle range
        :type rc: Rectangle
        :return: the value of the object that intersects the specified rectangle
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.is_match": """
        Determine whether the object satisfies the spatial relationship with the specified object

        :param data: the object to be matched
        :type data: Geometry or Point2D or Rectangle
        :param src_value: the value of the matched object
        :type src_value: int
        :param mode: matching spatial query mode
        :type mode: SpatialQueryMode or str
        :return: Return True if the specified object and the specified object satisfy the spatial relationship, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.matches": """
        Find out the values of all matched objects that satisfy the spatial relationship with the matched object.

        :param data: match space object
        :type data: Geometry or Point2D or Rectangle
        :param mode: matching spatial query mode
        :type mode: SpatialQueryMode or str
        :param excludes: The excluded value, that is, it does not participate in the matching operation
        :type excludes: list[int]
        :return: the value of the matched object
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.set_gridding": """
        Set the gridding level of the area object. By default, the grid of area objects is not done.

        :param gridding_level: gridding level
        :type gridding_level: GriddingLevel or str
        :return: self
        :rtype: GeometriesRelation
        """,

    "iobjectspy._jsuperpy.data.op.GeometriesRelation.set_tolerance": """
        Set node tolerance

        :param float tolerance: node tolerance
        :return: self
        :rtype: GeometriesRelation
        """,

    "iobjectspy._jsuperpy.data.op.aggregate_points_geo": """
    Perform density clustering on the point set. Density clustering algorithm introduction reference: py:meth:`iobjectspy.aggregate_points`

    :param points: set of input points
    :type points: list[Point2D] or tuple[Point2D]
    :param int min_pile_point_count: The threshold of the number of density cluster points, which must be greater than or equal to 2. The larger the threshold value, the harsher the conditions for clustering into a cluster. The recommended value is 4.
    :param float distance: The radius of density clustering.
    :param unit: The unit of the density cluster radius. If the spatial reference coordinate system prjCoordSys is invalid, this parameter is also invalid
    :type unit: Unit or str
    :param prj: The spatial reference coordinate system of the point collection
    :type prj: PrjCoordSys
    :param bool as_region: Whether to return the clustered region object
    :return: When as_region is False, return a list. Each value in the list represents the cluster category of the point object. The cluster category starts from 1, and 0 means invalid cluster.
             When as_region is True, the polygon object gathered by each cluster point will be returned
    :rtype: list[int] or list[GeoRegion]
    """,

    "iobjectspy._jsuperpy.data.op.can_contain": """
        Determine whether the searched geometric object contains the searched geometric object. It Return True if it contains.
        Note that if there is a containment relationship, then:

            * The intersection of the exterior of the searched geometric object and the interior of the searched geometric object is empty;
            * The internal intersection of two geometric objects is not empty or the boundary of the searched geometric object and the internal intersection of the searched geometric object are not empty;
            * Check line, check surface, line check surface, there is no inclusion situation;
            * And :py:meth:`is_within` is the inverse operation;
            * Types of geometric objects suitable for this relationship:

                * Search for geometric objects: point, line, surface;
                * The searched geometric objects: point, line, surface.

        .. image:: ../image/Geometrist_CanContain.png

        :param Geometry geo_search: Search for geometric objects, support point, line and area types.
        :param Geometry geo_target: The geometric object to be searched. It supports point, line and area types.
        :return: Return True if the searched geometric object contains the searched geometric object; otherwise, it Return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.clip": """
        Generate a geometric object after the operated object is clipped by the operated object.
        note:
        
        * Only the part of the operated geometric object that falls within the operated geometric object will be output as the result geometric object;
        * Clip and intersect are the same in spatial processing. The difference lies in the processing of the properties of the resulting geometric object. Clip analysis is only used for clipping. The resulting geometric object only retains the non-system fields of the manipulated geometric object, while Intersect performs the intersection analysis As a result, the fields of the two geometric objects can be reserved according to the field settings.
        * Types of geometric objects suitable for this operation:
        
            * Manipulate geometric objects: surface;
            * The manipulated geometric objects: line and surface.
        
        .. image:: ../image/Geometrist_Clip.png
        
        
        :param geometry: The operated geometric object, supports line and surface types.
        :type geometry: GeoLine or GeoRegion
        :param clip_geometry: Operate geometric objects, which must be surface objects.
        :type clip_geometry: GeoRegion or Rectangle
        :param float tolerance: Node tolerance
        :return: crop result object
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.op.compute_concave_hull": """
        Calculate the concave closure of the point set.
    
        :param points: The specified point set.
        :type points: list[Point2D] or tuple[Point2D]
        :param angle: The minimum angle in the concave package. The recommended value is 45 degrees to 75 degrees. The larger the angle, the more the concave hull will solve the shape of the convex hull, the smaller the angle, the sharper the angle between adjacent vertices of the concave polygon produced.
        :type angle: float
        :return: Return the concave polygon that can contain all points in the specified point set.
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.data.op.compute_convex_hull": """
        Calculate the convex closure of the geometric object, that is, the smallest circumscribed polygon. Return a simple convex polygon.
    
        :param points: point set
        :type points: list[Point2D] or tuple[Point2D] or Geometry
        :return: The smallest circumscribed polygon.
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.data.op.compute_default_tolerance": """
        Calculate the default tolerance of the coordinate system.
    
        :param prj: Specified projected coordinate system type object.
        :type prj: PrjCoordSys
        :return: Return the default tolerance value of the specified projected coordinate system type object.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.op.compute_distance": """
        Find the distance between two geometric objects.
        Note: The types of geometric objects can only be points, lines and areas. The distance here refers to the shortest distance between the edges of two geometric objects. For example: the shortest distance from a point to a line is the vertical distance from the point to the line.
    
        :param geometry1: the first geometric object
        :type geometry1: Geometry or Point2D or Rectangle
        :param geometry2: the second geometric object
        :type geometry2: Geometry or Point2D or Rectangle
        :return: the distance between two geometric objects
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.op.compute_geodesic_area": """
        Calculate the latitude and longitude area.
    
        note:
    
        * Use this method to calculate the latitude and longitude area. When specifying the projection coordinate system type object (PrjCoordSys) through the prj parameter, you must set the projection coordinate through the set_type method of the object
          to geographic longitude and latitude coordinate system (PrjCoordSysType.PCS_EARTH_LONGITUDE_LATITUDE), otherwise the calculation result is wrong.
    
        :param geometry: The specified area object whose latitude and longitude area needs to be calculated.
        :type geometry: GeoRegion
        :param prj: Specified projection coordinate system type
        :type prj: PrjCoordSys
        :return: latitude and longitude area
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.op.compute_geodesic_distance": """
        Calculate the length of the geodesic.
        The geodesic line between two points on the surface is called the geodesic. The geodesic on the sphere is the great circle.
        The geodesic line, also known as the "geodetic line" or "geodetic line", is the shortest curve between two points on the ellipsoid of the earth. On the earth line, the main curvature direction of each point is consistent with the surface normal at that point. It is a great arc on the surface of a sphere and a straight line on the plane.
        In geodetic surveying, the normal section line is usually replaced by the geodetic line for research and calculation of various problems on the ellipsoid.
    
        A geodesic is a curve with zero geodesic curvature at each point on a curved surface.
    
        :param points: The latitude and longitude coordinate point string that constitutes the geodesic line.
        :type points: list[Point2D] or tuple[Point2D]
        :param major_axis: The major axis of the ellipsoid where the geodesic line is located.
        :type major_axis: float
        :param flatten: The flattening of the ellipsoid where the geodesic line is located.
        :type flatten: float
        :return: The length of the geodesic.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.op.compute_geodesic_line": """
        Calculate the geodesic line according to the specified start and end points, and return the result line object.
    
        :param Point2D start_point: The start point of the input geodesic.
        :param Point2D end_point: The end point of the input geodesic.
        :param prj: Spatial reference coordinate system.
        :type prj: PrjCoordSys
        :param int segment: the number of arc segments used to fit the semicircle
        :return: The geodesic is constructed successfully, and the geodesic object is returned, otherwise it Return None
        :rtype: GeoLine
        """,

    "iobjectspy._jsuperpy.data.op.compute_geodesic_line2": """
        Calculate the geodesic line according to the specified starting point, azimuth angle and distance, and return the result line object.
    
        :param Point2D start_point: The start point of the input geodesic.
        :param float angle: The azimuth angle of the input geodesic. It can be positive or negative.
        :param float distance: The input geodesic length. The unit is meters.
        :param prj: Spatial reference coordinate system.
        :type prj: PrjCoordSys
        :param int segment: the number of arc segments used to fit the semicircle
        :return: The geodesic is constructed successfully, and the geodesic object is returned, otherwise it Return None
        :rtype: GeoLine
        """,

    "iobjectspy._jsuperpy.data.op.compute_parallel": """
        Find the parallel line of the known polyline based on the distance, and return the parallel line.
    
        :param GeoLine geo_line: known polyline object.
        :param float distance: The distance between the parallel lines to be sought.
        :return: Parallel lines.
        :rtype: GeoLine
        """,

    "iobjectspy._jsuperpy.data.op.compute_parallel2": """
    Find a line that passes through a specified point and is parallel to a known line.

    :param Point2D point: Any point outside the straight line.
    :param Point2D start_point: A point on the line.
    :param Point2D end_point: Another point on the line.
    :return: parallel lines
    :rtype: GeoLine
    """,

    "iobjectspy._jsuperpy.data.op.compute_perpendicular": """
    Calculate the perpendicular from the known point to the known line.

    :param Point2D point: a known point.
    :param Point2D start_point: A point on the line.
    :param Point2D end_point: Another point on the line.
    :return: point to line perpendicular
    :rtype: GeoLine
    """,

    "iobjectspy._jsuperpy.data.op.compute_perpendicular_position": """
    Calculate the vertical foot from a known point to a known line.

    :param Point2D point: a known point.
    :param Point2D start_point: A point on the line.
    :param Point2D end_point: Another point on the line.
    :return: point on a straight line
    :rtype: GeoLine
    """,

    "iobjectspy._jsuperpy.data.op.erase": """
        Erase the part that overlaps with the operated object on the operated object.
        note:
    
        * If all objects are erased, None will be returned;
        * The operation geometric object defines the erasing area. All the operated geometric objects falling in the operating geometric object area will be removed, and the feature elements falling outside the area will be output as the result geometric object, which is the opposite of Clip operation;
        * Types of geometric objects suitable for this operation:
    
            * Manipulate geometric objects: surface;
            * Operated geometric objects: point, line, surface.
    
        .. image:: ../image/Geometrist_Erase.png
    
        :param geometry: the operated geometric object, supports point, line and area object types
        :type geometry: GeoPoint or GeoLine or GeoRegion
        :param erase_geometry: Operate geometric objects, which must be area objects.
        :type erase_geometry: GeoRegion or Rectangle
        :param float tolerance: Node tolerance
        :return: The geometric object after erasing operation.
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.op.georegion_to_center_line": """
        Extract the centerline of the area object, generally used to extract the centerline of the river.
        This method is used to extract the center line of the area object. If the surface contains an island hole, the island hole will be bypassed during extraction and the shortest path will be used to bypass it. As shown below.
    
        .. image:: ../image/RegionToCenterLine_1.png
    
        If the area object is not a simple long strip, but has a bifurcated structure, the extracted center line is the longest segment. As shown below.
    
        .. image:: ../image/RegionToCenterLine_2.png
    
        If the extracted center line is not the desired center line, you can extract the center line of the area object by specifying the start point and end point, which is generally used to extract the center line of a river. Especially the centerline of the main stream of the river,
        And you can specify the start and end points of extraction. If the surface contains an island hole, the island hole will be bypassed during extraction, and the shortest path will be used to bypass. As shown below.
    
        .. image:: ../image/RegionToCenterLine_3.png
    
        The start and end points specified by the pnt_from and pnt_to parameters are used as reference points for extraction, that is, the center line extracted by the system may not strictly start from the specified start point and end at the specified end point. The system generally finds a closer point as the starting point or end point of the extraction near the specified starting point and ending point.
        Also note:
    
            * If the start point and end point are specified as the same point, which is equivalent to not specifying the extracted start point and end point, the longest center line of the area object will be extracted.
            * If the specified start or end point is outside the area object, the extraction fails.
    
        :param GeoRegion source_region: Specifies the region object whose centerline is to be extracted.
        :param Point2D pnt_from: Specifies the starting point for extracting the center line.
        :param Point2D pnt_to: Specifies the end point of the extracted center line.
        :return: The extracted centerline is a two-dimensional line object
        :rtype: GeoLine
        """,

    "iobjectspy._jsuperpy.data.op.has_area_intersection": """
    Judge whether the area of the object intersects, at least one of the query object and the target object is a surface object, and the result of the intersection does not include only contact. Support point, line, area and text objects.

        :param Geometry geo_search: query object
        :param Geometry geo_target: target object
        :param float tolerance: node tolerance
        :return: Return True if the area of the two objects intersect, otherwise False
        :rtype: bool
        """,

        "iobjectspy._jsuperpy.data.op.has_common_line": """
        Determine whether the searched geometric object has a common line segment with the searched geometric object. Return True if there is a common line segment.
    
        .. image:: ../image/Geometrist_HasCommonLine.png
    
        :param geo_search: Search for geometric objects. Only line and area types are supported.
        :type geo_search: GeoLine or GeoRegion
        :param geo_target: The searched geometric object, only supports line and area types.
        :type geo_target: GeoLine or GeoRegion
        :return: Return True if the searched geometric object and the searched geometric object have a common line segment; otherwise, return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.has_common_point": """
        Determine whether the searched geometric object has a common node with the searched geometric object. If there are common nodes, return true.
    
        .. image:: ../image/Geometrist_HasCommonPoint.png
    
        :param geo_search: Search for geometric objects, support point, line and area types.
        :type geo_search: Geometry
        :param geo_target: The geometric object to be searched. It supports point, line and area types.
        :type geo_target: Geometry
        :return: Return true if the searched geometric object and the searched geometric object share nodes; otherwise, it Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.has_cross": """
        Determine whether the searched geometric object passes through the searched geometric object. It returns True if it crosses.
        Note that if two geometric objects have a crossing relationship:
    
        * The intersection of the interior of the searched geometric object and the interior of the searched geometric object is not empty and the intersection of the interior of the searched geometric object and the exterior of the searched geometric object is not empty.
        * When the searched geometric object is a line, the intersection between the searched geometric object and the searched geometric object is not empty but the boundary intersection is empty;
        * Types of geometric objects suitable for this relationship:
    
            * Search for geometric objects: lines;
            * The searched geometric objects: line and surface.
    
        .. image:: ../image/Geometrist_HasCross.png
    
        :param GeoLine geo_search: Search for geometric objects. Only line types are supported.
        :param geo_target: The searched geometric object, supports line and area types.
        :type geo_target: GeoLine or GeoRegion or Rectangle
        :return: Return True when searching for geometric objects to traverse the searched object; otherwise, return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.has_hollow": """
        Determine whether the specified surface object contains sub-objects of hole type
    
        :param geometry: The area object to be judged, currently only supports 2D area objects
        :type geometry: GeoRegion
        :return: Whether the surface object contains sub-objects of the hole type, True if it contains, otherwise False
        :rtype: bool
        """,

        "iobjectspy._jsuperpy.data.op.has_intersection": """
            Determine whether the searched geometric object and the searched geometric object have an area intersection. Intersect Return true.
            note:
        
            * Both the searched geometric object and the searched geometric object must be a surface object;
            * Types of geometric objects suitable for this relationship:
        
                * Search for geometric objects: point, line, surface;
                * The searched geometric objects: point, line, surface.
        
            .. image:: ../image/Geometrist_HasIntersection.png
        
            :param Geometry geo_search: query object
            :param Geometry geo_target: target object
            :param float tolerance: Node tolerance
            :return: Return True if the area of the two objects intersect, otherwise False
            :rtype: bool
            """,

    "iobjectspy._jsuperpy.data.op.has_overlap": """
        Determine whether the searched geometric object partially overlaps with the searched geometric object. If there is a partial overlap, it Return true.
        note:
    
        * There is no partial overlap between the point and any geometric object;
        * The dimensionality requirements of the searched geometric object and the searched geometric object are the same, that is, it can only be a line query line or a surface query surface;
        * Types of geometric objects suitable for this relationship:
    
            * Search for geometric objects: line, surface;
            * The searched geometric objects: line and surface.
    
        .. image:: ../image/Geometrist_HasOverlap.png
    
        :param geo_search: Search for geometric objects. Only line and area types are supported.
        :type geo_search: GeoLine or GeoRegion or Rectangle
        :param geo_target: The searched geometric object, only supports line and area types
        :type geo_target: GeoLine or GeoRegion or Rectangle
        :param float tolerance: Node tolerance
        :return: Return True if the searched geometric object and the searched geometric object partially overlap; otherwise, return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.has_touch": """
        Determine whether the boundary of the searched geometric object touches the boundary of the searched geometric object. When touching, the internal intersection of the searched geometric object and the searched geometric object is empty.
        note:
    
        * There is no boundary contact between point and point;
        * Types of geometric objects suitable for this relationship:
    
            * Search for geometric objects: point, line, surface;
            * The searched geometric objects: point, line, surface.
    
        .. image:: ../image/Geometrist_HasTouch.png
    
        :param geo_search: Search for geometric objects.
        :type geo_search: Geometry
        :param geo_target: The geometric object to be searched.
        :type geo_target: Geometry
        :return: Return True if the boundary of the searched geometric object touches the boundary of the searched geometric object; otherwise, it Return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.identity": """
        Perform the same operation on the operated object. That is, after the operation is executed, the operated geometric object contains the geometric shape from the operated geometric object.
        note:
    
        * The same operation is an operation in which the operated geometric object and the operated geometric object intersect first, and then the result of the intersection is merged with the operated geometric object.
    
            * If the operated geometric object is a point type, the result geometric object is the operated geometric object;
            * If the operated geometric object is of line type, the result geometric object is the operated geometric object, but the part that intersects with the operated geometric object will be interrupted;
            * If the operated geometric object is a face type, the resulting geometric object retains all the polygons within the controlled boundary with the operated geometric object, and divides the intersection with the operated geometric object into multiple objects.
    
        * Types of geometric objects suitable for this operation:
            Manipulate geometric objects: surface;
            The operated geometric objects: point, line, surface.
    
        .. image:: ../image/Geometrist_Identity.png
    
        :param geometry: The operated geometric object, which supports point, line and area objects.
        :type geometry: GeoPoint or GeoLine or GeoRegion
        :param identity_geometry: Operate geometric objects, which must be face objects.
        :type identity_geometry: GeoRegion or Rectangle
        :param float tolerance: Node tolerance
        :return: the geometric object after the same operation
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.op.intersect": """
        Intersect two geometric objects and return the intersection of two geometric objects. Currently, only line-line intersection and face-to-face intersection are supported.
        At present, only the intersection of surface and surface and the intersection of line and line are supported, as shown in the following figure:
    
        .. image:: ../image/Geometrist_Intersect.png
    
        Note that if two objects have multiple separate common parts, the result of the intersection will be a complex object.
    
        :param geometry1: The first geometric object to be intersected. It supports line and area types.
        :type geometry1: GeoLine or GeoRegion
        :param geometry2: The second geometric object to perform the intersection operation. It supports line and surface types.
        :type geometry2: GeoLine or GeoRegion
        :param float tolerance: node tolerance, currently only supports line-line intersection.
       
        :return: The geometric object after the intersection operation.
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.op.intersect_line": """
        Return the intersection of two line segments (straight lines).
    
        :param Point2D start_point1: The starting point of the first line.
        :param Point2D end_point1: The end point of the first line.
        :param Point2D start_point2: The start point of the second line.
        :param Point2D end_point2: The end point of the second line.
        :param bool is_extended: Whether to extend the line segment, if it is True, it will be calculated as a straight line, otherwise it will be calculated as a line segment.
        :return: The intersection of two line segments (straight lines).
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.op.intersect_polyline": """
        Return the intersection of two polylines.
    
        :param points1: The point string forming the first polyline.
        :type points1: list[Point2D] or tuple[Point2D]
        :param points2: The point string forming the second polyline.
        :type points2: list[Point2D] or tuple[Point2D]
        :return: The intersection point of the polyline formed by the point string.
        :rtype: list[Point2D]
        """,

    "iobjectspy._jsuperpy.data.op.is_disjointed": """
        Determine whether the searched geometric object is separated from the searched geometric object. Detach Return true.
        note:
    
        * The searched geometric object is separated from the searched geometric object, that is, there is no intersection;
        * Types of geometric objects suitable for this relationship:
    
             * Search for geometric objects: point, line, surface;
             * The searched geometric objects: point, line, surface.
    
        .. image:: ../image/Geometrist_IsDisjointed.png
    
        :param geo_search: Search for geometric objects, support point, line and area types.
        :type geo_search: Geometry
        :param geo_target: The geometric object to be searched. It supports point, line and area types.
        :type geo_target: Geometry
        :return: Return True if two geometric objects are separated; otherwise, return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.is_identical": """
        Determine whether the searched geometric object is exactly equal to the searched geometric object. That is, the geometric objects completely overlap, the number of object nodes is equal, and the coordinate values corresponding to the positive or reverse order are equal.
        note:
    
        * The type of the searched geometric object and the searched geometric object must be the same;
        * Types of geometric objects suitable for this relationship:
    
             * Search for geometric objects: point, line, surface;
             * The searched geometric objects: point, line, surface.
    
        .. image:: ../image/Geometrist_IsIdentical.png
    
        :param geo_search: Search for geometric objects, support point, line, and area types
        :type geo_search: Geometry
        :param geo_target: The geometric object to be searched. It supports point, line and area types.
        :type geo_target: Geometry
        :param float tolerance: node tolerance
        :return: return True if two objects are exactly equal; otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.is_left": """
        Determine whether the point is on the left side of the line.
    
        :param Point2D point: the specified point to be judged
        :param Point2D start_point: a point on the specified line
        :param Point2D end_point: Another point on the specified line.
        :return: If you click on the left side of the line, return True, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.is_on_same_side": """
        Determine whether two points are on the same side of the line.
    
        :param Point2D point1: the specified point to be judged
        :param Point2D point2: another point specified to be judged
        :param Point2D start_point: A point on the specified line.
        :param Point2D end_point: Another point on the specified line.
        :return: If the point is on the same side of the line, return True, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.is_parallel": """
        Determine whether the two lines are parallel.
    
        :param Point2D start_point1: The starting point of the first line.
        :param Point2D end_point1: The end point of the first line.
        :param Point2D start_point2: The start point of the second line.
        :param Point2D end_point2: The end point of the second line.
        :return: return True in parallel; otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.is_perpendicular": """
        Determine whether the two straight lines are perpendicular.
    
        :param Point2D start_point1: The starting point of the first line.
        :param Point2D end_point1: The end point of the first line.
        :param Point2D start_point2: The start point of the second line.
        :param Point2D end_point2: The end point of the second line.
        :return: Return True vertically; otherwise, return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.is_point_on_line": """
        Judge whether the known point is on the known line segment (straight line), return True for the point on the line, otherwise return False.
    
        :param Point2D point: known point
        :param Point2D start_point: the starting point of the known line segment
        :param Point2D end_point: the end point of the known line segment
        :param bool is_extended: Whether to extend the line segment, if it is True, it will be calculated as a straight line, otherwise it will be calculated as the line segment
        :return: Click on the line to return True; otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.is_project_on_line_segment": """
        Determine whether the foot from the known point to the known line segment is on the line segment, if it is, return True, otherwise return False.
    
        :param Point2D point: known point
        :param Point2D start_point: the starting point of the known line segment
        :param Point2D end_point: the end point of the known line segment
        :return: Whether the vertical foot of the point and the line is on the line. If it is, return True, otherwise return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.is_right": """
        Determine whether the point is on the right side of the line.
    
        :param Point2D point: the specified point to be judged
        :param Point2D start_point: a point on the specified line
        :param Point2D end_point: Another point on the specified line.
        :return: If you click to the right of the line, return True, otherwise return False
        :rtype: bool
           """,

    "iobjectspy._jsuperpy.data.op.is_within": """
        Determine whether the searched geometric object is in the searched geometric object. If it is, it Return True.
        note:
    
        * There is no within condition for line query point, surface query line or surface query point;
        * And can_contain are inverse operations;
        * Types of geometric objects suitable for this relationship:
    
            * Search for geometric objects: point, line, surface;
            * The searched geometric objects: point, line, surface.
    
        .. image:: ../image/Geometrist_IsWithin.png
    
        :param geo_search: Search for geometric objects, support point, line and area types.
        :type geo_search: Geometry
        :param geo_target: The geometric object to be searched, supports point, line and area types
        :type geo_target: Geometry
        :param float tolerance: node tolerance
        :return: The searched geometric object Return True within the searched geometric object; otherwise it Return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.op.nearest_point_to_vertex": """
        Find the closest point from the geometric object to the given point.
    
        :param vertex: the specified point
        :type vertex: Point2D
        :param geometry: the specified geometric object
        :type geometry: Rectangle or GeoLine or GeoRegion
        :return: The point closest to the specified point on the geometric object.
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.op.orthogonal_polygon_fitting": """
        Right-angle polygon fitting of surface objects
        If the distance from a series of continuous nodes to the lower bound of the minimum area bounding rectangle is greater than height_threshold,
        and the total width of the node is greater than width_threshold, then the continuous node is fitted.
    
        :param geometry: The polygon object to be right-angled can only be a simple area object
        :type geometry: GeoRegion or Rectangle
        :param float width_threshold: The threshold value from the point to the left and right boundary of the minimum area bounding rectangle
        :param float height_threshold: The threshold value from the point to the upper and lower boundary of the minimum area bounding rectangle
        :return: the polygon object to be rectangularized, if it fails, it Return None
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.data.op.point_to_segment_distance": """
        Calculate the distance from a known point to a known line segment.
    
        :param Point2D point: The known point.
        :param Point2D start_point: The starting point of the known line segment.
        :param Point2D end_point: The end point of the known line segment.
        :return: The distance from the point to the line segment. If the vertical foot from the point to the line segment is not on the line segment, the distance from the point to the closer end of the line segment is returned.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.op.resample": """
        Resample geometric objects.
        Resampling geometric objects is to remove some nodes according to certain rules to achieve the purpose of simplifying the data (as shown in the figure below). The results may be different due to the use of different resampling methods.
        SuperMap provides two methods for re-sampling geometric objects, namely the light barrier method and the Douglas-Puck method. For a detailed introduction to these two methods, please refer to the :py:class:`VectorResampleType` class.
    
        .. image:: ../image/VectorResample.png
    
    
        :param geometry: The specified geometric object to be resampled. Support line objects and area objects.
        :type geometry: GeoLine or GeoRegion
        :param distance: The specified resampling tolerance.
        :type distance: float
        :param resample_type: The specified resampling method.
        :type resample_type: VectorResampleType or str
        :return: The geometric object after resampling.
        :rtype: GeoLine or GeoRegion
        """,

    "iobjectspy._jsuperpy.data.op.smooth": """
        Smooth the specified point string object
    
        For more information about smoothing, please refer to the introduction of the :py:meth:`jsupepry.analyst.smooth` method.
    
        :param points: The point string that needs to be smoothed.
        :type points: list[Point2D] or tuple[Point2D] or GeoLine or GeoRegion
        :param smoothness: smoothness coefficient. The valid range is greater than or equal to 2. Setting a value less than 2 will throw an exception. The greater the smoothness coefficient, the more the number of nodes on the boundary of the line object or the area object, and the smoother it is. The recommended value range is [2,10].
        :type smoothness: int
        :return: Smooth processing result point string.
        :rtype: list[Point2D] or GeoLine or GeoRegion
        """,

    "iobjectspy._jsuperpy.data.op.split_line": """
        Use point, line or area objects to split (break) line objects.
        This method can be used to break or segment line objects using point, line, and area objects. Below is a simple line object to illustrate these three situations:
    
        * Point the object to interrupt the line object. Use the point object to break the line object, and the original line object is broken into two line objects at the point object position. As shown in the figure below, use a dot (black) to break the line (blue), and the result will be two line objects (red line and green line).
    
        .. image:: ../image/PointSplitLine.png
    
        * Use point, line or area objects to split (break) line objects. This method can be used to break or segment line objects using point, line, and area objects. Take a simple line object below
          to explain these three situations
    
          * When the dividing line is a line segment, the operation line will be divided into two line objects at the intersection point of the dividing line. As shown in the figure below, the black line in the figure is the dividing line. After dividing, the original line object is divided into two line objects (red line and green line).
    
          .. image:: ../image/LineSplitLine_1.png
    
          * When the dividing line is a polyline, there may be multiple intersections with the operation line. At this time, the operation line will be interrupted at all intersections, and then the line segments in the odd and even order will be merged in order to produce two line objects. That is, 
            when dividing lines by polylines, complex line objects may be generated. The following figure shows this situation. After segmentation, the red line and the green line are respectively a complex line object.
    
          .. image:: ../image/LineSplitLine_2.png
    
    
        * Area object dividing line object. The area object segment line object is similar to the line segment line object. The operation line will be broken at all the intersections of the segmentation surface and the operation line, and then the lines at the odd and even positions will be merged to produce two line objects.
          This situation will produce at least one complex line object. In the figure below, the area object (light orange) divides the line object into two complex line objects, red and green.
    
        .. image:: ../image/RegionSplitLine.png
    
    
        note:
    
        1. If the divided line object is a complex object, then if the dividing line passes through a sub-object, the sub-object will be divided into two line objects. Therefore, dividing a complex line object may generate multiple line objects.
        2. If the line object or area object used for segmentation has self-intersection, the segmentation will not fail, but the segmentation result may be incorrect. Therefore, you should try to use a line or area object that does not intersect itself to divide the line.
    
    
        :param source_line: the line object to be divided (interrupted)
        :type source_line: GeoLine
        :param split_geometry: The object used to split (break) line objects. It supports point, line and area objects.
        :type split_geometry: GeoPoint or GeoRegion or GeoLine or Rectangle or Point2D
        :param tolerance: The specified tolerance is used to determine whether the point object is on the line. If the vertical foot distance from the point to the line is greater than the tolerance value, the point object used for interrupting is considered invalid, and the interruption is not executed.
        :type tolerance: float
        :return: The divided line object array.
        :rtype: list[GeoLine]
        """,

    "iobjectspy._jsuperpy.data.op.split_region": """
        Use line or area geometry objects to divide area geometry objects.
        Note: There must be at least two intersection points between the segmented object and the segmented object in the parameters, otherwise the segmentation will fail.
    
        :param source_region: The region to be segmented.
        :type source_region: GeoRegion or Rectangle
        :param split_geometry: The geometric object used for splitting, which can be a line or area geometric object.
        :type split_geometry: GeoLine or GeoRegion or Rectangle
        :return: Return the segmented area object. Two area objects will be obtained after correct separation.
        :rtype: tuple[GeoRegion]
        """,

    "iobjectspy._jsuperpy.data.op.union": """
        Combine two objects. After merging, the two area objects are divided by polygons at the intersection.
        note:
    
        * The two geometric objects to be combined must be of the same type. The current version only supports the combination of surface and line types.
        * Types of geometric objects suitable for this operation:
    
            * Manipulate geometric objects: surface, line;
            * The manipulated geometric objects: surface, line.
    
        .. image:: ../image/Geometrist_Union.png
    
        :param geometry1: The operated geometric object.
        :type geometry1: GeoLine or GeoRegion
        :param geometry2: Operate geometric objects.
        :type geometry2: GeoLine or GeoRegion
        :param float tolerance: Node tolerance
        :return: The geometric object after the merge operation. Only supports generating simple line objects.
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.op.update": """
        Update the operated object. Using the manipulated geometric object to replace the overlapping part with the manipulated geometric object is a process of erasing and then pasting. Both the operating object and the operated object must be surface objects.
    
        .. image:: ../image/Geometrist_Update.png
    
        :param geometry: The operated geometric object, that is, the updated geometric object, must be a region object.
        :type geometry: GeoRegion or Rectangle
        :param update_geometry: Operate geometric objects. The geometric objects used for update operations must be surface objects.
        :type update_geometry: GeoRegion or Rectangle
        :param float tolerance: Node tolerance
        :return: The geometric object after the update operation.
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.data.op.xor": """
        XOR two objects. That is, for each operated geometric object, remove the part that intersects with the operated geometric object, and keep the remaining part.
        The two geometric objects for XOR operation must be of the same type, and only support surfaces.
    
        .. image:: ../image/Geometrist_XOR.png
    
        :param geometry1: The operated geometric object, only supports surface type.
        :type geometry1: GeoRegion or Rectangle
        :param geometry2: Manipulate geometric objects, only surface types are supported.
        :type geometry2: GeoRegion or Rectangle
        :param float tolerance: Node tolerance
        :return: The result geometric object of the XOR operation.
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.data._listener": """""",

    "iobjectspy._jsuperpy.data._listener.ProgressListener": """""",

    "iobjectspy._jsuperpy.data._listener.ProgressListener.equals": """""",

    "iobjectspy._jsuperpy.data._listener.ProgressListener.hashCode": """""",

    "iobjectspy._jsuperpy.data._listener.ProgressListener.stepped": """""",

    "iobjectspy._jsuperpy.data._listener.ProgressListener.toString": """""",

    "iobjectspy._jsuperpy.data._listener.PythonListenerBase": """""",

    "iobjectspy._jsuperpy.data._listener.PythonListenerBase.equals": """""",

    "iobjectspy._jsuperpy.data._listener.PythonListenerBase.hashCode": """""",

    "iobjectspy._jsuperpy.data._listener.PythonListenerBase.toString": """""",

    "iobjectspy._jsuperpy.data.dt": """""",

    "iobjectspy._jsuperpy.data.dt.Colors": """Color collection class. The main function of this class is to provide color sequences. It provides the generation of various gradient colors and random colors, as well as the generation of SuperMap predefined gradient colors.""",

    "iobjectspy._jsuperpy.data.dt.Colors.append": """
        Add a color value to the color collection

        :param value: RGB color value or RGBA color value
        :type value: tuple[int] or int
        """,

    "iobjectspy._jsuperpy.data.dt.Colors.clear": """ Clear all color values """,

    "iobjectspy._jsuperpy.data.dt.Colors.extend": """
        Add a collection of color values

        :param iterable: color value collection
        :type iterable: range[int] or range[tuple]
        """,

    "iobjectspy._jsuperpy.data.dt.Colors.index": """
        Return the sequence number of the color value

        :param value: RGB color value or RGBA color value
        :type value: tuple[int] or int
        :param int start: start to find the position
        :param int end: end search position
        :return: The location of the color value that meets the condition
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.Colors.insert": """
        Add color to the specified position

        :param int index: the specified position
        :param value: RGB color value or RGBA color value
        :type value: tuple[int] or int
        """,

    "iobjectspy._jsuperpy.data.dt.Colors.make_gradient": """
        Given the number of colors and control colors, generate a set of gradient colors, or generate a preset gradient color of the generation system. gradient_colors and gradient_type cannot be valid at the same time. However, gradient_type is preferred
        when it is valid to use gradient_type to generate system-defined gradients.

        :param int count: The total number of gradient colors to be generated.
        :param gradient_type: The type of gradient color.
        :type gradient_type: ColorGradientType or str
        :param bool reverse: Whether to reversely generate gradient colors, that is, whether to generate gradient colors from the end color to the start color. It only works when gradient_type is valid.
        :param Colors gradient_colors: gradient color set. That is, the control color of the gradient color is generated.
        :return:
        :rtype:
        """,

    "iobjectspy._jsuperpy.data.dt.Colors.make_random": """
        Used to generate a certain number of random colors.

        :param int count: number of interval colors
        :param Colors colors: Control color set.
        :return: A random color table generated by the number of interval colors and the set of control colors.
        :rtype: Colors
        """,

    "iobjectspy._jsuperpy.data.dt.Colors.pop": """
        Delete the color value at the specified position and return the color value. Delete the last color value when index is None

        :param int index: the specified position
        :return: the color value to be deleted
        :rtype: tuple
        """,

    "iobjectspy._jsuperpy.data.dt.Colors.remove": """
        Delete the specified color value

        :param value: the color value to be deleted
        :type value: tuple[int] or int
        """,

    "iobjectspy._jsuperpy.data.dt.Colors.values": """
        Return all color values


        :rtype: list[tuple]
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset": """
        The base class of dataset (vector dataset, raster dataset, image dataset, etc.), providing common attributes and methods of various dataset.
        A dataset is generally a collection of related data stored together; according to the different types of data, it is divided into vector dataset and raster datasets, and those designed to handle specific problems such as topology dataset, network dataset,
        etc. Dataset is the smallest unit of GIS data organization. The vector dataset is a collection of spatial features of the same type, so it can also be called a feature set. According to the different spatial characteristics of the features, the vector dataset
        are subdivided into point dataset, line dataset, surface dataset, etc. Each vector dataset is a collection of data with the same spatial characteristics and properties and organized together. The raster dataset is composed of pixel array, which is less
        expressive than the vector dataset, but the positional relationship of spatial phenomena can be well represented.
    
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.bounds": """
        Rectangle: Return the smallest bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is the current raster or image
        Geographical scope.
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.close": """
        Used to close the current dataset
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.datasource": """ Datasource: Return the datasource object to which the current dataset belongs """,

    "iobjectspy._jsuperpy.data.dt.Dataset.description": """str: Return the description information of the dataset added by the user.""",

    "iobjectspy._jsuperpy.data.dt.Dataset.encode_type": """
        EncodeType: Return the encoding method of this dataset when data is stored. Using compression encoding for dataset can reduce the space occupied by data storage and reduce the network load and server load during data transmission. 
        The encoding methods supported by the vector dataset are Byte, Int16, Int24, Int32, SGL, LZW, DCT, and can also be specified as not using encoding methods. The encoding methods supported by raster data are DCT, SGL, LZW, 
        and no encoding. For details, see: py:class:`EncodeType` type
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.from_json": """
        Get the dataset from the json string of the dataset. If the datasource is not opened, the datasource will be opened automatically.

        :param str value: json string
        :return: dataset object
        :rtype: Dataet
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.is_open": """
        Judge whether the dataset has been opened, return True when the dataset is opened, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.is_readonly": """
        Determine whether the dataset is read-only. If the dataset is read-only, no operations can be performed to rewrite the dataset. If the dataset is read-only, return True, otherwise return False.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.name": """str: Return the name of the dataset """,

    "iobjectspy._jsuperpy.data.dt.Dataset.open": """
        return True if the dataset is opened successfully, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.prj_coordsys": """PrjCoordSys: Return the projection information of the dataset.""",

    "iobjectspy._jsuperpy.data.dt.Dataset.rename": """
        Modify dataset name

        :param str new_name: new dataset name
        :return: Return True if the modification is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.set_bounds": """
        Set the minimum bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is
        the geographic extent of the current raster or image.

        :param Rectangle rc: The smallest bounding rectangle that contains all objects in the dataset.
        :return: self
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.set_description": """
        Set the description information of the dataset added by the user.

        :param str value: The description of the dataset added by the user.
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.set_prj_coordsys": """
        Set the projection information of the dataset

        :param PrjCoordSys value: projection information
        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.table_name": """str: Return the table name of the dataset. For database datasources, Return the name of the data table corresponding to this dataset in the database; for file datasource, Return the table name of the storage attribute of this dataset. """,

    "iobjectspy._jsuperpy.data.dt.Dataset.to_json": """
        Output the information of the dataset to the json string. The json string content of the dataset includes the connection information of the datasource and the name of the dataset.

        :rtype: str

        Example::
         >>> ds = Workspace().get_datasource('data')
         >>> print(ds[0].to_json())
         {"name": "location", "datasource": {"type": "UDB", "alias": "data", "server": "E:/data.udb", "is_readonly": false}}

        """,

    "iobjectspy._jsuperpy.data.dt.Dataset.type": """DatasetType: Return the dataset type """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid": """
        The raster dataset class. Raster dataset class, which is used to describe raster data, such as elevation dataset and land use maps. Raster data is organized in grid form and uses the pixel value of a two-dimensional grid to record data. Each
        cell represents a pixel element, and the grid value can describe various data information. Each grid (cell) in the raster dataset stores the attribute value representing the feature. The attribute value can be soil type, density value,
        elevation, temperature, humidity, etc.
    
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.block_size_option": """BlockSizeOption: The pixel block type of the dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.bounds": """
        Rectangle: Return the smallest bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is the geographical scope of the 
        raster or image.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.build_pyramid": """
        Create a specified type of pyramid for raster data, the purpose is to improve the display speed of raster data. Pyramids can only be created for original data; users can only create pyramids once for a dataset, if you want
        to create it again, you need to delete the original created pyramid first. When the raster dataset is displayed, all the created pyramids will be accessed. The figure below shows the process of building pyramids at different scales.

        :param resample_method: type of pyramid building method
        :type resample_method: ResamplingMethod or str
        :param function progress: progress information processing function, refer to:py:class:`.StepEvent`
        :return: Whether the creation is successful, it Return True if it succeeds, and False if it fails
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.build_statistics": """
        Perform statistical operations on the raster dataset and return the statistical result object of the raster dataset. The statistical results include the maximum, minimum, mean, median, mode, rare, variance, standard deviation, etc. of the raster dataset.

        :return: A dict object containing the maximum, minimum, mean, median, mode, rare, variance, and standard deviation. The key value in dict:

                -average: average
                -majority: majority
                -minority: rare number
                -max: maximum value
                -median: median
                -min: minimum value
                -stdDev: standard deviation
                -var: variance
                -is_dirty: Is it "dirty" data

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.build_value_table": """
        Create a raster value attribute table whose type is the attribute table dataset type TABULAR.
        The pixel format of the raster dataset is SINGLE and DOUBLE, and the attribute table cannot be created, that is, calling this method Return None.
        The returned attribute table dataset contains system fields and two fields that record raster information. GRIDVALUE records the raster value, and GRIDCOUNT records the number of pixels corresponding to the raster value.

        :param out_data: The datasource where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: result dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.calculate_extremum": """
        Calculate the extreme values of the raster dataset, namely the maximum and minimum values. Suggestion: After some analysis or operation of raster dataset, it is recommended to call this interface to calculate the maximum and minimum values.

        :return: Return true if the calculation is successful, otherwise Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.clip_region": """GeoRegion: the display area of the raster dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.close": """
        Used to close the current dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.color_table": """
        Colors: Color table of the dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.column_block_count": """
        int: The total number of columns obtained after the raster dataset is divided into blocks.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.datasource": """ Datasource: Return the datasource object to which the current dataset belongs """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.description": """str: Return the description information of the dataset added by the user.""",

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.encode_type": """
        EncodeType: Return the encoding method of this dataset when data is stored. Using compression encoding for dataset can reduce the space occupied by data storage and reduce the network load and server load during data transmission.
        The encoding methods supported by the vector dataset are Byte, Int16, Int24, Int32, SGL, LZW, DCT, and can also be specified as not using encoding methods. The encoding methods supported by raster data are DCT, SGL, LZW,
        and no encoding. For details, see: py:class:`EncodeType` type
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.from_json": """
        Get the dataset from the json string of the dataset. If the datasource is not opened, the datasource will be opened automatically.

        :param str value: json string
        :return: dataset object
        :rtype: Dataet
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.get_value": """
        Return the cell value corresponding to the grid of the raster dataset according to the given number of rows and columns. Note: The number of rows and columns of parameter values of this method is counted from zero.

        :param int col: The column of the specified raster dataset.
        :param int row: Specify the row of the raster dataset.
        :return: the grid value corresponding to the grid of the raster dataset.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.grid_to_xy": """
        The grid points corresponding to the specified number of rows and columns are converted into points in the geographic coordinate system, namely X, Y coordinates.

        :param int col: the specified column
        :param int row: the specified row
        :return: the corresponding point coordinates in the geographic coordinate system.
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.has_pyramid": """
        Whether the raster dataset has created pyramids.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.height": """int: The height of the raster data of the raster dataset. The unit is pixel""",

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.is_open": """
        Judge whether the dataset has been opened, return True when the dataset is opened, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.is_readonly": """
        Determine whether the dataset is read-only. If the dataset is read-only, no operations can be performed to rewrite the dataset. If the dataset is read-only, return True, otherwise return False.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.max_value": """float: The maximum value of the grid value in the raster dataset.""",

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.min_value": """float: the minimum value of the grid value in the raster dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.name": """str: Return the name of the dataset """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.no_value": """float: the null value of the raster dataset, when the dataset is null, the user can use -9999 to represent """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.open": """
        Open the dataset, return True if the dataset is opened successfully, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.pixel_format": """PixelFormat: The pixel format of raster data storage. Each pixel is represented by a different byte, and the unit is bit.""",

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.prj_coordsys": """PrjCoordSys: Return the projection information of the dataset.""",

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.remove_pyramid": """
        Delete the created pyramid

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.rename": """
        Modify dataset name

        :param str new_name: new dataset name
        :return: Return True if the modification is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.row_block_count": """
        int: The total number of rows obtained after the raster data is divided into blocks.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.set_bounds": """
        Set the minimum bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is
        the geographic extent of the current raster or image.

        :param Rectangle rc: The smallest bounding rectangle that contains all objects in the dataset.
        :return: self
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.set_clip_region": """
        Set the display area of the raster dataset.
        When the user sets this method, the raster dataset will be displayed according to the given area, and nothing outside the area will be displayed.

        note:

         -When the geographic range of the raster dataset set by the user (that is, the :py:meth:`set_geo_reference` method is called) has no overlap with the set clipping area, the raster dataset will not be displayed.
         -When resetting the geographic extent of the raster dataset, the clipping area of the raster dataset is not automatically modified.

        :param region: The display area of the raster dataset.
        :type region: GeoRegion or Rectangle
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.set_color_table": """
        Set the color table of the dataset

        :param Colors colors: color collection
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.set_description": """
        Set the description information of the dataset added by the user.

        :param str value: The description of the dataset added by the user.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.set_geo_reference": """
        Map the raster dataset to the specified geographic range in the geographic coordinate system.

        :param Rectangle rect: the specified geographic range
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.set_no_value": """
        Set the null value of the raster dataset. When the dataset is null, the user can use -9999 to indicate

        :param float value: null value
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.set_prj_coordsys": """
        Set the projection information of the dataset

        :param PrjCoordSys value: projection information
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.set_value": """
        Set the grid value corresponding to the grid of the grid dataset according to the given number of rows and columns. Note: The number of rows and columns of parameter values of this method is counted from zero.

        :param int col: The column of the specified raster dataset.
        :param int row: Specify the row of the raster dataset.
        :param float value: The grid value corresponding to the specified grid dataset.
        :return: The raster value corresponding to the raster of the raster dataset before modification.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.table_name": """str: Return the table name of the dataset. For database datasources, Return the name of the data table corresponding to this dataset in the database; for file datasource, Return the table name of the storage attribute of this dataset. """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.to_json": """
        Output the information of the dataset to the json string. The json string content of the dataset includes the connection information of the datasource and the name of the dataset.

        :rtype: str

        Example::
         >>> ds = Workspace().get_datasource('data')
         >>> print(ds[0].to_json())
         {"name": "location", "datasource": {"type": "UDB", "alias": "data", "server": "E:/data.udb", "is_readonly": false}}

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.type": """DatasetType: Return the dataset type """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.update": """
        Update according to the specified raster dataset.
        Note: The encoding method (EncodeType) and pixel type (PixelFormat) of the specified raster dataset and the updated raster dataset must be consistent

        :param dataset: The specified raster dataset.
        :type dataset: DatasetGrid or str
        :return: If the update is successful, return True, otherwise return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.update_pyramid": """
        Update the image pyramid of the raster dataset in the specified range.

        :param Rectangle rect: Update the specified image range of the pyramid
        :return: If the update is successful, return True, otherwise return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.width": """int: The width of the raster data of the raster dataset. The unit is pixel""",

    "iobjectspy._jsuperpy.data.dt.DatasetGrid.xy_to_grid": """
        Convert the point (XY) in the geographic coordinate system to the corresponding grid in the raster dataset.

        :param point: point in geographic coordinate system
        :type point: Point2D
        :return: the grid corresponding to the raster dataset, return columns and rows respectively
        :rtype: tuple[int]
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo": """
        Raster dataset information class. This category includes returning and setting the corresponding setting information of the raster dataset, such as the name, width, height, pixel format, encoding method, storage block size, and null value of the raster dataset.
        
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.__init__": """
        Construct a raster dataset information object

        :param str name: dataset name
        :param int width: the width of the dataset, in pixels
        :param int height: the height of the dataset, in pixels
        :param pixel_format: the pixel format stored in the dataset
        :type pixel_format: PixelFormat or str
        :param encode_type: encoding method of dataset storage
        :type encode_type: EncodeType or str
        :param block_size_option: the pixel block type of the dataset
        :type block_size_option: BlockSizeOption
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.block_size_option": """BlockSizeOption: The pixel block type of the dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.bounds": """Rectangle: The geographic extent of the raster dataset.""",

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.encode_type": """EncodeType: Return the encoding method of raster dataset data storage. Using compression encoding method for the dataset can reduce the space occupied by data storage and reduce the data Network load and server load during transmission.
        The encoding methods supported by the raster data are DCT, SGL, LZW or not using the encoding method """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.from_dict": """
        Read DatasetGridInfo information from dict

        :param dict values:
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.height": """int: The height of the raster data of the raster dataset. The unit is pixel """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.make_from_dict": """
        Read information from dict to build DatasetGridInfo object

        :param dict values:
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.max_value": """float: the maximum value in the grid rows and columns of the raster dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.min_value": """float: the minimum value in the grid rows and columns of the grid dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.name": """str: Dataset name """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.no_value": """float: The null value of the raster dataset. When this dataset is null, the user can use -9999 to represent """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.pixel_format": """PixelFormat: The pixel format of raster data storage. Each pixel is represented by a different byte, and the unit is bit.""",

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.set_block_size_option": """
        Set the pixel block type of the dataset. Store in blocks in a square manner. In the process of segmenting,
        if the raster data is not enough to be completely divided into blocks, then use spaces to fill in complete storage. The default value is BlockSizeOption.BS_256.

        :param value: pixel block of raster dataset
        :type value: BlockSizeOption or str
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.set_bounds": """
        Set the geographic extent of the raster dataset.

        :param Rectangle value: The geographic extent of the raster dataset.
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.set_encode_type": """
        Set the encoding method of grid dataset data storage. Using compression encoding for dataset can reduce the space occupied by data storage and reduce the network load and server load during data transmission.
        The encoding methods supported by raster data are DCT, SGL, LZW or not using encoding methods.

        :param value: The encoding method of raster dataset data storage
        :type value: EncodeType or str
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.set_height": """
        Set the height of the raster data of the raster dataset. The unit is pixel.

        :param float value: the height of the raster data of the raster dataset
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.set_max_value": """
        Set the maximum value in the rows and columns of the raster dataset.

        :param float value: the maximum value in the rows and columns of the raster dataset
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.set_min_value": """
        Set the minimum value in the rows and columns of the raster dataset

        :param float value: the minimum value in the rows and columns of the raster dataset
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.set_name": """
        Set the name of the dataset

        :param str value: dataset name
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.set_no_value": """
        Set the null value of the raster dataset. When this dataset is null, the user can use -9999 to indicate it.

        :param float value: the null value of the raster dataset
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.set_pixel_format": """
        Set the stored pixel format of the raster dataset

        :param value: the stored pixel format of the raster dataset
        :type value: PixelFormat or str
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.set_width": """
        Set the width of the raster data of the raster dataset. The unit is pixel.

        :param int value: The width of the raster data of the raster dataset. The unit is pixel.
        :return: self
        :rtype: DatasetGridInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.to_dict": """
        Output current object information as dict

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetGridInfo.width": """int: the width of the raster data of the raster dataset. The unit is pixel""",

    "iobjectspy._jsuperpy.data.dt.DatasetImage": """
        Image dataset class. Image dataset class, which is used to describe image data and does not have attribute information, such as image maps, multi-band images, and physical maps. The raster data is organized in a grid form and recorded using pixel values
        of a two-dimensional raster. The grid value can describe various data information. Each raster in the image dataset stores a color value or color index value (RGB value).
    
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.add_band": """
        Add multiple bands to the specified multi-band image dataset according to the specified index

        :param datasets: image dataset
        :type datasets: list[DatasetImage] or DatasetImage
        :param indexes: The band index to be appended. It is only valid when the input is a single DatasetImage data.
        :type indexes: list[int]
        :return: the number of bands added
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.band_count": """int: Return the number of bands """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.block_size_option": """BlockSizeOption: The pixel block type of the dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetImage.bounds": """
        Rectangle: Return the smallest bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is the current raster or image
        Geographical scope.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.build_pyramid": """
        Create a pyramid for the image dataset. The purpose is to improve the display speed of the image dataset. Pyramids can only be created for the original data; pyramids can only be created for one dataset at a time, when the image dataset is displayed,
        all the pyramids that have been created will be visited.

        :param function progress: progress information processing function, refer to:py:class:`.StepEvent`
        :return: Whether the creation is successful, it Return True if it succeeds, and False if it fails
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.build_statistics": """
        Perform statistical operations on the image dataset, and return the statistical result object of the image dataset. The statistical results include the maximum, minimum, mean, median, mode, rare, variance, standard deviation, etc. of the image dataset.

        :return: Return a dict. The dict contains the statistical results of each band. The statistical results are dict objects containing the maximum, minimum, mean, median, mode, rare, variance, and standard deviation. The key value in dict:

                -average: average
                -majority: majority
                -minority: rare number
                -max: maximum value
                -median: median
                -min: minimum value
                -stdDev: standard deviation
                -var: variance
                -is_dirty: Is it "dirty" data

        :rtype: dict[dict]
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.calculate_extremum": """
        Calculate the extreme values of the specified band of the image data, namely the maximum and minimum values.

        :param int band: The band number of the image data whose extreme value is to be calculated.
        :return: Return true if the calculation is successful, otherwise Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.clip_region": """GeoRegion: the display area of the image dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetImage.close": """
        Used to close the current dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.datasource": """ Datasource: Return the datasource object to which the current dataset belongs""",

    "iobjectspy._jsuperpy.data.dt.DatasetImage.delete_band": """
        Delete a band according to the specified index number

        :param int start_index: Specify the start index number of the deleted band.
        :param int count: The number of bands to be deleted.
        :return: Return true if the deletion is successful; otherwise, Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.description": """str: Return the description of the dataset added by the user.""",

    "iobjectspy._jsuperpy.data.dt.DatasetImage.encode_type": """
        EncodeType: Return the encoding method of this dataset when data is stored. Using compression encoding for dataset can reduce the space occupied by data storage and reduce the network load and server load during data transmission.
        The encoding methods supported by the vector dataset are Byte, Int16, Int24, Int32, SGL, LZW, DCT, and can also be specified as not using encoding methods. The encoding methods supported by raster data are DCT, SGL, LZW, 
        or no encoding. For details, see: py:class:`EncodeType` type
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.from_json": """
        Get the dataset from the json string of the dataset. If the datasource is not opened, the datasource will be opened automatically.

        :param str value: json string
        :return: dataset object
        :rtype: Dataet
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.get_band_index": """
        Get the serial number of the specified band name

        :param str name: band name
        :return: the serial number of the band
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.get_band_name": """
        Return the name of the band with the specified sequence number.

        :param int band: band number
        :return: band name
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.get_max_value": """
        Get the maximum pixel value of the specified band of the image dataset

        :param int band: Specified band index number, starting from 0.
        :return: The maximum pixel value of the specified band of the image dataset
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.get_min_value": """
        Get the minimum pixel value of the specified band of the image dataset

        :param int band: Specified band index number, starting from 0.
        :return: The minimum pixel value of the specified band of the image dataset
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.get_no_value": """
        Return the no value of the specified band of the image dataset.

        :param int band: Specified band index number, starting from 0
        :return: No value for the specified band in the image dataset
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.get_palette": """
        Get the color palette of the specified band of the image dataset

        :param int band: Specified band index number, starting from 0.
        :return: The color palette of the specified band of the image dataset
        :rtype: Colors
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.get_pixel_format": """
        Return the pixel format of the specified band of the image dataset.

        :param int band: Specified band index number, starting from 0.
        :return: The pixel format of the specified band of the image dataset.
        :rtype: PixelFormat
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.get_value": """
        Return the pixel value corresponding to the grid of the image dataset according to the given number of rows and columns. Note: The number of rows and columns of parameter values of this method is counted from zero.

        :param int col: The column of the specified image dataset.
        :param int row: The row of the specified image dataset.
        :param int band: Specified number of bands
        :return: The corresponding pixel value in the image dataset.
        :rtype: float or tuple
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.has_pyramid": """
        Whether the image dataset has created pyramids.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.height": """int: The height of the image data of the image dataset. The unit is pixel """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.image_to_xy": """
        According to the specified number of rows and columns, the corresponding image points are converted into points in the geographic coordinate system, namely X, Y coordinates.

        :param int col: the specified column
        :param int row: the specified row
        :return: the corresponding point coordinates in the geographic coordinate system.
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.is_open": """
        Judge whether the dataset has been opened, return True when the dataset is opened, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.is_readonly": """
        Determine whether the dataset is read-only. If the dataset is read-only, no operations can be performed to rewrite the dataset. If the dataset is read-only, return True, otherwise return False.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.name": """str: Return the name of the dataset """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.open": """
        Open the dataset, return True if the dataset is opened successfully, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.prj_coordsys": """PrjCoordSys: Return the projection information of the dataset.""",

    "iobjectspy._jsuperpy.data.dt.DatasetImage.remove_pyramid": """
        Image created pyramid

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.rename": """
        Modify dataset name

        :param str new_name: new dataset name
        :return: Return True if the modification is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.set_band_name": """
        Set the name of the band with the specified serial number.

        :param int band: band number
        :param str name: band name
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.set_bounds": """
        Set the minimum bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is
        the geographic extent of the current raster or image.

        :param Rectangle rc: The smallest bounding rectangle that contains all objects in the dataset.
        :return: self
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.set_clip_region": """
        Set the display area of the image dataset.
        When the user sets this method, the image grid dataset will be displayed according to the given area, and nothing outside the area will be displayed.

        note:

        -When the geographic range of the image dataset set by the user (that is, calling the :py:meth:`set_geo_reference` method) and the set cropping area do not overlap, the image dataset is not displayed.
        -When resetting the geographic range of the image dataset, the cropping area of the image dataset is not automatically modified.

        :param region: The display area of the image dataset.
        :type region: GeoRegion or Rectangle
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.set_description": """
        Set the description information of the dataset added by the user.

        :param str value: The description of the dataset added by the user.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.set_geo_reference": """
        Correspond to the image dataset to the specified geographic range in the geographic coordinate system.

        :param Rectangle rect: the specified geographic range
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.set_no_value": """
        Set the no value of the specified band of the image dataset.

        :param float value: No value specified.
        :param int band: Specified band index number, starting from 0.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.set_palette": """
        Set the color palette of the specified band of the image dataset

        :param Colors colors: color palette.
        :param int band: Specified band index number, starting from 0.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.set_prj_coordsys": """
        Set the projection information of the dataset

        :param PrjCoordSys value: projection information
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.set_value": """
        Set the corresponding pixel value of the image dataset according to the given number of rows and columns. Note: The number of rows and columns of parameter values of this method is counted from zero.

        :param int col: The column of the specified image dataset.
        :param int row: The row of the specified image dataset.
        :param value: The corresponding pixel value of the specified image dataset.
        :type value: tuple or float
        :param int band: Specified band number
        :return: The corresponding pixel value before modification in the image dataset.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.table_name": """str: Return the table name of the dataset. For database datasources, Return the name of the data table corresponding to this dataset in the database; for file datasource, Return the table name of the storage attribute of this dataset. """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.to_json": """
        Output the information of the dataset to the json string. The json string content of the dataset includes the connection information of the datasource and the name of the dataset.

        :rtype: str

        Example::
         >>> ds = Workspace().get_datasource('data')
         >>> print(ds[0].to_json())
         {"name": "location", "datasource": {"type": "UDB", "alias": "data", "server": "E:/data.udb", "is_readonly": false}}

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.type": """DatasetType: Return the dataset type """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.update": """
        Update according to the specified image dataset.
        Note: The encoding method (EncodeType) and pixel type (PixelFormat) of the specified image dataset and the updated image dataset must be consistent.

        :param dataset: The specified image dataset.
        :type dataset: DatasetImage or str
        :return: If the update is successful, return True, otherwise return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.update_pyramid": """
        Update the image pyramid of the image dataset in the specified range.

        :param Rectangle rect: Update the specified image range of the pyramid
        :return: If the update is successful, return True, otherwise return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.width": """int: The width of the image data of the image dataset. The unit is pixel """,

    "iobjectspy._jsuperpy.data.dt.DatasetImage.xy_to_image": """
        Convert the point (XY) in the geographic coordinate system to the corresponding pixel value in the image dataset.

        :param point: point in geographic coordinate system
        :type point: Point2D
        :return: the corresponding image point of the image dataset
        :rtype: tuple[int]
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo": """
    Image dataset information class, which is used to set the creation information of the image dataset, including name, width, height, number of bands, and storage block size.

    When setting the creation information of the image dataset through this class, you need to pay attention to:

    -Need to specify the number of image bands, the number of bands can be set to 0, after creation, you can add bands to the image;
    -All bands are set to the same pixel format and encoding method. After the image is successfully created, you can set different pixel formats and encoding types for each band according to your needs.

    """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.__init__": """
        Construct image dataset information object

        :param str name: dataset name
        :param int width: the width of the dataset, in pixels
        :param int height: the height of the dataset, in pixels
        :param pixel_format: the pixel format stored in the dataset
        :type pixel_format: PixelFormat or str
        :param encode_type: encoding method of dataset storage
        :type encode_type: EncodeType or str
        :param block_size_option: the pixel block type of the dataset
        :type block_size_option: BlockSizeOption
        :param int band_count: number of bands
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.band_count": """int: number of bands""",

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.block_size_option": """BlockSizeOption: The pixel block type of the dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.bounds": """Rectangle: The geographic extent of the image dataset.""",

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.encode_type": """EncodeType: Return the encoding method of the image dataset when data is stored. Using compression encoding for the dataset can reduce the space occupied by data storage and reduce data transmission Network load and server load at the time.
        The encoding methods supported by the raster data are DCT, SGL, LZW or not using the encoding method """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.from_dict": """
        Read DatasetImageInfo information from dict

        :param dict values:
        :return: self
        :rtype: DatasetImageInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.height": """int: The height of the image data of the image dataset. The unit is pixel """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.make_from_dict": """
        Read information from dict to build DatasetImageInfo object

        :param dict values:
        :rtype: DatasetImageInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.name": """str: dataset name """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.pixel_format": """PixelFormat: The pixel format of image data storage. Each pixel is represented by a different byte, and the unit is bit.""",

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.set_band_count": """
        Set the number of bands of the image dataset. When creating an image dataset, the number of bands can be set to 0. At this time, the settings of pixel format (pixel_format) and encoding format (encode_type) are invalid.
        Because this information is for the band, so it cannot be saved when the band is 0. The pixel format and encoding format of this image dataset will be based on the relevant information of the first band added to it.

        :param int value: The number of bands.
        :return: self
        :rtype: DatasetImageInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.set_block_size_option": """
        Set the pixel block type of the dataset. Store in blocks in a square manner. In the process of segmenting, if the image data is not enough for complete segmentation, then the space is used to supplement the complete storage. The default value is BlockSizeOption.BS_256.

        :param value: The pixel block of the image dataset
        :type value: BlockSizeOption or str
        :return: self
        :rtype: DatasetImageInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.set_bounds": """
        Set the geographic extent of the image dataset.

        :param Rectangle value: The geographic extent of the image dataset.
        :return: self
        :rtype: DatasetImageInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.set_encode_type": """
        Set the encoding method of image dataset data storage. Using compression encoding for dataset can reduce the space occupied by data storage and reduce the network load and server load during data transmission.
        The encoding methods supported by raster data are DCT, SGL, LZW or not using encoding methods.

        :param value: like the encoding method of dataset data storage
        :type value: EncodeType or str
        :return: self
        :rtype: DatasetImageInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.set_height": """
        Set the height of the image data of the image dataset. The unit is pixel.

        :param int value: The height of the image data of the image dataset. The unit is pixel.
        :return: self
        :rtype: DatasetImageInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.set_name": """
        Set the name of the dataset

        :param str value: dataset name
        :return: self
        :rtype: DatasetImageInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.set_pixel_format": """
        Set the storage pixel format of the image dataset. The image dataset does not support DOUBLE, SINGLE, BIT64 type pixel formats.

        :param value: the pixel format of the image dataset storage
        :type value: PixelFormat or str
        :return: self
        :rtype: DatasetImageInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.set_width": """
        Set the width of the image data of the image dataset. The unit is pixel.

        :param int value: The width of the image data of the image dataset. The unit is pixel.
        :return: self
        :rtype: DatasetImageInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.to_dict": """
        Output current object information as dict

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetImageInfo.width": """int: The width of the image data of the image dataset. The unit is pixel """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic": """
        Mosaic dataset. Used for efficient management and display of massive image data. Nowadays, the acquisition of images has become more and more convenient and efficient, and the demand for the management and service release of massive images has become more and more common. In order to complete this work more
        conveniently and efficiently, SuperMap GIS provides a solution based on mosaic dataset. The mosaic dataset is managed by the way of metadata + original image files. When adding image data to the mosaic dataset, only
        the path, contour, resolution and other meta-information of the image file will be recorded, and load the required image file according to the meta-information when it is used. Compared with the traditional warehouse management method, this mode greatly improves the
        speed, but also reduces the disk usage.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.add_files": """
        Adding images to the mosaic dataset is essentially adding and recording the file names of all images with the specified extension under the given path. That is, the mosaic dataset does not copy the image files into the database, but records the full path of the image ( Absolute path) information.

        :param directory_paths: Specify the path to add images, that is, the folder path (absolute path) where the image to be added is located or the full path (absolute path) list of multiple image files to be added.
        :type directory_paths: str or list[str]
        :param extension: The extension of the image file. When directory_paths is a folder path (that is, when the type of directory_paths is str), it is used to filter the image files in the folder.
                                         When the type of directory_paths is list, this parameter has no effect.
        :type extension: str
        :param clip_file_extension: The suffix name of the crop shape file, such as .shp, the object in the file will be the cropped display range of the image. The cropped image display is generally used for:
                                   When the image after the correction is generated no value region; The effective value region of the image is drawn by clipping the shape, and the purpose of removing the no-value region is achieved after clipping the display.
                                   In addition, the image and the crop shape have a one-to-one correspondence. Therefore, the crop shape file must be stored in the path specified by the directory_path parameter
                                   that is, the crop shape file and the image file are in the same directory.
        :type clip_file_extension: str
        :return: Whether the image is added successfully, True means success; False means failure.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.bound_count": """int: mosaic dataset band number""",

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.boundary_dataset": """DatasetVector: the boundary subdataset of the mosaic dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.bounds": """
        Rectangle: Return the smallest bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is the current raster or image
        geographical scope.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.build_pyramid": """
        Create image pyramids for all images in the mosaic dataset.

        :param resample_type: Pyramid resampling method
        :type resample_type: PyramidResampleType or str
        :param bool is_skip_exists: A Boolean value indicating whether to ignore the pyramid if the image has already been created. True means ignore, that is, do not recreate the pyramid; False means
                                    re-create a pyramid from an image of an existing pyramid..
        :return: return True if successful creation; otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.clip_dataset": """DatasetVector: the cropped sub-dataset of the mosaic dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.close": """
        Used to close the current dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.datasource": """ Datasource: Return the datasource object to which the current dataset belongs""",

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.description": """str: Return the description information of the dataset added by the user.""",

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.encode_type": """
        EncodeType: Return the encoding method of this dataset when data is stored. Using compression encoding for dataset can reduce the space occupied by data storage and reduce the network load and server load during data transmission.
        The encoding methods supported by the vector dataset are Byte, Int16, Int24, Int32, SGL, LZW, DCT, and can also be specified as not using encoding methods. The encoding methods supported by raster data are DCT, SGL, LZW, 
        or no encoding. For details, see: py:class:`EncodeType` type
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.footprint_dataset": """DatasetVector: the contour subset of the mosaic dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.from_json": """
        Get the dataset from the json string of the dataset. If the datasource is not opened, the datasource will be opened automatically.

        :param str value: json string
        :return: dataset object
        :rtype: Dataet
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.is_open": """
        Judge whether the dataset has been opened, return True when the dataset is opened, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.is_readonly": """
        Determine whether the dataset is read-only. If the dataset is read-only, no operations can be performed to rewrite the dataset. If the dataset is read-only, return True, otherwise return False.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.list_files": """
        Get all the raster files of the mosaic dataset

        :return: all raster files of the mosaic dataset
        :rtype: list[str]
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.name": """str: Return the name of the dataset """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.open": """
        Open the dataset, return True if the dataset is opened successfully, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.pixel_format": """PixelFormat: the bit depth of the mosaic dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.prj_coordsys": """PrjCoordSys: Return the projection information of the dataset.""",

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.rename": """
        Modify dataset name

        :param str new_name: new dataset name
        :return: Return True if the modification is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.set_bounds": """
        Set the minimum bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is
        the geographic extent of the current raster or image.

        :param Rectangle rc: The smallest bounding rectangle that contains all objects in the dataset.
        :return: self
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.set_description": """
        Set the description information of the dataset added by the user.

        :param str value: The description of the dataset added by the user.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.set_prj_coordsys": """
        Set the projection information of the dataset

        :param PrjCoordSys value: projection information
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.table_name": """str: Return the table name of the dataset. For database datasources, Return the name of the data table corresponding to this dataset in the database; for file datasource, Return the table name of the storage attribute of this dataset. """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.to_json": """
        Output the information of the dataset to the json string. The json string content of the dataset includes the connection information of the datasource and the name of the dataset.

        :rtype: str

        Example::
         >>> ds = Workspace().get_datasource('data')
         >>> print(ds[0].to_json())
         {"name": "location", "datasource": {"type": "UDB", "alias": "data", "server": "E:/data.udb", "is_readonly": false}}

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetMosaic.type": """DatasetType: Return the dataset type """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology": """""",

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.bounds": """
        Rectangle: Return the smallest bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, Represents the geographic range of
        the current grid or image.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.close": """
        Used to close the current dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.datasource": """ Datasource: Return the datasource object to which the current dataset belongs""",

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.description": """str: Return the description information of the dataset added by the user.""",

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.encode_type": """
        EncodeType: Return the encoding method of this dataset when data is stored. Using compression encoding for dataset can reduce the space occupied by data storage and reduce the network load and server load during data transmission.
        The encoding methods supported by the vector dataset are Byte, Int16, Int24, Int32, SGL, LZW, DCT, and can also be specified as not using encoding methods. The encoding methods supported by raster data are DCT, SGL, LZW, 
        or no encoding. For details, see: py:class:`EncodeType` type
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.from_json": """
        Get the dataset from the json string of the dataset. If the datasource is not opened, the datasource will be opened automatically.

        :param str value: json string
        :return: dataset object
        :rtype: Dataet
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.is_open": """
        Judge whether the dataset has been opened, return True when the dataset is opened, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.is_readonly": """
        Determine whether the dataset is read-only. If the dataset is read-only, no operations can be performed to rewrite the dataset. If the dataset is read-only, return True, otherwise return False.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.name": """str: Return the name of the dataset """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.open": """
        Open the dataset, return True if the dataset is opened successfully, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.prj_coordsys": """PrjCoordSys: Return the projection information of the dataset.""",

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.rename": """
        Modify dataset name

        :param str new_name: new dataset name
        :return: Return True if the modification is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.set_bounds": """
        Set the minimum bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is
        the geographic extent of the current raster or image.

        :param Rectangle rc: The smallest bounding rectangle that contains all objects in the dataset.
        :return: self
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.set_description": """
        Set the description information of the dataset added by the user.

        :param str value: The description of the dataset added by the user.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.set_prj_coordsys": """
        Set the projection information of the dataset

        :param PrjCoordSys value: projection information
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.table_name": """str: Return the table name of the dataset. For database datasources, Return the name of the data table corresponding to this dataset in the database; for file datasource, Return the table name of the storage attribute of this dataset. """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.to_json": """
        Output the information of the dataset to the json string. The json string content of the dataset includes the connection information of the datasource and the name of the dataset.

        :rtype: str

        Example::
         >>> ds = Workspace().get_datasource('data')
         >>> print(ds[0].to_json())
         {"name": "location", "datasource": {"type": "UDB", "alias": "data", "server": "E:/data.udb", "is_readonly": false}}

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetTopology.type": """DatasetType: Return the dataset type """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported": """""",

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.bounds": """
        Rectangle: Return the smallest bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is the current raster or image
        geographical scope.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.close": """
        Used to close the current dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.datasource": """ Datasource: Return the datasource object to which the current dataset belongs""",

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.description": """str: Return the description information of the dataset added by the user.""",

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.encode_type": """
        EncodeType: Return the encoding method of this dataset when data is stored. Using compression encoding for dataset can reduce the space occupied by data storage and reduce the network load and server load during data transmission.
        The encoding methods supported by the vector dataset are Byte, Int16, Int24, Int32, SGL, LZW, DCT, and can also be specified as not using encoding methods. The encoding methods supported by raster data are DCT, SGL, LZW, 
        or no encoding. For details, see: py:class:`EncodeType` type
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.from_json": """
        Get the dataset from the json string of the dataset. If the datasource is not opened, the datasource will be opened automatically.

        :param str value: json string
        :return: dataset object
        :rtype: Dataet
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.is_open": """
        Judge whether the dataset has been opened, return True when the dataset is opened, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.is_readonly": """
        Determine whether the dataset is read-only. If the dataset is read-only, no operations can be performed to rewrite the dataset. If the dataset is read-only, return True, otherwise return False.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.name": """str: Return the name of the dataset """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.open": """
        Open the dataset, return True if the dataset is opened successfully, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.prj_coordsys": """PrjCoordSys: Return the projection information of the dataset.""",

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.rename": """
        Modify dataset name

        :param str new_name: new dataset name
        :return: Return True if the modification is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.set_bounds": """
        Set the minimum bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is
        the geographic extent of the current raster or image.

        :param Rectangle rc: The smallest bounding rectangle that contains all objects in the dataset.
        :return: self
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.set_description": """
        Set the description information of the dataset added by the user.

        :param str value: The description of the dataset added by the user.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.set_prj_coordsys": """
        Set the projection information of the dataset

        :param PrjCoordSys value: projection information
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.table_name": """str: Return the table name of the dataset. For database datasources, Return the name of the data table corresponding to this dataset in the database; for file datasource, Return the table name of the storage attribute of this dataset. """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.to_json": """
        Output the information of the dataset to the json string. The json string content of the dataset includes the connection information of the datasource and the name of the dataset.

        :rtype: str

        Example::
         >>> ds = Workspace().get_datasource('data')
         >>> print(ds[0].to_json())
         {"name": "location", "datasource": {"type": "UDB", "alias": "data", "server": "E:/data.udb", "is_readonly": false}}

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetUnsupported.type": """DatasetType: Return the dataset type """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector": """
        Vector dataset class. It is used to describe vector dataset and manage and operate them accordingly. Operations on vector dataset mainly include data query, modification, deletion, and indexing.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.append": """
        Add records to the current dataset. The written data can be:

        -Recordset or list of Recordset. It is necessary to ensure that the dataset type and the attribute table structure of the Recordset being written are the same as the current dataset, otherwise, the attribute data writing may fail.
        -DatasetVector or a list of DatasetVector. It is necessary to ensure that the dataset type and the attribute table structure of the DatasetVector being written are the same as the current dataset, otherwise, the attribute data writing may fail.
        -A list of point2D or point2D. Setting Fields is not supported when writing data to Point2D.The current dataset must be a point dataset or CAD dataset.
        -List of Rectangle or Rectangle. Setting fields is not supported when the data to be written is Rectangle. The current dataset must be a surface dataset or a CAD dataset.
        -List of Geometry or Geometry. When the writing data is Geometry, the fields are not supported. When the Geometry type is:

            -Point, the current dataset must be a point dataset or a CAD dataset.
            -Line, the current dataset must be a line dataset or a CAD dataset
            -Surface, the current dataset must be face dataset or CAD dataset
            -Text, the current dataset must be a text dataset or a CAD dataset

        -Feature or Feature list. When fields are set, it must be ensured that the field type of Feature in the fields matches the field of the dataset, otherwise it may cause the write attribute to be lost
          Lost. When fields are empty, you must ensure that the fields in Feature exactly match the attribute fields of the current dataset. When Feature contains spatial objects, the types of spatial objects are:

            -Point, the current dataset must be a point dataset or a CAD dataset.
            -Line, the current dataset must be a line dataset or a CAD dataset
            -Face, the current dataset must be face dataset or CAD dataset
            -Text, the current dataset must be a text dataset or a CAD dataset


        :param data: data to be written
        :type data: Recordset or DatasetVector or Geometry or Rectangle or Point2D or Feature or list[Recordset] or list[DatasetVector] or list[Geometry] or list[Rectangle] or list[Point2D] or list[Feature]
        :param dict fields: Field mapping, key is the name of the field written in the data, and value is the field name of the current dataset.
        :return: Return True if data is written successfully, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.append_fields": """
        Add fields from the source dataset to the target dataset, and assign values to the fields based on the query results of the associated fields.

        note:

         * If a field in the field name set appended to the target dataset does not exist in the source dataset, this field will be ignored and only the fields existing in the source dataset will be appended;
         * If the set of field names corresponding to the additional field in the target dataset is specified, the additional field will be created in the target dataset according to the specified field name; when the specified field name already exists in the target dataset, it will be automatically added _x(1, 2, 3...) to create fields;
         * If you fail to create a field in the target dataset, ignore this field and continue to add other fields;
         * Must specify the source field name collection, otherwise the addition will not succeed;
         * It is not necessary to specify the target field name set. Once the target field name set is specified, the field names in this set must correspond to the field names in the source field name set.


        :param source: source dataset
        :type source: DatasetVector or str
        :param str source_link_field: The associated field in the source dataset and the target dataset.
        :param str target_link_field: The associated field in the target dataset and the source dataset.
        :param source_fields: The set of field names in the source dataset to be appended to the target dataset.
        :type source_fields: list[str] or str
        :param target_fields: The set of field names corresponding to the additional fields in the target dataset.
        :type target_fields: list[str] or str
        :return: A boolean value, indicating whether the appending field is successful, it Return true if it succeeds, otherwise it Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.bounds": """
        Rectangle: Return the smallest bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, represents the geographic range of
        The current grid or image.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.build_field_index": """
        Create an index for the non-spatial fields of the dataset

        :param field_names: non-spatial field names
        :type field_names: list[str] or str
        :param str index_name: index name
        :return: return true if created successfully, otherwise return false
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.build_spatial_index": """
        Create a spatial index for the vector dataset according to the specified spatial index information or index type.
        note:

            -The point dataset in the database does not support quad tree (QTree) index and R tree index (RTree);
            -The network dataset does not support any type of spatial index;
            -The attribute dataset does not support any type of spatial index;
            -The routing dataset does not support tile index (TILE);
            -The composite dataset does not support multi-level grid index;
            -The index can be created only when the database records are greater than 1000.

        :param spatial_index_info: spatial index information, or spatial index type, when it is a spatial index type, it can be an enumeration value or a name
        :type spatial_index_info: SpatialIndexInfo or SpatialIndexType
        :return: Return True if the index is created successfully, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.charset": """Charset: the character set of the vector dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetVector.child_dataset": """DatasetVector: Sub-dataset of vector dataset. Mainly used for network dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetVector.close": """
        Used to close the current dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.compute_bounds": """
        Recalculate the spatial extent of the dataset.

        :rtype: Rectangle
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.create_field": """
        Create field

        :param FieldInfo field_info: Field information. If the field type is a required field, the default value must be set. If the default value is not set, the addition fails.
        :rtype: bool
        :return: Return True if the field is created successfully, otherwise False
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.create_fields": """
        Create multiple fields

        :param list[FieldInfo] field_infos: field information collection
        :return: Return True if the field is created successfully, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.datasource": """ Datasource: Return the datasource object to which the current dataset belongs""",

    "iobjectspy._jsuperpy.data.dt.DatasetVector.delete_records": """
        Delete records in the dataset through the ID array.

        :param list[int] ids: ID array of records to be deleted
        :return: Return True if the deletion is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.description": """str: Return the description information of the dataset added by the user.""",

    "iobjectspy._jsuperpy.data.dt.DatasetVector.drop_field_index": """
        Specify the field according to the index name, delete the index of the field

        :param str index_name: field index name
        :return: Return True if the deletion is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.drop_spatial_index": """
        Delete the spatial index, return True if the delete succeeds, otherwise return False

        :rtype: bool

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.encode_type": """
        EncodeType: Return the encoding method of this dataset when data is stored. Using compression encoding for dataset can reduce the space occupied by data storage and reduce the network load and server load during data transmission.
        The encoding methods supported by the vector dataset are Byte, Int16, Int24, Int32, SGL, LZW, DCT, and can also be specified as not using encoding methods. The encoding methods supported by raster data are DCT, SGL, LZW, 
        or no encoding. For details, see: py:class:`EncodeType` type
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.field_infos": """list[FieldInfo]: All field information of the dataset""",

    "iobjectspy._jsuperpy.data.dt.DatasetVector.from_json": """
        Get the dataset from the json string of the dataset. If the datasource is not opened, the datasource will be opened automatically.

        :param str value: json string
        :return: dataset object
        :rtype: Dataet
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_available_field_name": """
        Generate a legal field name based on the incoming parameters.

        :param str name: field name
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_features": """
        Obtain feature objects according to specified attribute filter conditions

        :param str attr_filter: attribute filter condition, the default is None, that is, all feature objects in the current dataset are returned
        :param bool has_geometry: Whether to get the geometry object, when it is False, only the field value will be returned
        :param fields: result field name
        :type fields: list[str] or str
        :return: all feature objects that meet the specified conditions
        :rtype: list[Feature]

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_field_count": """
        Return the number of all fields in the dataset

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_field_indexes": """
        Return the relationship mapping object between the index built in the attribute table of the current dataset and the indexed field. The key value is the index value, and the mapping value is the field where the index is located.

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_field_info": """
        Get the field of the specified name or serial number

        :param item: field name or serial number
        :type item: int or str
        :return: field information
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_field_name_by_sign": """
        Obtain the field name according to the field ID.

        :param field_sign: field sign type
        :type field_sign: FieldSign or str
        :return: field type
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_field_values": """
        Get the field value of the specified field

        :param fields: list of field names
        :type fields: str or list[str]
        :return: Get the field value, each field name corresponds to a list
        :rtype: dist[str,list]
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_geometries": """
        Get geometric objects according to specified attribute filter conditions

        :param str attr_filter: attribute filter condition, the default is None, that is, all geometric objects in the current dataset are returned
        :return: all geometric objects that meet the specified conditions
        :rtype: list[Geometry]
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_record_count": """
        Return the number of all records in the vector dataset.

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_recordset": """
        Return an empty record set or a record set object including all records according to the given parameters.

        :param bool is_empty: Whether to return empty recordset parameters. When true, an empty record set is returned. When it is false, it Return a record collection object containing all records.
        :param cursor_type: The cursor type, so that the user can control the attributes of the query set. When the cursor type is dynamic, the record set can be modified. When the cursor type is static, the record set is read-only. Can be enumerated value or name
        :type cursor_type: CursorType or str
        :param fields: The name of the result field that needs to be output, if it is None, all fields are reserved
        :type fields: list[str] or str
        :return: Record set object that meets the conditions
        :rtype: Recordset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_spatial_index_type": """
        Get spatial index type

        :rtype: SpatialIndexType
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_tolerance_dangle": """
        Get short suspension tolerance

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_tolerance_extend": """
        Obtain long suspension tolerance

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_tolerance_grain": """
        Get particle tolerance

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_tolerance_node_snap": """
        Get node tolerance

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.get_tolerance_small_polygon": """
        Get minimum polygon tolerance

        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.index_of_field": """
        Get the serial number of the specified field name

        :param str name: field name
        :return: If the field exists, return the serial number of the field, otherwise return -1
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.is_available_field_name": """
        Determine whether the specified field name is legal and not occupied

        :param str name: field name
        :return: Return True if the field name is legal and not occupied, otherwise it Return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.is_file_cache": """
        Return whether to use file cache. File caching can improve browsing speed.
        Note: The file cache is only valid for the vector dataset of the created map frame index under the Oracle datasource.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.is_open": """
        Judge whether the dataset has been opened, return True when the dataset is opened, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.is_readonly": """
        Determine whether the dataset is read-only. If the dataset is read-only, no operations can be performed to rewrite the dataset. If the dataset is read-only, return True, otherwise return False.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.is_spatial_index_dirty": """
        Determine whether the spatial index of the current dataset needs to be rebuilt. Because after the process of modifying the data, the spatial index may need to be rebuilt.
        note:

         -When there is no spatial index in the vector dataset, if the number of records has reached the requirements for establishing a spatial index, it will return True and it is recommended that the user create a spatial index; otherwise, it will return False.
         -If the vector dataset has a spatial index (except for the library index), but the number of records has not reached the requirement for establishing a spatial index, it return True.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.is_spatial_index_type_supported": """
        Determine whether the current dataset supports the specified type of spatial index.

        :param spatial_index_type: spatial index type, which can be an enumerated value or a name
        :type spatial_index_type: SpatialIndexType or str
        :return: If the specified spatial index type is supported, the return value is true, otherwise it is false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.name": """str: Return the name of the dataset """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.open": """
        Open the dataset, return True if the dataset is opened successfully, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.parent_dataset": """DatasetVector: The parent dataset of the vector dataset. Mainly used for network dataset """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.prj_coordsys": """PrjCoordSys: Return the projection information of the dataset.""",

    "iobjectspy._jsuperpy.data.dt.DatasetVector.query": """
        The vector dataset is queried by setting query conditions. This method queries spatial information and attribute information by default.

        :param QueryParameter query_param: query conditions
        :return: The result record set that meets the query conditions
        :rtype: Recordset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.query_with_bounds": """
        Query record set based on geographic scope

        :param Rectangle bounds: known spatial extent
        :param str attr_filter: query filter conditions, equivalent to the Where clause in the SQL statement
        :param cursor_type: cursor type, can be enumerated value or name
        :type cursor_type: CursorType or str
        :return: The result record set that meets the query conditions
        :rtype: Recordset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.query_with_distance": """
        Used to query records that are concentrated in the buffer of the specified space object and meet certain conditions.

        :param geometry: The spatial object used for query.
        :type geometry: Geometry or Point2D or Rectangle
        :param float distance: query radius
        :param unit: The unit of the query radius, if it is None, the unit of the query radius is the same as the unit of the dataset.
        :type unit: Unit or str
        :param str attr_filter: query filter conditions, equivalent to the Where clause in the SQL statement
        :param cursor_type: cursor type, can be enumerated value or name
        :type cursor_type: CursorType or str
        :return: The result record set that meets the query conditions
        :rtype: Recordset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.query_with_filter": """
        Query the record set according to the specified attribute filter condition

        :param str attr_filter: query filter conditions, equivalent to the Where clause in the SQL statement
        :param cursor_type: cursor type, can be enumerated value or name
        :type cursor_type: CursorType or str
        :param result_fields: result field name
        :type result_fields: list[str] or str
        :param bool has_geometry: Whether to include geometric objects
        :return: The result record set that meets the query conditions
        :rtype: Recordset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.query_with_ids": """
        According to the specified ID array, query the record set that meets the record

        :param list[int] ids: ID array
        :param str id_field_name: The field name used to represent the ID in the dataset. The default is "SmID"
        :param cursor_type: cursor type
        :type cursor_type: CursorType or str
        :return: The result record set that meets the query conditions
        :rtype: Recordset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.re_build_spatial_index": """
        Rebuild on the basis of the original spatial index. If the original spatial index is damaged, it can still be used after the reconstruction is successful.

        :return: Return True if the index is successfully rebuilt, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.remove_field": """
        Delete the specified field

        :param item: field name or serial number
        :type item: int or str
        :return: Return True if the deletion is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.rename": """
        Modify dataset name

        :param str new_name: new dataset name
        :return: Return True if the modification is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.reset_tolerance_as_default": """
        Set all tolerances to default values, and the unit is the same as the unit of the vector dataset coordinate system:

         -The default value of node tolerance is 1/1000000 of the width of the dataset;
         -The default value of the particle tolerance is 1/1000 of the width of the dataset;
         -The default value of the short suspension tolerance is 1/10000 of the width of the dataset;
         -The default value of the long suspension tolerance is 1/10000 of the width of the dataset;
         -The default value of the minimum polygon tolerance is 0.

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.set_bounds": """
        Set the minimum bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, it is
        the geographic extent of the current raster or image.

        :param Rectangle rc: The smallest bounding rectangle that contains all objects in the dataset.
        :return: self
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.set_charset": """
        Set the character set of the dataset

        :param value: character set of the dataset
        :type value: Charset or str
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.set_description": """
        Set the description information of the dataset added by the user.

        :param str value: The description of the dataset added by the user.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.set_file_cache": """
        Set whether to use file cache.

        :param bool value: Whether to use file cache
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.set_prj_coordsys": """
        Set the projection information of the dataset

        :param PrjCoordSys value: projection information
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.set_tolerance_dangle": """
        Set short suspension tolerance

        :param float value: short overhang tolerance

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.set_tolerance_extend": """
        Set long suspension tolerance

        :param float value: long suspension tolerance
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.set_tolerance_grain": """
        Set particle tolerance

        :param float value: particle tolerance
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.set_tolerance_node_snap": """
        Set node tolerance

        :param float value: node tolerance
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.set_tolerance_small_polygon": """
        Set minimum polygon tolerance

        :param float value: minimum polygon tolerance
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.stat": """
        Perform statistics on the specified fields in a given way.
        The current version provides 6 statistical methods. The maximum, minimum, average, sum, standard deviation, and variance of statistical fields.
        The statistical field types supported by the current version are Boolean, byte, double precision, single precision, 16-bit integer, and 32-bit integer.

        :param item: field name or serial number
        :type item: str or int
        :param stat_mode: field statistics mode
        :type stat_mode: StatisticMode or str
        :return: statistical results
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.table_name": """str: Return the table name of the dataset. For database datasources, Return the name of the data table corresponding to this dataset in the database; for file datasource, Return the table name of the storage attribute of this dataset. """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.to_json": """
        Output the information of the dataset to the json string. The json string content of the dataset includes the connection information of the datasource and the name of the dataset.

        :rtype: str

        Example::
         >>> ds = Workspace().get_datasource('data')
         >>> print(ds[0].to_json())
         {"name": "location", "datasource": {"type": "UDB", "alias": "data", "server": "E:/data.udb", "is_readonly": false}}

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.truncate": """
        Clear all records in the vector dataset.

        :return: Whether clearing the record is successful, it Return True if it succeeds, and False if it fails.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.type": """DatasetType: Return the dataset type """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.update_field": """
        According to the specified field name to be updated, the field value of all records that meet the attributeFilter condition is updated with the specified field value for updating. The field that needs to be updated cannot be a system field.
        That is to say, the field to be updated cannot be a field starting with sm (except smUserID).

        :param item: field name or serial number
        :type item: str or int
        :param value: Specify the field value for update.
        :type value: int or float or str or datetime.datetime or bytes or bytearray
        :param str attr_filter: The query condition of the record to be updated, if the attributeFilter is an empty string, all records in the table are updated
        :return: Return True if the field is updated successfully, otherwise Return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVector.update_field_express": """
        According to the specified field name to be updated, use the specified expression calculation result to update the field values of all records that meet the query conditions. The fields need to be updated cannot be the system fields, which means they cannot be fields starting with Sm (except smUserID).

        :param item: field name or serial number
        :type item: str or int
        :param str express: The specified expression, the expression can be a field operation or a function operation. For example: "SMID", "abs(SMID)", "SMID+1", "'string'".
        :param str attr_filter: The query condition of the record to be updated, if the attributeFilter is an empty string, all records in the table are updated
        :return: Return True if the field is updated successfully, otherwise Return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo": """
        Vector dataset information class. Include the information of the vector dataset, such as the name of the vector dataset, the type of the dataset, the encoding method, whether to use file cache, etc. File caching is only for map frame index
    
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.__init__": """
        Construct vector dataset information class

        :param str name: dataset name
        :param dataset_type: dataset type
        :type dataset_type: DatasetType or str
        :param encode_type: The compression encoding method of the dataset. Supports four compression encoding methods, namely single-byte, double-byte, three-byte and four-byte encoding methods
        :type encode_type: EncodeType or str
        :param bool is_file_cache: Whether to use file cache. File cache is only useful for map frame index
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.encode_type": """EncodeType: The compression encoding method of the dataset. Supports four compression encoding methods, namely single-byte, double-byte, three-byte and four-byte encoding the way""",

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.from_dict": """
        Read DatasetVectorInfo object from dict

        :param dict values: dict object containing vector dataset information, see: py:meth:`to_dict`
        :rtype: self
        :rtype: DatasetVectorInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.is_file_cache": """bool: Whether to use file cache. File cache is only useful for image frame indexing.""",

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.make_from_dict": """
        Construct DatasetVectorInfo object from dict

        :param dict values: dict object containing vector dataset information, see: py:meth:`to_dict`
        :rtype: DatasetVectorInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.name": """str: dataset name, limitation of the name of the dataset: The length of the dataset name is limited to 30 characters (that is, it can be 30 English letters or 15 Chinese characters), the characters composing the dataset name can be
        letters, Chinese characters, numbers and underscores. The dataset name cannot start with numbers and underscores. If it starts with a letter, the dataset name cannot conflict with the reserved keywords of the database. """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.set_encode_type": """
        Set the compression encoding method of the dataset

        :param value: The compression encoding method of the dataset
        :type value: EncodeType or str
        :return: self
        :rtype: DatasetVectorInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.set_file_cache": """
        Set whether to use file cache. The file cache is only useful for map frame indexing.

        :param bool value: Whether to use file cache
        :return: self
        :rtype: DatasetVectorInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.set_name": """
        Set the name of the dataset

        :param str value: dataset name
        :return: self
        :rtype: DatasetVectorInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.set_type": """
        Set the type of dataset

        :param value: dataset type
        :type value: DatasetType or str
        :return: self
        :rtype: DatasetVectorInfo
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.to_dict": """
        Output the information of the current object as a dict object

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVectorInfo.type": """DatasetType: Dataset Type""",

    "iobjectspy._jsuperpy.data.dt.DatasetVolume": """""",

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.bounds": """
        Rectangle: Return the smallest bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset, represents the geographic range of 
        the current grid or image.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.close": """
        Used to close the current dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.datasource": """ Datasource: Return the datasource object to which the current dataset belongs""",

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.description": """str: Return the description information of the dataset added by the user.""",

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.encode_type": """
        EncodeType: Return the encoding method of this dataset when data is stored. Using compression encoding for dataset can reduce the space occupied by data storage and reduce the network load and server load during data transmission.
        The encoding methods supported by the vector dataset are Byte, Int16, Int24, Int32, SGL, LZW, DCT, and can also be specified as not using encoding methods. The encoding methods supported by raster data are DCT, SGL, LZW, 
        Or no encoding. For details, see: py:class:`EncodeType` type
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.from_json": """
        Get the dataset from the json string of the dataset. If the datasource is not opened, the datasource will be opened automatically.

        :param str value: json string
        :return: dataset object
        :rtype: Dataet
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.is_open": """
        Judge whether the dataset has been opened, return True when the dataset is opened, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.is_readonly": """
        Determine whether the dataset is read-only. If the dataset is read-only, no operations can be performed to rewrite the dataset. If the dataset is read-only, return True, otherwise return False.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.name": """str: Return the name of the dataset """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.open": """
        Open the dataset, return True if the dataset is opened successfully, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.prj_coordsys": """PrjCoordSys: Return the projection information of the dataset.""",

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.rename": """
        Modify dataset name

        :param str new_name: new dataset name
        :return: Return True if the modification is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.set_bounds": """
        Set the minimum bounding rectangle that contains all objects in the dataset. For a vector dataset, it is the smallest bounding rectangle of all objects in the dataset; for a raster dataset,
        it represents the geographic range of the current grid or image.

        :param Rectangle rc: The smallest bounding rectangle that contains all objects in the dataset.
        :return: self
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.set_description": """
        Set the description information of the dataset added by the user.

        :param str value: The description of the dataset added by the user.
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.set_prj_coordsys": """
        Set the projection information of the dataset

        :param PrjCoordSys value: projection information
        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.table_name": """str: Return the table name of the dataset. For database datasources, Return the name of the data table corresponding to this dataset in the database; for file datasource, Return the table name of the storage attribute of this dataset. """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.to_json": """
        Output the information of the dataset to the json string. The json string content of the dataset includes the connection information of the datasource and the name of the dataset.

        :rtype: str

        Example::
         >>> ds = Workspace().get_datasource('data')
         >>> print(ds[0].to_json())
         {"name": "location", "datasource": {"type": "UDB", "alias": "data", "server": "E:/data.udb", "is_readonly": false}}

        """,

    "iobjectspy._jsuperpy.data.dt.DatasetVolume.type": """DatasetType: Return the dataset type """,

    "iobjectspy._jsuperpy.data.dt.JoinItem": """
    Connection information class. Used to connect vector dataset with external tables. The external table can be a DBMS table corresponding to another vector dataset (there is no spatial geometric information in the pure attribute dataset), or it can also be a user-created
    business table. It should be noted that the vector dataset and the external table must belong to the same datasource. When a connection is established between the two tables, by operating the main table, you can query the external table and make thematic map
    and do some analysis etc. When there is a one-to-one or many-to-one relationship between the two tables, join can be used. When it is a many-to-one relationship, it is allowed to specify the association between multiple fields. Instances of this type can be created.

    There are two ways to establish a connection between dataset tables, one is join and the other is link. The related settings of the join are implemented through the JoinItem class, and the link settings are through LinkItem class.
    In addition, the two dataset tables used to establish a connection must be under the same datasource, and the two dataset tables used to establish an linked relationship may not be under the same datasource.

    The following example of the query is used to illustrate the difference between connect and link. Suppose the dataset table used for query is DatasetTableA, and the table to be linked or connected is DatasetTableB.
    The connected or linked relationship between DatasetTableA and DatasetTableB is used to query the records in DatasetTableA that meet the query conditions:

        -Join
            Set the connection information to connect DatasetTableB to DatasetTableA, that is, establish the JoinItem class and set its properties. When the query operation of DatasetTableA is executed,
            according to the connection conditions and query conditions, the system will form a query result table between the content in DatasetTableA and DatasetTableB that meets the conditions, and this
            query table is stored in the memory. When the result needs to be returned, the corresponding content is retrieved from the memory.

        -Association (link)
            Set the association information that associates DatasetTableB (secondary table) to DatasetTableA (main table), that is, establish the LinkItem class and set its properties, DatasetTableA and
            DatasetTableB use the foreign key (LinkItem.foreign_keys) of the primary table DatasetTableA and the primary key of the secondary table DatasetTableB
            (LinkItem.primary_keys method) to realize the association. When the query operation of DatasetTableA is executed, according to the filter conditions and query conditions in the associated information,
            the system will query the content that meets the conditions in DatasetTableA and DatasetTableB respectively. The query results of DatasetTableA and DatasetTableB are regarded as independent
            and stored in the memory as two result table. When the results need to be returned, SuperMap will splice the two results and return them. Therefore, from the perspective of the application layer, connect and link operations are very similar.

        -LinkItem only supports left connection, UDB, PostgreSQL and DB2 datasources do not support LinkItem, that is, setting LinkItem for UDB, PostgreSQL and DB2 data engines does not work;

        -JoinItem currently supports left joins and inner joins, but does not support full joins and right joins. UDB engine does not support inner joins;

        -Constraints for using LinkItem: Spatial data and attribute data must have associated conditions, that is, there are associated fields between the main spatial dataset and the external attribute table. Main spatial dataset: The dataset used to associate with external tables. External attribute table: a data table created by the user through Oracle or SQL Server, or a DBMS table corresponding to another vector dataset.


    Example::

        >>> ds = Workspace().get_datasource('data')
        >>> dataset_world = ds['World']
        >>> dataset_capital = ds['Capital']
        >>> foreign_table_name = dataset_capital.table_name
        >>>
        >>> join_item = JoinItem()
        >>> join_item.set_foreign_table(foreign_table_name)
        >>> join_item.set_join_filter('World.capital=%s.capital'% foreign_table_name)
        >>> join_item.set_join_type(JoinType.LEFTJOIN)
        >>> join_item.set_name('Connect')

        >>> query_parameter = QueryParameter()
        >>> query_parameter.set_join_items([join_item])
        >>> recordset = dataset_world.query(query_parameter)
        >>> print(recordset.get_record_count())
        >>> recordset.close()

    """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.__init__": """
        Construct a JoinItem object

        :param str name: the name of the connection information object
        :param str foreign_table: the name of the foreign table
        :param str join_filter: The join expression with the external table, that is, set the associated field between the two tables
        :param str join_type: the type of connection between the two tables
        """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.foreign_table": """str: the name of the external table""",

    "iobjectspy._jsuperpy.data.dt.JoinItem.from_dict": """
        Read JoinItem information from dict

        :param dict values: dict containing JoinItem information, see to_dict for details
        :return: self
        :rtype: JoinItem
        """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.from_json": """
        Parse the JoinItem information from the json string to construct a new JoinItem object

        :param str value: json string
        :rtype: JoinItem
        """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.join_filter": """str: The join expression with the external table, that is, set the associated field between the two tables """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.join_type": """JoinType: The type of connection between the two tables""",

    "iobjectspy._jsuperpy.data.dt.JoinItem.make_from_dict": """
        Read information from dict to construct JoinItem object.

        :param dict values: dict containing JoinItem information, see to_dict for details
        :rtype: JoinItem
        """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.name": """str: The name of the connection information object""",

    "iobjectspy._jsuperpy.data.dt.JoinItem.set_foreign_table": """
        Set the connection information external table name

        :param str value: external table name
        :return: self
        :rtype: JoinItem
        """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.set_join_filter": """
        Set the connection expression with the external table, that is, set the associated fields between the two tables. For example, connect the District field of a house's polygon dataset (Building) to the Region field of a
        Homeowner's pure property dataset (Owner), and the table names corresponding to the two dataset are Table_Building and Table_Owner respectively, and the connection expression is
        'Table_Building.district = Table_Owner.region', when multiple fields are connected, use AND to connect multiple expressions.

        :param str value: The connection expression with the external table, that is, set the associated field between the two tables
        :return: self
        :rtype: JoinItem
        """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.set_join_type": """
        Set the type of connection between the two tables. The connection type is used to query the two connected tables and determines the condition of the records returned.

        :param value: the type of connection between the two tables
        :type value: JoinType or str
        :return: self
        :rtype: JoinItem
        """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.set_name": """
        Set the name of the connection information object

        :param str value: connection information name
        :return: self
        :rtype: JoinItem
        """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.to_dict": """
        Output current object information as dict

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.dt.JoinItem.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem": """
    The Link information class is used to associate the vector dataset with other dataset. The linked dataset can be the DBMS table corresponding to another vector dataset (where there is no spatial geometric information in the pure attribute dataset). User-created
    Business tables need to be plugged into the SuperMap datasource. It should be noted that the vector dataset and the linked dataset can belong to different datasources. There are two ways to establish the connection between the dataset tables, one is
    join, one is link. The related settings of the connection are implemented through the JoinItem class, and the related settings of the link are implemented through the LinkItem class.
    Besides, the two dataset tables must be under the same datasource, and the two dataset tables used to establish the linked relationship may not be under the same datasource.
    The following example of the query is used to illustrate the difference between connect and link. Suppose the dataset table used for query is DatasetTableA, and the table to be linked or connected is DatasetTableB.
    The connection or link relationship between DatasetTableA and DatasetTableB is used to query the records in DatasetTableA that meet the query conditions:

        -Join
            Set the connection information to connect DatasetTableB to DatasetTableA, that is, establish the JoinItem class and set its properties. When the query operation of DatasetTableA is executed,
            according to the connection conditions and query conditions, the system will form a query result table between the content in DatasetTableA and DatasetB that meets the conditions, and this
            query table is stored in the memory. When the result needs to be returned, the corresponding content is retrieved from the memory.

        -Association (link)
            Set the linked information that link DatasetTableB (secondary table) to DatasetTableA (main table), that is, establish the LinkItem class and set its properties. DatasetTableA and
            DatasetTableB use the foreign key (LinkItem.foreign_keys) of the primary table DatasetTableA and the primary key of the secondary table DatasetTableB
            (LinkItem.primary_keys method) to realize the association, when the query operation of DatasetTableA is executed, the system will according to the filter conditions and query conditions in the associated information,
            Query the content that meets the conditions in DatasetTableA and DatasetTableB respectively. The query results of DatasetTableA and DatasetTableB are regarded as independent
            and the two result tables are stored in the memory. When the results need to be returned, SuperMap will splice the two results and return them. Therefore, from the perspective of the application layer, the connect and link operations are very similar.

        -LinkItem only supports left connection, UDB, PostgreSQL and DB2 datasources do not support LinkItem, that is, setting LinkItem for UDB, PostgreSQL and DB2 data engines does not work;

        -JoinItem currently supports left joins and inner joins, but does not support full joins and right joins. UDB engine does not support inner joins;

        -Constraints for using LinkItem: Spatial data and attribute data must have associated conditions, that is, there are associated fields between the main spatial dataset and the external attribute table. Main spatial dataset: The dataset used to associate with external tables. External attribute table: a data table created by the user through Oracle or SQL Server, or a DBMS table corresponding to another vector dataset.

    Example:
        # The'source' dataset is the main dataset, the field used for the source dataset is'LinkID', the'lind_dt' dataset is the external dataset, that is, the dataset to be linked, and the field used for the link in link_dt is' ID'

        >>> ds_db1 = Workspace().get_datasource('data_db_1')
        >>> ds_db2 = Workspace().get_datasource('data_db_2')
        >>> source_dataset = ds_db1['source']
        >>> linked_dataset = ds_db2['link_dt']
        >>> linked_dataset_name = linked_dataset.name
        >>> linked_dataset_table_name = linked_dataset.table_name
        >>>
        >>> link_item = LinkItem()
        >>>
        >>> link_item.set_connection_info(ds_db2.connection_info)
        >>> link_item.set_foreign_table(linked_dataset_name)
        >>> link_item.set_foreign_keys(['LinkID'])
        >>> link_item.set_primary_keys(['ID'])
        >>> link_item.set_link_fields([linked_dataset_table_name+'.polulation'])
        >>> link_item.set_link_filter('ID <100')
        >>> link_item.set_name('link_name')

    """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.__init__": """
        Construct LinkItem object

        :param list[str] foreign_keys: The main dataset is used to correlate the fields of the foreign table
        :param str name: the name of the associated information object
        :param str foreign_table: The name of the dataset of the foreign table, that is, the name of the associated dataset
        :param list[str] primary_keys: the associated fields in the external table dataset
        :param list[str] link_fields: the name of the field being queried in the external table dataset
        :param str link_filter: query condition of external table dataset
        :param DatasourceConnectionInfo connection_info: connection information of the datasource where the external table dataset is located
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.connection_info": """DatasourceConnectionInfo: Connection information of the datasource where the external table dataset is located""",

    "iobjectspy._jsuperpy.data.dt.LinkItem.foreign_keys": """list[str]: The main dataset is used to associate external table fields""",

    "iobjectspy._jsuperpy.data.dt.LinkItem.foreign_table": """str: The name of the dataset of the external table, that is, the name of the associated dataset """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.from_dict": """
        Read information from dict to construct LinkItem object.

        :param dict values: dict containing LinkItem information, see to_dict for details
        :return: self
        :rtype: LinkItem
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.from_json": """
        Construct LinkItem object from json string

        :param str value: json string information
        :rtype: LinkItem
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.link_fields": """list[str]: The name of the field being queried in the external table dataset """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.link_filter": """str: query condition of external table dataset """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.make_from_dict": """
        Read information from dict to construct LinkItem object, construct a new LinkItem object

        :param dict values: dict containing LinkItem information, see to_dict for details
        :rtype: LinkItem
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.name": """str: the name of the associated information object""",

    "iobjectspy._jsuperpy.data.dt.LinkItem.primary_keys": """list[str]: the associated fields in the external table dataset """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.set_connection_info": """
        Set the connection information of the datasource where the external dataset is located

        :param DatasourceConnectionInfo value: Connection information of the datasource where the external table dataset is located
        :return: self
        :rtype: LinkItem
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.set_foreign_keys": """
        Set the main dataset to be used to correlate the fields of the external table

        :param list[str] value: The main dataset is used to associate the fields of the external table
        :return: self
        :rtype: LinkItem
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.set_foreign_table": """
        Set the name of the dataset of the external table, that is, the name of the associated dataset

        :param str value: The name of the dataset of the external table, that is, the name of the associated dataset
        :return: self
        :rtype: LinkItem
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.set_link_fields": """
        Set the name of the field to be queried in the external table dataset

        :param list[str] value: The name of the field being queried in the external table dataset
        :return: self
        :rtype: LinkItem
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.set_link_filter": """
        Set the query conditions of the external table dataset

        :param str value: query condition of external table dataset
        :return: self
        :rtype: LinkItem
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.set_name": """
        Set the name of the associated information object

        :param str value: the name of the associated information object
        :return: self
        :rtype: LinkItem
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.set_primary_keys": """
        Set the associated fields in the external dataset

        :param list[str] value: The associated fields in the external table dataset
        :return: self
        :rtype: LinkItem
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.to_dict": """
        Output information of current object to dict

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.dt.LinkItem.to_json": """
        Output current object information to json string, see to_dict for details.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter": """
        Query parameter class. Used to describe the restrictive conditions of a conditional query, such as the SQL statements, cursor methods, and spatial data position relationship condition settings. Conditional query, is to query all
        the elements of a certain condition of the record, and the result of the query is a record set. The query parameter class is used to set the query conditions of the conditional query to obtain the record set. Conditional query includes two main query methods, one is SQL
        query, also known as attribute query, is to select records by constructing SQL conditional statements containing attribute fields, operation symbols and values to obtain a record set; the other is spatial query, which is based on geographic or spatial features
        to query the record to get the record set.
    
        QueryParameter contains the following parameters:
    
        -attribute_filter: str
            The SQL conditional statement constructed by the query is the SQL WHERE clause statement. SQL query is also called attribute query, which uses one or more SQL conditional statements to query records.
            SQL statements are conditional statements that include attribute fields, operators, and values. For example, if you want to query a clothing store in a business district whose annual sales exceeded 300,000 last year, the SQL query statement constructed is:
    
            >>> attribute_filter ='Sales> 30,0000 AND SellingType ='Garment''
    
            For datasources of different engines, the applicable conditions and usage of different functions are different. For database-type datasources (Oracle Plus, SQL Server Plus, PostgreSQL and DB2 datasources), please refer to the database related documents for the usage of the functions.
    
        -cursor_type: CursorType
            The type of cursor used by the query. SuperMap supports two types of cursors, dynamic cursors and static cursors. When using dynamic cursor query, the record set will be dynamically refreshed, consuming a lot of resources.
            When using a static cursor, the query is a static copy of the record set, which is more efficient. It is recommended to use a static cursor when querying. The record set obtained by using a static cursor is not editable.
            For details, see CursorType type.
            The DYNAMIC type is used by default.
    
        -has_geometry: bool
            Whether the query result contains geometric object fields. If the spatial data is not taken during the query, that is, only the attribute information is queried, then in the returned Recordset, all the methods that operate on the spatial objects of the record set
            will be invalid. For example, calling :py:meth:`Recordset.get_geometry` will return null.
    
        -result_fields: list of str
            Set the query result field collection. For the record set of the query result, you can set the fields contained in it. If it is empty, all fields will be queried.
    
        -order_by: list of str
            SQL query sort field. The records in the record set obtained by SQL query can be sorted according to the specified field, and can be specified as ascending or descending order, where asc means ascending order and desc means descending order. The field used for sorting must be numeric. For example, to sort by SmID in descending order, you can set it as:

            >>> query_paramater.set_order_by(['SmID desc'])
    
        -group_by: list of str
            SQL query field for grouping conditions. For each field in the record set obtained by SQL query, you can group according to the specified field, and the records with the same specified field value will be placed together.
            note:
    
                -Spatial query does not support group_by, otherwise the results of spatial query may be incorrect
                -Group_by is valid only when cursor_type is STATIC
    
        -spatial_query_mode: SpatialQueryMode
            Spatial query mode
    
        -spatial_query_object: DatasetVector or Recordset or Geometry or Rectangle or Point2D
            The search object of the spatial query.
            If the search object is a dataset or record set type, it must be consistent with the geographic coordinate system of the dataset corresponding to the layer being searched.
            When there are overlapping objects in the search dataset/record set, the results of the spatial query may be incorrect. It is recommended to traverse the search dataset/record set, and use a single-object query for spatial query one by one.
    
        -time_conditions: list of TimeCondition
            Temporal model query conditions. See: py:class:`TimeCondition` description for details.
    
        -link_items: list of LinkItem
            Related query information. When the vector dataset being queried has an associated external table, the result of the query will contain records that meet the conditions in the associated external table. Specific view: py:class:`LinkItem` description
    
        -join_items: list of JoinItem
            Connect to query information. When the vector dataset being queried has a connected external table, the result of the query will contain records that meet the conditions in the connected external table. Specific view: py:class:`JoinItem` description
    
    
        Example::
            # Perform SQL query
    
            >>> parameter = QueryParameter('SmID <100','STATIC', False)
            >>> ds = Datasource.open('E:/data.udb')
            >>> dt = ds['point']
            >>> rd = dt.query(parameter)
            >>> print(rd.get_record_count())
            99
            >>> rd.close()
    
    
            # Perform spatial query
    
            >>> geo = dt.get_geometries('SmID = 1')[0]
            >>> query_geo = geo.create_buffer(10, dt.prj_coordsys,'meter')
            >>> parameter.set_spatial_query_mode('contain').set_spatial_query_object(query_geo)
            >>> rd2 = dt.query(parameter)
            >>> print(rd2.get_record_count())
            10
            >>> rd2.close()
    
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.attribute_filter": """str: SQL conditional statement constructed by the query, that is, SQL WHERE clause statement.""",

    "iobjectspy._jsuperpy.data.dt.QueryParameter.cursor_type": """ CursorType: The cursor type used by the query """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.from_dict": """
        Read query parameters from dict

        :param dict values: A dict object containing query parameters. Specific view: py:meth:`to_dict`
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.from_json": """
        Construct dataset query parameter object from json string

        :param str value: json string
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.group_by": """list[str]: SQL query group condition field """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.has_geometry": """bool: Whether the query result contains geometric object fields""",

    "iobjectspy._jsuperpy.data.dt.QueryParameter.join_items": """list[JoinItem]: Join query information. When the vector dataset being queried has connected external tables, the query results will contain the corresponding The records that meet the conditions in the connected external table. For details, see: py:class:`JoinItem` description """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.link_items": """list[LinkItem]: Related query information. When the vector dataset being queried has related external tables, the query results will contain related The records that meet the conditions in the linked external table. For details, see: py:class:`LinkItem` description """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.make_from_dict": """
        Construct dataset query parameter object from dict

        :param dict values: A dict object containing query parameters. Specific view: py:meth:`to_dict`
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.order_by": """list[str]: SQL query sort field.""",

    "iobjectspy._jsuperpy.data.dt.QueryParameter.result_fields": """list[str]: query result field collection. For the query result record set, you can set the fields contained in it, if it is empty, then all fields will be queried .""",

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_attribute_filter": """
        Set attribute query conditions

        :param str value: Attribute query conditions
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_cursor_type": """
        Set the cursor type used by the query. The default is DYNAMIC

        :param value: cursor type
        :type value: CursorType or str
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_group_by": """
        Set the field of the SQL query grouping condition.

        :param list[str] value: SQL query field for grouping conditions
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_has_geometry": """
        Set whether to query geometric objects. If set to False, geometric objects will not be returned, the default is True

        :param bool value: Query whether to include geometric objects.
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_join_items": """
        Set query conditions for connection query

        :param list[JoinItem] value: the query condition of the query
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_link_items": """
        Set query conditions for related queries

        :param list[LinkItem] value: query condition of related query
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_order_by": """
        Set the SQL query sort field

        :param list[str] value: SQL query sort field
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_result_fields": """
        Set query result fields

        :param list[str] value: query result field
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_spatial_query_mode": """
        Set the spatial query mode, see: py:class:`.SpatialQueryMode` description

        :param value: The query mode of the spatial query.
        :type value: SpatialQueryMode or str
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_spatial_query_object": """
        Set the search object of spatial query

        :param value: Search object for spatial query
        :type value: DatasetVector or Recordset or Geometry or Rectangle or Point2D
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.set_time_conditions": """
        Set the query conditions of the time field for spatiotemporal query

        :param list[TimeCondition] value: query conditions for time-space query
        :return: self
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.spatial_query_mode": """SpatialQueryMode: Spatial query mode.""",

    "iobjectspy._jsuperpy.data.dt.QueryParameter.spatial_query_object": """DatasetVector or Recordset or Geometry or Rectangle or Point2D: The search object for spatial query.""",

    "iobjectspy._jsuperpy.data.dt.QueryParameter.time_conditions": """list[TimeCondition]: time-space model query conditions. For details, please refer to: py:class:`TimeCondition` description.""",

    "iobjectspy._jsuperpy.data.dt.QueryParameter.to_dict": """
        Output dataset query parameter information to dict

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.dt.QueryParameter.to_json": """
        Output query parameters as json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset": """
        Record set class. Through this class, the data in the vector dataset can be manipulated. Datasources include file type and database type. The spatial geometric information and attribute information in the database type data are stored in an integrated manner. Each vector dataset
        corresponds to a DBMS table, in which its geometric shape and attribute information are stored in an integrated manner. The geometric fields in the table store the spatial geometric information of the elements. For pure attribute dataset in vector dataset, there are no
        geometric fields, and the recordset is a subset of the DBMS table. The spatial geometry information and attribute information are stored separately in the file-type data, the application of the record set may be more confusing. During operation, the distinction between file type and database type data is shielded, 
        and the data is regarded as a table of integrated storage of spatial information and attribute information, while the record set is a subset of which is taken out for operation. One record in a recordset, or a
        row, corresponds to an element, contains spatial geometric information and attribute information of the feature. A column in the record set corresponds to the information of a field.
    
        The record set can directly obtain a record set from the vector dataset. There are two methods: the user can directly return from the vector dataset through the :py:meth:`DatasetVector.get_recordset` method
        It can also be returned through a query statement. The difference is that the record set obtained by the former contains all the spatial geometric information and attribute information of this type of set, while the record set obtained by the latter is the record set filtered by the query statement.
    
        The following code demonstrates reading data from a record set and batch writing data to a new record set::
    
        >>> dt = Datasource.open('E:/data.udb')['point']
        >>> rd = dt.query_with_filter('SmID <100 or SmID> 1000','STATIC')
        >>> all_points = []
        >>> while rd.has_next():
        >>> geo = rd.get_geometry()
        >>> all_points.append(geo.point)
        >>> rd.move_next()
        >>> rd.close()
        >>>
        >>> new_dt = dt.datasource.create_vector_dataset('new_point','Point', adjust_name=True)
        >>> new_dt.create_field(FieldInfo('object_time', FieldType.DATETIME))
        >>> new_rd = new_dt.get_recordset(True)
        >>> new_rd.batch_edit()
        >>> for point in all_points:
        >>> new_rd.add(point, {'object_time': datetime.datetime.now()})
        >>> new_rd.batch_update()
        >>> print(new_rd.get_record_count())
        >>> new_rd.close()
    
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.add": """
        Add a record to the record set. The record set must open the edit mode, see: py:meth:`edit` and :py:meth:`batch_edit`

        :param data: The spatial object to be written. If the dataset of the record set is an attribute table, pass in None. If data is not empty, the type of the geometric object must match the type of the dataset to write successfully.
                     E.g:

                     -:py:class:`Point2D` and :py:class:`GeoPoint` support writing to point dataset and CAD dataset
                     -:py:class:`GeoLine` supports writing to line dataset and CAD dataset
                     -:py:class:`Rectangle` and :py:class:`GeoRegion` support writing to surface dataset and CAD dataset
                     -:py:class:`GeoText` supports writing to text dataset and CAD dataset

        :type data: Point2D or Rectangle or Geometry or Feature
        :param dict values: The attribute field values to be written. It must be a dict. The key value of dict is the field name, and the value of dict is the field value. If data is Feature, this parameter is invalid because Feature already contains attribute field values.
        :return: Return True if writing is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.batch_edit": """
        The batch update operation begins. After the batch update operation is completed, you need to use :py:meth:`batch_update` to submit the modified records. You can use: py:meth:`set_batch_record_max` to modify
        the maximum number of records submitted as a result of a batch update operation, see: py:meth:`set_batch_record_max`

        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.batch_update": """
        Unified submission of batch update operations. After calling this method, the previous batch update operation will take effect, and the update status will become a single update. If you need to perform subsequent operations in batches, you need to call the :py:meth:`batch_edit` method again.
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.bounds": """Rectangle: Return the bounding rectangle of the geometric object corresponding to all records in the attribute data table of the record set.""",

    "iobjectspy._jsuperpy.data.dt.Recordset.close": """
        Release the record set. The record set must be released after the record set is no longer used.
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.dataset": """DatasetVector: The dataset where the record set is located""",

    "iobjectspy._jsuperpy.data.dt.Recordset.datasource": """Datasource: The datasource where the record set is located""",

    "iobjectspy._jsuperpy.data.dt.Recordset.delete": """
        Used to delete the current record in the dataset, and return true if successful.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.delete_all": """
        Physically delete all the records in the specified record set, that is, delete the records from the physical storage medium of the computer and cannot be restored.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.dispose": """
        Release the record set, the record set must be released after the completion of the operation and no longer in use, the same function as close
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.edit": """
        Lock and edit the current record of the record set, return True if successful. After editing with this method, you must use the :py:meth:`update` method to update the record set, and brfore: py:meth:`update`,
        the current recorded position cannot be moved, otherwise the editing fails and the record set may be damaged.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.field_infos": """list[FieldInfo]: All field information of the dataset""",

    "iobjectspy._jsuperpy.data.dt.Recordset.from_json": """
        Parse from the json string to obtain the record set

        :param str value: json string
        :rtype: Recordset
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_batch_record_max": """int: Return the maximum number of records automatically submitted as a result of the batch update operation""",

    "iobjectspy._jsuperpy.data.dt.Recordset.get_feature": """
        Get the feature object of the current record, if the retrieval fails, return None

        :rtype: Feature
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_features": """
        Get all the feature objects of the record set. After calling this method, the position of the record set will move to the very beginning position.

        :rtype: list[Feature]
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_field_count": """
        Get the number of fields

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_field_info": """
        Get field information based on field name or serial number

        :param value: field name or serial number
        :type value: str or int
        :return: field information
        :rtype: FieldInfo
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_geometries": """
        Get all geometric objects in the record set. After calling this method, the position of the record set will move to the very beginning position.

        :rtype: list[Geometry]
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_geometry": """
        Get the geometric object of the current record, if there is no geometric object in the record set or get failed, return None

        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_id": """
        Return the ID number of the geometric object corresponding to the current record in the attribute table of the dataset (ie the value of the SmID field).

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_query_parameter": """
        Get the query parameters corresponding to the current record set

        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_record_count": """
        Return the number of records in the record set

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_value": """
        Get the field value of the specified attribute field in the current record

        :param item: field name or serial number
        :type item: str or int
        :rtype: int or float or str or datetime.datetime or bytes or bytearray
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.get_values": """
        Get the attribute field value of the current record.

        :param bool exclude_system: Whether to include system fields. All fields beginning with "Sm" are system fields. The default is True
        :param bool is_dict: Whether to return in the form of a dict. If a dict is returned, the key of the dict is the field name and value is the attribute field value. Otherwise, the field value is returned as a list. The default is False
        :return: attribute field value
        :rtype: dict or list
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.has_next": """
        Whether there is another record in the record set that can be read, if yes, return True, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.index_of_field": """
        Get the serial number of the specified field name

        :param str name: field name
        :return: If the field exists, return the serial number of the field, otherwise return -1
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.is_bof": """
        Determine whether the current record position is before the first record in the record set (of course, there is no data before the first record), if it is, return True; otherwise, return False.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.is_close": """
        Determine whether the record set has been closed. It Return True if it is closed, otherwise it Return False.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.is_empty": """
        Determine whether there are records in the record set. True means there is no data in the record set

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.is_eof": """
        Whether the record set reaches the end, if it reaches the end, return True, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.is_readonly": """
        Judge whether the record set is read-only, read-only return True, otherwise return False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.move": """
        Move the current record position by 'count' lines, and set the record at that position as the current record. Return True if successful. If count is less than 0, it means to move forward, if it is greater than 0, it means to move backward. If it is equal to 0, it will not move.
        If the number of rows moved is too many, beyond the scope of the Recordset, it will return False and the current record will not move.

        :param int count: the number of records moved
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.move_first": """
        Used to move the current record position to the first record so that the first record becomes the current record. Return True if successful.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.move_last": """
        Used to move the current record position to the last record, making the last record the current record. Return True if successful

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.move_next": """
        Move the current record position to the next record to make this record the current record. Return True if successful, otherwise False

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.move_prev": """
        Move the current record position to the previous record to make this record the current record. Return True if successful.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.move_to": """
        It is used to move the current record position to the specified position, and the record at the specified position is regarded as the current record. Return True if successful.

        :param int position: the position to move to, which is the first record
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.refresh": """
        Refresh the current record set to reflect the changes in the dataset. Return True if successful, otherwise return False. The difference between this method and: py:meth:`update` is that the update method is to submit
        the modified result, and the refresh method is to dynamically refresh the record set. In order to dynamically display the changes in the dataset during multi-user concurrent operations, the refresh method is often used.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.seek_id": """
        Search the record with the specified ID number in the record and locate the record as the current record. Return true if successful, otherwise false

        :param int value: ID number to search
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.set": """
        Modify the current record. The record set must open the edit mode, see: py:meth:`edit` and :py:meth:`batch_edit`

        :param data: The space object to be written. If the dataset of the record set is an attribute table, pass in None. If data is not empty, the type of the geometric object must match the type of the dataset to write successfully.
                     E.g:

                     -:py:class:`Point2D` and :py:class:`GeoPoint` support writing to point dataset and CAD dataset
                     -:py:class:`GeoLine` supports writing to line dataset and CAD dataset
                     -:py:class:`Rectangle` and :py:class:`GeoRegion` support writing to surface dataset and CAD dataset
                     -:py:class:`GeoText` supports writing to text dataset and CAD dataset

        :type data: Point2D or Rectangle or Geometry or Feature
        :param values: The attribute field values to be written. It must be a dict. The key value of dict is the field name, and the value of dict is the field value. If data is Feature, this parameter is invalid because
                       Feature already contains attribute field values. If data is empty, only the attribute field value will be written.
        :return: Return True if writing is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.set_batch_record_max": """
        Set the maximum number of records submitted as a result of a batch update operation. After the batch update of all records that need to be updated is completed, when the update result is submitted, if the number of updated records exceeds the maximum number of records, The system will submit the updated results in batches,
        that is, the maximum number of records submitted each time, until all updated records are submitted. For example, if the maximum number of records submitted is set to 1000, and the number of records to be updated is 3800,
        after the records are updated in batches, the system will submit the update results in four times, that is, 1,000 records for the first time, 1,000 for the second time, 1,000 for the third time, and 800 for the fourth time.

        :param int count: The maximum number of records submitted as a result of the batch update operation.
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.set_value": """
        Write the field value to the specified field. The record set must open the edit mode, see: py:meth:`edit` and :py:meth:`batch_edit`

        :param item: field name or serial number, cannot be a system field.
        :type item: str or int
        :param value: The field value to be written. The corresponding relationship between field type and value type is:

                      -BOOLEAN: bool
                      -BYTE: int
                      -INT16: int
                      -INT32: int
                      -INT64: int
                      -SINGLE: float
                      -DOUBLE: float
                      -DATETIME: datetime.datetime or int (time stamp in seconds) or a string in the format "%Y-%m-%d %H:%M:%S"
                      -LONGBINARY: bytearray or bytes
                      -TEXT: str
                      -CHAR: str
                      -WTEXT: str
                      -JSONB: str

        :type value: bool or int or float or datetime.datetime or bytes or bytearray or str
        :return: Return True if successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.set_values": """
        Set the field value. The record set must open the edit mode, see: py:meth:`edit` and :py:meth:`batch_edit`

        :param dict values: The attribute field values to be written. Must be a dict, the key value of dict is the field name, and the value of dict is the field value
        :return: Return the number of successfully written fields
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.statistic": """
        Through the field name or serial number, the specified field, such as maximum, minimum, average, sum, standard deviation, and variance statistics.

        :param item: field name or serial number
        :type item: str or int
        :param stat_mode: statistical mode
        :type stat_mode: StatisticMode or str
        :return: Statistics results.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.to_json": """
        Output the dataset and query parameters of the current record set as a json string. Note that to_json using Recordset only saves the query parameters of the dataset information, and only applies to the result record set obtained by using the DatasetVector entry query, including
        :py:meth:`DatasetVector.get_recordset`, :py:meth:`DatasetVector.query`, :py:meth:`DatasetVector.query_with_bounds`,
        :py:meth:`DatasetVector.query_with_distance`, :py:meth:`DatasetVector.query_with_filter` and :py:meth:`DatasetVector.query_with_ids`.
        If it is a record set obtained by internal query of other functions, it may not be able to fully ensure whether the query parameters are consistent with the query parameters entered during the query.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.dt.Recordset.update": """
        Used to submit changes to the record set, including operations such as adding, editing records, and modifying field values. After using :py:meth:`edit` to modify the record set, you need to use update to submit the modification. Every time a record is modified,
        you need to call update once to commit the changes.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo": """
        Spatial index information class. This class provides the information needed to create a spatial index, including the type of spatial index, the number of leaf nodes, map fields, map width and height, and multi-level grid size.
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.__init__": """
        Construct the spatial index information class of the dataset.

        :param index_type: dataset spatial index type
        :type index_type: SpatialIndexType or str
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.from_dict": """
         Read SpatialIndexInfo information from dict

        :param dict values:
        :return: self
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.grid_center": """Point2D: The center point of the grid index. Generally the center point of the dataset.""",

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.grid_size0": """float: the size of the first level grid of the multi-level grid index""",

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.grid_size1": """float: the size of the second level grid of the multi-level grid index""",

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.grid_size2": """float: the size of the third level grid of the multi-level grid index""",

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.leaf_object_count": """int: the number of leaf nodes in the R-tree spatial index""",

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.make_from_dict": """
        Read information from the dict to construct a SpatialIndexInfo object.

        :param dict values:
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.make_mgrid": """
        Build a multi-level grid index

        Multi-level grid index, also called dynamic index.
        Multi-level grid index combines the advantages of R-tree index and quad-tree index, provides very good concurrent editing support, and has good universality. If you are not sure what kind of spatial index the data is suitable for, you can create multiple levels Grid index for it.
        Organize and manage data by dividing multi-layer grids. The basic method of grid indexing is to divide the dataset into equal or unequal grids according to certain rules, and record the position of each geographic object.
        The regular grid is commonly used in GIS. When a user performs a spatial query, first calculate the grid where the user query object is located, and quickly query the selected geographic object through the grid, which can optimize the query operation.

        :param Point2D center: the specified grid center point
        :param float grid_size0: The size of the first level grid. The unit is the same as the dataset
        :param float grid_size1: The size of the secondary grid. The unit is the same as the dataset
        :param float grid_size2: The size of the three-level grid. The unit is the same as the dataset
        :return: Multi-level grid index information
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.make_qtree": """
        Build quadtree index information.
        Quadtree index. Quadtree is an important hierarchical dataset structure, which is mainly used to express the spatial hierarchical relationship under two-dimensional coordinates. In fact, it is an extension of one-dimensional binary tree in two-dimensional space. So, the quadtree index
        is a map divided into four equal parts, and then divide it into four equal parts in each grid, subdividing it layer by layer until it can no longer be divided. Now in SuperMap, the quadtree can be divided into up to 13 layers. Based on Hilbert
        (Hilbert) coding ordering rules, from the quadtree, it is possible to determine which minimum range the indexed attribute value of each object instance in the index class belongs to. Thereby improving retrieval efficiency

        :param int level: The level of the quadtree, the maximum is 13 levels
        :return: Quadtree index information
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.make_rtree": """
        Build R-tree index information.
        R-tree index is a disk-based index structure. It is a natural expansion of B-tree (one-dimensional) in high-dimensional space. It is easy to integrate with existing database systems and can support various types of spatial query processing operations.
        It is widely used and is currently one of the most popular spatial indexing methods. R-tree spatial index is to design a more rectangular objects comprising a space, enclose some target objects that are spatially close to each other in this rectangle.
        These rectangles are used as spatial indexes, which contain pointers to the contained spatial objects.

        When performing a spatial search, first determine which rectangles fall in the search window, and then further determine which objects are the content to be searched. This can increase the retrieval speed.

        :param int leaf_object_count: the number of leaf nodes in the R-tree spatial index
        :return: R-tree index information
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.make_tile": """
        Construct map frame index information.
        In SuperMap, the spatial objects are classified according to a certain attribute field of the dataset or according to a given range, and the classified spatial objects are managed through the index to improve the query and retrieval speed

        :param float tile_width: tile width
        :param float tile_height: tile height
        :return: sheet index information
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.quad_level": """int: the level of the quadtree index""",

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.set_grid_center": """
        Set the center point of the grid index. It is generally the center point of the dataset.

        :param Point2D value: the center point of the grid index
        :return: self
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.set_grid_size0": """
        Set the size of the first-level grid in the multi-level grid index.

        :param float value: The size of the first level grid in the multi-level grid index.
        :return: self
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.set_grid_size1": """
        Set the size of the second-level index grid of the multi-level grid index. The unit is consistent with the unit of the dataset

        :param float value: The size of the second level index grid of the multilevel grid index
        :return: self
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.set_grid_size2": """
        Set the size of the third-level grid in the multi-level grid index.

        :param float value: The size of the three-level grid. The unit is the same as the dataset
        :return: self
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.set_leaf_object_count": """
        Set the number of leaf nodes in the R-tree spatial index.

        :param int value: the number of leaf nodes in the R-tree spatial index
        :return: self
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.set_quad_level": """
        Set the level of the quadtree index, the maximum value is 13

        :param int value: the level of the quadtree index
        :return: self
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.set_tile_height": """
        Set the height of the space index. The unit is consistent with the unit of the dataset range

        :param float value: the height of the space index
        :return: self
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.set_tile_width": """
        Set the width of the space index. The unit is consistent with the unit of the dataset range.

        :param float value: the width of the space index
        :return: self
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.set_type": """
        Set the spatial index type

        :param value: spatial index type
        :type value: SpatialIndexType or str
        :return: self
        :rtype: SpatialIndexInfo
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.tile_height": """float: the height of the map frame of the spatial index""",

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.tile_width": """float: the width of the spatial index frame""",

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.to_dict": """
        Output current object to dict

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.dt.SpatialIndexInfo.type": """ SpatialIndexType: the type of spatial index """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition": """
    Defines a single time field spatiotemporal model management query function interface
    """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.__init__": """
        Construct the query condition object of the spatiotemporal model

        :param field_name: field name
        :type field_name: str
        :param time: query time
        :type time: datetime.datetime
        :param condition: Conditional operator for query time. For example: >, <, >=, <=, =
        :type condition: str
        :param back_condition: the specified latter condition operator, for example: and, or
        :type back_condition: str
        """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.back_condition": """ specifies the latter condition operator, for example: and, or""",

    "iobjectspy._jsuperpy.data.dt.TimeCondition.condition": """str: Conditional operator for querying time. For example: >, <, >=, <=, = """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.field_name": """str: field name """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.from_dict": """
        Read TimeCondition information from the dict object.

        :param dict values: dict containing TimeCondition information, refer to to_dict for details
        :rtype: TimeCondition
        :rtype: TimeCondition
        """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.from_json": """
        Construct TimeCondition from json string.

        :param str value: json string
        :rtype: TimeCondition
        """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.make_from_dict": """
        Construct TimeCondition object from dict object

        :param dict values: dict containing TimeCondition information, refer to to_dict for details
        :rtype: TimeCondition
        """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.set_back_condition": """
        The next conditional operator of the query condition. For example: and, or

        :param str value: the last condition operator of the query condition
        :return: self
        :rtype: TimeCondition
        """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.set_condition": """
        Set the condition operator of the query condition.

        :param str value: Condition operator of query condition, >, <, >=, <=, =
        :return: self
        :rtype: TimeCondition
        """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.set_field_name": """
        Set the field name of the query condition

        :param str value: field name of query condition
        :return: self
        :rtype: TimeCondition
        """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.set_time": """
        Set the time value of the query condition

        :param datetime.datetime value: time value
        :return: self
        :rtype: TimeCondition
        """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.time": """datetime.datetime: the time as the query condition""",

    "iobjectspy._jsuperpy.data.dt.TimeCondition.to_dict": """
        Output the current object as a dict object

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.data.dt.TimeCondition.to_json": """
        Output the current object as a json string

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.dt.combine_band": """
        Three single-band dataset into RGB dataset
    
        :param red_dataset: Single band dataset R.
        :type red_dataset: Dataset or str
        :param green_dataset: Single band dataset G
        :type green_dataset: Dataset or str
        :param blue_dataset: single band dataset B
        :type blue_dataset: Dataset or str
        :param out_data: The datasource where the result dataset is located. If it is empty, use the datasource where the red_dataset dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: The name of the synthetic RGB dataset.
        :return: Return the dataset object or dataset name if the synthesis is successful, Return None if it fails
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.ds": """""",

    "iobjectspy._jsuperpy.data.ds.Datasource": """
        The datasource defines a consistent data access interface and specifications. The physical storage of the datasource can be either a file or a database. The main basis for distinguishing different storage methods is the type of data engine used:
        When using the UDB engine, the datasource is stored in the form of files (*.udb, *.udd)-- file-type datasource use .udb files to store spatial data. When using the spatial database engine, the datasource is stored in the specified
        DBMS. Each datasource exists in a workspace, and different datasources are distinguished by datasource aliases. Through the datasource object, you can create, delete, and copy the dataset.
    
    
        Use create_vector_dataset to quickly create vector dataset::
    
            >>> ds = Datasource.create('E:/data.udb')
            >>> location_dt = ds.create_vector_dataset('location','Point')
            >>> print(location_dt.name)
            location
    
    
        Append data to point dataset::
    
            >>> location_dt.append([Point2D(1,2), Point2D(2,3), Point2D(3,4)])
            >>> print(location_dt.get_record_count())
            3
    
        The datasource can directly write geometric objects, feature objects, point data, etc.::
    
            >>> rect = location_dt.bounds
            >>> location_coverage = ds.write_spatial_data([rect],'location_coverage')
            >>> print(location_coverage.get_record_count())
            1
            >>> ds.delete_all()
            >>> ds.close()
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.alias": """str: The alias of the datasource. The alias is used to uniquely identify the datasource in the workspace, and the datasource can be accessed through it. The alias of the datasource is creating data Given when the source or datasource is opened.
        Different aliases can be used to open the same datasource. """,

    "iobjectspy._jsuperpy.data.ds.Datasource.change_password": """
        Modify the password of the opened datasource

        :param str old_password: old password
        :param str new_password: new password
        :return: Return True if successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.close": """
        Close the current datasource.

        :return: Return True if closed successfully, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.connection_info": """DatasourceConnectionInfo: datasource connection information""",

    "iobjectspy._jsuperpy.data.ds.Datasource.contains": """
        Check whether there is a dataset with the specified name in the current datasource

        :param str name: dataset name
        :return: The current datasource contains the specified name of the dataset Return True, otherwise it Return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.copy_dataset": """
        Copy the dataset. Before copying the dataset, you must ensure that the current datasource is open and writable. When copying a dataset, the encoding method of the dataset can be modified through the EncodeType parameter.
        For the encoding method of dataset storage, please refer to EncodeType enumeration type. Since the CAD dataset does not support any encoding, the EncodeType set when copying the CAD dataset is invalid

        :param source: The source dataset to be copied. It can be a dataset object, or a combination of a datasource alias and a dataset name. The combination of the datasource name and the dataset name can use any of "|", "\\\", "/".
                        E.g.::

                        >>> source ='ds_alias/point_dataset'

                        or::

                        >>> source ='ds_alias|point_dataset'

        :type source: Dataset or str
        :param str out_dataset_name: The name of the target dataset. When the name is empty or illegal, a legal dataset name will be automatically obtained
        :param encode_type: The encoding method of the dataset. Can be: py:class:`EncodeType` enumeration value or name.
        :type encode_type: EncodeType or str
        :param function progress: A function for processing progress information, please refer to :py:class:`.StepEvent` for details.
        :return: Return the result dataset object if the copy is successful, otherwise it Return None
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.create": """
        Create a new datasource based on the specified datasource connection information.

        :param conn_info: datasource connection information, please refer to: py:meth:`DatasourceConnectionInfo.make`
        :type conn_info: str or dict or DatasourceConnectionInfo
        :return: datasource object
        :rtype: Datasource
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.create_dataset": """
        Create a dataset. Create a dataset based on the specified dataset information. If the name of the dataset is invalid or already exists, the creation of the dataset will fail. Adjust_name can be set to True to 
        automatically get a valid data set name    

        :param dataset_info: dataset information
        :type dataset_info: DatasetVectorInfo or DatasetImageInfo or DatasetGridInfo
        :param bool adjust_name: When the dataset name is invalid, whether to automatically adjust the dataset name and use a legal dataset name. The default is False.
        :return: Return the result dataset object if the creation is successful, otherwise it Return None
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.create_dataset_from_template": """
        Create a new dataset object based on the specified template dataset.

        :param Dataset template: template dataset
        :param str name: dataset name
        :param bool adjust_name: When the dataset name is invalid, whether to automatically adjust the dataset name and use a legal dataset name. The default is False.
        :return: Return the result dataset object if the creation is successful, otherwise it Return None
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.create_mosaic_dataset": """
        Create a mosaic dataset object based on the dataset name and projection information.

        :param name: dataset name
        :type name: str
        :param prj_coordsys: Specify the projection information of the mosaic dataset. Support epsg encoding, PrjCoordSys object, PrjCoordSysType type, xml or wkt or projection information file.
                             Note that if an integer value is passed in, it must be in epsg encoding and cannot be an integer value of type PrjCoordSysType.
        :type prj_coordsys: int or str or PrjCoordSys or PrjCoordSysType
        :param adjust_name: When the dataset name is invalid, whether to automatically adjust the dataset name and use a legal dataset name. The default is False.
        :type adjust_name: bool
        :return: Return the result dataset object if the creation is successful, otherwise it Return None
        :rtype: DatasetMosaic
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.create_vector_dataset": """
        Create a vector dataset object based on the name and type of the dataset.

        :param str name: dataset name
        :param dataset_type: The dataset type, which can be an enumeration value or name of the dataset type. Support TABULAR, POINT, LINE, REGION, TEXT, CAD, POINT3D, LINE3D, REGION3D
        :type dataset_type: DatasetType or str
        :param bool adjust_name: When the dataset name is invalid, whether to automatically adjust the dataset name and use a legal dataset name. The default is False.
        :return: Return the result dataset object if the creation is successful, otherwise it Return None
        :rtype: DatasetVector
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.datasets": """list[Dataset]: All dataset objects in the current datasource """,

    "iobjectspy._jsuperpy.data.ds.Datasource.delete": """
        Delete the specified dataset, which can be the name or serial number of the dataset

        :param item: The name or serial number of the dataset to be deleted
        :type item: str or int
        :return: Return True if the dataset is deleted successfully, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.delete_all": """Delete all dataset under the current datasource""",

    "iobjectspy._jsuperpy.data.ds.Datasource.description": """str: Return the description information about the datasource added by the user """,

    "iobjectspy._jsuperpy.data.ds.Datasource.field_to_point_dataset": """
        Create a point dataset from the X and Y coordinate fields in the attribute table of a vector dataset. That is, use the X and Y coordinate fields in the attribute table of the vector dataset as the X and Y coordinates of the dataset to create a point dataset.

        :param source_dataset: a vector dataset with coordinate fields in the associated attribute table
        :type source_dataset: DatasetVector or str
        :param str x_field: A field representing the abscissa of a point.
        :param str y_field: A field representing the vertical coordinate of a point.
        :param str out_dataset_name: The name of the target dataset. When the name is empty or illegal, a legal dataset name will be automatically obtained
        :return: Return a point dataset successfully, otherwise return None
        :rtype: DatasetVector
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.flush": """
        Save the data in the memory that has not yet been written into the database to the database

        :param str dataset_name: The name of the dataset to be refreshed. When an empty string or None is passed in, it means refresh all dataset; otherwise, refresh the dataset with the specified name.
        :return: Return True if successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.from_json": """
        Open the datasource from the json format string. The json string format is the json string format of DatasourceConnectionInfo. Specific parameters
        :py:meth:`DatasourceConnectionInfo.to_json` and :py:meth:`to_json`

        :param str value: json string format
        :return: datasource object
        :rtype: Datasource
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.get_available_dataset_name": """
        Return the name of an unused dataset in a datasource. Dataset name restriction: The length of the dataset name is limited to 30 characters (that is, it can be 30 English letters or 15 Chinese characters),
        the characters that make up the dataset name can be letters, Chinese characters, numbers and underscores. The dataset name cannot start with numbers and underscores. The dataset name cannot conflict with the reserved keywords of the database.

        :param str name: dataset name
        :return: valid dataset name
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.get_count": """
        Get the number of dataset

        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.get_dataset": """
        Get the dataset object according to the dataset name or serial number

        :param item: the name or serial number of the dataset
        :type: str or int
        :return: dataset object
        :rtype: Dataset
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.index_of": """
        Return the index value of the dataset corresponding to the given dataset name in the dataset collection

        :param str name: dataset name
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.inner_point_to_dataset": """
        Create the interior point dataset of the vector dataset, and copy the attributes of the geometric objects in the vector dataset to the corresponding point dataset attribute table

        :param source_dataset: the vector dataset to calculate the inlier dataset
        :type source_dataset: DatasetVector or str
        :param str out_dataset_name: The name of the target dataset. When the name is empty or illegal, a legal dataset name will be automatically obtained
        :return: Return the interior point dataset after creation. Create failed and return None
        :rtype: DatasetVector
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.is_available_dataset_name": """
        Determine whether the name of the dataset passed in by the user is legal. When creating a dataset, check the validity of its name.

        :param str name: the name of the dataset to be checked
        :return: If the dataset name is valid, return True, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.is_opened": """
        Return whether the datasource is open, if the datasource is open, Return true, if the datasource is closed, Return false.

        :return: Whether the datasource is open
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.is_readonly": """
        Return whether the datasource is opened in read-only mode. For file datasources, if they are opened in read-only mode, they are shared and can be opened multiple times; if they are opened in non-read-only mode, they can only be opened once.
        For the image datasource (IMAGEPLUGINS engine type), it can only be opened in read-only mode.

        :return: Whether the datasource is opened as read-only
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.label_to_text_dataset": """
        Used to generate a text dataset from the attribute field of the dataset. The text objects in the text dataset generated by this method all use the inner points of their corresponding spatial objects as the corresponding anchor points.
        The corresponding space object, that is, the content of the current text object, comes from the attribute value of the corresponding space object.

        :param source_dataset: the vector dataset to calculate the inlier dataset
        :type source_dataset: DatasetVector or str
        :param str text_field: The name of the attribute field to be converted.
        :param TextStyle text_style: the style of the result text object
        :param str out_dataset_name: The name of the target dataset. When the name is empty or illegal, a legal dataset name will be automatically obtained
        :return: successfully Return a text dataset, otherwise it Return None
        :rtype: DatasetVector
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.last_date_updated": """
        Get the last update time of the datasource

        :rtype: datetime.datetime
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.open": """
        Open the datasource according to the datasource connection information. If the connection information set is UDB type datasource. It will return directly. It does not support directly opening the memory datasource. To use the memory datasource, you need to use :py:meth:`create`.

        :param conn_info: datasource connection information, please refer to: py:meth:`DatasourceConnectionInfo.make`
        :type conn_info: str or dict or DatasourceConnectionInfo
        :return: datasource object
        :rtype: Datasource
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.prj_coordsys": """PrjCoordSys: Get projection information of datasource""",

    "iobjectspy._jsuperpy.data.ds.Datasource.refresh": """Refresh the datasource of the database type""",

    "iobjectspy._jsuperpy.data.ds.Datasource.set_description": """
        Set the description information about the datasource added by the user. Users can add any information you want to add in the description information, such as the person who created the datasource, the source of the data, the main content of the data,
        accuracy information, and quality of the data, which are of great significance for maintaining the data

        :param str description: The description information about the datasource added by the user
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.set_prj_coordsys": """
        Set the projection information of the datasource

        :param PrjCoordSys prj: projection information
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.to_json": """
        Return the datasource as a json format string. Specifically return the json string of the datasource connection information, that is, use: py:class:`DatasourceConnectionInfo.to_json`.

        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.type": """EngineType: datasource engine type""",

    "iobjectspy._jsuperpy.data.ds.Datasource.workspace": """Workspace: Workspace object to which the current datasource belongs""",

    "iobjectspy._jsuperpy.data.ds.Datasource.write_attr_values": """
        Write the attribute data to the attribute dataset (DatasetType.TABULAR).

        :param data: The data to be written. data must be a list or tuple or set, each element item in the list (or tuple), it can be a list or tuple, at this time
                     data is equivalent to a two-dimensional array, for example:

                     >>> data = [[1,2.0,'a1'], [2,3.0,'a2'], [3,4.0,'a3']]

                     or::

                     >>> data = [(1,2.0,'a1'), (2,3.0,'a2'), (3,4.0,'a3')]

                     If the element item in data is not a list or tuple, it will be treated as an element. E.g.::

                     >>> data = [1,2,3]

                     or::

                     >>> data = ['test1','test2','test3']

                     Then the final result dataset will contain a dataset with 1 column and 3 rows. For the element item in data as dict, each dict object will be written as a string::

                     >>> data = [{1:'a'}, {2:'b'}, {3:'c'}]

                     It is equivalent to writing::

                     >>> data = ["{1:'a'}", "{2:'b'}", "{3:'c'}"]

                     In addition, the user needs to ensure that each element in the list has the same structure. The program will automatically sample up to 20 records, and calculate the reasonable field type according to the sampled field value type. The specific corresponding is:

                      -int: FieldType.INT64
                      -str: FieldType.WTEXT
                      -float: FieldType.DOUBLE
                      -bool: FieldType.BOOLEAN
                      -datetime.datetime: FieldType.DATETIME
                      -bytes: FieldType.LONGBINARY
                      -bytearray: FieldType.LONGBINARY
                      -Other: FieldType.WTEXT

        :type data: list or tuple
        :param str out_dataset_name: The name of the result dataset. When the name is empty or illegal, a legal dataset name will be automatically obtained
        :return: Return DatasetVector when writing data successfully, otherwise return None
        :rtype: DatasetVector
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.write_features": """
        Write the feature object to the dataset.

        :param data: The set of feature objects to be written. The user needs to ensure that the structure of all elements in the collection must be the same, including the same geometric object type and field information.
        :type data: list[Feature] or tuple[Feature]
        :param str out_dataset_name: The name of the result dataset. When the name is empty or illegal, a legal dataset name will be automatically obtained
        :return: Return the result dataset object if writing is successful, otherwise it Return None
        :rtype: DatasetVector
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.write_recordset": """
        Write a record set object or dataset object to the current datasource.

        :param source: the record set or dataset object to be written
        :param str out_dataset_name: The name of the result dataset. When the name is empty or illegal, a legal dataset name will be automatically obtained
        :return: Return DatasetVector when writing data successfully, otherwise return None
        :rtype: DatasetVector
        """,

    "iobjectspy._jsuperpy.data.ds.Datasource.write_spatial_data": """
        Write spatial data (Point2D, Point3D, Rectangle, Geometry) into the vector dataset.

        :param data: The data to be written. data must be a list or tuple or each element item in a set, list (or tuple), and can be Point2D, Point, GeoPoint, GeoLine, GeoRegion, Rectangle:
                        -If all elements in data are Point2D or GeoPoint, a point dataset will be created
                        -If all elements in data are Point3D or GeoPoint3D, a 3D point dataset will be created
                        -If all elements in data are GeoLine, a line dataset will be created
                        -If all elements in data are Rectangle or GeoRegion, a polygon dataset will be created
                        -Otherwise, a CAD dataset will be created.
        :type data: list o tuple
        :param str out_dataset_name: The name of the result dataset. When the name is empty or illegal, a legal dataset name will be automatically obtained
        :param values: Spatial data to be written to the attribute field value of the dataset. If it is not None, it must be a list or tuple, and the length must be the same as the data length.
                        Each element item in values can be a list or tuple. In this case, values is equivalent to a two-dimensional array, for example:

                        >>> values = [[1,2.0,'a1'], [2,3.0,'a2'], [3,4.0,'a3']]

                        or

                        >>> values = [(1,2.0,'a1'), (2,3.0,'a2'), (3,4.0,'a3')]

                        If the element item in values is not a list or tuple, it will be treated as an element. E.g.::

                        >>> values = [1,2,3]

                        or::

                        >>> values = ['test1','test2','test3']

                        Then the final result dataset will contain a dataset with 1 column and 3 rows. For the element item in data as dict, each dict object will be written as a string::

                        >>> data = [{1:'a'}, {2:'b'}, {3:'c'}]

                        It is equivalent to writing::

                        >>> values = ["{1:'a'}", "{2:'b'}", "{3:'c'}"]

                        In addition, the user needs to ensure that each element in the list has the same structure. The program will automatically sample up to 20 records, and calculate the reasonable field type according to the sampled field value type. The specific corresponding is:

                         -int: FieldType.INT64
                         -str: FieldType.WTEXT
                         -float: FieldType.DOUBLE
                         -bool: FieldType.BOOLEAN
                         -datetime.datetime: FieldType.DATETIME
                         -bytes: FieldType.LONGBINARY
                         -bytearray: FieldType.LONGBINARY
                         -Other: FieldType.WTEXT


        :return: Return DatasetVector when writing data successfully, otherwise return None
        :rtype: DatasetVector
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo": """
        datasource connection information class. It includes all the information for datasource connection, such as the name of the server to be connected, database name, user name, password, etc. When a workspace is saved, the connection information for the datasources in the workspace
        is stored in the workspace file. For different types of datasources, the connection information is different. So when using the members contained in this class, please pay attention to the datasource type that the member applies to.
    
        E.g.::
            >>> conn_info = DatasourceConnectionInfo('E:/data.udb')
            >>> print(conn_info.server)
            'E:\data.udb'
            >>> print(conn_info.type)
            EngineType.UDB
    
    
        Create OraclePlus database connection information::
    
            >>> conn_info = (DatasourceConnectionInfo().
            >>> set_type(EngineType.ORACLEPLUS).
            >>> set_server('server').
            >>> set_database('database').
            >>> set_alias('alias').
            >>> set_user('user').
            >>> set_password('password'))
            >>> print(conn_info.database)
            'server'
    
    
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.__init__": """
        Construct datasource connection object

        :param str server: database server name, file name or service address:

                           -For MEMORY, it is':memory:'
                           -For UDB files, it is the absolute path of the file. Note: When the length of the absolute path exceeds the 260-byte length of the UTF-8 encoding format, the datasource cannot be opened.
                           -For Oracle database, its server name is its TNS service name;
                           -For SQL Server databases, the server name is the DSN (Database Source Name) name of the system;
                           -For PostgreSQL database, the server name is "IP: Port Number", and the default port number is 5432;
                           -For the DB2 database, it has been cataloged, so there is no need to configure the server;
                           -For Kingbase database, its server name is its IP address;
                           -For the GoogleMaps datasource, its service address is set to "http://maps.google.com" by default and cannot be changed;
                           -For SuperMapCloud datasource, its service address;
                           -For the MAPWORLD datasource, its service address is set to "http://www.tianditu.cn" by default and cannot be changed;
                           -For OGC and REST datasources, its service address.
                           -If the user is set to IMAGEPLUGINS, the parameter of this method is set to the map cache configuration file (SCI) name, then the user can load the map cache

        :param engine_type: The engine type of the datasource connection, you can use the EngineType enumeration value and name
        :type engine_type: EngineType or str
        :param str alias: datasource alias. The alias is the unique identification of the datasource. The logo is not case sensitive
        :param bool is_readonly: Whether to open the datasource in read-only mode. If you open the datasource in read-only mode, the related information of the datasource and the data in it cannot be modified.
        :param str database: The name of the database connected to the datasource
        :param str driver: Driver name required for datasource connection:

                               -For SQL Server database, it uses ODBC connection, and the returned driver is named SQL Server or SQL Native Client.
                               -For the WMTS service published by iServer, the driver name returned is WMTS.

        :param str user: The username for logging in to the database. Applicable to database type datasources.
        :param str password: The password for logging in to the database or file connected to the datasource. For the GoogleMaps datasource, if you open a datasource based on an earlier version, the password returned is the key obtained by the user after registering on the Google official website
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.alias": """str: datasource alias, which is the unique identifier of the datasource. The identifier is not case sensitive """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.database": """str: The name of the database to which the datasource is connected""",

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.driver": """str: the driver name required for datasource connection""",

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.from_dict": """
        Read the database datasource connection information from the dict object. The value in the current object will be overwritten after reading.

        :param dict values: A dict containing datasource connection information.
        :return: self
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.from_json": """
        Construct the datasource connection information object from the json string.

        :param str value: json string
        :return: datasource connection information object
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.is_readonly": """bool: Whether to open the datasource in read-only mode""",

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.is_same": """
        Determine whether the current object and the specified database connection information object point to the same datasource object.
        If two database connection information points to the same datasource, you must:

            -The database engine type (type) is the same
            -The database server name, file name or service address (server) is the same
            -The name of the database connected to the database (database) is the same. Set if necessary.
            -The user name (user) of the database is the same, set if necessary.
            -The password (password) of the database or file connected to the datasource is the same, set if necessary.
            -Whether to open in read-only mode (is_readonly) is the same, set if necessary.

        :param DatasourceConnectionInfo other: The database connection information object to be compared.
        :return: Return True to indicate that the connection information with the specified database points to the same datasource object. Otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.load_from_dcf": """
        Load the database connection information from the dcf file and return a new database connection information object.

        :param str file_path: dcf file path.
        :return: datasource connection information object
        :type: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.load_from_xml": """
        Load the database connection information from the specified xml string and return a new database connection information object.

        :param str xml: the xml string of the connection information of the imported datasource
        :return: datasource connection information object
        :type: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.make": """
        Construct a database connection information object.

        :param value: An object containing datasource connection information:

                          -If it is a DatasourceConnectionInfo object, return the object directly.
                          -If it is a dict, refer to make_from_dict
                          -If it is str, it can be:

                              -':memory:', Return the database connection information of the memory datasource engine
                              -udb or udd file, Return the database connection information of the UDB datasource engine
                              -dcf file, refer to save_as_dcf
                              -xml string, refer to to_xml

        :type value: str or DatasourceConnectionInfo or dict
        :return: datasource connection information object
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.make_from_dict": """
        Construct a datasource connection object from the dict object. Return a new database connection information object.

        :param dict values: A dict containing datasource connection information.
        :return: datasource connection information object
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.password": """str: the password of the database or file to which the datasource is connected""",

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.save_as_dcf": """
        Save the current dataset connection information object to the DCF file.

        :param str file_path: dcf file path.
        :return: Return True if saved successfully, otherwise False
        :type: bool
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.server": """ str: database server name, file name or service address """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.set_alias": """
        Set datasource alias

        :param str value: The alias is the unique identifier of the datasource. The logo is not case sensitive
        :return: self
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.set_database": """
        Set the name of the database to which the datasource is connected. Applicable to database type datasources

        :param str value: The name of the database connected to the datasource.
        :return: self
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.set_driver": """
        Set the driver name required for datasource connection.

        :param str value: Driver name required for datasource connection:

                              -For SQL Server database, it uses ODBC to connect, and the set driver is named SQL Server or SQL Native Client.
                              -For the WMTS service published by iServer, the set driver name is WMTS, and this method must be called to set its driver name.

        :return: self
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.set_password": """
        Set the password of the database or file connected to the login datasource

        :param str value: The password of the database or file to which the login datasource is connected. For the GoogleMaps datasource, if you open a datasource based on an earlier version, you need to enter a password. The password is the key obtained by the user after registering on the Google official website.
        :return: self
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.set_readonly": """
        Set whether to open the datasource in read-only mode.

        :param bool value: Specify whether to open the datasource in read-only mode. For UDB datasource, if its file attribute is read-only, it must be set to read-only before it can be opened.
        :return: self
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.set_server": """
        Set the database server name, file name or service address

        :param str value: database server name, file name or service address:

                              -For MEMORY, it is':memory:'
                              -For UDB files, it is the absolute path of the file. Note: When the length of the absolute path exceeds the 260-byte length of the UTF-8 encoding format, the datasource cannot be opened.
                              -For Oracle database, its server name is its TNS service name;
                              -For SQL Server databases, the server name is the DSN (Database Source Name) name of the system;
                              -For PostgreSQL database, the server name is "IP: Port Number", and the default port number is 5432;
                              -For the DB2 database, it has been cataloged, so there is no need to configure the server;
                              -For Kingbase database, its server name is its IP address;
                              -For the GoogleMaps datasource, its service address is set to "http://maps.google.com" by default and cannot be changed;
                              -For SuperMapCloud datasource, its service address;
                              -For the MAPWORLD datasource, its service address is set to "http://www.tianditu.cn" by default and cannot be changed;
                              -For OGC and REST datasources, its service address.
                              -If the user is set to IMAGEPLUGINS, the parameter of this method is set to the map cache configuration file (SCI) name, then the user can load the map cache

        :return: self
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.set_type": """
        Set the type of engine connected to the datasource.

        :param value: Engine type of datasource connection
        :type value: EngineType or str
        :return: self
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.set_user": """
        Set the user name for logging in to the database. Applicable to database type datasources

        :param str value: user name to log in to the database
        :return: self
        :rtype: DatasourceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.to_dict": """
        Output the current datasource connection information as a dict object.

        :return: a dict containing datasource connection information
        :rtype: dict

        Example::
            >>> conn_info = (DatasourceConnectionInfo().
            >>> set_type(EngineType.ORACLEPLUS).
            >>> set_server('oracle_server').
            >>> set_database('database_name').
            >>> set_alias('alias_name').
            >>> set_user('user_name').
            >>> set_password('password_123'))
            >>>
            >>> print(conn_info.to_dict())
            {'type':'ORACLEPLUS','alias':'alias_name','server':'oracle_server','user':'user_name','is_readonly': False,'password':'password_123','database' :'database_name'}

        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.to_json": """
        Output as json format string

        :return: json format string
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.to_xml": """
        Output the current dataset connection information as an xml string

        :return: The XML string converted from the current datasource connection information object.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.type": """EngineType: datasource type""",

    "iobjectspy._jsuperpy.data.ds.DatasourceConnectionInfo.user": """str: the user name to log in to the database """,

    "iobjectspy._jsuperpy.data.ws.user": """""",

    "iobjectspy._jsuperpy.data.ws.Workspace": """
        The workspace is the user's working environment, which mainly completes the organization and management of data, including opening, closing, creating, and saving workspace files. Workspace is an important concept as part of SuperMap.
        The workspace stores all the datasources and the organization relationship of the map in an engineering project (the same transaction process). You can manage datasources and maps through workspace objects. Only the connection information and
        location of the datasource are stored in the workspace,the actual datasource is stored in the database or UDB. The workspace only stores some configuration information of the map, such as the number of layers in the map, the dataset referenced by the layer, the map range,
        background style, etc. In the current version, only one workspace object can exist in a program. If the user does not open a specific workspace, the program will create a workspace object by default. If the user needs to open a new
        workspace objects, you need to save and close the current workspace first, otherwise, some information stored in the workspace may be lost.
    
        For example, create a datasource object::
    
            >>> ws = Workspace()
            >>> ws.create_datasource(':memory:')
            >>> print(len(ws.datasources))
            1
            >>> ws_a = Workspace()
            >>> ws_a.create_datasource(':memory:')
            >>> ws == ws_a
            True
            >>> print(len(ws_a.datasources))
            2
            >>> ws.close()
    
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.add_map": """
        Add Map to the current workspace

        :param str map_name: map name
        :param map_or_xml: XML description of the map object or map
        :type map_or_xml: Map or str
        :return: The serial number of the newly added map in this map collection object.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.caption": """str: Workspace display name, which is convenient for users to make some identification.""",

    "iobjectspy._jsuperpy.data.ws.Workspace.clear_maps": """
        Delete all maps in this map collection object, that is, all maps saved in the workspace.

        :return: Workspace object itself
        :rtype: Workspace
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.close": """
        Close the workspace, closing the workspace will destroy the instance objects in the current workspace. Before closing the workspace, make sure that the map and other contents of the workspace used are closed or disconnected.
        If the workspace is registered on the Java side, the workspace object will not be actually closed, only the binding relationship to the Java workspace object will be released, and you will not be able to continue working with Java
        workspace objects unless you construct a new instance using Workspace().
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.close_all_datasources": """Close all datasources""",

    "iobjectspy._jsuperpy.data.ws.Workspace.close_datasource": """
        Close the specified datasource.

        :param item: alias or serial number of the datasource
        :type item: str or int
        :return: Return True if closed successfully, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.connection_info": """WorkspaceConnectionInfo: Workspace connection information""",

    "iobjectspy._jsuperpy.data.ws.Workspace.create": """
        Create a new workspace object. Before creating a new workspace, the user can save the current workspace object by setting save_existed to True, or set
        saved_connection_info to saves as the current workspace to the specified location.

        :param WorkspaceConnectionInfo conn_info: connection information of the workspace
        :param bool save_existed: Whether to save the current workspace work. If set to True, the current workspace will be saved and then closed, otherwise the current workspace will be closed directly, and then the new workspace object will be opened. save_existed is only suitable for situations where the current workspace is not in memory. The default is True.
        :param WorkspaceConnectionInfo saved_connection_info: Choose to save the current work in the workspace specified by saved_connection_info. The default is None.
        :return: new workspace object
        :rtype: Workspace
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.create_datasource": """
        Create a new datasource based on the specified datasource connection information.

        :param conn_info: udb file path or datasource connection information:
                          -datasource connection information. For details, please refer to: py:meth:`DatasourceConnectionInfo.make`
                          -If conn_info is str, it can be':memory:', udb file path, udd file path, dcf file path, xml string of datasource connection information
                          -If conn_info is a dict, it is the return result of :py:meth:`DatasourceConnectionInfo.to_dict`.
        :type conn_info: str or dict or DatasourceConnectionInfo
        :return: datasource object
        :rtype: Datasource
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.datasources": """list[Datasource]: All datasource objects in the current workspace.""",

    "iobjectspy._jsuperpy.data.ws.Workspace.description": """str: the description or descriptive information of the current workspace added by the user""",

    "iobjectspy._jsuperpy.data.ws.Workspace.get_datasource": """
        Get the specified datasource object.

        :param item: alias or serial number of the datasource
        :type item: str or int
        :return: datasource object
        :rtype: Datasource
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.get_map": """
        Get the map object with the specified name or serial number

        :param index_or_name: the specified map name or serial number
        :type index_or_name: int or str
        :return: map object
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.get_map_xml": """
        Return the XML description of the map with the specified name or sequence number

        :param index_or_name: the specified map name or serial number
        :type index_or_name: int or str
        :return: XML description of the map
        :rtype: str
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.get_maps": """
        Return all maps

        :return: All Maps in the current workspace
        :rtype: list[Map]
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.index_of_datasource": """
        Find the serial number of the specified datasource alias. An exception will be thrown if it does not exist.

        :param str alias: datasource alias
        :return: the serial number of the datasource
        :rtype: int
        :raise ValueError: An exception is thrown when the specified datasource alias does not exist.
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.insert_map": """
        Add a map at the position of the specified serial number, and the content of the map is determined by the XML string.

        :param int index: The specified serial number.
        :param str map_name: The specified map name. The name is not case sensitive.
        :param map_or_xml: The XML string used to represent the map or map to be inserted.
        :type map_or_xml: Map or str
        :return: If the map is inserted successfully, return true; otherwise, return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.is_contains_datasource": """
        Whether there is a datasource with a specified serial number or datasource alias

        :param item: alias or serial number of the datasource
        :type item: str or int
        :return: return True if it exists, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.is_modified": """
        Return whether the content of the workspace has been changed. If some changes are made to the content of the workspace, it Return True, otherwise it Return False. The workspace is responsible for managing datasources, maps, any one of them
        changes, this attribute will return True. When closing the entire application, first use this attribute to determine whether the workspace has been changed, which can be used to prompt the user whether to save.

        :return: If some changes are made to the content of the workspace, it Return True, otherwise it Return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.modify_datasource_alias": """
        Modify the alias of the datasource. datasource aliases are not case sensitive

        :param str old_alias: the alias of the datasource to be modified
        :param str new_alias: the new alias of the datasource
        :return: If the datasource is modified successfully, it will return True, otherwise it will return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.open": """
        Open a new workspace object. Before opening a new workspace, the user can save the current workspace object by setting save_existed to True, or set
        saved_connection_info saves as the current workspace to the specified location.

        :param WorkspaceConnectionInfo conn_info: connection information of the workspace
        :param bool save_existed: Whether to save the current workspace work. If set to True, the current workspace will be saved and then closed, otherwise the current workspace will be closed directly, and then the new workspace object will be opened. save_existed is only suitable for situations where the current workspace is not in memory. The default is True.
        :param WorkspaceConnectionInfo saved_connection_info: Choose to save the current work in the workspace specified by saved_connection_info. The default is None.
        :return: new workspace object
        :rtype: Workspace

        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.open_datasource": """
        Open the datasource according to the datasource connection information. If the set connection information is a UDB type datasource, or is_get_existed is True, if the corresponding datasource already exists in the workspace, then it 
        will return directly. It does not support directly opening the memory datasource. To use the memory datasource, you need to use :py:meth:`create_datasource` to create the memory datasource.

        :param conn_info: udb file path or datasource connection information:
                          -datasource connection information. For details, please refer to: py:meth:`DatasourceConnectionInfo.make`
                          -If conn_info is str, it can be':memory:', udb file path, udd file path, dcf file path, xml string of datasource connection information
                          -If conn_info is a dict, it is the return result of :py:meth:`DatasourceConnectionInfo.to_dict`.
        :type conn_info: str or dict or DatasourceConnectionInfo
        :param bool is_get_existed: is_get_existed is True, if the corresponding datasource already exists in the workspace, it will return directly. When false, a new datasource will be opened. For UDB datasources, whether is_get_existed is True or False, the datasource in the workspace will be returned first. To determine whether DatasourceConnectionInfo is the same datasource as the datasource in the workspace, you can check:py:meth:`DatasourceConnectionInfo.is_same`
        :return: datasource object
        :rtype: Datasource


        >>> ws = Workspace()
        >>> ds = ws.open_datasource('E:/data.udb')
        >>> print(ds.type)
        EngineType.UDB

        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.remove_map": """
        Delete the map with the specified serial number or name in this map collection object

        :param index_or_name: the serial number or name of the map to be deleted
        :type index_or_name: str or int
        :return: If the deletion is successful, return true; otherwise, return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.rename_map": """
        Modify the name of the map object

        :param str old_name: the current name of the map object
        :param str new_name: the specified new map name
        :return: Return True if the modification is successful, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.save": """
        Used to save the existing workspace without changing the original name

        :return: Return True if saved successfully, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.save_as": """
        Use the specified workspace to connect the information object to save the workspace file.

        :param WorkspaceConnectionInfo conn_info: Workspace connection information object
        :return: Return True if Save As is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.set_caption": """
        Set the workspace display name.

        :param str caption: workspace display name
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.set_description": """
        Set the description or descriptive information of the current workspace joined by the user

        :param str description: The description or descriptive information of the current workspace added by the user
        """,

    "iobjectspy._jsuperpy.data.ws.Workspace.set_map": """
        The map represented by the specified map or the XML string of the map replaces the map with the specified sequence number in the map collection object.

        :param index_or_name: the specified serial number or map name
        :type index_or_name: int or str
        :param map_or_xml: The XML string representation of the new map used to replace the specified map.
        :type map_or_xml: Map or str
        :return: If the operation is successful, return true; otherwise, return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo": """
        Workspace connection information class. It includes all the information for connecting to the workspace, such as the name of the server to be connected, the name of the database, the username, and the password. For different types of workspaces, so when using the
        members contained in this class, please pay attention to the type of workspace that the member applies to.
        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.__init__": """
        Initialize the workspace link information object.

        :param str server: database server name or file name
        :param workspace_type: the type of workspace
        :type workspace_type: WorkspaceType or str
        :param version: version of the workspace
        :type version: WorkspaceVersion or str
        : param str driver: the driver name database using ODBC connection settings, log currently supported database workspace, SQL Server database using ODBC connection, the driver name, such as SQL Server databases to SQL Server or SQL Native Client
        :param str database: the name of the database connected to the workspace
        :param str name: the name of the workspace in the database
        :param str user: username to log in to the database
        :param str password: The password of the database or file connected to the login workspace.
        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.database": """str: The name of the database to which the workspace is connected. For database type workspaces """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.driver": """str: The driver name of the database connected using ODBC""",

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.name": """str: The name of the workspace in the database. For file-type workspaces, this name is empty """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.password": """str: the password of the database or file connected to the login workspace """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.server": """str: database server name or file name""",

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.set_database": """
        Set the name of the database connected to the workspace. Applicable to database type workspace

        :param str value: The name of the database connected to the workspace
        :return: self
        :rtype: WorkspaceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.set_driver": """
        Set the driver name of the database connected using ODBC. For the currently supported database workspace, SQL Server database uses ODBC connection, SQL Server database driver
        The program name is SQL Server or SQL Native Client.

        :param str value: The driver name of the database connected using ODBC
        :return: self
        :rtype: WorkspaceConnectionInfo

        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.set_name": """
        Set the name of the workspace in the database.

        :param str value: The name of the workspace in the database. For file-type workspaces, set this name to empty
        :return: self
        :rtype: WorkspaceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.set_password": """
        Set the password of the database or file connected to the login workspace. This password setting is only valid for Oracle and SQL datasources, and invalid for local (UDB) datasources.

        :param str value: the password of the database or file connected to the login workspace
        :return: self
        :rtype: WorkspaceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.set_server": """
        Set the database server name or file name.

        :param str value: For Oracle database, its server name is its TNS service name; for SQL Server database, its server name is its system's DNS (Database Source Name) name; for SXWU and SMWU files, its server name is its file The name, which includes the path name and file extension. In particular, the path here is an absolute path.
        :return: self
        :rtype: WorkspaceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.set_type": """
        Set the type of workspace.

        :param value: the type of workspace
        :type value: WorkspaceType or str
        :return: self
        :rtype: WorkspaceConnectionInfo

        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.set_user": """
        Set the user name for logging in to the database. Applicable to database type workspace.

        :param str value: user name to log in to the database
        :return: self
        :rtype: WorkspaceConnectionInfo
        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.set_version": """
        Set the workspace version.

        :param value: version of the workspace
        :type value: WorkspaceVersion or str
        :return: self
        :rtype: WorkspaceConnectionInfo


        For example, set the workspace version to UGC60::

            >>> conn_info = WorkspaceConnectionInfo()
            >>> conn_info.set_version('UGC60')
            >>> print(conn_info.version)
            WorkspaceVersion.UGC60

        """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.type": """WorkspaceType: The type of workspace. The workspace can be stored in a file or in a database. The currently supported file-based workspace type is SXWU format and SMWU format work space;
        The database-based workspace is in ORACLE format and SQL format; the default workspace type is unstored workspace """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.user": """str: the user name to log in to the database """,

    "iobjectspy._jsuperpy.data.ws.WorkspaceConnectionInfo.version": """WorkspaceVersion: The version of the workspace. The default is UGC70.""",

    "iobjectspy._jsuperpy.data.ws.add_map": """
    Add Map to the current workspace

    :param str map_name: map name
    :param map_or_xml: XML description of the map object or map
    :type map_or_xml: Map or str
    :return: The serial number of the newly added map in this map collection object.
    :rtype: int
    """,

    "iobjectspy._jsuperpy.data.ws.close_datasource": """
    Close the specified datasource.

    Specific reference :py:meth:`Workspace.close_datasource`

    :param item: alias or serial number of the datasource
    :type item: str or int
    :return: Return True if closed successfully, otherwise return False
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.data.ws.create_datasource": """
        Create a new datasource based on the specified datasource connection information.
    
        :param conn_info: udb file path or datasource connection information:
                          -datasource connection information. For details, please refer to: py:meth:`DatasourceConnectionInfo.make`
                          -If conn_info is str, it can be':memory:', udb file path, udd file path, dcf file path, xml string of datasource connection information
                          -If conn_info is a dict, it is the return result of :py:meth:`DatasourceConnectionInfo.to_dict`.
        :type conn_info: str or dict or DatasourceConnectionInfo
        :return: datasource object
        :rtype: Datasource
        """,

    "iobjectspy._jsuperpy.data.ws.get_datasource": """
        Get the specified datasource object.
    
        Specific reference:py:meth:`Workspace.get_datasource`
    
        :param item: alias or serial number of the datasource
        :type item: str or int
        :return: datasource object
        :rtype: Datasource
        """,

    "iobjectspy._jsuperpy.data.ws.get_map": """
        Get the map object with the specified name or serial number
    
        :param index_or_name: the specified map name or serial number
        :type index_or_name: int or str
        :return: map object
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.data.ws.list_datasources": """
        Return all datasource objects in the current workspace.
    
        Specific reference :py:attr:`Workspace.datasources`
    
        :return: all datasource objects in the current workspace
        :rtype: list[Datasource]
        """,

    "iobjectspy._jsuperpy.data.ws.list_maps": """
        Return all map objects in the current workspace
    
        :return: all maps in the current workspace
        :rtype: list[Map]
        """,

    "iobjectspy._jsuperpy.data.ws.open_datasource": """
        Open the datasource according to the datasource connection information. If the set connection information is a UDB type datasource, or is_get_existed is True, if the corresponding datasource already exists in the workspace, then it
        will return directly. It does not support directly opening the memory datasource. To use the memory datasource, you need to use :py:meth:`create_datasource` to create the memory datasource.
    
        Specific reference:py:meth:`Workspace.open_datasource`
    
        :param conn_info: udb file path or datasource connection information:
                              -datasource connection information. For details, please refer to: py:meth:`DatasourceConnectionInfo.make`
                              -If conn_info is str, it can be':memory:', udb file path, udd file path, dcf file path, xml string of datasource connection information
                              -If conn_info is a dict, it is the return result of :py:meth:`DatasourceConnectionInfo.to_dict`.
        :type conn_info: str or dict or DatasourceConnectionInfo
        :param bool is_get_existed: is_get_existed is True, if the corresponding datasource already exists in the workspace, it will return directly. When false, a new datasource will be opened. For UDB datasources, whether is_get_existed is True or False, the datasource in the workspace will be returned first. To determine whether DatasourceConnectionInfo is the same datasource as the datasource in the workspace, you can check:py:meth:`DatasourceConnectionInfo.is_same`
        :return: datasource object
        :rtype: Datasource
        """,

    "iobjectspy._jsuperpy.data.ws.remove_map": """
        Delete the map with the specified serial number or name in this map collection object
    
        :param index_or_name: the serial number or name of the map to be deleted
        :type index_or_name: str or int
        :return: If the deletion is successful, return true; otherwise, return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.convert": """""",

    "iobjectspy._jsuperpy.data.convert.dataset_dim2_to_dim3": """
        Convert a two-dimensional dataset to a three-dimensional dataset, and the two-dimensional point, line and area dataset will be converted to three-dimensional point, line and area dataset respectively.
    
        :param source: two-dimensional dataset, supporting point, line and area dataset
        :type source: DatasetVector or str
        :param z_field_or_value: The source field name of the z value or the specified z value. If it is a field, it must be a numeric field.
        :type z_field_or_value: str or float
        :param line_to_z_field: When the input is a two-dimensional line dataset, it is used to specify the field name of the ending z value, and z_field_or_value is the name of the field of the starting z value.
                                line_to_z_field must be a field name, the specified z value is not supported.
        :type line_to_z_field: str
        :param saved_fields: the names of the fields to be reserved
        :type saved_fields: list[str] or str
        :param out_data: The datasource where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: result three dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_dim3_to_dim2": """
        Convert three-dimensional point, line and area dataset into two-dimensional point, line and area dataset.
    
        :param source: 3D dataset, supports 3D point, line and area dataset
        :type source: DatasetVector or str
        :param out_z_field: A field that retains the Z value. If it is None or illegal, a valid field will be obtained to store the Z value of the object
        :type out_z_field: str
        :param saved_fields: the names of the fields that need to be reserved
        :type saved_fields: list[str] or str
        :param out_data: The datasource where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: result two-dimensional dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_field_to_point": """
        According to the fields in the dataset, a two-dimensional point dataset or a three-dimensional point dataset is constructed. If a valid z_field is specified, a three-dimensional point dataset will be obtained, otherwise a two-dimensional point dataset will be obtained
    
        :param source: The dataset that provides the data, which can be an attribute table or a dataset such as point, line, area, etc.
        :type source: DatasetVector or str
        :param x_field: The source field of the x coordinate value. It must be valid.
        :type x_field: str
        :param y_field: The source field of the y coordinate value. It must be valid.
        :type y_field: str
        :param z_field: The source field of the z coordinate value, optional.
        :type z_field: str
        :param saved_fields: The names of the fields that need to be reserved.
        :type saved_fields: list[str] or str
        :param out_data: The datasource where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: 2D point or 3D point dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_field_to_text": """
        Convert point dataset to text dataset
    
        :param source: input two-dimensional point dataset
        :type source: DatasetVector or str
        :param str field: A field containing text information, used to construct the text information of a text geometric object.
        :param saved_fields: the names of the fields that need to be reserved
        :type saved_fields: list[str] or str
        :param out_data: The datasource where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: result text dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_line_to_point": """
        Convert line dataset to point dataset
    
        :param source: two-dimensional line dataset
        :type source: DatasetVector or str
        :param mode: the way to convert line objects to point objects
        :type mode: LineToPointMode or str
        :param saved_fields: the names of the fields that need to be reserved
        :type saved_fields: list[str] or str
        :param out_data: The datasource where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: result two-dimensional point dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_line_to_region": """
        Convert a line dataset to a polygon dataset. This method converts the line object directly to the area object. If the line object is not first connected, the conversion may fail. If you want to convert a line dataset to a polygon dataset, a more
        Reliable approach is the topological aspect: py:func:`.topology_build_regions`
    
        :param source: two-dimensional line dataset
        :type source: DatasetVector or str
        :param saved_fields: the names of the fields that need to be reserved
        :type saved_fields: list[str] or str
        :param out_data: datasource information where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: result 2D surface dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_network_to_line": """
        Convert the two-dimensional network dataset into a line dataset. The SmEdgeID, SmFNode and SmTNode field values of the network dataset will be stored in the EdgeID, FNode and TNode fields of the result dataset
        If EdgeID, FNode or TNode is already occupied, a valid field will be obtained.
    
        :param source: the converted two-dimensional network dataset
        :type source: DatasetVector or str
        :param saved_fields: The names of the fields to be saved.
        :type saved_fields: list[str] or str
        :param out_data: datasource information where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: result two-dimensional line dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_network_to_point": """
        The idea of two-dimensional dataset into a set of network data point dataset, SmNodeID field value of dataset will be stored in the field NodeID result dataset, if already occupied NodeID, it obtains a valid field.
    
        :param source: the converted two-dimensional network dataset
        :type source: DatasetVector or str
        :param saved_fields: The names of the fields to be saved.
        :type saved_fields: list[str] or str
        :param out_data: datasource information where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: result two-dimensional point dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_point_to_line": """
    Collect the two-dimensional point data into point objects, group the line objects according to the grouping field, and return a two-dimensional line dataset

    :param source: two-dimensional point dataset
    :type source: DatasetVector or str
    :param group_fields: The field names used for grouping in the two-dimensional point dataset. Only when the field values of the grouped field names are equal will the points be connected into a line.
    :type group_fields: list[str]
    :param order_fields: Sort fields, the points in the same group are sorted according to the ascending order of the field value of the sort field, and then connected into a line. If it is None, the SmID field is used for sorting by default.
    :type order_fields: list[str] or str
    :param field_stats: field statistics, field statistics are performed on the point attributes in the same group. It is a list, each element in the list is a tuple, the size of the tuple is 2, the first element of the tuple is the field name to be counted, and the second element of the tuple is the statistics type.
                        Note that: py:attr:`AttributeStatisticsMode.MAXINTERSECTAREA` is not supported
    :type field_stats: list[tuple(str,AttributeStatisticsMode)] or list[tuple(str,str)] or str
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :return: Two-dimensional point dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.data.convert.dataset_region_to_line": """
        Convert a 2D area object into a line dataset. This method will directly convert each point object into a line object. If you need to extract a line dataset that does not contain repeated lines, you can use: py:func:`.pickup_border`
    
        :param source: two-dimensional surface dataset
        :type source: DatasetVector or str
        :param saved_fields: the names of the fields that need to be reserved
        :type saved_fields: list[str] or str
        :param out_data: The datasource where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: result line dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_region_to_point": """
        Convert 2D polygon dataset to point dataset
    
        :param source: two-dimensional surface dataset
        :type source: DatasetVector or str
        :param mode: the way to convert area object to point object
        :type mode: RegionToPointMode or str
        :param saved_fields: the names of the fields that need to be reserved
        :type saved_fields: list[str] or str
        :param out_data: datasource information where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: result two-dimensional point dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_text_to_field": """
        Store the text information of the two-dimensional text dataset in the field. The text information of the text object will be stored in the specified out_field field.
    
        :param source: The input two-dimensional text dataset.
        :type source: DatasetVector or str
        :param out_field: The name of the field that stores the text information. If the field name specified by out_field already exists, it must be a text field. If it does not exist, a new text field will be created.
        :type out_field: str
        :return: Return True if successful, otherwise return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.data.convert.dataset_text_to_point": """
        Convert a two-dimensional text dataset to a point dataset, and the text information of the text object will be stored in the specified out_field field
    
        :param source: input two-dimensional text dataset
        :type source: DatasetVector or str
        :param str out_field: The name of the field storing text information. If the field name specified by out_field already exists, it must be a text field. If it does not exist, a new text field will be created.
        :param saved_fields: The names of the fields that need to be reserved.
        :type saved_fields: list[str] or str
        :param out_data: The datasource where the result dataset is located
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: result dataset name
        :return: Two-dimensional point dataset or dataset name
        :rtype: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.data": """""",
    "iobjectspy._jsuperpy.data.op.zoom_geometry":
        """
        The scale transformation (zoom) of geometric objects supports point, line and area geometric objects.
        For any point on the geometric object:
            Scale transformation in the x direction: result_point.x = point.x * scala_x + center_point.x * (1-scala_x)
            Scale transformation in the y direction: result_point.y = point.y * scala_y + center_point.y * (1-scala_y)
    
        :param geometry: the geometric object to be transformed
        :type geometry: GeoPoint or GeoLine or GeoRegion
        :param Point2D center_point: zoom reference point, generally the center point of geometric objects
        :param float scale_x: The scaling factor in the x direction. When the value is less than 1, the geometric object is reduced; when the value is greater than 1, the geometric object is enlarged; when it is equal to 1, the geometric object remains unchanged
        :param float scale_y: The scaling factor in the y direction. When the value is less than 1, the geometric object is reduced; when the value is greater than 1, the geometric object is enlarged; when it is equal to 1, the geometric object remains unchanged
        :return: Return True for success, False for failure
        :rtype: bool
        """,
    "iobjectspy._jsuperpy.data.op.divide_polygon":
        """
        The object cutting used for national land parcel data can be cut by area or quantity. For example, a large parcel of land can be divided into a 10 acre plot. You can also divide the entire parcel into 10 parts, each with the same area.
    
        >>> ds = open_datasource('E:/data.udb')
        >>> dt = ds['dltb']
        >>> polygon = dt.get_geometries('SmID == 1')[0]
        >>> #Equal parts cut into 5 parts
        >>> divide_result = divide_polygon(polygon,'PART','NORTH', angle=45, divide_parts=5, prj=dt.prj_coordsys)
        >>> print(len(divide_result))
        5
        >>> #cut by area, cut to get a surface object with an area of â€‹â€‹30 square meters
        >>> divide_result = divide_polygon(polygon,'AREA','EAST', 0.0, divide_parts=1, divide_area=500,
        >>> divide_area_unit='SQUAREMETER', prj=dt.prj_coordsys)
        >>> print(len(divide_result))
        2
        >>> print(divide_result[0].area)
        500.0
    
    
        :param polygon: the divided two-dimensional polygon object, cannot be empty
        :type polygon: GeoRegion or Rectangle
        :param divide_type: face cut type, default is'PART'
        :type divide_type: DividePolygonType or str
        :param orientation: the orientation of face cutting, the default is'NORTH'
        :type orientation: DividePolygonOrientation or str
        :param float angle: The cutting azimuth angle, the clockwise included angle with the true north direction. If the cutting azimuth is 0 or 180 degrees, the cutting azimuth cannot be north and south. If the cutting azimuth is 90 or 270 degrees, 
                            The cutting position cannot be east and west.
        :param int divide_parts: The number of face cuts. For area cutting, the number of cuts cannot be greater than (the area of â€‹â€‹the object before cutting/cutting area), if it is cut in equal parts, it means the number after the final cut.
        :param float divide_area: The cutting area. When the cutting type is face cutting, this parameter must be set.
        :param divide_area_unit: The unit of the cutting area. When divide_area is set, this parameter needs to be set at the same time.
        :type divide_area_unit: AreaUnit or str
        :param float remainder_area: When the cutting type is area cutting, there may be small area objects left. You can use this parameter to merge the small area objects into adjacent objects. If the remaining area is less than the currently specified area value, it will be merged. 
                                     It is valid only when the value is greater than 0. If it is less than or equal to 0, it is not merged.
        :param prj: The spatial reference coordinate system of the segmented area object. Geographical coordinate system is not supported, because the cutting surface object needs to be cut according to the area (equivalent cutting needs to be converted to equal area cutting), and the effective area cannot be directly calculated under the latitude and longitude. 
                        The area must be converted to the projected coordinate system to calculate the area, but after the projection system, the data will be greatly deformed, which may lead to errors in the final result.
        :type prj: PrjCoordSys or str
        :return: The area object array obtained after splitting
        :rtype: list[GeoRegion]
        """,
    "iobjectspy._jsuperpy.data.ws.create_mem_datasource":
        """
        Create an in-memory data source
    
        :return: data source object
        :rtype: Datasource
        """,

}

_jsuperpy_analyst_locale = {
    "iobjectspy._jsuperpy.analyst.na": """
Two-Dimensional Network Analysis Module
""",

    "iobjectspy._jsuperpy.analyst.na.AllocationAnalystResult": """
    The analysis result class of resource allocation.
    """,

    "iobjectspy._jsuperpy.analyst.na.AllocationAnalystResult.demand_results": """DemandResult: Demand result object""",

    "iobjectspy._jsuperpy.analyst.na.AllocationAnalystResult.edges": """list[int]: collection of IDs of arcs passed in the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.AllocationAnalystResult.nodes": """list[int]: collection of node IDs passed in the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.AllocationAnalystResult.parse": """""",

    "iobjectspy._jsuperpy.analyst.na.AllocationAnalystResult.routes": """GeoLineM: The routing result of the allocation path analyzed by resource allocation.""",

    "iobjectspy._jsuperpy.analyst.na.AllocationAnalystResult.supply_center_node_id": """int: ID of the resource supply center to which it belongs""",

    "iobjectspy._jsuperpy.analyst.na.AllocationDemandType": """
    Resource allocation demand model

    :var AllocationDemandType.NODE: Node demand mode. In this mode, only the resource demand of the node is considered in the analysis, and the demand of the arc is excluded. For example, at Christmas, Saint
                                    The elderly give gifts to the children. Santaâ€™s location is a fixed center point, the number of gifts is the amount of resources, and the childâ€™s address is the demand node, a certain
                                    Children's demand for the number of gifts is the value of the node demand field of the node. Obviously, when Santa Claus gives gifts to children, we only consider gifts
                                    This is a node demand event.
    :var AllocationDemandType.EDGE: Edge demand mode. In this mode, only the demand for resources on the edge is considered during analysis, and the demand for nodes is excluded. For example, at Christmas, Saint
                                    The elderly give gifts to the children. Santaâ€™s location is a fixed center point, Santaâ€™s car gasoline inventory is the resource, and the childrenâ€™s address is the demand.
                                    The fuel consumption of the node, from the fixed center point to the address of the adjacent child and the address of the adjacent child is the arc demand field value. Obviously santa knot
                                    When children deliver gifts, we only consider the distribution of driving fuel consumption. This is an arc demand event.
    :var AllocationDemandType.BOTH: Node and edge demand mode. At the same time, consider the needs of the nodes and the needs of the arcs. For example, at Christmas, Santa Claus sends gifts to children, namely
                                    Considering the distribution of gifts and driving fuel consumption, this is a node and edge demand event.

    """,

    "iobjectspy._jsuperpy.analyst.na.BurstAnalystResult": """Burst analysis result class. Burst analysis results return key facilities, common facilities and edges.""",

    "iobjectspy._jsuperpy.analyst.na.BurstAnalystResult.critical_nodes": """list[int]: Critical facilities in the burst analysis that affect the upstream and downstream of the burst location.
                      Critical facilities include two types of facilities:

                       1. All facilities in the upstream of the burst location that directly affect the burst location.
                       2. The downstream facilities are directly affected by the location of the burst pipe and have outflow (that is, the outflow degree is greater than 0).
        """,

    "iobjectspy._jsuperpy.analyst.na.BurstAnalystResult.edges": """list[int]: The edges that affect the position of the burst tube and the edges affected by the position of the burst tube. It is the key to two-way search from the position of the burst tube The edge to which facilities and general facilities are traversed.""",

    "iobjectspy._jsuperpy.analyst.na.BurstAnalystResult.normal_nodes": """list[int]: Common facilities affected by the location of the burst tube in the burst analysis.
                      General facilities include three types of facilities:

                       1. Facilities that are directly affected by the location of the burst pipe and have no outflow (the outflow degree is 0).
                       2. All facilities A directly affected by the outflow edge of each upstream critical facility (excluding all critical facilities), and facility A needs to meet, the influencing edge from upstream critical facility to facility A and upstream and downstream critical facilities The edge of influence has a common part.
                       3. Facility A (critical facility 2 and ordinary facility 1) that is directly affected by the location of the blast pipe downstream of the location of the blast pipe, and the facilities directly affecting facility A in the upstream of facility A
                          Point B (excluding all key facilities), and it needs to be satisfied that the influencing arc from facility A to facility B and the influencing arc of upstream and downstream key facilities have a common part.

        """,

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo": """
    Demand point information class. The coordinates or node ID of the demand point and the demand quantity of the demand point are stored.
    """,

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.demand_node": """int: Demand point ID""",

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.demand_point": """Point2D: Demand point coordinates""",

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.demands": """list[float]: Demand quantity of demand point.""",

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.end_time": """datetime.datetime: The latest time of arriving, which means the latest time point when the vehicle arrives at that point""",

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.set_demand_node": """
        Set demand point ID

        :param int value: demand point ID
        :return: self
        :rtype: DemandPointInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.set_demand_point": """
        Set the coordinates of demand point

        :param Point2D value: the coordinates of demand point
        :return: self
        :rtype: DemandPointInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.set_demands": """
        Set the demand for the demand point. The demand can be multi-dimensional, and its dimension must be the same as the vehicle's load dimension and meaning. If the demand of a destination is too large to exceed the maximum load of the vehicle, this point will be discarded in the analysis.

        :param value: The demand quantity of the demand point.
        :type value: list[float] or tuple[float]
        :return: self
        :rtype: DemandPointInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.set_end_time": """
        Set the latest arrival time  

        :param value: the latest arrival time, which means the latest time when the vehicle arrives at that point
        :type value: datetime.datetime
        :return: self
        :rtype: DemandPointInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.set_start_time": """
        Set the earliest arrival time.

        :param value: the earliest time of arrival, which means the earliest time when the vehicle arrives at that point.
        :type value: datetime.datetime or str
        :return: self
        :rtype: DemandPointInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.set_unload_time": """
        Set the unloading time.

        :param value: Time to unload the cargo, which means the time the vehicle needs to stay at this point. The default unit is minutes.
        :type value: int
        :return: self
        :rtype: DemandPointInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.start_time": """datetime.datetime: Earliest time of arrival, which means the earliest time point when the vehicle arrives at that point""",

    "iobjectspy._jsuperpy.analyst.na.DemandPointInfo.unload_time": """int: Unloading time, indicating the time the vehicle needs to stay at that point. The default unit is minutes.""",

    "iobjectspy._jsuperpy.analyst.na.DemandResult": """
    Demand result class. This class is used to return relevant information about demand results, including demand node ID and resource supply center ID.
    """,

    "iobjectspy._jsuperpy.analyst.na.DemandResult.actual_resource": """float: The actual amount of resources allocated, only valid for resource allocation.""",

    "iobjectspy._jsuperpy.analyst.na.DemandResult.demand_id": """int: When the :py:attr:`is_edge` method is True, this method return the ID of the edge, when it is False, this method what is returned is the ID of the node.""",

    "iobjectspy._jsuperpy.analyst.na.DemandResult.is_edge": """bool: Return whether the demand result is an edge. If it is not an edge, the demand result is a node. Only valid for resource allocation, otherwise False.""",

    "iobjectspy._jsuperpy.analyst.na.DemandResult.supply_center_node_id": """int: Resource Supply Center ID""",

    "iobjectspy._jsuperpy.analyst.na.DirectionType": """
    Direction, used for driving guidance

    :var DirectionType.EAST: East
    :var DirectionType.SOUTH: South
    :var DirectionType.WEST: West
    :var DirectionType.NORTH: North
    :var DirectionType.NONE: The node has no direction
    """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst": """Facility network analysis class.

       Facilities network analysis class. It is one of the network analysis functions, mainly used for various connectivity analysis and tracking analysis.

       The facility network is a network with directions. That is, the medium (water flow, current, etc.) will flow in the network according to the rules of the network itself.

       The premise of facility network analysis is that a dataset for facility network analysis has been established. The basis for establishing a dataset for facility network analysis is to establish a network dataset, and use it on this basis
       The :py:meth:`build_facility_network_directions` method gives the network dataset unique data information for facility network analysis, that is, the network dataset
       Establish the flow direction so that the original network dataset has the most basic conditions for facility network analysis. At this time, various facility network analysis can be performed. If your facility network
       with level information, you can further use the :py:meth:`build_facility_network_hierarchies` method to add level information.
    """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.__init__": """

        :param analyst_setting: Set the network analysis environment.
        :type analyst_setting: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.analyst_setting": """FacilityAnalystSetting: Facility network analysis environment""",

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.burst_analyse": """
        Two-way tube explosion analysis, by specifying the edge of the tube, find the nodes in the upstream and downstream of the edge of the tube that directly affect the position of the tube and the nodes directly affected by the position of the tube.

        :param source_nodes: The specified array of facility node ID . It can not be empty.
        :type source_nodes: list[int] or tuple[int]
        :param int edge_or_node_id: The specified edge ID or node ID, it's the location of the tube burst.
        :param bool is_uncertain_direction_valid: Whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_id: Whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID.
        :return: Explosion tube analysis result
        :rtype: BurstAnalyseResult
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.check_loops": """
        Check the network loop and return the ID array of the edges that make up the loop.

        In the facility network, a loop refers to a closed path formed by two or more edge segments with a flow direction value of 2 (that is, an uncertain flow direction). This means that the loop must meet the following two conditions at the same time:

         1. It is a closed path composed of at least two edges;
         2. The flow directions of the edge segments forming the loop are all 2, that is, the flow direction is uncertain.

        For the flow direction, please refer to the :py:meth:`build_facility_network_directions` method.

        The figure below is a part of the facility network, using different symbols to show the flow direction of the network edge. Perform a loop check on the network and check out two loops, the red closed path in the figure.
        On the upper right, there is an edge with a flow direction of 2. Since it does not form a closed path with other edges with a flow direction of 2, it is not a loop:

        .. image:: ../image/CheckLoops.png


        :return: The array of the edge ID that make up the loop.
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_common_ancestors": """
        According to the given array of edge ID or node ID , find the common upstream edge of these edges and return the edge ID array.
        Common upstream refers to a common upstream network of multiple nodes (or edges). This method is used to find the common upstream edge of multiple edges, that is, take the intersection of the respective upstream edges of these edges, and return the edge ID of these edges as a result.

        As shown in the figure below, the flow is in the direction indicated by the arrow in the figure. The first two figures are the results of upstream tracking of node 1 and node 2, and find their respective upstream edges (green).
        The three pictures look for a common upstream edge (orange) for node 1 and node 2. It is easy to see that the common upstream edge of node 1 and node 2 is the intersection of their respective upstream edges.

        .. image:: ../image/CommonAncestors.png

        :param edge_or_node_ids: specified array of edge ID or node ID 
        :type edge_or_node_ids: list[int] or tuple[int]
        :param bool is_uncertain_direction_valid: Whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_ids: Whether edge_or_node_ids represents the edge ID, True represents the edge ID, and False represents the node ID.
        :return: The array of edge ID 
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_common_catchments": """
        According to the specified node ID array or edge ID array, find the common downstream edge of these nodes, and return the edge ID array.

        Common downstream refers to a common downstream network of multiple nodes (or edges). This method is used to find the common downstream edges of multiple nodes, that is, take the intersection of the respective downstream edges of these nodes, and return the edge IDs of these edges as a result.

        As shown in the figure below, the flow is in the direction indicated by the arrow in the figure. The first two figures are the results of downstream tracking of node 1 and node 2, and find the respective downstream edges (green).
        The three pictures look for a common downstream edge (orange) for node 1 and node 2. It is easy to see that the common downstream edge of node 1 and node 2 is the intersection of their respective downstream edges.

        .. image:: ../image/CommonCatchments.png

        :param edge_or_node_ids: specified node ID array or edge ID array
        :type edge_or_node_ids: list[int]
        :param bool is_uncertain_direction_valid: Whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_ids: Whether edge_or_node_ids represents the edge ID, True represents the edge ID, and False represents the node ID.
        :return: The array of edge IDs that are common downstream of the given node
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_connected_edges": """
        According to the given node ID array or edge ID array, find the edges connected with these edges (or nodes), and return the edge ID array.
        This method is used to find the edge that is connected to a given edge (or node). After finding the connected edge, the corresponding connect nodes can be found according to the network topology, that is, the starting node and the ending node of the edge..

        :param edge_or_node_ids: node ID array or edge ID array
        :type edge_or_node_ids: list[int] or tuple[int]
        :param bool is_edge_ids: Whether edge_or_node_ids represents the edge ID, True represents the edge ID, and False represents the node ID.
        :return: The array of edge IDs that are common downstream of the given node
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_critical_facilities_down": """
        Downstream key facility search, that is, find the key downstream facility nodes of a given edge, and return the ID array of the key facility node and the downstream edge ID array affected by the given edge.
        In the search and analysis of downstream key facilities, we divide the nodes of the facility network into two types: ordinary nodes and facility nodes. The facility nodes are considered to be nodes that can affect network connectivity.
        For example, a valve in a water supply pipe network; ordinary nodes are nodes that do not affect network connectivity, such as fire hydrants or three links in the water supply pipe network.

        The downstream key facility search analysis will filter out the key nodes from the given facility nodes. These key nodes are the most basic nodes for maintaining connectivity between the analysis edge and its downstream, that is,
        After closing these key nodes, the analysis node cannot communicate with the downstream. At the same time, the result of this analysis also includes the union of downstream edges affected by a given edge.

        The search method of key facility nodes can be summarized as follows: starting from the analysis edge and searching its downstream, the first facility node encountered in each direction is the key facility node to be searched.

        :param source_node_ids: The specified facility node ID array. Can not be empty.
        :type source_node_ids: list[int] or tuple[int]
        :param int edge_or_node_id: Specified analysis edge ID or node ID
        :param bool is_uncertain_direction_valid: Whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_id: Whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID.
        :return: facility network analysis result
        :rtype: FacilityAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_critical_facilities_up": """
        Upstream key facility search, that is, find the key facility nodes upstream of a given arc, and return the key node ID array and its downstream edge ID array.
        In the search and analysis of upstream key facilities, we divide the nodes of the facility network into two types: ordinary nodes and facility nodes. The facility nodes are considered to be the nodes that can affect network connectivity.
        For example, a valve in a water supply pipe network; ordinary nodes are nodes that do not affect network connectivity, such as fire hydrants or three links in the water supply pipe network. The upstream critical facility search and analysis needs to specify facility nodes and
        Analysis node, where the analysis node can be a facility node or an ordinary node.

        The upstream key facility search analysis will filter out the key nodes from the given facility nodes. These key nodes are the most basic nodes for maintaining connectivity between the analysis edge and its upstream, that is,
        After closing these key nodes, the analysis node cannot communicate with the upstream. At the same time, the result of the analysis also includes the union of the downstream edges of the key nodes found.

        The search method of key facility nodes can be summarized as follows: starting from the analysis edge and tracing back to its upstream, the first facility node encountered in each direction is the key facility node to be searched.
        As shown in the figure below, starting from the analysis edge (red), the key facility nodes found include: 2, 8, 9, and 7. Nodes 4 and 11 are not the first facility node encountered in the backtracking direction.
        Therefore, it is not a critical facility node. As an illustration, only the upstream part of the analysis edge is given here, but note that the analysis results will also give the downstream edges of key facility nodes 2, 8, 9 and 7.

        .. image:: ../image/findCriticalFacilitiesUp.png

        * Applications

        After a pipe burst occurs in the water supply network, all valves can be used as facility nodes, and the bursting pipe section or pipe point can be used as an analysis edge or analysis node to find and analyze upstream key facilities.
        Quickly find the minimum number of valves in the upstream that need to be closed. After closing these valves, the burst pipe section or pipe point no longer communicates with its upstream, thereby preventing the outflow of water and preventing the disaster from aggravating and
        Waste of resources. At the same time, the analysis shows that the union of the downstream edges of the valve that needs to be closed, that is, the range of influence after the valve is closed, is used to determine the water stop area, and promptly notify and emergency measures.

        .. image:: ../image/FindClosestFacilityUp.png


        :param source_node_ids: The specified facility node ID array. Can not be empty.
        :type source_node_ids: list[int] or tuple[int]
        :param int edge_or_node_id: analysis edge ID or node ID
        :param bool is_uncertain_direction_valid: Whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: facility network analysis result
        :rtype: FacilityAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_loops": """
        According to the given node ID array or edge ID array, find the loops connected with these nodes (edges), and return the edge ID array that forms the loop.

        :param edge_or_node_ids: The specified node or edge ID array.
        :type edge_or_node_ids: list[int] or tuple[int]
        :param bool is_edge_ids: whether edge_or_node_ids represents the edge ID, True represents the edge ID, False represents the node ID
        :return: The edge ID array of the loop connected with the given edge.
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_path": """
        Facility network path analysis, that is, according to the given start and end node IDs, find the path with the least cost, and return the edges, nodes and costs included in the path.

        The search process of the least costly path between two nodes is: starting from a given starting node, according to the flow direction, find all paths to a given end node, and then find the least costly one and return.

        The figure below is a schematic diagram of the minimum cost path for two nodes. Starting from the starting node B, along the network flow direction, there are three paths to the ending node P, namely BDLP, BCGIJKP
        And E-E-F-H-M-N-O-P, the path B-C-G-I-J-K-P  has the least cost, which is 105, so this path is the least costly path from node B to P.

        .. image:: ../image/FacilityFindPath.png

        :param int start_id: Starting node ID or edge ID.
        :param int end_id: End node ID or edge ID. The start ID and end ID must be node ID or edge ID at the same time
        :param str weight_name: The name of the specified weight field information object.
        :param bool is_uncertain_direction_valid: Whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: Facility network analysis result.
        :rtype: FacilityAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_path_down": """

        Facility network downstream path analysis, according to a given node ID or edge ID participating in the analysis, query the node (edge) downstream path with the least cost, and return the edge, node and cost included in the path.

        The search process of the downstream least costly path can be understood as: starting from a given node (or edge), according to the flow direction, find all the downstream paths of the node (or edge), and then find out from it
        Return the least expensive one. This method is used to find the minimum cost path downstream of a given node.

        The figure below is a simple facility network. Arrows are used on the network edges to mark the flow of the network, and the weights are marked next to the edges. For the analysis node H, perform the downstream least cost path analysis.
        First, start from node H, search down according to the flow direction, and find all downstream paths of node H. There are 4 paths in total, including: HLG, HLK, HMS and HMQR.
        The network resistance (ie, the weight) calculates the cost of these paths, and it can be concluded that the cost of the HLK path is 11.1. Therefore, the lowest cost path of node H is HLK.

        .. image:: ../image/PathDown.png

        :param int edge_or_node_id: the specified node ID or edge ID
        :param str weight_name: The name of the specified weight field information object. That is, set the specified in the network analysis environment: py:attr:`FacilityAnalystSetting.weight_fields`
                                Specific one: py:class:`WeightFieldInfo`: py:attr:`WeightFieldInfo.weight_name`.
        :param bool is_uncertain_direction_valid: Specifies whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: Facility network analysis result.
        :rtype: FacilityAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_path_up": """
        Analysis of the upstream path of the facility network, according to the given node ID or edge ID, query the node (edge) upstream path with the least cost, and return the edge, node and cost included in the path.

        The search process of the upstream minimum cost path can be understood as: starting from a given node (or edge), according to the flow direction, find all the upstream paths of the node (or edge), and then find from it.
        Return the least expensive one. This method is used to find the minimum cost path upstream of a given node.

        The figure below is a simple facility network. Arrows are used on the network edges to mark the flow of the network, and the weights are marked next to the edges. For the analysis node I, perform the upstream minimum cost path analysis.
        First, start from node I and trace upward according to the flow direction to find all the upstream paths of node I. There are 6 in total, including: EFI, AFI, BGJI, DGJI, CGJI
        And HJI, and then calculate the cost of these paths according to the network resistance (ie weight), it can be concluded that the cost of the EFI path is the smallest, which is 8.2. Therefore, the upstream of node I is the smallest
        The cost path is EFI.

        .. image:: ../image/PathUp.png

        :param int edge_or_node_id: node ID or edge ID
        :param str weight_name: The name of the weight field information object
        :param bool is_uncertain_direction_valid: Specifies whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: facility network analysis result
        :rtype: FacilityAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_sink": """
        Find the sink according to a given node ID or edge ID, that is, starting from a given node (edge), find the downstream sink that flows out of the node according to the flow direction, and return the minimum cost for the given node to reach the sink The edges, nodes, and costs included in the path.
        Starting from a given node, this method finds the downstream sink point that flows out of the node according to the flow direction. The result of the analysis is the edge, node and cost included in the minimum cost path from the node to the found sink.
        If there are multiple sinks in the network, the farthest sink will be searched, which is the sink with the least cost and the largest cost from a given node. In order to facilitate understanding, the realization process of this function can be divided into three steps:

         1. Starting from a given node, according to the flow direction, find all the sink points downstream of the node;
         2. Analyze the minimum cost path from a given node to each sink and calculate the cost;
         3. Select the path corresponding to the maximum cost calculated in the previous step as the result, and give the edge ID array, node ID array and the cost of the path on the path.

        Note: The node ID array in the analysis result does not include the analysis node itself.

        The figure below is a simple facility network. Arrows are used on the network edges to mark the flow of the network, and the weights are marked next to the edges. Perform search sink analysis for analysis node D. Know,
        Starting from node D and searching downwards according to the flow direction, there are 4 sinks in total. The least costly paths from node D to sink are: EHLG, EHLK, EHMS and EHMQR,
        According to the network resistance, that is, the weight of the edge, it can be calculated that the cost of the EHMQR path is 16.6, so the node R is the sink found.

        .. image:: ../image/FindSink.png

        :param int edge_or_node_id: node ID or edge ID
        :param str weight_name: The name of the weight field information object
        :param bool is_uncertain_direction_valid: Specifies whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: facility network analysis result
        :rtype: FacilityAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_source": """

        Find the source according to a given node ID or edge ID, that is, starting from a given node (edge), find the network source flowing to the node according to the flow direction, and return the edges, nodes and costs included in the minimal cost path from the source to the given node.
        This method starts from a given node, according to the flow direction, finds the network source node (that is, the source point) that flows to the node, and the result of the analysis is the least costly path from the found source to the given node.
        Including edges, nodes and costs. If there are multiple sources in the network, it will search for the farthest source that is the least expensive to reach a given node. In order to facilitate understanding, the realization process of this function can be divided into three steps:

         1. Starting from a given node, according to the flow direction, find all the source points upstream of the node;
         2. Analyze the minimum cost path for each source to reach a given node and calculate the cost;
         3. Select the path corresponding to the maximum cost calculated in the previous step as the result, and give the edge ID array, node ID array and the cost of the path on the path.

        Note: The node ID array in the analysis result does not include the analysis node itself.

        The figure below is a simple facility network. Arrows are used on the network edges to mark the flow of the network, and the weights are marked next to the edges. For the analysis node M, perform source search analysis. Know,
        Starting from node M and tracing upward according to the flow direction, there are 7 sources in total. The least costly paths from source to node M are: CHM, AEHM, BDEHM, FDEHM,
        JNM, INM, and PNM, according to the network resistance, which is the edge weight, can calculate that the cost of the BDEHM path is the largest, which is 18.4. Therefore, node B is the source found.

        .. image:: ../image/FindSource.png

        :param int edge_or_node_id: node ID or edge ID
        :param str weight_name: The name of the weight field information object
        :param bool is_uncertain_direction_valid: Specifies whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: facility network analysis result
        :rtype: FacilityAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.find_unconnected_edges": """
        According to the given node ID array, find the edges that are not connected to these nodes, and return the edge ID array.
        This method is used to find edges that are not connected to a given node. After finding connected edges, the corresponding disconnected nodes can be queried according to the network topology, that is, the starting node and ending node of the edge.

        :param edge_or_node_ids: node ID array or edge ID array
        :type edge_or_node_ids: list[int] or tuple[int]
        :param bool is_edge_ids: whether edge_or_node_ids represents the edge ID, True represents the edge ID, False represents the node ID
        :return: edge ID array
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.is_load": """
        Determine whether the network dataset model is loaded.

        :return: The network dataset model load return True, otherwise it return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.load": """
        Load the facility network model according to the facility network analysis environment settings.

        Note that in the following two situations, the load method must be called again to load the network model, and then analyze.
             -The parameters of the facility network analysis environment setting object have been modified, and the method needs to be called again, otherwise the modification will not take effect and the analysis result will be wrong;
             -Any modification to the network dataset used, including modifying the data in the network dataset, replacing the dataset, etc., needs to reload the network model, otherwise the analysis may go wrong.

        :return: Used to indicate the success of loading the facility network model. It returns true if it succeeds, otherwise it returns false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.set_analyst_setting": """
        Set up the environment for facility network analysis.

        The setting of environmental parameters of facility network analysis directly affects the results of facility network analysis. The parameters required for facility network analysis include: the dataset used for facility network analysis (
        The network dataset of flow direction is established or the network dataset of flow direction and level is established at the same time, which means that the method corresponds to: py:class:`FacilityAnalystSetting`
        The specified network dataset must have flow direction or flow direction and level information), node ID field, edge ID field, edge start node ID field, edge end node ID field, weight
        value information, distance tolerance from point to edge, obstacle node, obstacle edge, flow direction, etc.

        :param value: facility network analysis environment parameter
        :type value: FacilityAnalystSetting
        :return: self
        :rtype: FacilityAnalyst
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.trace_down": """
        Perform downstream tracking based on the given edge ID or node ID, that is, find the downstream of a given edge (node), and return the edge, node and total cost included in the downstream.
        Downstream tracking is the process of starting from a given node (or ) edge and finding its downstream according to the flow direction. This method is used to find the downstream of a given edge, and the analysis results are the edges, nodes, and costs flowing through the entire downstream.

        Downstream tracking is often used to analyze the scope of influence. E.g:

        -After the tap water supply pipeline bursts, all downstream pipelines at the location of the accident will be tracked and analyzed through downstream, and then the affected water supply area will be determined through spatial query, so as to promptly issue notices and adopt
          Take emergency measures, such as a fire truck or a water company arranging vehicles to deliver water to the water-shutdown area.

        -When pollution is found in a certain location of the river, downstream tracking can be used to analyze all downstream river sections that may be affected, as shown in the figure below. Before analysis, you can also
          Types, discharges, etc., combined with appropriate water quality management models, analyze the downstream river sections or locations that will not be polluted before pollution is removed, and set them as obstacles (set in FacilityAnalystSetting),
          When tracking downstream, the tracking stops when the obstacle is reached, which can narrow the scope of analysis. After identifying the potentially affected reach, the spatial query and analysis are used to mark all the nearby reach
          Water-using units and residential areas shall issue notices in a timely manner and take emergency measures to prevent further expansion of pollution hazards.


        :param int edge_or_node_id: node ID or edge ID
        :param str weight_name: The name of the weight field information object
        :param bool is_uncertain_direction_valid: Specifies whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: Facility network analysis result.
        :rtype: FacilityAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalyst.trace_up": """
        Perform upstream tracking based on a given node ID or edge ID, that is, find the upstream of a given node, and return the edge, node and total cost contained in the upstream.

        * Upstream and downstream

          For a node (or edge) of a facility network, the edge and the node through which resources in the network finally flow into the node (or edge) are called its upstream; The edge and network through which the node (or edge) flows out and finally flows into the sink point is called its downstream.

          Take the upstream and downstream of the node as an example. The following figure is a schematic diagram of a simple facility network, using arrows to mark the flow of the network. According to the flow direction, it can be seen that the resources flow through the nodes
          2, 4, 3, 7, 8, and edges 10, 9, 3, 4, and 8 eventually flow into node 10. Therefore, these nodes and edges are called upstream of node 10, and the nodes are called its upstream node,
          The edge is called its upstream edge. Similarly, resources flow out of node 10, flow through nodes 9, 11, 12, and edges 5, 7, 11, and finally flow out of the network. Therefore, these nodes and edges are called
          the downstream of node 10, where the node is called its downstream node, and the edge is called its downstream edge.

          .. image:: ../image/UpAndDown.png

        * Upstream tracking and downstream tracking

          Upstream tracking is the process of starting from a given node (or edge) and finding its upstream according to the flow direction. Similarly, downstream tracking starts from a given node (or edge), according to the flow direction,
          find its downstream process. The FacilityAnalyst class respectively provides methods for upstream or downstream tracking starting from a node or edge. The result of the analysis is the upstream or downstream found
          The edge ID array and node ID array included in the tour, and the cost of flowing through the entire upstream or downstream. This method is used to find the upstream of a given edge.

        * Applications

          A common application of upstream tracking is to help locate the source of river water pollutants. Rivers are not only an important path for the earthâ€™s water cycle, but also the most important freshwater resource for mankind.
          If the source of pollution is not found and eliminated in time, it is likely to affect people's normal drinking water and health. Because the river flows from high to low under the influence of gravity, when the river is polluted,
          It should be considered that there may be pollution sources in the upstream, such as industrial wastewater discharge, domestic sewage discharge, pesticide and fertilizer pollution, etc. The general steps for tracking the source of river water pollutants are generally:

            -When the monitoring data of the water quality monitoring station shows that the water quality is abnormal, first determine the location of the abnormality, and then find the edge or node where the location is (or the nearest) on the river network (network dataset), as the upstream tracking starting point;
            -If you know the normal water quality monitoring locations closest to the starting point in the upstream of the starting point, you can set these locations or the river section where they are located as obstacles, which can help further narrow the scope of the analysis. Because it can be considered that upstream of the normal location of water quality monitoring, it is impossible for the pollution source of this investigation to exist. After setting as an obstacle, perform upstream tracking analysis. After tracking to the location, it will not continue to track the upstream of the location;
            -Perform upstream tracking analysis to find all river sections that converge to the river section where the water quality abnormality occurs;
            -Use spatial query and analysis to find all possible pollution sources located near these river sections, such as chemical plants, garbage treatment plants, etc.;
            -Further screening of pollution sources based on the monitoring data of abnormal water quality;
            -Analyze the pollutant discharge load of the selected pollution sources and rank them according to their likelihood of causing pollution;
            -Conduct on-site investigations and research on possible pollution sources in order to finally determine the source of the pollution.


        :param int edge_or_node_id: node ID or edge ID
        :param str weight_name: The name of the weight field information object
        :param bool is_uncertain_direction_valid: Specifies whether the uncertain flow direction is valid. Specify true to indicate that the uncertain flow direction is valid, and analyze when the uncertain flow direction is encountered
                                                  continue; specify false, indicating that the uncertain flow direction is invalid, and it will stop continuing in that direction when encountering an uncertain flow direction
                                                  continue to find. When the value of the flow direction field is 2, it means that the flow direction of the edge is uncertain.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: Facility network analysis result.
        :rtype: FacilityAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystResult": """
    Facility network analysis result class. This class is used to obtain the results of facility network analysis such as finding sources and sinks, upstream and downstream tracking, and finding routes, including result edge ID array, result node ID array, and cost.
    """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystResult.cost": """float: The cost of the facility network analysis result.
                  For different facility network analysis functions, the meaning of the return value of this method is different:

                  -Find Source: This value is the cost of the least costly path from the analysis edge or node to the source.
                  -Find sink: This value is the least costly path cost of analyzing edge or node to sink.
                  -Upstream Tracking: This value is the total cost of analyzing the edge or the edge included upstream of the node.
                  -Downstream Tracking: This value is the total cost of analyzing the edge or the edge included downstream of the node.
                  -Path analysis: This value is the cost of the least costly path found.
                  -Upstream path analysis: This value is the cost of the found upstream path with the least cost.
                  -Downstream path analysis: This value is the cost of the found downstream path with the least cost.
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystResult.edges": """list[int]: The edge ID array in the facility network analysis result.
                      For different facility network analysis functions, the meaning of the return value of this method is different:

                      -Find source: This value is the edge ID array of the edge included in the least costly path from the analysis edge or node to the source.
                      -Find sink: This value is the edge ID array of the edge included in the least costly path from the analyzed edge or node to the sink.
                      -Upstream Tracking: This value is the edge ID array of the edge included in the upstream of the analyzed edge or node.
                      -Downstream Tracking: The value is an array of edge IDs of the analyzed edge or the edge contained downstream of the node.
                      -Path analysis: The value is the edge ID array of the edges that the least costly path found .
                      -Upstream path analysis: This value is the edge ID array of the edges that the found upstream least costly path passes.
                      -Downstream path analysis: This value is the edge ID array of the edges that the found downstream least costly path passes.
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystResult.nodes": """list[int]: The node ID array in the facility network analysis result.
                      For different facility network analysis functions, the meaning of the return value of this method is different:

                      -Find Source: This value is the node ID array of the nodes included in the least costly path from the analysis edge or node to the source.
                      -Find sink: This value is the node ID array of the nodes included in the least costly path from the analyzed edge or node to the sink.
                      -Upstream Tracking: The value is the node ID array of the nodes included in the upstream of the analysis edge or node.
                      -Downstream tracking: This value is the node ID array of the nodes included in the downstream of the analysis edge or node.
                      -Path analysis: The value is an array of node IDs of the nodes that the least costly path found.
                      -Upstream path analysis: This value is the node ID array of the nodes that the found upstream least costly path passes.
                      -Downstream path analysis: This value is the node ID array of the nodes that the found downstream least costly path passes.
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting": """
    Facilities network analysis environment setting class. Facilities network analysis environment setting class. This class is used to provide all the parameter information needed for facility network analysis. The setting of each parameter of the facility network analysis environment setting category directly affects the result of the analysis.
    """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.barrier_edge_ids": """list[int]: ID list of barrier edge segments""",

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.barrier_node_ids": """list[int]: ID list of barrier nodes""",

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.direction_field": """str: flow direction field""",

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.edge_id_field": """str: The field that marks the edge ID in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.f_node_id_field": """str: The field that marks the starting node ID of the edge in the network dataset """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.network_dataset": """DatasetVector: network dataset""",

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.node_id_field": """str: The field that identifies the node ID in the network dataset """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.set_barrier_edge_ids": """
        Set the ID list of barrier edges

        :param value: ID list of barrier edge
        :type value: str or list[int]
        :return: self
        :rtype: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.set_barrier_node_ids": """
        Set the ID list of barrier nodes

        :param value: ID list of barrier node
        :type value: str or list[int]
        :return: self
        :rtype: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.set_direction_field": """
        Set flow direction field

        :param str value: flow direction field
        :return: self
        :rtype: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.set_edge_id_field": """
        Set the field that identifies the node ID in the network dataset

        :param str value: The field that marks the edge segment ID in the network dataset
        :return: self
        :rtype: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.set_f_node_id_field": """
        Set the field to mark the starting node ID of the edge in the network dataset

        :param str value: The field that marks the starting node ID of the edge in the network dataset
        :return: self
        :rtype: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.set_network_dataset": """
        Set up network dataset

        :param dt: network dataset
        :type dt: DatasetVetor or str
        :return: self
        :rtype: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.set_node_id_field": """
        Set the field of the network dataset to identify the node ID

        :param str value: The field that identifies the node ID in the network dataset
        :return: self
        :rtype: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.set_t_node_id_field": """
        Set the field to mark the starting node ID of the edge in the network dataset

        :param str value:
        :return: self
        :rtype: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.set_tolerance": """
        Set node tolerance

        :param float value: node tolerance
        :return: self
        :rtype: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.set_weight_fields": """
        Set weight field

        :param value: weight field
        :type value: list[WeightFieldInfo] or tuple[WeightFieldInfo]
        :return: self
        :rtype: FacilityAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.t_node_id_field": """str: the field that marks the starting node ID of the edge in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.tolerance": """float: node tolerance""",

    "iobjectspy._jsuperpy.analyst.na.FacilityAnalystSetting.weight_fields": """list[WeightFieldInfo]: weight field """,

    "iobjectspy._jsuperpy.analyst.na.GroupAnalystResult": """
    Group analysis result class. This class is used to return the results of grouping analysis, including the unallocated distribution point set and the analysis result item set.
    """,

    "iobjectspy._jsuperpy.analyst.na.GroupAnalystResult.error_terminal_point_indexes": """list[int]: a collection of unallocated distribution points """,

    "iobjectspy._jsuperpy.analyst.na.GroupAnalystResult.groups": """list[GroupAnalystResultItem]: Analysis result item collection""",

    "iobjectspy._jsuperpy.analyst.na.GroupAnalystResultItem": """
    Group analysis result item category. The group analysis result item records the index of the center point in each group, the set of distribution point indexes contained in the group, the total cost in the group, and the set of lines from each distribution point to the center point and the total load of the group.
    
    """,

    "iobjectspy._jsuperpy.analyst.na.GroupAnalystResultItem.center": """int: The index of the center point of the grouping result""",

    "iobjectspy._jsuperpy.analyst.na.GroupAnalystResultItem.cost": """float: total cost of grouping results""",

    "iobjectspy._jsuperpy.analyst.na.GroupAnalystResultItem.lines": """list[GeoLineM]: The collection of lines from each distribution point to the center point of the grouping result""",

    "iobjectspy._jsuperpy.analyst.na.GroupAnalystResultItem.load_sum": """float: total load of grouping results""",

    "iobjectspy._jsuperpy.analyst.na.GroupAnalystResultItem.members": """list[int]: The index collection of the distribution points of the grouping result""",

    "iobjectspy._jsuperpy.analyst.na.LocationAnalystResult": """
    The location analysis result class.
    """,

    "iobjectspy._jsuperpy.analyst.na.LocationAnalystResult.demand_results": """list[DemandResult]: Demand result object array """,

    "iobjectspy._jsuperpy.analyst.na.LocationAnalystResult.supply_results": """list[SupplyResult]: resource supply result object array """,

    "iobjectspy._jsuperpy.analyst.na.MapMatching": """
    Map matching based on HMM (Hidden Markov Chain).
    Divide the trajectory points according to the identification field, sort and divide the trajectory by the time field, and find the most likely route of each trajectory. The purpose is to restore the real path based on the track points.
    """,

    "iobjectspy._jsuperpy.analyst.na.MapMatching.__init__": """
        Initialization object

        :param PathAnalystSetting path_analyst_setting: Best path analysis parameters
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatching.batch_match": """
        Batch map matching, input a series of points for map matching. Note that this method assumes that the input point string belongs to the same track line by default.

        :param points: track points to be matched
        :type points: list[TrackPoint] or tuple[TrackPoint]
        :return: Map matching result
        :rtype: MapMatchingResult
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatching.batch_match_dataset": """
        Map the dataset and save the result as point data

        :param source_dataset: original track point dataset
        :type source_dataset: DatasetVector or str
        :param str id_field: ID field of the track. Track points with the same ID value belong to a track, such as mobile phone number, license plate number, etc. When no ID field is specified, all points in the dataset will be classified as a track.
        :param str time_field: The time field of the track point, must be a time or timestamp type field
        :param float split_time_milliseconds: The time interval for splitting the track. If the time interval between two adjacent points in time is greater than the specified time interval for splitting the track, the track will be split between the two points.
        :param out_data: The datasource to save the result dataset
        :type out_data: Datasource or str
        :param str out_dataset_name: result dataset name
        :param str result_track_index_field: The field that saves the track index. After the track is divided, a track may be divided into multiple sub-tracks.
                                              result_track_index_field will store the index value of the sub track, the value starts from 1. Because the result dataset will 
                                              save all fields of the source track point dataset, so it must be ensured that the result_track_index_field field value is not occupied in the source track point dataset
        :return: The result track point dataset, correctly matched to the track point on the road.
        :rtype: DatasetVector
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatching.match": """
        Real-time map matching. Real-time map matching only inputs one track point at a time, but the information of the previous track point matching will continue to be retained for the current match.
        There may be multiple results returned by real-time map matching. The number of returned results is determined by the road that can be matched at the current point. The returned results are arranged in descending order of the possibility of the result. Before the trajectory is matched, the result returned by the current result only reflects the possible results of the current trajectory point and the previous point.

        When is_new_track is True, it means that a new track will be opened, the previous matching records and information will be cleared, and the current point will be the first point of the track.

        :param point: track point to be matched
        :type point: TrackPoint
        :param bool is_new_track: Whether to open a new track
        :return: real-time map matching
        :rtype: list[MapMatchingLikelyResult]
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatching.max_limited_speed": """float: maximum limit speed""",

    "iobjectspy._jsuperpy.analyst.na.MapMatching.measurement_error": """float: track point error value""",

    "iobjectspy._jsuperpy.analyst.na.MapMatching.path_analyst_setting": """PathAnalystSetting: Optimal path analysis parameter""",

    "iobjectspy._jsuperpy.analyst.na.MapMatching.set_max_limited_speed": """
        Set the maximum speed limit. The unit is km/h. When the calculated speed value of two adjacent points is greater than the specified speed limit, the two points are considered unreachable, that is, there is no effective road connecting.
        The default value is 150 km/h.

        :param float value:
        :return: self
        :rtype: MapMatching
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatching.set_measurement_error": """
        Set the track point error value. For example, the GPS error value, in meters. If the distance from the track point to the nearest road exceeds the error value, the track point is considered illegal. 
        Setting a reasonable error value has a direct impact on the result of map matching. If the accuracy of the obtained track points is high, setting a smaller value can effectively improve the performance, for example, 15 meters. The default value is 30 meters.

        :param float value: track point error value
        :return: self
        :rtype: MapMatching
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatching.set_path_analyst_setting": """
        Set optimal path analysis parameters

        :param PathAnalystSetting path_analyst_setting: Best path analysis parameters
        :return: self
        :rtype: MapMatching
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingLikelyResult": """
    Real-time map matching result class
    """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingLikelyResult.distance_to_road": """float: the closest distance from the original track point to the current track path.""",

    "iobjectspy._jsuperpy.analyst.na.MapMatchingLikelyResult.edges": """list[int]: ID of the edge that the matching path passes through """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingLikelyResult.evaluate_error": """
        Evaluate the error rate of current map matching results.
        Enter the real road line object and calculate the error rate of the matching result.

        :param truth_edges: real road line objects
        :type truth_edges: list[GeoLine] or tuple[GeoLine]
        :return: the error rate of the current result
        :rtype: float
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingLikelyResult.evaluate_truth": """
        Evaluate the correctness of the current map matching results.
        Input the real road line object and calculate the correctness of the matching result.

        The formula for calculating correctness is:

        .. image:: ../image/evaluationTruth.png

        :param truth_edges: real road line objects
        :type truth_edges: list[GeoLine] or tuple[GeoLine]
        :return: the correctness of the current result
        :rtype: float
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingLikelyResult.probability": """float: When real-time map matching, when calculating which road the current point belongs to, the algorithm will generate the matching probability value from this point to all possible roads nearby, and select the probability The highest value as the
                  Point matching road """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingLikelyResult.rectified_point": """Point2D: The track point after map matching, which corresponds to the point processed by each input point. The size of the array is equal to the number of input points.""",

    "iobjectspy._jsuperpy.analyst.na.MapMatchingLikelyResult.track_line": """GeoLine: The result track line object. The line object constructed by :py:attr:`track_points`.""",

    "iobjectspy._jsuperpy.analyst.na.MapMatchingLikelyResult.track_points": """list[Point2D]: The track point string obtained after map matching, the track point string removes duplicate points and some points that failed to match """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingResult": """
    The map matching result class. Including the trajectory point, trajectory line, edge id, matching accuracy rate, error rate, etc. obtained after matching.
    """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingResult.edges": """list[int]: ID of the edge that each matching path passes""",

    "iobjectspy._jsuperpy.analyst.na.MapMatchingResult.evaluate_error": """
        Evaluate the error rate of current map matching results.
        Enter the real road line object and calculate the error rate of the matching result.

        :param truth_edges: real road line objects
        :type truth_edges: list[GeoLine] or tuple[GeoLine]
        :return: the error rate of the current result
        :rtype: float
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingResult.evaluate_truth": """
        Evaluate the correctness of the current map matching results.
        Input the real road line object and calculate the correctness of the matching result.

        The formula for calculating correctness is:

        .. image:: ../image/evaluationTruth.png

        :param truth_edges: real road line objects
        :type truth_edges: list[GeoLine] or tuple[GeoLine]
        :return: the correctness of the current result
        :rtype: float
        """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingResult.rectified_points": """list[Point2D]: The trajectory points after map matching, which corresponds to the points processed by each input point. The size of the array is equal to the number of input points.""",

    "iobjectspy._jsuperpy.analyst.na.MapMatchingResult.track_line": """GeoLine: The result track line object. The line object constructed by :py:attr:`track_points`.

                    .. image:: ../image/MapMatchingResult.png

         """,

    "iobjectspy._jsuperpy.analyst.na.MapMatchingResult.track_points": """list[Point2D]: The track point string obtained after map matching, the track point string removes duplicate points and some points that failed to match """,

    "iobjectspy._jsuperpy.analyst.na.NetworkDatasetErrors": """
    The check result of the topology relationship of the network dataset, including the error information of the edge segment of the network dataset and the node error information.
    """,

    "iobjectspy._jsuperpy.analyst.na.NetworkDatasetErrors.arc_errors": """dict[int,int]: edge error information. The key is the SmID of the error edge in the network dataset, and the value is the error type.""",

    "iobjectspy._jsuperpy.analyst.na.NetworkDatasetErrors.node_errors": """dict[int,int]: node error information. The key is the SmID of the error node in the network dataset, and the value is the error type.""",

    "iobjectspy._jsuperpy.analyst.na.NetworkSplitMode": """
    Construct a network dataset interruption mode. Used to control the mode of processing line-line breaks or dot-line breaks when building a network dataset

    :var NetworkSplitMode.NO_SPLIT: Do not interrupt
    :var NetworkSplitMode.LINE_SPLIT_BY_POINT: point to break the line
    :var NetworkSplitMode.LINE_SPLIT_BY_POINT_AND_LINE: break the line and the line, and click to break the line at the same time
    :var NetworkSplitMode.TOPOLOGY_PROCESSING: Topology processing mode. When using this method, the line dataset used for construction is first to remove duplicate lines, extend long suspension lines, and
                                               topological processing operations such as edge intersection, removal of short suspension lines, removal of redundant points, merging of adjacent endpoints, and removal of false nodes, and then construct a network dataset.
    """,

    "iobjectspy._jsuperpy.analyst.na.PathAnalystSetting": """Best path analysis environment setting, this kind of abstract base class, users can choose to use:py:class:`SSCPathAnalystSetting` or :py:class:`TransportationPathAnalystSetting`""",

    "iobjectspy._jsuperpy.analyst.na.PathAnalystSetting.network_dataset": """DatasetVector: network dataset""",

    "iobjectspy._jsuperpy.analyst.na.PathAnalystSetting.set_network_dataset": """
        Set up a network dataset for optimal path analysis

        :param dataset: network dataset
        :type dataset: DatasetVetor or str
        :return: current object
        :rtype: PathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.PathGuide": """
    Driving guidance

    Driving guidance records how to drive step by step from the starting point to the end of a path, and each key element on the path corresponds to a driving guidance sub-item. These key elements include sites (points input by the user for 
    analysis, which can be ordinary points or nodes), edges passed by and network nodes. Through the driving guidance sub-item object, you can obtain the ID, name, serial number, weight, and length of the key elements in the route, and can also 
    determine whether it is an edge or a stop, as well as information such as driving direction, turning direction, and cost. By extracting and organizing the stored key element information according to the sequence number of the driving guidance 
    sub-items, it is possible to describe how to reach the end of the route from the beginning of the route.

    The figure below is an example of recent facility search and analysis. The results of the analysis give three preferred paths. The information of each route is recorded by a driving guidance object. For example, the second route is composed 
    of key elements such as stops (starting and ending points, which can be general coordinate points or network nodes), road sections (edges), intersections (network nodes), etc., and it is guided from its corresponding driving The information of 
    these key elements can be obtained in the driving guidance sub-item of the guide, so that we can clearly describe how the route travels from the start point to the end point, such as which road to drive and how long to turn.

    .. image:: ../image/PathGuide.png


    """,

    "iobjectspy._jsuperpy.analyst.na.PathGuide.__getitem__": """
        Get the driving guidance item of the specified location

        :param item: Specified driving guide index subscript
        :type item: int
        :return: driving guide sub-item
        :rtype: PathGuideItem
        """,

    "iobjectspy._jsuperpy.analyst.na.PathGuide.__len__": """
        Return the number of driving guide items

        :return: number of driving guide items
        :rtype: int
        """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem": """

    In traffic network analysis, the sub-items of driving guidance can be summarized into the following categories:

    -Station: The point selected by the user for analysis, such as the points to be passed when the best path analysis is performed.

    -Line segment from site to network: When the site is a common coordinate point, the site needs to be attributed to the network before analysis can be performed based on the network. Please refer to the introduction of :py:attr:`TransportationPathAnalystSetting.tolerance` method.

      As shown in the figure below, the red dotted line is the shortest straight line distance from the site to the network. Note that when the site is near the edge of the network edge, as shown on the right, this distance refers to the distance between the site and the end of the edge.

      .. image:: ../image/PathGuideItem_4.png

    -The corresponding point of the station on the network: corresponding to the "line segment from the station to the network", this point is the corresponding point on the network when the station (ordinary coordinate point) is attributed to the network. In the 
    case shown in the left picture above, this point is the vertical foot point of the station on the corresponding edge; in the case shown in the right picture above, this point is the end point of the edge.

    -Road section: that is, a section of road through which you drive. In the traffic network, edges are used to simulate roads, so the driving sections are all located on the edges. Note that multiple edges may be merged into one driving guidance sub-item. The 
    conditions for merging are that their edge names are the same, and the turning angle between adjacent edges is less than 30 degrees. It needs to be emphasized that the last driving section before arriving at the station and the first driving section after arriving
     at the station contain only one edge or part of an edge. Even if the above conditions are met, it will not be merged with adjacent edges into one driving guide. lead.

      As shown in the figure below, the driving section between the two stations is marked with different colors. Among them, the first road segment (red) after station 1, although the name of its edge is the same as the names of the following edges, and the steering 
      angle is less than 30 degrees, it is the first road segment after the station , So they are not merged. The three edges covered by the blue section have the same name and the turning angle is less than 30 degrees, so they are merged into one driving guidance 
      sub-item; the pink section has a different edge name from the previous section, so it becomes Another driving guidance sub-item; because the green section is the last road section before reaching the stop, it is also a separate driving guidance sub-item.

      .. image:: ../image/PathGuideItem_5.png

    -Turning point: the intersection between two adjacent driving sections. An intersection refers to an intersection of an actual road (such as an intersection or a T-junction) that may change direction. The driving direction at the turning point can be
      change. As shown in the figure above, the nodes 2783, 2786 and 2691 are all turning points. The turning point must be the network node.

    The value returned by each method of PathGuideItem can be used to determine which type of driving guide item belongs to. The following table summarizes the comparison table of the return value of each method of the five driving guide items.
    It is convenient for users to understand and use driving guidance.

    .. image:: ../image/PathGuideItem_6.png


    The following examples can help users understand the content and functions of the driving guidance and driving guidance sub-items. The blue dotted line in the figure below is a path in the results of the nearest facility search and analysis.
    In the returned results of the facility search, the driving guidance corresponding to this route can be obtained.

    .. image:: ../image/PathGuideItem_1.png

    The driving guide used to describe this path contains 7 sub-items. These 7 driving guidance sub-items include 2 stops (that is, the starting point and the end point, corresponding to serial numbers 0 and 6), 3 edges (that is, road sections, 
    serial numbers are 1, 3, 5), and 2 network nodes ( That is, the turning point, the serial numbers are 2 and 4 respectively). The following table lists the information of these 7 driving guidance sub-items, including whether it is a stop (:py:attr:`is_stop` ), 
    whether it is an edge (:py:attr:`is_edge` ), and the serial number (:py :attr:`index` ), driving direction (:py:attr:`direction_type` ), turning direction (:py:attr:`turn_type`) and edge name (:py:attr:`name`) and other information.

    .. image:: ../image/PathGuideItem_2.png

    Organize the information recorded by the driving guidance sub-item to get the guidance description of the route as shown in the following table.

    .. image:: ../image/PathGuideItem_3.png

    """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.bounds": """Rectangle : Fan the child with the guide around the guide when the running subkey line type (i.e.,:. py: attr:` is_edge` Return True ), is the minimum enclosing rectangle of the line;
                      Point type (ie: py:attr:`is_edge` Return False), it is the point itself """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.direction_type": """DirectionType: The direction of the travel guide item, only if the travel guide item is line type (ie: py:attr:`is_edge` Return True) is meaningful, and can be east, south, west, and north """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.distance": """float: The distance from the station to the network is only valid when the driving guidance item is a station. The site may not be on the network (neither on the edge nor on the node), and the site 
    must be attributed to the network in order to perform analysis based on the network. The distance refers to the distance from the station to the nearest edge. As shown in the figure below, the orange dots represent the network nodes, the blue dots represent the edges, 
    the gray dots represent the stations, and the red line segments represent the distance.

                  .. image:: ../image/PathGuideItemDistance.png

                  When the driving guidance item is of a type other than the station, the value is 0.0.
        """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.guide_line": """GeoLineM: Return the travel guide line segment when the travel guide item is line type (ie: py:attr:`is_edge` Return True) .
                     When :py:attr:`is_edge` Return false, the method Return None. """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.index": """int: The serial number of the travel guide item.
                Except for the following two situations, this method Return -1:

                 -When the driving guidance item is a station, the value is the serial number of the station in all stations, starting from 1. For example, a station is the second station passed by the driving route, then this
                   Index value of the site is 2;
                 -When the driving guidance item is a turning point, the value is the number of intersections from that point to the previous turning point or stop. For example, the two intersections before a certain turning point are the closest stations,
                   Then the Index value of this turning point is 2; when a certain point is a stop and a turning point at the same time, the Index is the position of the stop in all the stops in the whole driving process.
        """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.is_edge": """bool: Return whether the driving guide item is of line or point type. If True, it means line type, such as the line segment and road segment from the station to the network; If False, it means point type,
                 Such as stations, turning points or stations are attributed to corresponding points on the network. """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.is_stop": """bool: Return whether the travel guide item is a stop or the stop is attributed to the corresponding point on the network. When is_stop Return true, the corresponding travel The guide item may be a site, or when the site is a coordinate point, it is attributed to the corresponding point on the network.""",

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.length": """float: Return the length of the corresponding line segment when the travel guide item is line type (ie: py:attr:`is_edge` Return True). Unit For rice """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.name": """str: The name of the travel guide item.
                Except for the following two cases, this method Return an empty string:

                -When the driving guidance item is a stop (node mode) or turning point, the value is based on the value of the node name field specified in the traffic network analysis environment
                  Given, an empty string if not set;
                -When the driving guidance item is a road segment or a line segment from a station to the network, the value is based on the value of the node name field specified in the traffic network analysis environment
                  Given, or an empty string if not set.
        """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.node_edge_id": """int: ID of the travel guide item.
                Except for the following three situations, this method Return -1:

                 -When the driving guidance item is a stop in node mode, the stop is a node, and the node ID of the node is returned;
                 -When the driving guidance item is a turning point, the turning point is a node, and the node ID of the node is returned;
                 -When the driving guidance item is a road segment, the edge ID of the edge corresponding to the road segment is returned. If the road segment is merged by multiple edges, the ID of the first edge is returned.
        """,

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.side_type": """SideType: When the driving guide item is a stop, whether the stop is on the left or right side of the road or on the road. When the driving guide item is outside the stop Type, the method Return NONE""",

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.turn_angle": """float: When the driving guidance item is a point type, the turning angle of the next step at this point. The unit is degree, and the accuracy is 0.1 degree. When :py:attr:`is_edge` Return True, the method Return -1""",

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.turn_type": """TurnType: Return when the driving guide item is a point type (ie: py:attr:`is_edge` Return False), the next step at this point Direction of turn.
                     When :py:attr:`is_edge` Return True, the method Return None""",

    "iobjectspy._jsuperpy.analyst.na.PathGuideItem.weight": """float: Return the weight of the driving guide item, that is, the cost of using the guide item. The unit is the same as the unit of the weight field information (:py:class:`WeightFieldInfo`) object specified by the 
    transportation network analysis parameter (TransportationAnalystParameter).
                  .
                  When the driving guidance item is a road section, a turning point or a stop in the node mode, the cost obtained is meaningful, otherwise it is 0.0.

                  -When the driving guidance sub-item is a road segment, the corresponding cost is calculated according to the edge weight and the steering weight. If the steering table is not set, the steering weight is 0;
                  -When the driving guidance item is a turning point or a stop in node mode (both are nodes), it is the corresponding turning weight. If the steering table is not set, it is 0.0.
        """,

    "iobjectspy._jsuperpy.analyst.na.PathInfo": """
    Guidance information, through this category, you can obtain guidance information based on the route after SSC path analysis
    """,

    "iobjectspy._jsuperpy.analyst.na.PathInfo.__getitem__": """
        Get the driving guidance item of the specified location

        :param item: Specified driving guide index subscript
        :type item: int
        :return: driving guide sub-item
        :rtype: PathInfoItem
        """,

    "iobjectspy._jsuperpy.analyst.na.PathInfo.__len__": """
        Return the number of driving guide items

        :return: number of driving guide items
        :rtype: int
        """,

    "iobjectspy._jsuperpy.analyst.na.PathInfoItem": """
    Boot information item
    """,

    "iobjectspy._jsuperpy.analyst.na.PathInfoItem.direction_to_swerve": """int: Return to the turning direction of the next road. Where 0 means going straight, 1 means turning left, 2 means turning right, 3 means turning left, 4 means Turn right, 5 means turn left,
        6 means a right back turn, 7 means a U-turn, 8 means a right turn and detour to the left, 9 means a right-angled hypotenuse turn right, and 10 means a roundabout. """,

    "iobjectspy._jsuperpy.analyst.na.PathInfoItem.junction": """Point2D: Through this interface, you can return to the intersection point coordinates of the next road""",

    "iobjectspy._jsuperpy.analyst.na.PathInfoItem.length": """float: Return the length of the current road.""",

    "iobjectspy._jsuperpy.analyst.na.PathInfoItem.route_name": """str: This interface can return the name of the current road. When the name of the road is "PathPoint", it means the point of arrival.""",

    "iobjectspy._jsuperpy.analyst.na.RouteType": """
    The analysis mode of the best path analysis is used for SSC-based best path analysis.

    :var RouteType.RECOMMEND: Recommended mode
    :var RouteType.MINLENGTH: The shortest distance
    :var RouteType.NOHIGHWAY: Do not take the high speed
    """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter": """
    Parameters for compiling the SSC file
    """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.edge_id_field": """str: The field that marks the edge ID in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.edge_name_field": """str: the name field of the edge""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.f_node_id_field": """str: The field that marks the starting node ID of the edge in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.file_path": """str: Path of SSC file""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.ft_single_way_rule_values": """list[str]: an array of strings used to represent forward one-way lines""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.level_field": """str: Road level field""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.network_dataset": """DatasetVector: network dataset""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.node_id_field": """str: The field that identifies the node ID in the network dataset """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.prohibited_way_rule_values": """list[str]: an array of strings representing prohibited lines """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.rule_field": """str: The field in the network dataset representing the traffic rules of the network edge""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_edge_id_field": """
        Set the field that identifies the node ID in the network dataset

        :param str value: The field that marks the edge segment ID in the network dataset
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_edge_name_field": """
        Set the field name of the edge

        :param str value: The name field of the edge segment.
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_f_node_id_field": """
        Set the field to mark the starting node ID of the edge in the network dataset

        :param str value: The field that marks the starting node ID of the edge in the network dataset
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_file_path": """
        Set the path of the SSC file

        :param str value: The path of the SSC file.
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_ft_single_way_rule_values": """
        Set the array of strings used to represent the forward one-way line

        :param value: An array of strings used to represent the forward one-way line
        :type value: str or list[str]
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_level_field": """
        Set the road grade field. The value range is 1-3. It is a required field. Among them, 3 has the highest road grade (highway, etc.), and 1 has the lowest road grade (country road, etc.).

        :param str value: Road grade field
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_network_dataset": """
        Set up network dataset

        :param dataset: network dataset
        :type dataset: DatasetVetor or str
        :return: current object
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_node_id_field": """
        Set the field of the network dataset to identify the node ID

        :param str value: The field that identifies the node ID in the network dataset
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_prohibited_way_rule_values": """
        Set up an array of strings representing forbidden lines

        :param value: an array of strings representing the forbidden line
        :type value: str or list[str]
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_rule_field": """
        Set the fields in the network dataset that represent the traffic rules of the network edge

        :param str value: A field in the network dataset representing the traffic rules of the network edge
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_speed_field": """
        Set the road speed field, which is not mandatory. Integer field, where 1 has the highest road speed (150km/h), 2 has a speed of 130km/h, 3 has a speed of 100km/h, and 4 has a speed of 90km/h,
        The speed of 5 is 70km/h, the speed of 6 is 50km/h, the speed of 7 is 30km/h, and the speeds of other values are unified to 10km/h

        :param str value: road speed field
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_t_node_id_field": """
        Set the field to mark the starting node ID of the edge in the network dataset

        :param str value:
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_tf_single_way_rule_values": """
        Set up an array of strings representing reverse one-way lines

        :param value: an array of strings representing the reverse one-way line
        :type value: str or list[str]
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_two_way_rule_values": """
        Set an array of strings representing two-way traffic lines

        :param value: An array of strings representing two-way traffic lines
        :type value: str or list[str]
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.set_weight_field": """
        Set weight field

        :param str value: weight field
        :return: self
        :rtype: SSCCompilerParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.speed_field": """str: Road speed field""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.t_node_id_field": """str: The field that marks the starting node ID of the edge in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.tf_single_way_rule_values": """list[str]: an array of strings representing reverse one-way lines""",

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.two_way_rule_values": """list[str]: an array of strings representing two-way traffic lines """,

    "iobjectspy._jsuperpy.analyst.na.SSCCompilerParameter.weight_field": """str: weight field """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst": """Path analysis class based on SSC files. Users can compile ssc files with :py:meth:`compile_ssc_data`. Generally, the performance of path analysis using SSC files is better than that based on
     Traffic network path analysis performance of the network dataset. """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.__init__": """
        Initialization object

        :param path_analyst_setting: Based on SSC path analysis environment parameter object.
        :type path_analyst_setting: SSCPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.find_path": """
        Best path analysis

        :param Point2D start_point: start point
        :param Point2D end_point: end point
        :param midpoints: midpoints
        :type midpoints: list[Point2D] or tuple[Point2D] or Point2D
        :param route_type: The analysis mode of the best route analysis, the default value is'RECOMMEND'
        :type route_type: RouteType or str
        :param bool is_alternative: Whether to return alternatives. True will return the alternative path, otherwise only the best path will be returned
        :return: Return True if the analysis is successful, and False if it fails
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.get_alternative_path_infos": """
        Return the guidance information of the candidate analysis results.

        :return: Guidance information for alternative analysis results
        :rtype: PathInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.get_alternative_path_length": """
        Return the total length of the candidate analysis results.

        :return: The total length of the candidate analysis results.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.get_alternative_path_points": """
        A collection of waypoints to return candidate analysis results.

        :return: The set of passing points for the alternative analysis results.
        :rtype: list[Point2D]
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.get_alternative_path_time": """
        Return the travel time of the candidate analysis result, in seconds. If you want to get the travel time, you need to specify the correct speed field when compiling the SSC file.

        :return: travel time of alternative analysis results
        :rtype: float
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.get_path_infos": """
        Return the guide information collection of the analysis result. Please ensure that the path analysis is successful before calling this interface.

        :return: guide information collection of analysis results
        :rtype: PathInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.get_path_length": """
        Return the total length of the analysis result. Please ensure that the path analysis is successful before calling this interface.

        :return: The total length of the analysis result.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.get_path_points": """
        A collection of waypoints to return analysis results. Please ensure that the path analysis is successful before calling this interface.

        :return: The collection of the coordinates of the passing point of the analysis result
        :rtype: list[Point2D]
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.get_path_time": """
        Return the travel time of the analysis result, in seconds. If you want to get the travel time, you need to specify the correct speed field when compiling the SSC file.

        :return: driving time of the analysis result
        :rtype: float
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalyst.set_analyst_setting": """
        Set path analysis environment parameters

        :param path_analyst_setting: Based on SSC path analysis environment parameter object.
        :type path_analyst_setting: SSCPathAnalystSetting
        :return: self
        :rtype: SSCPathAnalyst
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalystSetting": """
    Optimal path analysis environment setting based on SSC file
    """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalystSetting.__init__": """

        :param DatasetVector network_dt: network dataset name
        :param str ssc_file_path: SSC file path
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalystSetting.network_dataset": """DatasetVector: network dataset""",

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalystSetting.set_network_dataset": """
        Set up a network dataset for optimal path analysis

        :param dataset: network dataset
        :type dataset: DatasetVetor or str
        :return: current object
        :rtype: PathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalystSetting.set_ssc_file_path": """
        Set SSC file path

        :param str value: SSC file path
        :return: current object
        :rtype: SSCPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalystSetting.set_tolerance": """
        Set node tolerance

        :param float value: node tolerance
        :return: current object
        :rtype: SSCPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalystSetting.ssc_file_path": """str: SSC file path""",

    "iobjectspy._jsuperpy.analyst.na.SSCPathAnalystSetting.tolerance": """float: node tolerance""",

    "iobjectspy._jsuperpy.analyst.na.ServiceAreaResult": """
    Service area analysis result class.
    """,

    "iobjectspy._jsuperpy.analyst.na.ServiceAreaResult.edges": """list[int]: The set of edges passed by the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.ServiceAreaResult.nodes": """list[int]: The set of nodes passing through the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.ServiceAreaResult.routes": """list[GeoLineM]: A collection of routing objects of analysis results. Stored in accordance with the specified order of the center point, each service area covered (including partial coverage) routing.""",

    "iobjectspy._jsuperpy.analyst.na.ServiceAreaResult.service_region": """GeoRegion: The service area region object of the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.ServiceAreaResult.weight": """float: the weight spent""",

    "iobjectspy._jsuperpy.analyst.na.ServiceAreaType": """
    Service area type. Used for service area analysis.

    :var ServiceAreaType.SIMPLEAREA: Simple service area
    :var ServiceAreaType.COMPLEXAREA: complex service area
    """,

    "iobjectspy._jsuperpy.analyst.na.SideType": """
    Indicates whether it is on the left, right or on the road. Used for driving guidance.

    :var SideType.NONE: invalid value
    :var SideType.MIDDLE: On the road (that is, in the middle of the road)
    :var SideType.LEFT: the left side of the road
    :var SideType.RIGHT: the right side of the road
    """,

    "iobjectspy._jsuperpy.analyst.na.SupplyCenter": """
    Resource supply center class. The resource supply center category stores the information of the resource supply center, including the ID, maximum cost and type of the resource supply center.
    """,

    "iobjectspy._jsuperpy.analyst.na.SupplyCenter.__init__": """
        Initialization object

        :param supply_center_type: The types of resource supply center points include non-center, fixed center and optional center. Fixed center is used for resource allocation analysis; fixed center and optional center are used for location analysis,
                                   Non-centrality is not considered in both types of network analysis.
        :type supply_center_type: SupplyCenterType or str
        :param int center_node_id: ID of the resource supply center point.
        :param float max_weight: The maximum cost of the resource supply center (resistance value)
        :param float resource: The amount of resources in the resource supply center
        """,

    "iobjectspy._jsuperpy.analyst.na.SupplyCenter.center_node_id": """int: ID of the resource supply center""",

    "iobjectspy._jsuperpy.analyst.na.SupplyCenter.max_weight": """float: the maximum cost of the resource supply center.""",

    "iobjectspy._jsuperpy.analyst.na.SupplyCenter.resource": """float: the amount of resources in the resource supply center""",

    "iobjectspy._jsuperpy.analyst.na.SupplyCenter.set_center_node_id": """
        Set the ID of the resource supply center.

        :param int value: ID of the resource supply center
        :return: self
        :rtype: SupplyCenter
        """,

    "iobjectspy._jsuperpy.analyst.na.SupplyCenter.set_max_weight": """
        Set the maximum cost of the resource supply center. The larger the maximum resistance setting of the center point is, the larger the influence range of the resources provided by the center point is.
        The maximum resistance value is used to limit the cost from the demand point to the center point. If the cost of the demand point (edge or node) to this center is greater than the maximum resistance value, the demand point is filtered out. The maximum resistance value can be edited.

        :param float value: The maximum cost of the resource supply center (resistance value)
        :return: self
        :rtype: SupplyCenter
        """,

    "iobjectspy._jsuperpy.analyst.na.SupplyCenter.set_resource": """
        Set the resource amount of the resource supply center

        :param float value: The amount of resources in the resource supply center
        :return: self
        :rtype: SupplyCenter
        """,

    "iobjectspy._jsuperpy.analyst.na.SupplyCenter.set_supply_center_type": """
        Set the type of resource supply center point in network analysis

        :param value: The types of resource supply center points include non-center, fixed center and optional center. Fixed center is used for resource allocation analysis; fixed center and optional center are used for location analysis,
                      Non-centrality is not considered in both types of network analysis.
        :type value: SupplyCenterType or str
        :return: self
        :rtype: SupplyCenter
        """,

    "iobjectspy._jsuperpy.analyst.na.SupplyCenter.supply_center_type": """SupplyCenterType: The type of resource supply center point in network analysis""",

    "iobjectspy._jsuperpy.analyst.na.SupplyCenterType": """
    Constant type of resource center point in network analysis, mainly used for resource allocation and location selection

    :var SupplyCenterType.NULL: The non-central point is not considered in resource allocation and location selection.
    :var SupplyCenterType.OPTIONALCENTER: Optional center point for location selection
    :var SupplyCenterType.FIXEDCENTER: Fixed center point, used for resource allocation and location selection.
    """,

    "iobjectspy._jsuperpy.analyst.na.SupplyResult": """
    Resource supply center point result class.

    This category provides the results of resource supply, including the type of resource supply center, ID, maximum resistance, number of demand points, average cost, and total cost.
    """,

    "iobjectspy._jsuperpy.analyst.na.SupplyResult.average_weight": """float: average cost, that is, total cost divided by the number of points required""",

    "iobjectspy._jsuperpy.analyst.na.SupplyResult.center_node_id": """int: ID of the resource supply center""",

    "iobjectspy._jsuperpy.analyst.na.SupplyResult.demand_count": """int: the number of demand nodes served by the resource supply center""",

    "iobjectspy._jsuperpy.analyst.na.SupplyResult.max_weight": """float: The maximum cost (resistance value) of the resource supply center. The maximum resistance value is used to limit the cost from the demand point to the center point. 
                  If the cost of the demand point (node) to this center is greater than the maximum resistance value, the demand point is filtered out. The maximum resistance value can be edited. """,

    "iobjectspy._jsuperpy.analyst.na.SupplyResult.total_weight": """float: total cost. When the location selection analysis selects to allocate resources from the resource supply center, the total cost is the sum of the cost from the 
    resource supply center to all the demand nodes it serves; conversely, if the resource supply center is not allocated, the total cost is that The sum of the cost from all demand nodes served by the resource supply center to the resource supply center. """,
                  
    "iobjectspy._jsuperpy.analyst.na.SupplyResult.type": """SupplyCenterType: The type of the resource supply center""",

    "iobjectspy._jsuperpy.analyst.na.TerminalPoint": """
    Terminal point, used for grouping analysis, terminal point contains coordinate information and load
    """,

    "iobjectspy._jsuperpy.analyst.na.TerminalPoint.__init__": """
        Initialization object

        :param Point2D point: coordinate point information
        :param int load: load
        """,

    "iobjectspy._jsuperpy.analyst.na.TerminalPoint.load": """int: load amount""",

    "iobjectspy._jsuperpy.analyst.na.TerminalPoint.point": """Point2D: coordinate point""",

    "iobjectspy._jsuperpy.analyst.na.TerminalPoint.set_load": """
        Set load

        :param int load: load
        :return: self
        :rtype: TerminalPoint
        """,

    "iobjectspy._jsuperpy.analyst.na.TerminalPoint.set_point": """
        Set coordinate point

        :param Point2D point: coordinate point
        :return: self
        :rtype: TerminalPoint
        """,

    "iobjectspy._jsuperpy.analyst.na.TrackPoint": """
    Track coordinate point with time.
    """,

    "iobjectspy._jsuperpy.analyst.na.TrackPoint.__init__": """

        :param Point2D point: two-dimensional point coordinates
        :param datetime.datetime t: Time value, indicating the time of the coordinate position.
        :param int key: key value, used to identify point uniqueness
        """,

    "iobjectspy._jsuperpy.analyst.na.TrackPoint.key": """int: key value, used to identify the uniqueness of the point """,

    "iobjectspy._jsuperpy.analyst.na.TrackPoint.point": """Point2D: Two-dimensional point coordinates""",

    "iobjectspy._jsuperpy.analyst.na.TrackPoint.set_key": """
        Set the key value to identify the uniqueness of the point

        :param int value: key value
        :return: self
        :rtype: TrackPoint
        """,

    "iobjectspy._jsuperpy.analyst.na.TrackPoint.set_point": """
        Set location point

        :param value: position point
        :type value: Point2D or str
        :return: self
        :rtype: TrackPoint
        """,

    "iobjectspy._jsuperpy.analyst.na.TrackPoint.set_time": """
        Set time value

        :param value: time value, representing the time of the coordinate position
        :type value: datetime.datetime or str
        :return: self
        :rtype: TrackPoint
        """,

    "iobjectspy._jsuperpy.analyst.na.TrackPoint.time": """datetime.datetime: time value, representing the time of the coordinate location point""",

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing": """
    Track preprocessing class. Used to deal with abnormal points in the trajectory data, including trajectory segmentation, processing offset points, repeated points, sharp corners and other abnormal situations.
    """,

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.is_remove_redundant_points": """bool: Whether to remove duplicate points with equal spatial positions""",

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.measurement_error": """float: trajectory point error value""",

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.prj_coordsys": """PrjCoordSys: coordinate system of the point to be processed""",

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.rectify": """
        Trajectory preprocessing result

        :param points: Track point data to be processed.
        :type points: list[TrackPoint] or tuple[TrackPoint]
        :return: The processed track point dataset.
        :rtype: TrajectoryPreprocessingResult
        """,

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.rectify_dataset": """
        Preprocess the trajectory of the dataset, and save the result as point data

        :param source_dataset: original track point dataset
        :type source_dataset: DatasetVector or str
        :param str id_field: ID field of the track. Track points with the same ID value belong to a track, such as mobile phone number, license plate number, etc. When no ID field is specified, all 
        points in the dataset will be classified as a track.
                             
        :param str time_field: The time field of the track point, must be a time or timestamp type field
        :param float split_time_milliseconds: The time interval for splitting the track. If the time interval between two adjacent points in time is greater than the specified time interval for splitting the track, 
                                              The trajectory will be divided between two points.
        :param out_data: The datasource to save the result dataset
        :type out_data: Datasource or str
        :param str out_dataset_name: result dataset name
        :param str result_track_index_field:  The field that stores the track index. After the track is divided, one track may be divided into multiple sub-tracks. The result_track_index_field will store the index 
                                               value of the sub-track, and the value starts from 1. Because the result dataset will save all the fields of the source track point dataset, it is necessary to ensure 
                                               that the result_track_index_field field value is not occupied in the source track point dataset.
        :return: The result point dataset, the result point dataset after preprocessing.
        :rtype: DatasetVector
        """,

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.set_measurement_error": """
        Set the track point error value, such as GPS error value, in meters. Need to specify an appropriate error value according to the quality of the data. If the track point offset exceeds the error value, it will be processed.

        .. image:: ../image/MeasurementError.png

        :param float value: track point error value
        :return: self
        :rtype: TrajectoryPreprocessing
        """,

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.set_prj_coordsys": """
        Set the coordinate system of the point to be processed

        :param PrjCoordSys value: the coordinate system of the point to be processed
        :return: self
        :rtype: TrajectoryPreprocessing
        """,

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.set_remove_redundant_points": """
        Set whether to remove duplicate points with equal spatial positions

        .. image:: ../image/RemoveRedundantPoints.png

        :param bool value: Whether to remove duplicate points with equal spatial positions
        :return: self
        :rtype: TrajectoryPreprocessing
        """,

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.set_sharp_angle": """
        Set the sharp angle value. The unit is angle. When the included angle of three unequal points in a continuous period of time is less than the specified sharp angle value, the middle point will be corrected to be the midpoint 
        of the first and last two points.When the value is less than or equal to 0, sharp corners will not be processed.

        .. image:: ../image/SharpAngle.png

        :param float value: sharp angle value
        :return: self
        :rtype: TrajectoryPreprocessing
        """,

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.set_valid_region_dataset": """
        Set the effective surface. Only the points that fall within the effective surface are effective points.

        :param value: valid surface dataset
        :type value: DatasetVector or str
        :return: self
        :rtype: TrajectoryPreprocessing
        """,

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.sharp_angle": """float: sharp angle value""",

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessing.valid_region_dataset": """DatasetVector: valid surface dataset.""",

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessingResult": """
    Trajectory preprocessing result class
    """,

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessingResult.rectified_points": """list[Point2D]: The processed trajectory points, which correspond to the points processed by each input point. The size of the array is equal to the number of input points.""",

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessingResult.track_line": """GeoLine: The trajectory line generated by the processed trajectory points""",

    "iobjectspy._jsuperpy.analyst.na.TrajectoryPreprocessingResult.track_points": """list[Point2D]: The track points obtained after processing. For example, the remaining track points after removing all duplicate points """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst": """
    Traffic network analysis class. This class is used to provide transportation network analysis functions such as path analysis, traveling salesman analysis, service area analysis, multiple traveling salesman (logistics distribution) analysis, nearest facility search and location analysis.

    Traffic network analysis is an important part of network analysis, which is based on the analysis of traffic network models. Unlike the facility network model, the transportation network has no direction. Even though the direction can be specified for the network edge, the circulation 
    medium (pedestrian or transmission resource) can determine its own direction, speed, and destination.
    """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.__init__": """
        Initialization object

        :param TransportationAnalystSetting analyst_setting: Traffic network analysis environment setting object
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.allocate": """
        Resource allocation analysis.
        Resource allocation analysis simulates the supply and demand relationship model of resources in the real world network. Resources are gradually allocated from supply points to demand points (including edges or nodes) based on the setting of network resistance values, and ensure
        the supply point can provide resources for the demand point in the most cost-effective way. The demand point with the smallest resistance value from the center point (including edge or nodes) gets resources first, Then allocate the remaining resources to the demand points 
        (including edges or nodes) with the next smallest resistance value, and so on, until the resources at the center point are exhausted, and the allocation is suspended.
        

        :param supply_centers: collection of resource supply centers
        :type supply_centers: list[SupplyCenter] or tuple[SupplyCenter]
        :param demand_type: resource allocation mode
        :type demand_type: AllocationDemandType or str
        :param bool is_connected: Returns whether the route generated during the analysis must be connected. In the process of resource allocation analysis, the resources of a certain central point are allowed to pass through the service range of 
                                  other central points that have completed resource allocation and continue to allocate their own resources to the demand object, that is, set this item to false, so that the result route obtained is Not connected. 
                                  If set to true, during the resource allocation process of a certain central point, when it encounters an area that has been allocated to other centers, the allocation will stop, so that excess resources may accumulate 
                                  at the resource central point.

                                  For example: The problem of power transmission from the power grid is not allowed to have a crossover situation, it must be mutually connected and cannot be disconnected, and the problem of students going to school to 
                                  school is allowed to be set as a crossover distribution.

        :param bool is_from_center:Whether to allocate resources from the resource supply center. Since the edge in the network data has positive and negative resistance, that is, the forward resistance value of the edge and the reverse resistance value may 
                                  be different. Therefore, in the analysis, the resources are allocated from the resource supply center to the demand point and from the demand point to the demand point. Under the two forms of resource supply center allocation, 
                                  the analysis results obtained will be different.

                                    The following are examples of two actual application scenarios to help further understand the differences between the two forms. It is assumed that the positive and negative resistance values of the edges in the network datasets are different.

                                     -Starting from the resource supply center to allocate resources to demand points:

                                       If your resource center is some storage center, and the demand point is the major supermarkets, in the actual resource allocation, the goods in the storage center are transported 
                                       to the supermarkets that it serves. This form is that the resource supply center allocates to the demand points , That is, set is_from_center to true during analysis, that is, start 
                                       allocation from the resource supply center.

                                     -Do not allocate resources from the resource supply center:

                                       If your resource center is some schools, and the demand point is the residential area, in the actual resource allocation, the students go to the school from the residential area, 
                                       this form is not to allocate resources from the resource supply center, that is, analysis When you want to set is_from_center to false, that is, do not start the allocation from the 
                                       resource supply center.

        :param str edge_demand_field: edge demand field. This field is the name of the field in the network dataset used to indicate the amount of resources required by the network edge as a demand site.
        :param str node_demand_field: Node demand field. This field is the name of the field in the network dataset used to indicate the amount of resources required by the network node as the demand site.
        :param str weight_name: the name of the weight field information
        :return: resource allocation analysis result object
        :rtype: list[AllocationAnalystResult]
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.analyst_setting": """TransportationAnalystSetting: Traffic network analysis environment setting object""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.find_closest_facility": """
        The nearest facility is searched and analyzed according to the specified parameters, and the event point is the node ID or coordinates.

        The nearest facility analysis refers to a given incident and a group of facilities on the network, for the incident to find one or several facilities that can be reached with the least cost, the result is from the incident to the facility (or from the facility to the facility to Incident) the best path.

        Facilities and incidents are the basic elements of the nearest facility search and analysis. Facilities are facilities that provide services, such as schools, supermarkets, gas stations, etc.; incident points are locations of events that require the services of facilities.

        For example, in a traffic accident at a certain location, it is required to find the 3 hospitals that can be reached within 10 minutes. Those that can be reached within 10 minutes are not considered. In this example, the location of the accident is an incident, and the surrounding hospitals are facilities.

        .. image:: ../image/FindClosestFacility.png

        There are two ways to specify event points, one is to specify by coordinate points; the other is to specify the node ID in the network dataset, that is, to regard the network node as an event point

        The facilities are specified in the parameter parameter of the TransportationAnalystParameter type. Through the TransportationAnalystParameter object
        There are two ways to specify passing points:

         -Use the :py:meth:`TransportationAnalystParameter.set_nodes` method of this object to specify facilities in the form of an array of node IDs in the network dataset,
           Therefore, the facilities used in the analysis process are the corresponding network nodes;
         -Use the object's :py:meth:`TransportationAnalystParameter.set_points` method to specify facilities in the form of coordinate point strings, so during the analysis process
           The facilities used are the corresponding coordinate points.

        note:

         Incidents and facilities must be the same type, that is, both are specified in the form of coordinate points, or both are specified in the form of node ID. This method requires that both facilities and incidents are coordinate points, that is, they need to pass
         The :py:meth:`TransportationAnalystParameter.set_points` method of the TransportationAnalystParameter object is used to set facilities.

        :param TransportationAnalystParameter parameter: Transportation network analysis parameter object.
        :param event_id_or_point: event point coordinates or node ID
        :type event_id_or_point: int or Point2D
        :param int facility_count: The number of facilities to find.
        :param bool is_from_event: Whether to search from the event point to the facility.
        :param float max_weight: Find the radius. The unit is the same as the resistance field set in the network analysis environment. If you want to find the entire network, the value is set to 0.
        :return: Analysis result. The number of results is the same as the number of the closest facilities found
        :rtype: list[TransportationAnalystResult]
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.find_critical_edges": """
        Key edge query.

        The key edge indicates the edge that must pass between two points.

        By calling this interface, the ID array of the edges that must pass between two points can be obtained. If the return value is empty, it means that there is no critical edge at the two points.

        :param int start_node: analysis starting point
        :param int end_node: end of analysis
        :return: Key edge ID array.
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.find_critical_nodes": """
        Key node query.
        A key node means a node that must pass between two points.

        By calling this interface, you can get the node ID array that must pass between two points. If the return value is empty, it means that there is no key node at the two points.

        :param int start_node: analysis starting point
        :param int end_node: end of analysis
        :return: Key node ID array.
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.find_group": """
        Group analysis.

        Grouping analysis is based on the network analysis model. The distribution point (:py:class:`TerminalPoint`) is assigned according to certain rules (the distance from the distribution point to the center point cannot be greater than the maximum cost value max_cost,
        And the load of each center point cannot be greater than the maximum load max_load) to find the center point to which it belongs. Whenever a center point is assigned a distribution point, the load of the group where the center point is located will increase the corresponding distribution point Load.

        :param terminal_points: distribution point collection
        :type terminal_points: list[TerminalPoint]
        :param center_points: center point coordinate collection
        :type center_points: list[Point2D]
        :param float max_cost: maximum cost
        :param float max_load: maximum load
        :param str weight_name: the name of the weight field information
        :param barrier_nodes: barrier node ID list
        :type barrier_nodes: list[int] or tuple[int]
        :param barrier_edges: barrier edge ID list
        :type barrier_edges: list[int] or tuple[int]
        :param barrier_points: barrier coordinate point list
        :type barrier_points: list[Point2D] or tuple[Point2D]
        :param bool is_along_road: Whether to proceed along the road, if it is True, the distribution point will find a point on the nearest road (possibly a projection point or an edge node), and start from the nearest point on the road to find a reasonable 
                                 center point for clustering. If it is False, Then the distribution point will directly find the nearest center point, and then merge the small clusters formed by each center point.
        :return: group analysis result
        :rtype: GroupAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.find_location": """
        According to the given parameters, the site selection partition analysis.
        The location analysis is to determine the best location of one or more facilities to be built, so that the facilities can provide services or goods to the demander in the most cost-effective way. Location partitions are not just
         a site selection process, and the needs of the demand points are also allocated to the service areas of the corresponding facilities, so it is called site selection and zoning.

        -Resource supply center and demand point

          Resource supply center: the center point is a facility that provides resources and services. It corresponds to a network node. The relevant information of the resource supply center includes the maximum resistance value, the type of resource supply center, and the ID of the 
          node where the resource supply center is located in the network.

          Demand point: usually refers to the location where the services and resources provided by the resource supply center are needed, and it also corresponds to the network node.

          The maximum resistance value is used to limit the cost of the demand point to the resource supply center. If the cost from the demand point to the resource supply center is greater than the maximum resistance value, the demand point is filtered out, that is, the resource supply 
          center cannot serve the demand point.

          There are three types of resource supply centers: non-central points, fixed central points and optional central points. A fixed central point refers to a service facility (playing a resource supply role) that already exists in the network, has been built, or has been determined 
          to be established; an optional central point refers to a resource supply center that can establish service facilities, that is, the service facilities to be built will start from The site is selected among these optional central points; non-central points are not considered in the 
          analysis. In practice, the establishment of this facility may not be allowed or other facilities already exist.

          In addition, the demand points used in the analysis process are all network nodes, that is, except for the network nodes corresponding to various types of central points, all network nodes are used as resource demand points to participate in the site selection zone
          analysis, if you want to exclude a certain part of the node, you can set it as an obstacle point.

        -Whether to allocate resources from the resource supply center

          The location zone can choose to allocate resources from the resource supply center or not from the resource supply center:

           -Example of distribution (supply to demand) starting from the central point:

             Electricity is generated from power stations and transmitted to customers through the grid. Here, the power station is the center of the network model because it can provide power supply. The customers of electric energy 
             are distributed along the lines of the power grid (the edges in the network model)
            . In this case, resources are transmitted from the supplier to the need through the network to achieve resource allocation.

           -Example of not starting from the central point (demand to supply):

             The relationship between schools and students also constitutes a distribution of supply and demand in the network. The school is the resource provider, and it is responsible for providing places for school-age children. School-age children are the demand side of resources,
             They require admission. As the demand-side school-age children are distributed along the street network, they generate a demand for the school's resources as the supply side-student places.

        - Applications

          There are currently 3 primary schools in a certain area. According to demand, it is planned to build 3 more primary schools in this area. Nine locations are selected as candidate locations, and 3 best locations will be selected from these candidate locations to establish a new 
          elementary school. As shown in Figure 1, the existing 3 primary schools are fixed center points, and the 7 candidate positions are optional center points. The conditions to be met for a new elementary school are: residents in residential areas must walk to school within 30 minutes. 
          The site selection zoning analysis will give the best site location based on this condition, and circle each school, including the service areas of the three existing schools. As shown in Figure 2, the final optional center points with serial numbers 5, 6, and 8 were selected as the 
          best place to build a new school.

          Note: All the network nodes in the network dataset in the following two pictures are regarded as the residential areas in this area. All of them participate in the analysis of location selection. The number of residents in a residential area is the number of services required by the 
          residential area.
  

          .. image:: ../image/FindLocation_1.png


          .. image:: ../image/FindLocation_2.png

        :param supply_centers: collection of resource supply centers
        :type supply_centers: list[SupplyCenter] or tuple[SupplyCenter]
        :param int expected_supply_center_number: The number of resource supply centers expected to be used in the site selection of the final facility. When the input value is 0, the number of resource supply centers in the final facility location defaults to the minimum number 
                                                  of supply centers required in the coverage analysis area
        :param bool is_from_center: Whether to allocate resources from the resource supply center. Since the edge in the network data has positive and negative resistance, that is, the forward resistance value of the edge and the reverse resistance value may be different. Therefore, 
                                    in the analysis, the resources are allocated from the resource supply center to the demand point and from the demand point to the demand point. Under the two forms of resource supply center allocation, the analysis results obtained will be different.
                                    The following are examples of two actual application scenarios to help further understand the differences between the two forms. It is assumed that the positive and negative resistance values of the edges in the network datasets are different.

                                    -Starting from the resource supply center to allocate resources to demand points:

                                      If you choose a location for some storage centers, and the demand points are major supermarkets, in the actual resource allocation, the goods in the warehouse are transported to the supermarkets that they serve. This form is from the resource 
                                      supply center to the demand point. Allocation, that is, set is_from_center to True during analysis, that is, start allocation from the resource supply center.
                                    -Do not allocate resources from the resource supply center:

                                      If you choose a location for a service organization like a post office, a bank, or a school, and the demand point is a residential area, in the actual resource allocation, the residents of the residential area will take the initiative to 
                                      go to their service organization to handle business. The form is not to allocate resources from the resource supply center, that is, set is_from_center to False during analysis, that is, do not start the allocation from the resource supply center.
        :param str weight_name: the name of the weight field information
        :return: Location analysis result object
        :rtype: LocationAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.find_mtsp_path": """
        Multi-travel salesman (logistics distribution) analysis, the distribution center is a point coordinate string or a node ID array

        Multi-travel salesman analysis is also called logistics distribution, which means that given M distribution center points and N distribution destinations (M, N are integers greater than zero) in the network dataset, find a cost-effective distribution route, and give Out 
        the corresponding walking route. How to reasonably allocate the distribution order and delivery route to minimize the total cost of distribution or the cost of each distribution center is the problem that logistics distribution solves.

        There are two ways to specify the distribution center point, one is to specify the coordinate point collection, and the other is to specify the network node ID array.

        The delivery destination is specified in the parameter parameter of the TransportationAnalystParameter type. There are two ways to specify the delivery destination through the TransportationAnalystParameter object:

         -Use the object: py:meth:`TransportationAnalystParameter.set_nodes` method ,Specify the delivery destination in the form of the node ID array in the network dataset, so the delivery destination used in the analysis 
         process is the corresponding network node;
          
         -Use the object's :py:meth:`TransportationAnalystParameter.set_points` method ,The delivery destination is specified in the form of a coordinate point string, so the delivery destination used in the analysis process 
         is the corresponding coordinate point.
           .

        note:

        The distribution center point and the distribution destination must be the same type, that is, both are specified in the form of coordinate points, or both are specified in the form of node ID. This method requires that both the delivery destination and the delivery center point 
        are coordinate points.

        The result of multi-traveling salesman analysis will give the distribution destinations that each distribution center is responsible for, as well as the sequence of these distribution destinations, and the corresponding walking routes, so as to minimize the distribution cost of the 
        distribution center or make all the distributions The total cost of the center is minimal. Moreover, the distribution center point will eventually return to the distribution center point after completing the distribution task of the distribution destination it is responsible for.

        Application example: There are 50 newspapers and periodicals retail locations (distribution destinations) and 4 newspapers and periodicals supply locations (distribution centers). Now we are seeking the optimal route for these 4 supply locations to send newspapers to newspapers and 
        periodicals retail locations, which is a logistics and distribution problem.

        The figure below shows the analysis results of newspaper distribution. The larger red dots represent the 4 newspaper supply locations (distribution centers), while the other smaller dots represent the newspaper retail locations (delivery destinations).
        The distribution plan of each distribution center is marked with different colors, including the distribution destination, distribution sequence and distribution route it is responsible for.

        .. image:: ../image/MTSPPath_result1.png

        The figure below shows the distribution plan of the No. 2 distribution center circled by the rectangular frame in the figure above. The small blue dots marked with numbers are the delivery destinations (18 in total) that the No. 2 distribution center is 
        responsible for. The No. 2 distribution center will send newspapers in the order of the numbers marked on the delivery destinations, that is, No. 1 will be sent first From the newspaper retail location, send to the newspaper retail location No. 2, and so on, 
        and complete the distribution along the blue line obtained by the analysis, and finally return to the distribution center.

        .. image:: ../image/MTSPPath_result2.png

        It should be noted that since the purpose of logistics distribution is to find a solution that minimizes the total cost of distribution or the cost of each distribution center, it is possible that some logistics distribution centers may not participate in the distribution in the analysis results.

        :param TransportationAnalystParameter parameter: Transportation network analysis parameter object.
        :param center_nodes_or_points: distribution center point coordinate string or node ID array
        :type center_nodes_or_points: list[Point2D] or list[int]
        :param bool is_least_total_cost: Whether the distribution mode is the least total cost plan. If it is true, the distribution will be carried out according to the mode with the least total cost. At this time, it may happen that some distribution center points are more costly for distribution and other 
                                        distribution center points are less costly. If it is false, it is locally optimal. This scheme will control the cost of each distribution center point, so that the cost of each center point is relatively even, and the total cost may not be the smallest at this time.
        :return: Multi-travel salesman analysis results, the number of results is the number of central points participating in the distribution.
        :rtype: list[TransportationAnalystResult]
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.find_path": """
        Best path analysis.
        The problem that the best path analysis solves is that, given N points (N is greater than or equal to 2) in the network dataset, find the least costly path through these N points in the order of the given points.
        "Minimum cost" has many understandings, such as the shortest time, the lowest cost, the best scenery, the best road conditions, the least bridges, the least toll stations, and the most villages.

        .. image:: ../image/FindPath.png

        The passing point of the best path analysis is specified in the parameter of type :py:class:`TransportationAnalystParameter`. Via TransportationAnalystParameter
        There are two ways for objects to specify passing points:

         -Use the :py:meth:`TransportationAnalystParameter.set_nodes` method of this object to specify the points passed by the optimal path analysis in the form of an array of node IDs in the network dataset, so the points passed during the analysis process are the corresponding network nodes;
         -Use the :py:meth:`TransportationAnalystParameter.set_points` method of this object to specify the points passed by the best path analysis in the form of a coordinate point string, so the points passed during the analysis process are the corresponding coordinate points.

        In addition, through the :py:class:`TransportationAnalystParameter` object, you can also specify other information required for optimal path analysis, such as obstacle points (edges), whether the analysis results include routes,
        Driving guidance, passing edges or nodes, etc. For details, see the TransportationAnalystParameter class.

        It should be noted that the traveling salesman analysis (:py:meth:`find_tsp_path` method) in network analysis is similar to the best path analysis, which is to find the least expensive path to traverse all passing points in the network. But there is a clear difference between the two, that is, 
        when traversing the passing points, the two processes are different in the order of visiting the passing points:

         -Best path analysis: All points must be visited in the order of given passing points;
         -Traveling salesman analysis: It is necessary to determine the optimal order to visit all points, not necessarily in the order of the given passing points.


        :param TransportationAnalystParameter parameter: Transportation network analysis parameter object
        :param bool is_least_edges: Whether the number of edges is the least. true means that the query will be carried out according to the least number of edges. Since a small 
                                    number of edges does not mean that the length of the edge is short, the result detected at this time may not be the shortest path. As shown in 
                                    the figure below, if the number of edges of the green path connecting AB is less than the yellow path, when this parameter is set to True, the green 
                                    path is the path obtained by the query, and when the parameter is set to false, the yellow path is the path obtained by the query.

                                    .. image:: ../image/hasLeastEdgeCount.png

        :return: Best path analysis result
        :rtype: TransportationAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.find_service_area": """
        Service area analysis.
        The service area is an area centered on a designated point and within a certain resistance range, including all accessible edges and points. Service area analysis is the process of finding the service area (ie service area) for the location (ie center point) 
        that provides a certain service on the network based on a given resistance value (ie, service radius). Resistance can be the time of arrival, distance, or any other cost. For example: Calculate the 30-minute service area for a certain point on the network, 
        then the time from any point to the point in the resulting service area will not exceed 30 minutes.

        The result of service area analysis includes the routes and areas that each service center can serve. Routing refers to the path that extends from the service center and follows the principle that the resistance value is not greater than the specified service 
        radius; the service area is the area formed by enclosing the routing according to a certain algorithm. As shown in the figure below, the red dots represent the service center points that provide services or resources. The area areas of various colors are centered 
        on the corresponding service center points. Within the given resistance range, each service center The route served by the point is also marked with the corresponding color.
        
        .. image:: ../image/FindServiceArea_1.png

        -Service center

         There are two ways to specify the location of the service center point through the :py:class:`TransportationAnalystParameter` object:

          -Use the :py:meth:`TransportationAnalystParameter.set_nodes` method to specify the service center point in the form of an array of node IDs in the network dataset, 
            So the service center point used in this analysis process is the corresponding network node.
          -Use the :py:meth:`TransportationAnalystParameter.set_points` method to specify the service center point in the form of the coordinate point string of the service center point.
            The service center point used in the analysis process is the set of corresponding coordinate points.

        -Whether to analyze from the central point

          Whether to start the analysis from the central point, it reflects the relationship mode between the service center and the demand place that needs the service. Analyzing from the central point means that the service center provides services to the service demand; not starting from the central 
          point of analysis means that the service demand is proactively to the service center to obtain services. For example: a milk station delivers milk to various residential areas. If you want to analyze the service area of this milk station and check the range that the milk station can serve under 
          the conditions allowed, then you should use the central point in the actual analysis process. The beginning of the analysis model; another example, if you want to analyze the area that a certain school in an area can serve under permitted conditions, because in reality, students take the initiative 
          to come to the school to study and receive the services provided by the school, then In the actual analysis process, a mode that does not start from the center point should be used.

        -Mutually exclusive service areas

          If two or more adjacent service areas have intersections, they can be mutually exclusive. After mutual exclusion processing, these service areas will not overlap. As shown in the figure on the left, mutual exclusion is not processed, and the right picture is mutually exclusive.

          .. image:: ../image/FindServiceArea_2.png

        :param TransportationAnalystParameter parameter: Transportation network analysis parameter object.
        :param weights: Array of service area radius. The length of the array should be consistent with the number of given service center points, and the array elements correspond to the center points in a one-to-one order. Forward, reverse the weight per unit area radius information services specified in the same unit of the resistance of the field.
        :type weights: list[float]
        :param bool is_from_center: Whether to start the analysis from the center point.
        :param bool is_center_mutually_exclusive: Whether to perform service area mutual exclusion processing. If it is set to true, mutual exclusion processing is performed, and if it is set to false, mutual exclusion processing is not performed.
        :param service_area_type: service area type
        :type service_area_type: ServiceAreaType or str
        :return: Service area analysis result
        :rtype: list[ServiceAreaResult]
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.find_tsp_path": """
        Traveling salesman analysis.

        Traveling salesman analysis is to find a path through a specified series of points, and traveling salesman analysis is a disorderly path analysis. Traveling dealers can decide the order of visiting nodes by themselves, and the goal is to minimize the total impedance of the travel route (or close to the minimum).

        The passing point of the traveling salesman analysis is specified in the parameter parameter of the TransportationAnalystParameter type. There are two ways to specify passing points through the TransportationAnalystParameter object:

         -Use the :py:meth:`TransportationAnalystParameter.set_nodes` method of this object to specify the points passed by the traveling salesman analysis in the form of a node ID array in the network dataset, so the points passed during 
         the analysis process are the corresponding network nodes;;
         -Use the :py:meth:`TransportationAnalystParameter.set_points` method of this object to specify the points passed by the traveling salesman analysis in the form of a coordinate point string, so
           the point passed during the analysis is the corresponding coordinate point.

        It should be emphasized that this method defaults to the first point (node or coordinate point) in the given set of passing points as the starting point of the traveling salesman. In addition, the user can also specify the end point (corresponding to the is_end_node_assigned parameter in the method). 
        If you choose to specify the end point, the last point in the set of given passing points is the end point. At this time, the traveling salesman starts from the first given point and ends at the specified end. The visiting order of other passing points is determined by the traveling salesman himself.

        .. image:: ../image/FindTSPPath.png

        In addition, if you choose to specify the end point, the end point can be the same as the starting point, that is, the last point in the set of passing points is the same as the first point. At this time, the result of traveling salesman analysis is a closed path
        , That is, start from the starting point and finally return to that point.

        .. image:: ../image/FindTSPPath_1.png


        NOTE: When using this method, if you choose to specify the end point (is_end_node_assigned method corresponding to the reference number), a first point designated passing point and the last point may be set
        the same or different; other points are not allowed to have the same point, otherwise the analysis will fail; when the end point is not specified, the same point is not allowed, if there are the same points, the analysis will fail.


        It should be noted that the traveling salesman analysis (:py:meth:`find_path` method) in the network analysis is similar to the best path analysis, which is to find the least expensive path to traverse all passing points in the network. 
        But there is a clear difference between the two, that is, when traversing the passing points, the two processes are different in the order of visiting the passing points:

         -Best path analysis: All points must be visited in the order of given passing points;
         -Traveling salesman analysis: It is necessary to determine the optimal order to visit all points, not necessarily in the order of the given passing points.

        :param TransportationAnalystParameter parameter: Transportation network analysis parameter object.
        :param bool is_end_node_assigned: Whether to specify the end point. Specifying true means specifying the end point, and the last point in the set of given passing points is the end point; otherwise, no end point is specified.
        :return: Traveling salesman analysis result
        :rtype: TransportationAnalystResult
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.find_vrp": """
        Logistics distribution analysis.
        Compared with the previous logistics and distribution interface: py:meth:`find_mtsp_path`, this interface has more settings for vehicle information, demand, etc., which can more fully meet the needs of different situations.

       Logistics distribution analysis parameter object: py:class:`VRPAnalystParameter` You can set the name identification of obstacle edges, obstacle points, weight field information, and turn weight field. You can also set some 
       analysis results, that is, whether to include in the analysis results Analyze the following content: node collection, edge collection, routing object collection, and site collection.

        Vehicle information: py:class:`VehicleInfo` can set each vehicle's own load, maximum consumption and other conditions.

        The center point information center_nodes_or_points can be set to include the coordinates or node ID of the center; the demand point information demand_points can be set to the coordinates or node ID of each demand point, as well as the respective demand.

        By setting relevant information about vehicles, demand points and central points, the interface can reasonably divide routes according to these conditions and complete corresponding assignment tasks.

        :param VRPAnalystParameter parameter: Logistics distribution analysis parameter object.
        :param vehicles: array of vehicle information
        :type vehicles: list[VehicleInfo] or tuple[VehicleInfo]
        :param center_nodes_or_points: center point information array
        :type center_nodes_or_points: list[int] or list[Point2D] or tuple[int] or tuple[Point2D]
        :param demand_points: demand point information array
        :type demand_points: list[DemandPointInfo] or tuple[DemandPointInfo]
        :return: logistics delivery result
        :rtype: list[VRPAnalystResult]
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.load": """
        Load the network model.
        This method loads the network model according to the environmental parameters in the TransportationAnalystSetting object. After setting the parameters of the traffic network analysis environment, the related 
        parameters are modified. Only when this method is called, the traffic network analysis environment settings made will take effect in the process of traffic network analysis.

        :return: Return True if loading is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.set_analyst_setting": """
        Set traffic network analysis environment setting object
        When using traffic network analysis to perform various traffic network analysis, you must first set the traffic network analysis environment, and you must first set the traffic network analysis environment

        :param TransportationAnalystSetting analyst_setting: Traffic network analysis environment setting object
        :return: self
        :rtype: TransportationAnalyst
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalyst.update_edge_weight": """
        This method is used to update the weight of the edge.
        This method is used to modify the edge weights of the network model loaded into the memory, and does not modify the network dataset.

       This method can update the forward weight or the reverse weight of the edge. The forward weight refers to the cost from the start node of the edge to the end node, and the reverse weight refers to the cost 
       from the end node of the edge to the start node. Therefore, specify from_node_id as the starting node ID of the updated edge in the network dataset, and to_node_id as the end node ID of the edge, then update the 
       forward weight. Otherwise, specify from_node_id as the end of the edge in the network dataset Node ID, to_node_id is the starting node ID of the edge, then the reverse weight is updated.

        Note that a negative weight means that the edge is prohibited from passing in this direction.

        :param int edge_id: The ID of the edge being updated
        :param int from_node_id: The starting node ID of the edge to be updated.
        :param int to_node_id: End node ID of the edge to be updated.
        :param str weight_name: The name of the weight field information object to which the weight field to be updated belongs
        :param float weight: weight, that is, use this value to update the old value. The unit is the same as the unit of the weight field in the weight information field object specified by weight_name.
        :return: Successfully return the weight before the update. Failure return -1.7976931348623157e+308
        :rtype: float
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter": """
    Traffic network analysis parameter setting class.

    This class is mainly used to set the parameters of traffic network analysis. Through the traffic network analysis parameter
     setting class, you can set the name identification of obstacle edges, obstacle points, weight field information, analysis path 
     points or nodes, and you can also set some analysis results, that is, whether the analysis results include the analysis path The 
     following content: node collection, edge segment collection, routing object collection and site collection.

    """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.barrier_edges": """list[int]: Barrier edge ID list """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.barrier_nodes": """list[int]: Barrier node ID list """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.barrier_points": """list[Point2D]: List of barrier points""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.is_edges_return": """bool: Whether the passing edge is included in the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.is_nodes_return": """bool: Does the analysis result include passing nodes""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.is_path_guides_return": """bool: Whether the analysis result contains driving guide""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.is_routes_return": """bool: Return whether the analysis result contains routing (:py:class:`GeoLineM`) object""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.is_stop_indexes_return": """bool: Whether to include the site index in the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.nodes": """list[int]: Analysis path point """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.points": """list[Point2D]: Pass points during analysis""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_barrier_edges": """
        Set the barrier edge ID list. Optional. The obstacle edge specified here and the obstacle edge specified in the traffic network analysis environment (:py:class:`TransportationAnalystSetting`) 
        work together to analyze the traffic network.

        :param edges: list of obstacle edge IDs
        :type edges: list[int] or tuple[int]
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_barrier_nodes": """
        Set up a list of barrier node IDs. Optional. The obstacle node specified here and the obstacle node specified in the transportation network analysis environment (:py:class:`TransportationAnalystSetting`) 
        work together to analyze the traffic network.

        :param nodes: Barrier node ID list
        :type nodes: list[int] or tuple[int]
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_barrier_points": """
        Set the coordinate list of obstacle nodes. Optional. The specified obstacle point can not be on the network (neither on the edge nor on the node). The analysis will be based on the distance tolerance (:py:attr:`.TransportationPathAnalystSetting.tolerance`)
        The obstacle point comes down to the nearest network. Currently, it supports best route analysis, nearest facility search, traveling salesman analysis, and logistics distribution analysis.

        :param points: list of coordinates of barrier nodes
        :type points: list[Point2D] or tuple[Point2D]
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_edges_return": """
        Set whether the passing edge is included in the analysis result

        :param bool value: Specify whether the passing edge is included in the analysis result. Set to True, after the analysis is successful, you can use the TransportationAnalystResult object
                            :py:attr:`TransportationAnalystResult.edges` method Return the passing edge; if it is False, it Return None
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_nodes": """
        Set analysis route points. Required, but mutually exclusive with the :py:meth:`set_points` method. If set at the same time, only the last setting before the analysis is valid. For example, 
        if the node set is specified first, then the coordinate point set is specified, and then the analysis is performed. At this time, only the coordinate points are analyzed.

        :param nodes: ID of passing node
        :type nodes: list[int] or tuple[int]
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_nodes_return": """
        Set whether to include nodes in the analysis results

        :param bool value: Specify whether to include transit nodes in the analysis result. Set to True, after the analysis is successful, you can use the TransportationAnalystResult object
                            :py:attr:`TransportationAnalystResult.nodes` method Return the passing node; if it is False, it Return None
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_path_guides_return": """
        Set whether to include the driving guide set in the analysis result.

        This method must be set to True, and pass the :py:meth:`TransportationPathAnalystSetting.set_edge_name_field` method of the TransportationAnalystSetting class
        set the edge name field, the driving guide set will be included in the analysis result, otherwise the driving guide will not be returned, but it does not affect the acquisition of other content in the analysis result.
        
        :param bool value: Whether to include driving guidance in the analysis result. Set to True, after the analysis is successful, you can check the TransportationAnalystResult
                           : py:attr:`TransportationAnalystResult.path_guides` method Return travel guide; if it is False, it Return None
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_points": """
        Set the collection of passing points during analysis. Required, but mutually exclusive with the :py:meth:`set_nodes` method. If set at the same time, only the last setting before the analysis is valid. For example, first specify the node set, and then
        Specify a set of coordinate points and then analyze. At this time, only coordinate points are analyzed.

        If a point in the set of set waypoints is not within the range of the network dataset, the point will not participate in the analysis

        :param points: passing points
        :type points: list[Point2D] or tuple[Point2D]
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_routes_return": """
       Whether the analysis result contains routing (:py:class:`GeoLineM`) object

        :param bool value: Specify whether to include routing objects. Set to True, after the analysis is successful, you can use the TransportationAnalystResult object
                           :Py:attr:`TransportationAnalystResult.route` Return the route object; if it is False, it Return None
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_stop_indexes_return": """
        Set whether to include the site index in the analysis results

        :param bool value: Specify whether to include the site index in the analysis result. Set to True, after the analysis is successful, you can use the TransportationAnalystResult object
                            :py:attr:`TransportationAnalystResult.stop_indexes` method Return the site index; if it is False, it Return None
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.set_weight_name": """
        Set the name of the weight field information. If not set, the name of the first weight field information object in the weight field information set will be used by default

        :param str name: the name identifier of the weight field information
        :return: self
        :rtype: TransportationAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystParameter.weight_name": """str: the name of the weight field information""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystResult": """
    Traffic network analysis result class.

    This class is used to return the route set of the analysis result, the set of nodes and edges passed by the analysis, the set of driving guidance, the set of stations and the set of weights, and the cost of each station. Through this type of setting,
    The results of analysis such as optimal route analysis, traveling salesman analysis, logistics distribution and nearest facility search can be obtained flexibly.
    """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystResult.edges": """list[int]: Return the set of edges of the analysis result. Note that you must set the :py:meth:`TransportationAnalystParameter.set_edges_return` of the TransportationAnalystParameter object
                      When the method is set to True, the analysis result will include the set of passing edges, otherwise it will return None
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystResult.nodes": """list[int]: The set of path nodes that return the analysis results. Note that the :py:meth:`TransportationAnalystParameter.set_nodes_return` of the TransportationAnalystParameter object must be set
                      If the method is set to True, the analysis result will include the set of passing nodes, otherwise it will be an empty array. """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystResult.path_guides": """PathGuide: Return travel guide. Note that the :py:meth:`TransportationAnalystParameter.set_path_guides_return` of the TransportationAnalystParameter object must be added
                                When the method is set to True, the driving guidance will be included in the analysis result, otherwise it will be an empty array. """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystResult.route": """GeoLineM: The route object that Return the analysis result. Note that the :py:meth:`TransportationAnalystParameter.set_routes_return` of the TransportationAnalystParameter object must be added
                     If the method is set to true, the routing object will be included in the analysis result, otherwise it will return None""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystResult.stop_indexes": """list[int]: Return the site index, this array reflects the order of the sites after the analysis. Note that the TransportationAnalystParameter object must be
                      The :py:meth:`TransportationAnalystParameter.set_stop_indexes_return` method is set to True,  the site index will be included in the analysis result, otherwise it will be an empty array.
                      

                      In different analyses, the meaning of the return value of this method is different:

                      -Best path analysis (:py:meth:`TransportationAnalyst.find_path` method):

                          -Node mode: For example, if you set three nodes with analysis node IDs 1, 3, 5, the order of the result path must be 1, 3, 5, so the element values are 0, 1, 2, that is, 
                          the order of the result path Index in the initial set node string.

                          -Coordinate point mode: If the set analysis coordinate points are Pnt1, Pnt2, Pnt3, because the sequence of the result path must be Pnt1, Pnt2, Pnt3, so the element value 
                          is 0, 1, 2, that is, the coordinate point sequence of the result path is set in the initial coordinate The index in the point string.

                      -Traveling salesman analysis (:py:meth:`TransportationAnalyst.find_tsp_path` method):

                         -Node mode: If the analysis node ID is set to three nodes with 1, 3, and 5, and the sequence of the results is 3, 5, 1, then the element values are in order
                           1, 2, 0, that is, the index of the result path sequence in the initial set node string.

                         -Coordinate point mode: If the analysis coordinate points are set as Pnt1, Pnt2, Pnt3, and the sequence of the result path is Pnt2, Pnt3, Pnt1, the element 
                         values are 1, 2, 0 in turn, that is, the coordinate point sequence of the result is set in the initial coordinate point. The index in the string.

                      -Multiple traveling salesman analysis (:py:meth:`TransportationAnalyst.find_mtsp_path` method):

                        The meaning of the elements is the same as that of traveling salesman analysis, which represents the order in which the distribution route of the corresponding center 
                        point passes through the station. Note that when the distribution mode is locally optimal, all central points participate in the distribution, and when the total cost 
                        is the smallest mode, the number of central points participating in the distribution may be less than the specified number of central points.

                      -For the nearest facility search analysis (:py:meth:`TransportationAnalyst.find_closest_facility` method), this method is invalid.
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystResult.stop_weights": """list[float]: Return the cost (weight) between sites after sorting sites according to site index.
                        This method Return the cost between the station and the station. The station here refers to the analysis node or coordinate point, rather than all the nodes or coordinate points that the path passes.
                        The order of the sites associated with the weights returned by this method is the same as the order of the site index values returned in the :py:attr:`stop_indexes` method, but the subtle differences should be noted for different analysis functions. E.g:

                        -Best path analysis (:py:meth:`TransportationAnalyst.find_path` method): Suppose you specify passing points 1, 2, and 3, then the two-dimensional elements are: 
                        1 to 2 cost, 2 to 3 cost;

                        -Traveling salesman analysis (:py:meth:`TransportationAnalyst.find_tsp_path` method): Assuming that you specify passing points 1, 2, and 3, the site index in the 
                        analysis result is 1, 0, 2, and the two-dimensional elements are: 2 to 1 Cost, cost from 1 to 3;

                        -Multi-traveling salesman analysis (:py:meth:`TransportationAnalyst.find_mtsp_path` method): that is, logistics and distribution. The element is the cost between the stations that the path passes. It should be noted that the path of the multi-traveling salesman 
                        analysis passes through the stations It includes the center point, and the start and end points of the path are the center points. For example, if a result path starts from the center point 1, passing through stations 2, 3, and 4, and the corresponding station index 
                        is 1, 2, 0, the station weights are: 1 to 3 cost, 3 to 4 cost, 4 Cost to 2 and cost 2 to 1.

                        -For the nearest facility search analysis (:py:meth:`TransportationAnalyst.find_closest_facility` method), this method is invalid.
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystResult.weight": """float: the weight spent.""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting": """
    Traffic network analysis environment setting class. This class is used to provide all the parameter information needed for traffic network analysis. The setting of each parameter of the traffic network analysis environment setting category directly affects the result of the analysis.

    When using the traffic network analysis class (:py:class:`TransportationAnalyst`) to perform various traffic network analysis, you must first set the traffic network analysis environment, and the traffic network analysis environment is set through: py:class:`TransportationAnalyst The `:py:meth:`TransportationAnalyst.set_analyst_setting` method 
    of the class object is done.
    """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.barrier_edge_ids": """list[int]: ID list of barrier edge segments""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.barrier_node_ids": """list[int]: Barrier node ID list """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.bounds": """Rectangle: the analysis range of the best path analysis""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.edge_filter": """str: edge filter expression in traffic network analysis """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.edge_id_field": """str: The field that marks the edge ID in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.edge_name_field": """str: Road name field""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.f_node_id_field": """str: The field that marks the starting node ID of the edge in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.ft_single_way_rule_values": """list[str]: an array of strings used to represent forward one-way lines""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.network_dataset": """DatasetVector: network dataset""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.node_id_field": """str: The field that identifies the node ID in the network dataset """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.prohibited_way_rule_values": """list[str]: an array of strings representing prohibited lines """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.rule_field": """str: The field in the network dataset representing the traffic rules of the network edge""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_barrier_edge_ids": """
        Set the ID list of barrier edges

        :param value: ID list of barrier edge
        :type value: str or list[int]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_barrier_node_ids": """
        Set the ID list of barrier nodes

        :param value: ID list of barrier node
        :type value: str or list[int]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_bounds": """
        Set the analysis scope of the best path analysis

        :param value: The analysis range of the best path analysis
        :type value: Rectangle or str
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_edge_filter": """
        Set the edge filter expression in traffic network analysis

        :param value: edge filtering expression in traffic network analysis
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_edge_id_field": """
        Set the field that identifies the node ID in the network dataset

        :param str value: The field that marks the edge segment ID in the network dataset
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_edge_name_field": """
        Set road name field

        :param str value: Road name field
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_f_node_id_field": """
        Set the field to mark the starting node ID of the edge in the network dataset

        :param str value: The field that marks the starting node ID of the edge in the network dataset
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_ft_single_way_rule_values": """
        Set the array of strings used to represent the forward one-way line

        :param value: An array of strings used to represent the forward one-way line
        :type value: str or list[str]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_network_dataset": """
        Set up a network dataset for optimal path analysis

        :param dataset: network dataset
        :type dataset: DatasetVetor or str
        :return: current object
        :rtype: PathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_node_id_field": """
        Set the field of the network dataset to identify the node ID

        :param str value: The field that identifies the node ID in the network dataset
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_prohibited_way_rule_values": """
        Set up an array of strings representing forbidden lines

        :param value: an array of strings representing the forbidden line
        :type value: str or list[str]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_rule_field": """
        Set the fields in the network dataset that represent the traffic rules of the network edge

        :param str value: A field in the network dataset representing the traffic rules of the network edge
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_t_node_id_field": """
        Set the field to mark the starting node ID of the edge in the network dataset

        :param str value:
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_tf_single_way_rule_values": """
        Set up an array of strings representing reverse one-way lines

        :param value: an array of strings representing the reverse one-way line
        :type value: str or list[str]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_tolerance": """
        Set node tolerance

        :param float value: node tolerance
        :return: current object
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_two_way_rule_values": """
        Set an array of strings representing two-way traffic lines

        :param value: An array of strings representing two-way traffic lines
        :type value: str or list[str]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.set_weight_fields": """
        Set weight field

        :param value: weight field
        :type value: list[WeightFieldInfo] or tuple[WeightFieldInfo]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.t_node_id_field": """str : the number of network data centralized edges start flag field of the node ID """,

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.tf_single_way_rule_values": """list[str]: An array of strings representing reverse one-way lines""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.tolerance": """float: node tolerance""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.two_way_rule_values": """list[str]: an array of strings representing two-way traffic lines""",

    "iobjectspy._jsuperpy.analyst.na.TransportationAnalystSetting.weight_fields": """list[WeightFieldInfo]: weight field """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting": """
    The best path analysis environment for traffic network analysis.
    """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.__init__": """
        Initialization object

        :param network_dataset: network dataset
        :type network_dataset: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.barrier_edge_ids": """list[int]: ID list of barrier edge segments""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.barrier_node_ids": """list[int]: Barrier node ID list """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.bounds": """Rectangle: The analysis range of the best path analysis""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.edge_filter": """str: edge filtering expression in traffic network analysis """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.edge_id_field": """str: The field that marks the edge ID in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.edge_name_field": """str: Road name field""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.f_node_id_field": """str : mesh network dataset flag edge starting node ID field""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.ft_single_way_rule_values": """list[str]: an array of strings used to represent forward one-way lines""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.network_dataset": """DatasetVector: network dataset""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.node_id_field": """str: The field that identifies the node ID in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.prohibited_way_rule_values": """list[str]: an array of strings representing prohibited lines """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.rule_field": """str: The field in the network dataset representing the traffic rules of the network edge""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_barrier_edge_ids": """
        Set the ID list of barrier edges

        :param value: ID list of barrier edge
        :type value: str or list[int]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_barrier_node_ids": """
        Set the ID list of barrier nodes

        :param value: ID list of barrier node
        :type value: str or list[int]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_bounds": """
        Set the analysis scope of the best path analysis

        :param value: The analysis range of the best path analysis
        :type value: Rectangle or str
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_edge_filter": """
        Set the edge filter expression in traffic network analysis

        :param value: edge filtering expression in traffic network analysis
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_edge_id_field": """
        Set the field that identifies the node ID in the network dataset

        :param str value: The field that marks the edge segment ID in the network dataset
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_edge_name_field": """
        Set road name field

        :param str value: Road name field
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_f_node_id_field": """
        Set the field to mark the starting node ID of the edge in the network dataset

        :param str value: The field that marks the starting node ID of the edge in the network dataset
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_ft_single_way_rule_values": """
        Set the array of strings used to represent the forward one-way line

        :param value: An array of strings used to represent the forward one-way line
        :type value: str or list[str]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_network_dataset": """
        Set up a network dataset for optimal path analysis

        :param dataset: network dataset
        :type dataset: DatasetVetor or str
        :return: current object
        :rtype: PathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_node_id_field": """
        Set the field of the network dataset to identify the node ID

        :param str value: The field that identifies the node ID in the network dataset
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_prohibited_way_rule_values": """
        Set up an array of strings representing forbidden lines

        :param value: an array of strings representing the forbidden line
        :type value: str or list[str]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_rule_field": """
        Set the fields in the network dataset that represent the traffic rules of the network edge

        :param str value: A field in the network dataset representing the traffic rules of the network edge
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_t_node_id_field": """
        Set the field to mark the starting node ID of the edge in the network dataset

        :param str value:
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_tf_single_way_rule_values": """
        Set up an array of strings representing reverse one-way lines

        :param value: an array of strings representing the reverse one-way line
        :type value: str or list[str]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_tolerance": """
        Set node tolerance

        :param float value: node tolerance
        :return: current object
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_two_way_rule_values": """
        Set an array of strings representing two-way traffic lines

        :param value: An array of strings representing two-way traffic lines
        :type value: str or list[str]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.set_weight_fields": """
        Set weight field

        :param value: weight field
        :type value: list[WeightFieldInfo] or tuple[WeightFieldInfo]
        :return: self
        :rtype: TransportationPathAnalystSetting
        """,

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.t_node_id_field": """str: the field that marks the starting node ID of the edge in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.tf_single_way_rule_values": """list[str]: an array of strings representing reverse one-way lines""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.tolerance": """float: node tolerance""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.two_way_rule_values": """li st[str]: an array of strings representing two-way traffic lines""",

    "iobjectspy._jsuperpy.analyst.na.TransportationPathAnalystSetting.weight_fields": """list[WeightFieldInfo]: weight field """,

    "iobjectspy._jsuperpy.analyst.na.TurnType": """
    Turning direction for driving guidance

    :var TurnType.NONE: invalid value
    :var TurnType.END: End, no turn
    :var TurnType.LEFT: Turn left
    :var TurnType.RIGHT: Turn right
    :var TurnType.AHEAD: means go straight ahead
    :var TurnType.BACK: U-turn
    """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter": """
    Logistic distribution analysis parameter setting class.

    This class is mainly used to set the parameters of logistics distribution analysis. Through the traffic network analysis parameter 
    setting class, you can set the name identification of obstacle edges, obstacle points, and weight field information, and you can also 
    set some settings for the analysis results, that is, whether the analysis results include the following content of the analysis path: node 
    set, edge Segment collection, routing object collection, and site collection.
    """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.analyst_type": """VRPAnalystType: Analysis mode in logistics analysis""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.barrier_edges": """list[int]: Barrier edge ID list """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.barrier_nodes": """list[int]: Barrier node ID list """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.barrier_points": """list[Point2D]: The coordinate list of barrier nodes""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.is_edges_return": """bool: Whether the passing edge is included in the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.is_nodes_return": """bool: Whether the analysis result contains nodes""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.is_path_guides_return": """bool: Whether the analysis result contains driving guide""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.is_routes_return": """bool: Whether the analysis result contains routing objects""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.is_stop_indexes_return": """bool: whether to include site index""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.route_count": """int: The value of the number of vehicles dispatched in one analysis""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_analyst_type": """
        Set the logistics analysis mode, including LEASTCOST minimum cost mode (default value), AVERAGECOST average cost mode, AREAANALYST regional analysis mode.

        :param value: logistics analysis mode
        :type value: VRPAnalystType or str
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_barrier_edges": """
        Set obstacle edge ID list

        :param value: Barrier edge ID list
        :type value: list[int]:
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_barrier_nodes": """
        Set barrier node ID list

        :param value: Barrier node ID list
        :type value: list[int]:
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_barrier_points": """
        Set the coordinate list of obstacle nodes

        :param points: list of coordinates of barrier nodes
        :type points: list[Point2D] or tuple[Point2D]
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_edges_return": """
        Set whether the passing edge is included in the analysis result

        :param bool value: Whether the passing edge is included in the analysis result
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_nodes_return": """
        Set whether to include nodes in the analysis results

        :param bool value: Whether the analysis result contains nodes
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_path_guides_return": """
        Set whether to include driving guidance in the analysis result.

        :param bool value: Whether the analysis result includes driving guidance. This method must be set to True, and the edge name field must be set by the method: py:meth:`TransportationPathAnalystSetting.set_edge_name_field` of the class: py:class:`TransportationAnalystSetting`, 
                           then the driving guidance set will be included in the analysis result, otherwise The driving guide will not be returned, but it will not affect the acquisition of other content in the analysis results.
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_route_count": """
        Set the value of the number of vehicles dispatched in one analysis. Set as required. In this analysis, the number of routes is obtained based on the number of vehicles. The number of routes is the same as the actual number of vehicles dispatched; if this parameter is not set, 
        the default number of dispatched vehicles will not exceed the total number of vehicles that can be provided N (vehicleInfo[N])

        :param int value: Number of dispatched vehicles
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_routes_return": """
        Set whether the analysis result contains a collection of routing objects

        :param bool value: Whether the analysis result contains a collection of routing objects
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_stop_indexes_return": """
        Set whether to include site index

        :param bool value: whether to include the site index
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_time_weight_field": """
        Set the name of the time field information.

        :param str value: The name of the time field information, the value set is the name of the weight field information in :py:class:`TransportationAnalystSetting`.
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_vrp_direction_type": """
        Set the type of logistics analysis route

        :param value: Type of logistics analysis route
        :type value: VRPDirectionType or str
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.set_weight_name": """
        Set the name of the weight field information

        :param str value: the name of the weight field information
        :return: self
        :rtype: VRPAnalystParameter
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.time_weight_field": """str: the name of the time field information""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.vrp_direction_type": """VRPDirectionType: Type of logistics analysis route""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystParameter.weight_name": """str: the name of the weight field information""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult": """
    VRP analysis result class.

    This class is used to obtain the route collection of the analysis result, the node collection and the edge collection, the driving guidance collection, 
    the station collection and the weight collection and the cost of each station. And the time consumption and total load consumption of the VRP line.
    """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult.edges": """list[int]: The set of edges passed by the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult.nodes": """list[int]: a collection of nodes passing through the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult.path_guides": """list[PathGuideItem]: Return travel guide """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult.route": """GeoLineM: The route object of the analysis result""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult.stop_indexes": """list[int]: Site index, reflecting the order of the sites after analysis.

                      According to different analysis line types: py:class:`VRPDirectionType`, the meaning of the value of this array is different:

                       -ROUNDROUTE: The first element and the last element are the center point index, and the other elements are the demand point index.
                       -STARTBYCENTER: The first element is the center point index, and the other elements are the demand point index.
                       -ENDBYCENTER: The last element is the center point index, and the other elements are the demand point index.
        """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult.stop_weights": """list[float]: After sorting the sites according to the site index, the cost (weight) between sites """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult.times": """list[datetime.datetime]: Return the departure time of each distribution point in each route of the logistics distribution (except the last point, which represents the time of arrival)""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult.vehicle_index": """int: vehicle index of each route in logistics distribution""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult.vrp_demands": """list[int]: The load of each line in the logistics distribution """,

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystResult.weight": """float: the total cost of each delivery route.""",

    "iobjectspy._jsuperpy.analyst.na.VRPAnalystType": """
    Analysis Mode in Logistics Analysis

    :var VRPAnalystType.LEASTCOST: least cost mode
    :var VRPAnalystType.AVERAGECOST: Average cost mode
    :var VRPAnalystType.AREAANALYST: Area analysis mode
    """,

    "iobjectspy._jsuperpy.analyst.na.VRPDirectionType": """
    Types of VRP analysis routes

    :var VRPDirectionType.ROUNDROUTE: Start from the center point and return to the center point.
    :var VRPDirectionType.STARTBYCENTER: Starting from the center point but not returning to the center point.
    :var VRPDirectionType.ENDBYCENTER: Do not start from the center point but return to the center point.
    """,

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo": """
    Vehicle information category. Information such as the maximum cost value and maximum load of the vehicle is stored.
    """,

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.area_ratio": """float: area coefficient of logistics analysis""",

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.cost": """float: the maximum cost of the vehicle""",

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.end_time": """datetime.datetime: the latest vehicle return time""",

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.load_weights": """list[float]: the load of the vehicle""",

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.se_node": """int: start and end node ID in one-way route of logistics analysis""",

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.se_point": """Point2D: start and end point coordinates in one-way route of logistics analysis""",

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.set_area_ratio": """
        Set the regional coefficient of logistics analysis. It is only valid when :py:class:`VRPAnalystType` is :py:attr:`VRPAnalystType.AREAANALYST`.

        :param float value: Area coefficient of logistics analysis
        :return: self
        :rtype: VehicleInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.set_cost": """
        Set the maximum cost of the vehicle

        :param float value: The maximum cost value of the vehicle.
        :return: self
        :rtype: VehicleInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.set_end_time": """
        Set the latest vehicle return time

        :param value: the latest return time of the vehicle
        :type value: datetime.datetime or int or str
        :return: self
        :rtype: VehicleInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.set_load_weights": """
        Set the load capacity of the vehicle. The load capacity can be multi-dimensional, for example, the maximum carrying weight and the maximum carrying volume can be set at the same time. It is required that the transport vehicle load of each line in the analysis does not exceed this value.

        :param value: the load of the vehicle
        :type value: list[float]
        :return: self
        :rtype: VehicleInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.set_se_node": """
        Set the start and end node ID in the one-way route of logistics analysis.

        When setting this method, the route type: py:class:`VRPDirectionType` must be: py:attr:`VRPDirectionType.STARTBYCENTER` or
        Or: py:attr:`VRPDirectionType.ENDBYCENTER` This parameter only works.

        When the route type is: py:attr:`VRPDirectionType.STARTBYCENTER`, this parameter indicates the final stop position of the vehicle.

        When the route type is: py:attr:`VRPDirectionType.ENDBYCENTER`, this parameter indicates the initial starting position of the vehicle.

        :param int value: start and end node ID in one-way route of logistics analysis
        :return: self
        :rtype: VehicleInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.set_se_point": """
        Set the starting and ending point coordinates in the one-way route of logistics analysis.

        When setting this method, the route type :py:class:`VRPDirectionType` must be :py:attr:`VRPDirectionType.STARTBYCENTER` or :py:attr:`VRPDirectionType.ENDBYCENTER` This parameter is effective.

        When the route type is: py:attr:`VRPDirectionType.STARTBYCENTER`, this parameter indicates the final stop position of the vehicle.

        When the route type is: py:attr:`VRPDirectionType.ENDBYCENTER`, this parameter indicates the initial starting position of the vehicle.

        :param Point2D value: starting and ending point coordinates in one-way route of logistics analysis
        :return: self
        :rtype: VehicleInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.set_start_time": """
        Set the earliest departure time of the vehicle

        :param value: The earliest departure time of the vehicle
        :type value: datetime.datetime or int or str
        :return: self
        :rtype: VehicleInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.VehicleInfo.start_time": """datetime.datetime: earliest vehicle departure time""",

    "iobjectspy._jsuperpy.analyst.na.WeightFieldInfo": """
    Weight field information class.

    Stores the relevant information of the weight field in the network analysis, including the forward weight field and the 
    reverse weight field. The weight field is a field indicating the weight value of the cost. The value of the forward weight 
    field indicates the cost required from the start to the end of the edge. The value of the reverse weight field indicates the cost required from the end point to the start point of the edge.
    """,

    "iobjectspy._jsuperpy.analyst.na.WeightFieldInfo.__init__": """
        Initialization object

        :param str weight_name: the name of the weight field information
        :param str ft_weight_field: forward weight field or field expression
        :param str tf_weight_field: reverse weight field or field expression
        """,

    "iobjectspy._jsuperpy.analyst.na.WeightFieldInfo.ft_weight_field": """str: Forward weight field or field expression """,

    "iobjectspy._jsuperpy.analyst.na.WeightFieldInfo.set_ft_weight_field": """
        Set forward weight field or field expression

        :param str value: forward weight field or field expression
        :return: self
        :rtype: WeightFieldInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.WeightFieldInfo.set_tf_weight_field": """
        Set reverse weight field or field expression

        :param str value: reverse weight field or field expression
        :return: self
        :rtype: WeightFieldInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.WeightFieldInfo.set_weight_name": """
        Set the name of the weight field information

        :param str value: the name of the weight field information
        :return: self
        :rtype: WeightFieldInfo
        """,

    "iobjectspy._jsuperpy.analyst.na.WeightFieldInfo.tf_weight_field": """str: reverse weight field or field expression """,

    "iobjectspy._jsuperpy.analyst.na.WeightFieldInfo.weight_name": """str: the name of the weight field information""",

    "iobjectspy._jsuperpy.analyst.na.append_to_network_dataset": """
    To add data to an existing network dataset, you can add points, lines or networks.
    Network datasets are generally constructed from line data (and point data). Once the data used to construct the network changes, the original network will become outdated. If the network is not updated in time, the correctness of the 
    analysis results may be affected. By adding new data to the original network, a newer network can be obtained without rebuilding the network. As shown in the figure below, several roads (red lines) have been newly built in a certain area. 
    These roads are abstracted as line data and added to the network constructed before the expansion, thereby updating the road network.

    .. image:: ../image/AppendToNetwork.png

    This method supports adding points, lines, and network dataset to an existing network, and can add multiple dataset of the same or different types at the same time, for example, adding one point data and two line data at the same time.
    Note that if the data to be added has multiple types, the system will add the network first, then the line, and finally the point. The methods and rules for adding points, lines and networks to the network are introduced below.

    * To add points to an existing network:

      After a point is added to an existing network, it will become a new node in the network. When adding points to an existing network, you need to pay attention to the following points:

      1. The point to be added must be on the edge of the existing network. After appending, add a new node at that point on the edge, and the edge will be automatically broken into two edges at the new node, as shown in the following figure, point a and point d. If the point to be added is not on the network, that is, it is not on the edge, nor does it overlap the node, it will be ignored and will not be added to the network, because the isolated node has no geological significance in the network. This is the case at point b in the figure below.
      2. If the point to be added overlaps the node of the existing network, merge the point to be added with the overlapping node, as shown in point c in the figure below.

      .. image:: ../image/AppendPointsToNetwork.png

    * Add line to existing network

      After the line is added to the existing network, it will become a new edge in the network, and the end of the line and the intersection with other lines (or edges) will be interrupted and new nodes will be added. When adding points to an existing network, you need to pay attention to the following points:

      1. The line to be added cannot overlap or partially overlap with the existing network edge, otherwise it will cause errors in the added network.

    * Add another network to an existing network

      After adding a network to an existing network, the two will become one network, as shown in the figure below. Note that, as with the additional line, when adding a network to an existing network, you need to ensure that there is no overlap or partial overlap of edges between the two networks, 
      otherwise it will cause errors in the added network.

      .. image:: ../image/AppendChildNet_1.png

      When the network to be added overlaps with the network to be added, a new node will be added at the intersection to establish a new topological relationship.

      .. image:: ../image/AppendChildNet_3.png

      The connectivity of the network does not affect the addition of the network. In the following example, after adding the network to be added to the original network, the result is a network dataset containing two subnets, and the two subnets are disconnected.

      .. image:: ../image/AppendChildNet_2.png

    * Note:

      1. This method will directly modify the added network dataset, and will not generate a new network dataset.
      2. The point, line or network dataset to be added must have the same coordinate system as the network dataset to be added.
      3. In the point, line or network dataset to be appended, if there are attribute fields that are the same as the network dataset (name and type must be the same), then these attribute values will be automatically retained in the appended network dataset; 
      if there are no identical Fields are not reserved. Among them, the attributes of the point dataset and the node dataset of the network dataset are retained in the node attribute table of the added network; the attributes of the line dataset are retained 
      in the edge attribute table of the added network.

    :param network_dataset: the added network dataset
    :type network_dataset: DatasetVector or str
    :param appended_datasets: The specified data to be appended can be point, line or network datasets.
    :type appended_datasets: list[DatasetVector]
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: Whether the append is successful. If successful, return True, otherwise return False.
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.na.build_facility_network_directions": """
    Create a flow direction for the network dataset based on the location of the source and sink in the specified network dataset. The network dataset that flows to the future can be used for various facility network analysis.
    A facility network is a network with directions. Therefore, after creating a network dataset, a flow direction must be created for it before it can be used for various facility network path analysis, connectivity analysis, upstream and downstream tracking, etc.

    Flow direction refers to the direction of resource flow in the network. The flow direction in the network is determined by the source and sink: resources always flow from the source to the sink. This method creates a flow direction for the network dataset through the given source and sink, 
    as well as the facility network analysis parameter settings. After the flow direction is successfully created, two aspects of information will be written in the network dataset: flow direction and node type.

    * Flow direction

      The flow direction information will be written into the flow direction field of the subline dataset of the network dataset, and the field will be created if it does not exist.

      There are four values in the flow direction field: 0,1,2,3, the meaning of which is shown in the figure below. Take line AB as an example:

      0 means the flow direction is the same as the digitization direction. The digitization direction of the line segment AB is A-->B, and A is the source point, so the flow direction of AB is from A to B, which is the same as its digitization direction.

      1 means the flow direction is opposite to the digitization direction. The digitization direction of the line segment AB is A-->B, and A is the meeting point, so the flow direction of AB is from B to A, which is the opposite of its digitization direction.

      2 stands for invalid direction, also called uncertain flow direction. Both A and B are source points, so resources can flow from A to B, and from B to A, which constitutes an invalid flow.

      3 stands for disconnected edges, also called uninitialized direction. The line segment AB is not connected to the node where the source and sink are located, it is called a disconnected edge.

      .. image:: ../image/BuildFacilityNetworkDirections_1.png

    * Node type

      After establishing the flow direction, the system will also write the node type information into the node type field of the sub-point dataset of the specified network dataset. Node types are divided into source, sink, and ordinary nodes.
      The following table lists the value and meaning of the node type field:

      .. image:: ../image/BuildFacilityNetworkDirections_2.png


    :param network_dataset: The network dataset of the flow direction to be created. The network dataset must be modifiable.
    :type network_dataset: DatasetVector or str
    :param source_ids: The network node ID array corresponding to the source. Both sources and sinks are used to establish the flow of network dataset. The flow direction of the network dataset is determined by the location of the source and sink.
    :type source_ids: list[int] or tuple[int]
    :param sink_ids: sink ID array. The ID array of the network node corresponding to the sink. Both sources and sinks are used to establish the flow of network dataset. The flow direction of the network dataset is determined by the location of the source and sink.
    :type sink_ids: list[int] or tuple[int]
    :param str ft_weight_field: forward weight field or field expression
    :param str tf_weight_field: reverse weight field or field expression
    :param str direction_field: flow direction field, used to save the flow direction information of the network dataset
    :param str node_type_field: The name of the node type field. The node type is divided into source node, intersection node, and ordinary node. This field is a field in the network node dataset. If it does not exist, create the field.
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: return true if created successfully, otherwise false
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.na.build_facility_network_hierarchies": """
    Create a level for the network dataset with flow direction, and write the level information of the network dataset in the specified level field.

    To establish a hierarchy for a network dataset, first, the network dataset must have established a flow direction, that is, the network dataset operated by the method for establishing a hierarchy must have flow direction information.

    The grade field is recorded as an integer in the form of an integer. The value starts from 1, and the higher the grade, the smaller the value. For example, after the river is graded, the grade of the first-level river is recorded as 1, 
    the grade of the second-level river is recorded as 2, and so on. Note that a value of 0 means that the level cannot be determined, usually because the edge is not connected.

    :param network_dataset: The network dataset of the level to be created. The network dataset must be modifiable.
    :type network_dataset: DatasetVector or str
    :param source_ids: source ID array
    :type source_ids: list[int]
    :param sink_ids: sink ID array
    :type sink_ids: list[int]
    :param str direction_field: flow direction field
    :param bool is_loop_valid: Specify whether the loop is valid. When the parameter is true, the loop is valid; when the parameter is false, the loop is invalid.
    :param str ft_weight_field: forward weight field or field expression
    :param str tf_weight_field: reverse weight field or field expression
    :param hierarchy_field: The given hierarchy field name, used to store hierarchy information.
    :type hierarchy_field: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: return true if created successfully, otherwise false
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.na.build_network_dataset": """
    The network dataset is the data basis for network analysis. The network dataset consists of two sub-dataset (a line dataset and a point dataset), which store the edges and nodes of the network model respectively.
    It also describes the spatial topological relationship between edges and edges, edges and nodes, and nodes and nodes.

    This method provides a network dataset based on a single line dataset or multiple line and point datasets. If the user's dataset already has the correct network relationship, you can directly use :py:meth:`build_network_dataset_known_relation` 
    to quickly build a network dataset.

    For the constructed network dataset, you can use :py:meth:`validate_network_dataset` to check whether the network topology is correct.

    :param lines: The line dataset used to construct the network dataset, there must be at least one line dataset.
    :type lines: DatasetVector or list[DatasetVector]
    :param points: The point dataset used to construct the network dataset.
    :type points: DatasetVector or list[DatasetVector]
    :param split_mode: break mode, default is no break
    :type split_mode: NetworkSplitMode
    :param float tolerance: node tolerance
    :param line_saved_fields: Fields that need to be reserved in the line dataset
    :type line_saved_fields: str or list[str]
    :param point_saved_fields: The fields that need to be reserved in the point dataset.
    :type point_saved_fields: str or list[str]
    :param out_data: The datasource object that holds the result network dataset
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result network dataset
    :rtype: DatasetVector
    """,

    "iobjectspy._jsuperpy.analyst.na.build_network_dataset_known_relation": """
    According to the point, line data and the existing fields that express the topological relationship between edges and nodes, a network dataset is constructed.
    When the line and point objects in the existing line and point dataset correspond to the edges and nodes of the network to be constructed, and have information describing the spatial topological relationship between the two, that is, the line dataset contains the edge ID and the edge starting point. 
    Start node ID and end node ID fields. When the point dataset contains the node ID field of the point object, this method can be used to construct a network dataset.

    After successfully constructing a network dataset using this method, the number of result objects is consistent with the number of objects in the source data, that is, a line object in the line data is written as an edge, and a point object in the point data is written as a node, 
    and retain all non-system fields of the point and line datasets to the result dataset.

    For example, for pipeline and pipe point data collected for establishing a pipe network, the pipeline and pipe points are all identified by a unique fixed code. One of the characteristics of the pipe network is that the pipe points are only located at both ends of the pipeline, 
    so the pipe points correspond to all the nodes of the pipe network to be constructed, and the pipeline corresponds to all the edges of the pipe network to be constructed, and there is no need to break at the intersection of the pipeline and the pipeline.  In the pipeline data, 
    the pipe point information at both ends of the pipeline object is recorded, that is, the start pipe point code and the end pipe point code, which means that the pipeline and pipe point data already contain the information of the spatial topological relationship between the two, 
    so it is suitable for use This method builds a network dataset.
    
    Note that the edge ID, edge start node ID, edge end node ID, and node ID fields of the network dataset constructed in this way are the fields specified when calling this method, not SmEdgeID, SmFNode, System fields such as SmTNode and SmNodeID. Specifically, the corresponding fields can be obtained 
    through the :py:meth:`.DatasetVector.get_field_name_by_sign` method of DatasetVector.

    :param line: the line dataset used to construct the network dataset
    :type line: str or DatasetVector
    :param point: point dataset used to construct the network dataset
    :type point: str or DatasetVector
    :param str edge_id_field: The field representing the edge ID in the specified line dataset. If it is specified as a null or empty string, or the specified field does not exist, SMID is automatically used as the edge ID.
                                Only 16-bit integer and 32-bit integer fields are supported.
    :param str from_node_id_field: The field representing the starting node ID of the edge in the specified line dataset. Only 16-bit integer and 32-bit integer fields are supported.
    :param str to_node_id_field: The field in the specified line dataset that represents the end node ID of the edge. Only 16-bit integer and 32-bit integer fields are supported.
    :param str node_id_field: The field representing the node ID in the specified point dataset. Only 16-bit integer and 32-bit integer fields are supported.
    :param out_data: The datasource object that holds the result network dataset
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result network dataset
    :rtype: DatasetVector
    """,

    "iobjectspy._jsuperpy.analyst.na.compile_ssc_data": """
    Compile network data into SSC file containing shortcut information

    :param SSCCompilerParameter parameter: SSC file compilation parameter class.
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: Return True for success, False for failure
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.na.fix_ring_edge_network_errors": """
    Fix the topological error that the first and last nodes of the edge segment are equal in the topology error of the network dataset. For the topology error check of the network dataset, refer to: py:meth:`.validate_network_dataset` for details.

    For edges with the same beginning and end, the center point of the edge is automatically taken to break the edge into two.

    :param network_dataset: the network dataset to be processed
    :type network_dataset: str or DatasetVector
    :param error_ids: SmIDs of edges that are equal to each other.
    :type error_ids: list[int] or tuple[int] or str
    :param str edge_id_field: The edge ID field of the network dataset. If it is empty, the edge ID field stored in the network dataset will be used by default.
    :param str f_node_id_field: The starting node ID field of the network dataset. If it is empty, the starting node ID field stored in the network dataset will be used by default.
    :param str t_node_id_field: The end node ID field of the network dataset. If it is empty, the end node ID field stored in the network dataset will be used by default.
    :param str node_id_field: The node ID field of the network dataset. If it is empty, the node ID field stored in the network dataset will be used by default.
    :return: Return True for success, False for failure
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.na.split_track": """
    The trajectory is divided, and the trajectory is divided into segments according to the time interval.

    .. image:: ../image/splitTrack.png

    :param track_points: track point string
    :type track_points: list[TrackPoint] or tuple[TrackPoint]
    :param float split_time_milliseconds: Time interval value, in milliseconds. When the time interval between two consecutive points is greater than the specified time interval value, 
                                          the trajectory will be divided from the two points
    :return: result track segment
    :rtype: list[list[TrackPoint]]
    """,

    "iobjectspy._jsuperpy.analyst.na.validate_network_dataset": """
    This method is used to check the network dataset and give error information, so that users can modify the data according to the error information, so as to avoid network analysis errors caused by data errors.

    The error types of the results of checking the network datasets are shown in the following table:

    .. image:: ../image/TransportationNetwork_Check.png


    :param network_dataset: the network dataset or 3D network dataset to be checked
    :type network_dataset: DatasetVector or str
    :param str edge_id_field: The edge ID field of the network dataset. If it is empty, the edge ID field stored in the network dataset will be used by default.
    :param str f_node_id_field: The starting node ID field of the network dataset. If it is empty, the starting node ID field stored in the network dataset will be used by default.
    :param str t_node_id_field: The end node ID field of the network dataset. If it is empty, the end node ID field stored in the network dataset will be used by default.
    :param str node_id_field: The node ID field of the network dataset. If it is empty, the node ID field stored in the network dataset will be used by default.
    :return: Error result information of the network dataset.
    :rtype: NetworkDatasetErrors
    """,

    "iobjectspy._jsuperpy.analyst.sa": """Spatial Analysis Module""",

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomata": """
    Cellular automata based on artificial neural network.
    """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomata.ann_cellular_automata": """
        Cellular automata based on artificial neural network.

        :param parameter: Cellular automata parameters based on artificial neural network.
        :type parameter: ANNCellularAutomataParameter
        :param out_data: The datasource of the output dataset.
        :type out_data: Datasource or DatasourceConnectionInfo or str
        :param str out_dataset_name: The name of the output dataset.
        :param progress_func: progress information processing function, refer to: py:class:`.StepEvent`
        :type progress_func: function
        :param flush_func: Cellular automata flushing information processing function, refer to: py:class:`.CellularAutomataFlushedEvent`
        :type flush_func: function
        :return: The result of cellular automata based on artificial neural network, including land type (if any), accuracy (if any), and result raster dataset.
        :rtype: ANNCellularAutomataResult
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomata.ann_train": """
        Artificial neural network training.

        :param float error_rate: artificial neural network training termination condition, expected error value.
        :param int max_times: artificial neural network training termination condition, the maximum number of iterations.
        :return: artificial neural network training result
        :rtype: ANNTrainResult
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomata.initialize_ann": """
        Initialize cellular automata based on artificial neural network

        :param train_start_cell_grid: training starting grid dataset
        :type train_start_cell_grid: DatasetGrid or str
        :param train_end_cell_grid: training end grid dataset
        :type train_end_cell_grid: DatasetGrid or str
        :param ann_train_values:
        :type ann_train_values: list[int] or tuple[int]
        :param spatial_variable_grids: spatial variable grid dataset
        :type spatial_variable_grids: list[DatasetGrid] or list[str]
        :param ann_parameter: artificial neural network training parameter settings.
        :type ann_parameter: ANNParameter
        :return: Whether the initialization is successful
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter": """
    Cellular automata parameter setting based on artificial neural network.
    """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.alpha": """int: diffusion parameter""",

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.cellular_automata_parameter": """CellularAutomataParameter: Cellular AutomataParameter""",

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.conversion_class_ids": """list[int]: The classification ID (ie raster value) array of the cellular automata conversion rule """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.conversion_rules": """list[list[bool]]: Cellular Automata Conversion Rules""",

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.end_cell_grid": """DatasetGrid: end raster dataset""",

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.is_check_result": """bool: Whether to check the result or not""",

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.set_alpha": """
        Set diffusion parameters

        :param int value: Diffusion parameter. Generally 1-10.
        :return: self
        :rtype: ANNCellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.set_cellular_automata_parameter": """
        Set the parameters of cellular automata

        :param value: parameter of cellular automaton
        :type value: CellularAutomataParameter
        :return: self
        :rtype: ANNCellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.set_check_result": """
        Set whether to detect the result

        :param bool value: Whether the test result
        :return: self
        :rtype: ANNCellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.set_conversion_class_ids": """
        Set the classification ID (ie raster value) array of the cellular automata conversion rule

        :param value: The classification ID (ie raster value) array of the cellular automata conversion rule
        :type value: list[int] or tuple[int]
        :return: self
        :rtype: ANNCellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.set_conversion_rules": """
        Set cellular automata conversion rules.

        :param value: Set cellular automata conversion rules
        :type value: list[list[bool]]
        :return: self
        :rtype: ANNCellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.set_end_cell_grid": """
        Set the ending raster dataset. Must be set when :py:attr:`.is_check_result` is True

        :param value: Terminate the raster dataset
        :type value: DatasetGrid or str
        :return: self
        :rtype: ANNCellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.set_threshold": """
        Set the threshold of cell transition probability

        :param float value: Cell transition probability threshold
        :return: self
        :rtype: ANNCellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataParameter.threshold": """float: cell transition probability threshold""",

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataResult": """Cellular automata result based on artificial neural network""",

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataResult.accuracies": """list[float]: correct rate """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataResult.convert_values": """list[float]: Conversion value array, which is the raster type of the conversion rule """,

    "iobjectspy._jsuperpy.analyst.sa.ANNCellularAutomataResult.result_dataset": """DatasetGrid: Cellular Automata raster result dataset""",

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter": """
    Artificial neural network parameter settings.
    """,

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.__init__": """
        Initialization object

        :param bool is_custom_neighborhood: Whether to customize the neighborhood range
        :param int neighborhood_number: neighborhood range
        :param list[list[bool]] custom_neighborhoods: custom neighborhood range.
        :param float learning_rate: learning rate
        :param int sample_count: number of samples
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.custom_neighborhoods": """list[list[bool]]: custom field range """,

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.is_custom_neighborhood": """bool: Whether to customize the neighborhood range""",

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.learning_rate": """float: learning rate""",

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.neighborhood_number": """int: neighborhood range """,

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.sample_count": """int: number of samples""",

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.set_custom_neighborhood": """
        Set whether to customize the neighborhood range

        :param bool value: Whether to customize the neighborhood range
        :return: self
        :rtype: ANNParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.set_custom_neighborhoods": """
        Set custom realm scope

        :param value: custom field range
        :type value: list[list[bool]]
        :return: self
        :rtype: ANNParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.set_learning_rate": """
        Set the learning rate

        :param float value: learning rate
        :return: self
        :rtype: ANNParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.set_neighborhood_number": """
        Set neighborhood range

        :param int value: neighborhood range
        :return: self
        :rtype: ANNParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNParameter.set_sample_count": """
        Set the number of samples

        :param int value: number of samples
        :return: self
        :rtype: ANNParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.ANNTrainResult": """
    Artificial Neural Network (ANN) training results
    """,

    "iobjectspy._jsuperpy.analyst.sa.ANNTrainResult.accuracy": """float: training accuracy rate""",

    "iobjectspy._jsuperpy.analyst.sa.ANNTrainResult.convert_values": """dict[int, error]: training iteration result, key is the number of iterations, value is the error rate """,

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult": """
    Raster basic statistical analysis result class

    """,

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult.first_quartile": """float: the first quartile calculated by the basic statistical analysis of the grid""",

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult.kurtosis": """float: kurtosis calculated by basic statistical analysis of the raster""",

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult.max": """float: the maximum value calculated by basic statistical analysis of the grid""",

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult.mean": """float: the minimum value calculated by the basic statistical analysis of the grid""",

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult.median": """float: the median calculated by basic statistical analysis of the grid""",

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult.min": """float: """,

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult.skewness": """float: the skewness calculated by basic statistical analysis of the raster""",

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult.std": """float: the mean square deviation (standard deviation) calculated by basic statistical analysis of the raster""",

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult.third_quartile": """float: the third quartile calculated by the basic statistical analysis of the grid""",

    "iobjectspy._jsuperpy.analyst.sa.BasicStatisticsAnalystResult.to_dict": """
        Output as dict object

        :rtype: dict
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataFlushedEvent": """
    Cellular automata refreshes the transaction class.
    """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataFlushedEvent.__init__": """
        :param str flush_file_path: Tif file path for flushing
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataFlushedEvent.flush_file_path": """str: the path of the tif file used for refreshing """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataFlushedListener": """
    The listener for cellular automata to refresh information is called internally, but not external users.
    """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataFlushedListener.CAFlushed": """""",

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataFlushedListener.__init__": """

        :param progress_fun: Cellular automata refresh information processing function
        :type progress_fun: function
        :param name: uniquely identifying name.
        :type name: str
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter": """
    Cellular automata parameter setting class. Including setting the starting grid and spatial variable grid data, as well as the display and output configuration of the simulation process (simulation result iterative refresh, simulation result output), etc.
    """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.cell_grid": """DatasetGrid: starting data grid""",

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.flush_file_path": """str: file path for interface refresh """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.flush_frequency": """int: refresh frequency of iteration results""",

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.is_save": """bool: whether to save the intermediate iteration result""",

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.iterations": """int: number of iterations""",

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.output_dataset_name": """str: """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.output_datasource": """Datasource: datasource for saving intermediate iteration results.""",

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.save_frequency": """int: Frequency of saving intermediate iteration results""",

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.set_cell_grid": """
        Set the starting data grid.

        :param cell_grid: starting data grid
        :type cell_grid: DatasetGrid or str
        :return: self
        :rtype: CellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.set_flush_file_path": """
        Set the file path for interface refresh.The suffix name must be'.tif'

        :param str value: file path for interface refresh
        :return: self
        :rtype: CellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.set_flush_frequency": """
        Set the refresh frequency of iteration results. That is, the output information and graphs are refreshed every few iterations.

        :param int flush_frequency: Iteration result refresh frequency
        :return: self
        :rtype: CellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.set_iterations": """
        Set the number of iterations

        :param int value: number of iterations
        :return: self
        :rtype: CellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.set_output_dataset_name": """
        Set the name of the dataset to save the intermediate iteration results

        :param str dataset_name: the name of the dataset to save the intermediate iteration results
        :return: self
        :rtype: CellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.set_output_datasource": """
        Set the datasource for saving intermediate iteration results.

        :param datasource: The datasource for saving intermediate iteration results.
        :type datasource: Datasource or str or DatasourceConnectionInfo
        :return: self
        :rtype: CellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.set_save": """
        Set whether to save intermediate iteration results. That is, whether to output the result during the simulation.

        :param bool save: whether to save intermediate iteration results
        :return: self
        :rtype: CellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.set_save_frequency": """
        Set the saving frequency of intermediate iteration results. That is, the result is output every number of iterations.

        :param int save_frequency: save frequency of intermediate iteration results
        :return: self
        :rtype: CellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.set_simulation_count": """
        Set the number of conversions. The number of analog conversions is a parameter required for the simulation process, and refers to the number of cities added between two different time periods.

        :param int simulation_count: conversion number
        :return: self
        :rtype: CellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.set_spatial_variable_grids": """
        Set the grid array of spatial variable data.

        :param spatial_variable_grids: grid array of spatial variable data
        :type spatial_variable_grids: DatasetGrid or list[DatasetGrid] or tuple[DatasetGrid]
        :return: self
        :rtype: CellularAutomataParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.simulation_count": """int: conversion number """,

    "iobjectspy._jsuperpy.analyst.sa.CellularAutomataParameter.spatial_variable_grids": """list[DatasetGrid]: spatial variable data grid array""",

    "iobjectspy._jsuperpy.analyst.sa.CutFillResult": """
    Fill and excavation result information class. This object is used to obtain the results of filling and digging calculations on a raster dataset, such as the area of filling and digging, the volume of filling and digging, etc.

    Explanation of the area and volume unit of the result of filling and cutting:

    The area unit of the filling and excavation is square meters, and the unit of the volume is the unit of square meters multiplied by the elevation (that is, the grid value for filling and excavation). But it should be noted that if the grid for filling and cutting calculation is a geographic coordinate system, the area value is a value approximately converted to square meters.
    """,

    "iobjectspy._jsuperpy.analyst.sa.CutFillResult.__init__": """
        Internal constructor, users do not need to use

        :param float cut_area: The excavated area as a result of the fill and cut analysis. The unit is square meter. When the grid for filling and cutting is a geographic coordinate system, the value is approximate conversion
        :param float cut_volume: The excavation volume of the fill and cut analysis results. The unit is square meters multiplied by the raster value (ie elevation value) of the fill and cut grid
        :param float fill_area: Fill area with the result of fill and cut analysis. The unit is square meter. When the grid for filling and cutting is a geographic coordinate system, the value is approximate conversion.
        :param float fill_volume: Fill volume with the analysis result of fill and cut. The unit is the square meter multiplied by the grid value (ie elevation value) of the fill and cut grid.
        :param float remainder_area: The area that has not been filled and cut in the fill and cut analysis. The unit is square meter. When the grid for filling and cutting is a geographic coordinate system, the value is approximate conversion.
        :param cut_fill_grid_result: The result dataset of fill and cut analysis. Cell value greater than 0 means the depth to be digged, and less than 0 means the depth to be filled.
        :type cut_fill_grid_result: DatasetGrid or str
        """,

    "iobjectspy._jsuperpy.analyst.sa.GridHistogram": """
    Create a histogram of the given raster dataset.

    A histogram, also known as a histogram, is a series of rectangular blocks with different heights to represent the distribution of a piece of data. Generally, the horizontal axis represents the category, and the vertical axis represents the distribution.

    The horizontal axis of the grid histogram represents the grouping of grid values. The grid values will be divided into these N (100 by default) groups, that is, each group corresponds to a grid value range; the vertical axis represents the frequency, that is
    the number of cells whose grid value is within the value range of each group.

    The figure below is a schematic diagram of the grid histogram. The minimum and maximum values of the raster data are 0 and 100 respectively, and the number of groups is 10, and the frequency of each group is obtained, and the following histogram is drawn. 
    The frequency of the group is marked above the rectangular block. For example, the grid value range of the sixth group is [50,60), and there are 3 cells in the raster data with values in this range, so the frequency of this group is 3. .

    .. image:: ../image/BuildHistogram.png

    Note: The value range of the last group of the histogram group is front closed and then closed, and the rest are front closed and then opened.

    After obtaining the GridHistogram object of the raster dataset through this method, the frequency of each group can be returned through the get_frequencies method of the object, and the group number of the grid histogram can be re-specified through 
    the get_group_count method, and then passed The get_frequencies method returns the frequency of each group.

    The figure below is an example of creating a raster histogram. In this example, the minimum grid value is 250, the maximum grid value is 1243, and the number of groups is 500. Get the frequency of each group and draw the grid histogram as shown on the right. 
    From the raster histogram on the right, you can intuitively understand the distribution of raster values in the raster dataset.

    .. image:: ../image/BuildHistogram_1.png

    """,

    "iobjectspy._jsuperpy.analyst.sa.GridHistogram.__init__": """
        Construct a raster histogram object

        :param source_data: the specified raster dataset
        :type source_data: DatasetGrid or str
        :param group_count: The number of groups of the specified histogram. Must be greater than 0.
        :type group_count: int
        :param function_type: FunctionType
        :type function_type: The specified transformation function type.
        :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
        :type progress: function
        """,

    "iobjectspy._jsuperpy.analyst.sa.GridHistogram.get_frequencies": """
        Return the frequency of each group in the grid histogram. Each group of the histogram corresponds to a grid value range, and the number of all cells within this range is the frequency of the group.

        :return: Return the frequency of each group of the raster histogram.
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.analyst.sa.GridHistogram.get_group_count": """
        Return the number of groups on the horizontal axis of the grid histogram.

        :return: Return the number of groups on the horizontal axis of the grid histogram.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.analyst.sa.GridHistogram.get_segments": """
        Return the interval information of each group of the grid histogram.

        :return: The interval information of each group of the grid histogram.
        :rtype: list[GridHistogram.HistogramSegmentInfo]
        """,

    "iobjectspy._jsuperpy.analyst.sa.GridHistogram.set_group_count": """
        Set the number of groups on the horizontal axis of the grid histogram.

        :param int count: The number of groups on the horizontal axis of the grid histogram. Must be greater than 0.
        :rtype: self
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter": """
    Point density difference (Density) interpolation parameter class. Point density interpolation method, used to express the density distribution of sampling points.
    The resolution setting of the result raster of the point density interpolation needs to be combined with the size of the point dataset. Generally, the row and column value of the result raster (that is, the result raster dataset range divided by the resolution) can be better reflected within 500 Out density trend. 
    Because point density interpolation only supports fixed-length search mode temporarily, the search_radius value setting is more important. This value needs to be set by the user according to the data distribution of the points to be interpolated and the range of the point dataset.
    """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.__init__": """
        Construct a point density difference interpolation parameter class object

        :param float resolution: the resolution used during interpolation
        :param float search_radius: Find the search radius of the points involved in the operation
        :param int expected_count: The number of points expected to participate in the interpolation operation
        :param Rectangle bounds: The range of interpolation analysis, used to determine the range of running results
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.bounds": """Rectangle: The range of interpolation analysis, used to determine the range of running results""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.expected_count": """int: Return the number of points expected to participate in the interpolation operation, indicating the minimum number of samples expected to participate in the operation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.resolution": """float: the resolution used during interpolation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.search_mode": """SearchMode: During interpolation operation, the way to find points involved in the operation, only supports fixed-length search (KDTREE_FIXED_RADIUS) """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.search_radius": """float: Find the search radius of the points involved in the operation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.set_bounds": """
        Set the range of interpolation analysis to determine the range of running results

        :param Rectangle value: The range of interpolation analysis, used to determine the range of running results
        :return: self
        :rtype: InterpolationParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.set_expected_count": """
        Set the number of points expected to participate in the interpolation operation

        :param int value: Indicates the minimum number of samples expected to participate in the operation
        :return: self
        :rtype: InterpolationDensityParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.set_resolution": """
        Set the resolution used in interpolation operation.

        :param float value: the resolution used during interpolation
        :return: self
        :rtype: InterpolationParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.set_search_radius": """
        Set the search radius to find the points involved in the operation. The unit is the same as the unit of the point dataset (or the dataset to which the record set belongs) used for interpolation. The search radius determines the search range of the points involved in the calculation. 
        When calculating the unknown value of a certain position, the position will be the center of the circle, and the search_radius will be the radius. The sampling points within this range will participate in the calculation, that is, the position of the The predicted value is determined by the value of the sampling points in the range.

        :param float value: Find the search radius of the points involved in the operation
        :return: self
        :rtype: InterpolationDensityParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationDensityParameter.type": """InterpolationAlgorithmType: The type of algorithm supported by the interpolation branch""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter": """
    Inverse Distance Weighted parameter class,
    """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.__init__": """
        Construct IDW interpolation parameter class.

        :param float resolution: the resolution used during interpolation
        :param search_mode: search mode, QUADTREE is not supported
        :type search_mode: SearchMode or str
        :param float search_radius: Find the search radius of the points involved in the operation
        :param int expected_count: The number of points expected to participate in the interpolation operation
        :param int power: The power of the distance weight calculation. The lower the power value, the smoother the interpolation result. The higher the power value, the more detailed the details of the interpolation result. This parameter should be a value greater than 0. If this parameter is not specified, the method will set it to 1 by default
        :param Rectangle bounds: The range of interpolation analysis, used to determine the range of running results
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.bounds": """Rectangle: The range of interpolation analysis, used to determine the range of running results""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.expected_count": """int: The number of points expected to participate in the interpolation operation. If the search_mode is set to KDTREE_FIXED_RADIUS, the number of points involved in the interpolation operation is also specified. When the number of points in the search range is less than the specified The number of points is assigned a null value. """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.power": """int: the power of distance weight calculation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.resolution": """float: the resolution used during interpolation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.search_mode": """SearchMode: Find the way to participate in the operation during interpolation operation. QUADTREE is not supported""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.search_radius": """float: Find the search radius of the points involved in the operation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.set_bounds": """
        Set the range of interpolation analysis to determine the range of running results

        :param Rectangle value: The range of interpolation analysis, used to determine the range of running results
        :return: self
        :rtype: InterpolationParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.set_expected_count": """
        Set the number of points expected to participate in the interpolation operation. If search_mode is set to KDTREE_FIXED_RADIUS, and the number of points participating in the interpolation operation is specified at the same time, when the number of points in the search range is less than the specified number of points, a null value is assigned.

        :param int value: Indicates the minimum number of samples expected to participate in the operation
        :return: self
        :rtype: InterpolationIDWParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.set_power": """
        Set the power of distance weight calculation. The lower the power value, the smoother the interpolation result, and the higher the power value, the more detailed the interpolation result. This parameter should be a value greater than 0. 
        If this parameter is not specified, the method will set it to 1 by default.

        :param int value: the power of distance weight calculation
        :return: self
        :rtype: InterpolationIDWParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.set_resolution": """
        Set the resolution used in interpolation operation.

        :param float value: the resolution used during interpolation
        :return: self
        :rtype: InterpolationParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.set_search_mode": """
        Set the way to find the points involved in the interpolation operation. Does not support QUADTREE

        :param value: In interpolation operation, find the way to participate in the operation
        :type value: SearchMode or str
        :return: self
        :rtype: InterpolationIDWParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.set_search_radius": """
       Set the search radius to find the points involved in the operation. The unit is the same as the unit of the point dataset (or the dataset to which the record set belongs) used for interpolation. The search radius determines the search range of the points involved in the calculation. 
       When calculating the unknown value of a certain position, the position will be the center of the circle, and the search_radius will be the radius. The sampling points within this range will participate in the calculation, that is, the position of the The predicted value is determined by 
       the value of the sampling points in the range.

        If you set search_mode to KDTREE_FIXED_COUNT and specify the range of points involved in the search, when the number of points in the search range is less than the specified number of points, it will be assigned a null value. When the number of points in the search range is greater than 
        the specified number of points, the nearest to the interpolation point will be returned The specified number of points are interpolated.

        :param float value: Find the search radius of the points involved in the operation
        :return: self
        :rtype: InterpolationIDWParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationIDWParameter.type": """InterpolationAlgorithmType: The type of algorithm supported by the interpolation branch""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter": """
    Kriging (Kriging) interpolation method parameters.

    The Kriging method is a spatial data interpolation processing method in geostatistics. The main purpose is to use the variance of each data point to deduce the weight relationship between an unknown point and each known point, and then use the variance of each data point to calculate the weight relationship between an unknown point and each known point. 
    The value of the data point and its weight relationship with the unknown point infer the value of the unknown point. The biggest feature of the Kriging method is not only to provide a predicted value with a minimum estimation error, but also to clearly indicate the magnitude of the error value. Generally speaking, many geological parameters, such as topography itself, 
    have a continuous nature, so any two points within a short distance must have a spatial relationship. Conversely, if two points on an irregular surface are far apart, they can be regarded as stastically indepedent in a statistical sense. This spatial continuity that changes with distance can be used by semivariogram ) To show. Therefore, if you want to deduce the value of 
    an unknown point from the known scattered points, you can use the semivariogram to deduce the spatial relationship between the known points and the points to be evaluated. Then the semivariogram is derived from this space parameter, and the weight relationship between the unknown point and the known point can be derived from the semivariogram between each data point, and then 
    the value of the unknown point can be derived. The advantage of Kriging's method is based on spatial statistics as its solid theoretical foundation. The physical meaning is clear; it can not only estimate the spatial variation distribution of the measured parameters, but also estimate the variance distribution of the parameters. The disadvantage of the Kriging method is that 
    the calculation steps are cumbersome, the calculation amount is large, and the variogram sometimes needs to be selected artificially based on experience.

    The Kriging interpolation method can use two methods to obtain the sampling points involved in the interpolation, and then obtain the predicted value of the corresponding location point. One is to obtain all the sampling points in the range within a certain range around the location of the predicted value to be calculated. The predicted value of the location point is obtained through 
    a specific interpolation calculation formula; the other is to obtain a certain number of sampling points around the location where the predicted value is to be calculated, and the predicted value of the location point is obtained through a specific interpolation calculation formula.

    The Kriging interpolation process is a multi-step process, including:
        -Create a variogram and covariance function to estimate the value of statistical correlation (also known as spatial autocorrelation);
        -Predict the unknown value of the position to be calculated.

    Semivariogram and semivariogram:
        -Calculate the semivariogram value of any two points that are h units apart in all sampling points, then the distance h between any two points is generally unique. The distance of all point pairs and the corresponding semivariogram value are quickly displayed in h In the coordinate space with the X coordinate axis and the Y coordinate axis as the semivariable function value, 
        the semivariogram is obtained. The smaller the distance, the smaller the semivariogram, and as the distance increases, the spatial dependence between any two points becomes smaller, making the semivariogram value tend to a stable value. This stable value is called the sill value (Sill); and the minimum h value when the sill value is reached is called the autocorrelation threshold (Range).
        
    Nugget effect:
        -When the distance between points is 0 (for example, step size=0), the semivariable function value is 0. However, within an infinitely small distance, the semivariable function usually shows a nugget effect, which is a value greater than zero. If the intercept of the semivariable function on week Y is 2, 
        the nugget effect value is 2.
        -The nugget effect is a measurement error, or a spatial variation at a small distance smaller than the sampling step, or both. The measurement error is mainly caused by the inherent error of the observation instrument. The spatial variation range of natural phenomena is large (can be on a small scale or on a large scale). 
        Changes on scales smaller than the step size are represented as part of the nugget.

    Obtaining the semivariogram is one of the key steps for spatial interpolation prediction. One of the main applications of the Kriging method is to predict the attribute value of non-sampling points. The semivariogram provides the spatial autocorrelation information of the sampling points. According to the semivariogram, Choose a suitable semi-variation model, 
    that is, a curve model that fits the semi-variation graph.
    
    Different models will affect the obtained prediction results. If the curve of the semivariogram close to the origin is steeper, the closer area will have a greater impact on the predicted value. Therefore, the output surface will be less smooth.

    The semi-variable function models supported by SuperMap include exponential, spherical and Gaussian models. See the VariogramMode class for details

    """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.__init__": """
        Construct the Kriging interpolation parameter object.

        :param float resolution: the resolution used during interpolation
        :param krighing_type: The algorithm type of interpolation analysis. Supports three settings: KRIGING, SimpleKRIGING, UniversalKRIGING, and KRIGING is used by default.
        :type krighing_type: InterpolationAlgorithmType or str
        :param search_mode: Search mode.
        :type search_mode: SearchMode or str
        :param float search_radius: Find the search radius of the points involved in the operation. The unit is the same as the unit of the point dataset (or the dataset to which the record set belongs) used for interpolation. The search radius determines the search range of the points involved in the calculation. 
                                    When calculating the unknown value of a location, the location is the center of the circle, and search_radius is the radius. The sampling points within this range will participate in the calculation, that is, the prediction of the location The value is determined by the value of the 
                                    sampling point in the range.
        :param int expected_count: The number of points expected to participate in the interpolation operation. When the search method is variable length search, it indicates the maximum number of points expected to participate in the operation.
        :param int max_point_count_in_node: The maximum number of points to find in a single block. When using QuadTree to find interpolation points, you can set the maximum number of points in a block.
        :param int max_point_count_for_interpolation: Set the maximum number of points involved in interpolation during block search. Note that this value must be greater than zero. When using QuadTree to find interpolation points, you can set the maximum number of points involved in interpolation
        :param variogram: Kriging (Kriging) interpolation type of semi-variable function. The default value is VariogramMode.SPHERICAL
        :type variogram: VariogramMode or str
        :param float angle: Rotation angle value in Kriging algorithm
        :param float mean: The average value of the interpolation field, that is, the sum of the interpolation field values of the sampling points divided by the number of sampling points.
        :param exponent: the order of the trend surface equation in the sample data used for interpolation
        :type exponent: Exponent or str
        :param float nugget: Nugget effect value.
        :param float range_value: Autocorrelation threshold.
        :param float sill: abutment value
        :param Rectangle bounds: The range of interpolation analysis, used to determine the range of running results
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.angle": """float: Rotation angle value in Kriging algorithm""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.bounds": """Rectangle: The range of interpolation analysis, used to determine the range of running results""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.expected_count": """int: the number of points expected to participate in the interpolation operation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.exponent": """Exponent: the order of the trend surface equation in the sample data used for interpolation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.max_point_count_for_interpolation": """int: The maximum number of points involved in interpolation during block search""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.max_point_count_in_node": """int: Maximum number of points to find in a single block""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.mean": """float: The average value of the interpolation field, that is, the sum of the sampling point interpolation field values divided by the number of sampling points.""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.nugget": """float: nugget effect value.""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.range": """float: autocorrelation threshold""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.resolution": """float: the resolution used during interpolation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.search_mode": """SearchMode: During interpolation, the way to find points involved in the operation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.search_radius": """float: Find the search radius of the points involved in the operation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_angle": """
        Set the rotation angle value in the Kriging algorithm

        :param float value: Rotation angle value in Kriging algorithm
        :return: self
        :rtype: InterpolationKrigingParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_bounds": """
        Set the range of interpolation analysis to determine the range of running results

        :param Rectangle value: The range of interpolation analysis, used to determine the range of running results
        :return: self
        :rtype: InterpolationParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_expected_count": """
        Set the number of points expected to participate in the interpolation operation

        :param int value: Indicates the minimum number of samples expected to participate in the operation
        :return: self
        :rtype: InterpolationIDWParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_exponent": """
        Set the order of the trend surface equation in the sample data for interpolation

        :param value: The order of the trend surface equation in the sample point data used for interpolation
        :type value: Exponent or str
        :return: self
        :rtype: InterpolationKrigingParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_max_point_count_for_interpolation": """
        When setting block search, the maximum number of points involved in interpolation. Note that this value must be greater than zero. When using QuadTree to find interpolation points, you can set the maximum number of points involved in interpolation

        :param int value: Maximum number of points involved in interpolation during block search
        :return: self
        :rtype: InterpolationKrigingParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_max_point_count_in_node": """
        Set the maximum number of search points in a single block. When using QuadTree to find interpolation points, you can set the maximum number of points in a block.

        :param int value: The maximum number of search points in a single block. When using QuadTree to find interpolation points, you can set the maximum number of points in the block
        :return: self
        :rtype: InterpolationKrigingParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_mean": """
        Set the average value of the interpolation field, that is, the sum of the sampling point interpolation field values divided by the number of sampling points.

        :param float value: The average value of the interpolation field, that is, the sum of the sampling point interpolation field values divided by the number of sampling points.
        :return: self
        :rtype: InterpolationKrigingParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_nugget": """
        Set the value of the nugget effect.

        :param float value: Nugget effect value.
        :return: self
        :rtype: InterpolationKrigingParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_range": """
        Set autocorrelation threshold

        :param float value: autocorrelation threshold
        :return: self
        :rtype: InterpolationKrigingParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_resolution": """
        Set the resolution used in interpolation operation.

        :param float value: the resolution used during interpolation
        :return: self
        :rtype: InterpolationParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_search_mode": """
        Set the way to find the points involved in the interpolation operation

        :param value: In interpolation operation, find the way to participate in the operation
        :type value: SearchMode or str
        :return: self
        :rtype: InterpolationIDWParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_search_radius": """
        Set the search radius to find the points involved in the operation. The unit is the same as the unit of the point dataset (or the dataset to which the record set belongs) used for interpolation. The search radius determines the search range of the points involved in the calculation. 
        When calculating the unknown value of a certain position, the position will be the center of the circle, and the search_radius will be the radius. The sampling points within this range will participate in the calculation, that is, the position of the The predicted value is determined by 
        the value of the sampling points in the range.

        The search mode is set to "variable length search" (KDTREE_FIXED_COUNT), and a fixed number of sample points within the maximum search radius will be used for interpolation. The maximum search radius is 0.2 times the diagonal length of the rectangle corresponding to the area range of 
        the point dataset.
        

        :param float value: Find the search radius of the points involved in the operation
        :return: self
        :rtype: InterpolationIDWParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_sill": """
        Set abutment value

        :param float value: abutment value
        :return: self
        :rtype: InterpolationKrigingParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.set_variogram_mode": """
        Set the semi-variable function type for Kriging interpolation. The default value is VariogramMode.SPHERICAL

        :param value: Kriging (Kriging) interpolation semi-variable function type
        :type value: VariogramMode or
        :return: self
        :rtype: InterpolationKrigingParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.sill": """float: abutment value""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.type": """InterpolationAlgorithmType: The type of algorithm supported by the interpolation branch""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationKrigingParameter.variogram_mode": """VariogramMode: Kriging interpolation semi-variable function type. The default value is VariogramMode.SPHERICAL""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationParameter": """""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationParameter.bounds": """Rectangle: Interpolation analysis range, used to determine the range of running results""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationParameter.resolution": """float: the resolution used during interpolation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationParameter.set_bounds": """
        Set the range of interpolation analysis to determine the range of running results

        :param Rectangle value: The range of interpolation analysis, used to determine the range of running results
        :return: self
        :rtype: InterpolationParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationParameter.set_resolution": """
        Set the resolution used in interpolation operation.

        :param float value: the resolution used during interpolation
        :return: self
        :rtype: InterpolationParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationParameter.type": """InterpolationAlgorithmType: the type of algorithm supported by the interpolation branch""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter": """
    Radial Basis Function (RBF) interpolation parameter class
    """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.__init__": """
        Construct a parameter class object of radial basis function interpolation.

        :param float resolution: the resolution used during interpolation
        :param search_mode: Search mode.
        :type search_mode: SearchMode or str
        :param float search_radius: Find the search radius of the points involved in the operation. The unit is the same as the unit of the point  (or the dataset to which the record set belongs) used for interpolation. The search radius determines the search range of the points involved in the calculation. 
                                    When calculating the unknown value of a location, the location is the center of the circle, and search_radius is the radius. The sampling points within this range will participate in the calculation, that is, the prediction of the location The value is determined by the value of the 
                                    sampling point in the range.
        :param int expected_count: The number of points expected to participate in the interpolation operation. When the search method is variable length search, it indicates the maximum number of points expected to participate in the operation.
        :param int max_point_count_in_node: The maximum number of points to find in a single block. When using QuadTree to find interpolation points, you can set the maximum number of points in a block.
        :param int max_point_count_for_interpolation: Set the maximum number of points involved in interpolation during block search. Note that this value must be greater than zero. When using QuadTree to find interpolation points, you can set the maximum number of points involved in interpolation
        :param float smooth: smoothing coefficient, the value range is [0,1]
        :param float tension: Tension coefficient
        :param Rectangle bounds: The range of interpolation analysis, used to determine the range of running results
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.bounds": """Rectangle: The range of interpolation analysis, used to determine the range of running results""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.expected_count": """int: The number of points expected to participate in the interpolation operation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.max_point_count_for_interpolation": """int: The maximum number of points involved in interpolation during block search""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.max_point_count_in_node": """int: Maximum number of search points in a single block""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.resolution": """float: the resolution used during interpolation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.search_mode": """SearchMode: Find the way to participate in the operation during interpolation operation. KDTREE_FIXED_RADIUS is not supported """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.search_radius": """float: Find the search radius of the points involved in the operation""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.set_bounds": """
        Set the range of interpolation analysis to determine the range of running results

        :param Rectangle value: The range of interpolation analysis, used to determine the range of running results
        :return: self
        :rtype: InterpolationParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.set_expected_count": """
        Set the number of points expected to participate in the interpolation operation

        :param int value: Indicates the minimum number of samples expected to participate in the operation
        :return: self
        :rtype: InterpolationRBFParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.set_max_point_count_for_interpolation": """
        When setting block search, the maximum number of points involved in interpolation. Note that this value must be greater than zero. When using QuadTree to find interpolation points, you can set the maximum number of points involved in interpolation

        :param int value: Maximum number of points involved in interpolation during block search
        :return: self
        :rtype: InterpolationRBFParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.set_max_point_count_in_node": """
        Set the maximum number of search points in a single block. When using QuadTree to find interpolation points, you can set the maximum number of points in a block.

        :param int value: The maximum number of search points in a single block. When using QuadTree to find interpolation points, you can set the maximum number of points in the block
        :return: self
        :rtype: InterpolationRBFParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.set_resolution": """
        Set the resolution used in interpolation operation.

        :param float value: the resolution used during interpolation
        :return: self
        :rtype: InterpolationParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.set_search_mode": """
        Set the way to find the points involved in the interpolation operation.

        :param value: In interpolation operation, find the way to participate in the operation
        :type value: SearchMode or str
        :return: self
        :rtype: InterpolationRBFParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.set_search_radius": """
        Set the search radius to find the points involved in the operation. The unit is the same as the unit of the point dataset (or the dataset to which the record set belongs) used for interpolation. The search radius determines the search range of the points involved in the calculation. 
        When calculating the unknown value of a certain location, the location will be the center of the circle and the search_radiu s will be the radius. The sampling points within this range will participate in the calculation, that is, the location The predicted value of is determined by the 
        value of the sampling points in the range.

        The search mode is set to "variable length search" (KDTREE_FIXED_COUNT), and a fixed number of sample points within the maximum search radius will be used for interpolation. 
        The maximum search radius is 0.2 times the diagonal length of the rectangle corresponding to the area range of the point dataset.

        :param float value: Find the search radius of the points involved in the operation
        :return: self
        :rtype: InterpolationRBFParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.set_smooth": """
        Set smooth coefficient

        :param float value: smoothness coefficient
        :return: self
        :rtype: InterpolationRBFParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.set_tension": """
        Set tension coefficient

        :param float value: Tension coefficient
        :return: self
        :rtype: InterpolationRBFParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.smooth": """float: smoothness coefficient""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.tension": """float: tension coefficient""",

    "iobjectspy._jsuperpy.analyst.sa.InterpolationRBFParameter.type": """InterpolationAlgorithmType: The type of algorithm supported by the interpolation branch""",

    "iobjectspy._jsuperpy.analyst.sa.NDVI": """
    The normalized vegetation index is also called the normalized difference vegetation index or standard difference vegetation index or biomass index change. The vegetation can be separated from the water and soil.

    :param input_data: Multi-band image dataset.
    :type input_data: DatasetImage or str
    :param int nir_index: index of near infrared band
    :param int red_index: the index of the red band
    :param out_data: result datasource
    :type out_data: Datasource or str
    :param str out_dataset_name: result dataset name
    :return: Result dataset, used to save NDVI value. The range of NDVI value is between -1 and 1.
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.NDWI": """
    Normalized water index. NDWI is generally used to extract water information in images, and the effect is better.

    :param input_data: Multi-band image dataset.
    :type input_data: DatasetImage or str
    :param int nir_index: index of near infrared band
    :param int green_index: the index of the green band
    :param out_data: result datasource
    :type out_data: Datasource or str
    :param str out_dataset_name: result dataset name
    :return: Result dataset, used to save NDWI value.
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShape": """Neighbourhood shape base class. Neighborhoods can be divided into rectangular neighbourhoods, circular neighbourhoods, circular neighbourhoods and fan-shaped neighbourhoods according to their shapes. Neighbourhood shapes Related parameter settings """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShape.shape_type": """NeighbourShapeType: Neighborhood shape type for domain analysis""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeAnnulus": """Circular neighborhood shape class""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeAnnulus.__init__": """
        Construct circular neighborhood shape objects

        :param float inner_radius: inner ring radius
        :param float outer_radius: outer ring radius
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeAnnulus.inner_radius": """float: inner ring radius""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeAnnulus.outer_radius": """float: outer ring radius""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeAnnulus.set_inner_radius": """
        Set inner ring radius

        :param float value: inner ring radius
        :return: self
        :rtype: NeighbourShapeAnnulus
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeAnnulus.set_outer_radius": """
        Set the radius of the outer ring

        :param float value: outer ring radius
        :return: self
        :rtype: NeighbourShapeAnnulus
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeAnnulus.shape_type": """NeighbourShapeType: Neighborhood shape type for domain analysis""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeCircle": """Circular neighborhood shape class""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeCircle.__init__": """
        Construct a circular neighborhood shape class object

        :param float radius: the radius of the circular neighborhood
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeCircle.radius": """float: radius of circular neighborhood""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeCircle.set_radius": """
        Set the radius of the circular neighborhood

        :param float value: the radius of the circular neighborhood
        :return: self
        :rtype: NeighbourShapeCircle
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeCircle.shape_type": """NeighbourShapeType: Neighborhood shape type for domain analysis""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeRectangle": """Rectangular neighborhood shape class""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeRectangle.__init__": """
        Construct a rectangular neighborhood shape class object

        :param float width: the width of the rectangular neighborhood
        :param float height: the height of the rectangular neighborhood
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeRectangle.height": """float: height of rectangular neighborhood""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeRectangle.set_height": """
        Set the height of the rectangular neighborhood

        :param float value: the height of the rectangular neighborhood
        :return: self
        :rtype: NeighbourShapeRectangle
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeRectangle.set_width": """
        Set the width of the rectangular neighborhood

        :param float value: the width of the rectangular neighborhood
        :return: self
        :rtype: NeighbourShapeRectangle
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeRectangle.shape_type": """NeighbourShapeType: Neighborhood shape type for domain analysis""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeRectangle.width": """float: the width of the rectangular neighborhood""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeWedge": """Sector neighborhood shape class""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeWedge.__init__": """
        Construct a fan-shaped neighborhood shape class object

        :param float radius: the radius of the shape neighborhood
        :param float start_angle: The starting angle of the fan-shaped neighborhood. The unit is degrees. It is specified that the horizontal right is 0 degrees, and the angle is calculated by rotating clockwise.
        :param float end_angle: The ending angle of the fan-shaped neighborhood. The unit is degrees. It is specified that the horizontal right is 0 degrees, and the angle is calculated by rotating clockwise.
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeWedge.end_angle": """float: The ending angle of the fan-shaped neighborhood. The unit is degrees. The horizontal right is 0 degrees, and the angle is calculated by rotating clockwise. """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeWedge.radius": """float: the radius of the fan-shaped neighborhood""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeWedge.set_end_angle": """
        Set the ending angle of the fan-shaped neighborhood. The unit is degrees. It is specified that the horizontal right is 0 degrees, and the angle is calculated by rotating clockwise.

        :param float value:
        :return: self
        :rtype: NeighbourShapeWedge
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeWedge.set_radius": """
        Set the radius of the fan-shaped neighborhood

        :param float value: the radius of the fan-shaped neighborhood
        :return: self
        :rtype: NeighbourShapeWedge
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeWedge.set_start_angle": """
        Set the starting angle of the fan-shaped neighborhood. The unit is degrees. It is specified that the horizontal right is 0 degrees, and the angle is calculated by rotating clockwise.

        :param float value: The starting angle of the fan-shaped neighborhood. The unit is degrees. It is specified that the horizontal right is 0 degrees, and the angle is calculated by rotating clockwise.
        :return: self
        :rtype: NeighbourShapeWedge
        """,

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeWedge.shape_type": """NeighbourShapeType: Neighborhood shape type for domain analysis""",

    "iobjectspy._jsuperpy.analyst.sa.NeighbourShapeWedge.start_angle": """float: The starting angle of the fan-shaped neighborhood. The unit is degree. The horizontal right is 0 degrees, and the angle is calculated by rotating clockwise. """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomata": """
    Cellular automata based on principal component analysis.

    Cellular automata (CA) is a network dynamics model in which time, space, and state are discrete, and spatial interaction and time causality are local. 
    It has the ability to simulate the spatiotemporal evolution process of complex systems.

    When geographic simulations need to use many spatial variables, these spatial variables are often related. It is necessary to use principal component analysis to effectively compress multiple spatial variables into a few principal components and reduce the difficulty of setting weights. 
    The cellular automata of component analysis is applied in the spatial simulation of urban development.
    """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomata.pca": """
        Sampling and principal component analysis are performed on the cell dataset.

        This method is used to set the corresponding weight value using the number of principal components obtained before the cellular automata analysis based on principal component analysis.

        :param spatial_variable_grids: spatial variable grid dataset.
        :type spatial_variable_grids: list[DatasetGrid] or tuple[DatasetGird]
        :param int sample_count: The number of samples. Randomly sample the specified number of samples from the entire raster data
        :param float component_radio: Principal component ratio, the value range is [0,1], for example, when the value is 0.8, it means to select the first n principal components whose cumulative contribution rate reaches 80%.
        :param function progress_func: progress information processing function, refer to: py:class:`.StepEvent`
        :return: Principal component analysis result, including the number of principal components, contribution rate, eigenvalue and eigenvector
        :rtype: PCAEigenResult
        """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomata.pca_cellular_automata": """
        Cellular automata based on principal component analysis.

        :param parameter: The parameters of cellular automata based on principal component analysis.
        :type parameter: PCACellularAutomataParameter
        :param out_data: The datasource of the output result dataset.
        :type out_data: Datasource or str
        :param out_dataset_name: The name of the output dataset.
        :type out_dataset_name: str
        :param progress_func: progress information processing function, refer to: py:class:`.StepEvent`
        :type progress_func: function
        :param flush_func: Cellular automata flushing information processing function, refer to: py:class:`.CellularAutomataFlushedEvent`
        :type flush_func: function
        :return: result raster dataset
        :rtype: DatasetGrid
        """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter": """
    Cellular automata parameter class based on principal component analysis. In the cellular automata process based on principal component analysis, principal component analysis needs to be generated. This process requires setting the principal component weight value and the parameters required for the simulation 
    process (non-linear exponential transformation value, diffusion index), etc.
    """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.alpha": """int: diffusion parameter""",

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.cellular_automata_parameter": """CellularAutomataParameter: Cellular AutomataParameter""",

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.component_weights": """list[float]: Principal component weight array """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.conversion_rules": """dict[int,bool]: Conversion rules """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.conversion_target": """int: conversion target """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.index_k": """float: Non-linear exponential transformation value.""",

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.set_alpha": """
        Set the diffusion parameters. Generally 1-10.

        :param int value: Diffusion parameter.
        :return: self
        :rtype: PCACAParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.set_cellular_automata_parameter": """
        Set cellular automata parameters.

        :param value: Cellular automata parameters
        :type value: CellularAutomataParameter
        :return: self
        :rtype: PCACAParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.set_component_weights": """
        Set the principal component weight array.

        :param value: Principal component weight array
        :type value: list[float] or tuple[float]
        :return: self
        :rtype: PCACAParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.set_conversion_rules": """
        Set conversion rules. For example, in the change of land use, water areas are non-convertible land and farmland is convertible land.

        :param value: conversion rules
        :type value: dict[int,bool]
        :return: self
        :rtype: PCACAParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.set_conversion_target": """
        Set conversion goals. For example, in the conversion of farmland to urban land, urban land is the conversion target.

        :param int value: conversion target
        :return: self
        :rtype: PCACAParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.PCACellularAutomataParameter.set_index_k": """
        Set the non-linear exponential transformation value. This system is 4.

        :param float value: Non-linear exponential transformation value.
        :return: self
        :rtype: PCACAParameter
        """,

    "iobjectspy._jsuperpy.analyst.sa.PCAEigenResult": """
    Principal component analysis result class. Principal component analysis has different numbers of principal components due to different sampling numbers and principal component ratios. Therefore, it is necessary to set the weights according to the results (principal components and contribution rate, etc.) obtained after principal component analysis. 
    After setting the weights, you can Use cellular automata to simulate.

    """,

    "iobjectspy._jsuperpy.analyst.sa.PCAEigenResult.component_count": """int: number of principal components""",

    "iobjectspy._jsuperpy.analyst.sa.PCAEigenResult.pca_eigen_values": """list[PCAEigenValue]: Principal component analysis feature value result array """,

    "iobjectspy._jsuperpy.analyst.sa.PCAEigenResult.pca_loadings": """list[float]: Principal component contribution rate """,

    "iobjectspy._jsuperpy.analyst.sa.PCAEigenResult.spatial_dataset_raster_names": """list[str]: spatial variable data name""",

    "iobjectspy._jsuperpy.analyst.sa.PCAEigenValue": """
    Principal component analysis eigenvalue result class.
    """,

    "iobjectspy._jsuperpy.analyst.sa.PCAEigenValue.contribution_rate": """float: contribution rate""",

    "iobjectspy._jsuperpy.analyst.sa.PCAEigenValue.cumulative": """float: cumulative contribution rate""",

    "iobjectspy._jsuperpy.analyst.sa.PCAEigenValue.eigen_value": """float: characteristic value""",

    "iobjectspy._jsuperpy.analyst.sa.PCAEigenValue.spatial_dataset_raster_name": """str: spatial variable data name""",

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable": """
    Raster reclassification mapping table class. Provides single-value or range reclassification of the source raster dataset, and includes the processing of non-valued data and unclassified cells.

    The reclassification mapping table is used to illustrate the correspondence between the source data and the result data value. This corresponding relationship is expressed by these parts: reclassification type, reclassification interval set, processing of non-valued and unclassified data.

    -Types of reclassification
      There are two types of reclassification, single value reclassification and range reclassification. Single value reclassification is to re-assign certain single values. For example, a cell with a value of 100 in the source raster is assigned a value of 1 and output to the result raster; 
      range reclassification re-assigns a value in an interval It is a value, such as re-assigning a value of 200 to cells in the source raster whose raster value is in the range of [100,500) and output to the result raster. Set the reclassification type through the :py:meth:`set_reclass_type` method of this class.

    -Reclassification interval collection
      The reclassified interval set specifies the corresponding relationship between a certain raster value of the source raster or a raster value in a certain interval and the new value after reclassification, which is set by the :py:meth:`set_segments` method of this class.
      This set is composed of several ReclassSegment objects. This object is used to set the information of each reclassification interval, including the start value and end value of the source raster single value or interval to be re-assigned, and the type of reclassification interval.
      And the interval value of the grid reclassification or the new value corresponding to the single value of the source raster, etc., see: py:class:`.ReclassSegment` class for details.

    -Handling of non-valued and unclassified data
      For the no value in the source raster data, you can set whether to keep no value through the :py:meth:`set_retain_no_value` method of this class. If it is False, that is, if it is not kept as no value, you can use :py:meth: The `set_change_no_value_to` method specifies a value for no-value data.

      For raster values that are not involved in the reclassification mapping table, you can use the :py:meth:`set_retain_missing_value` method of this class to set whether to keep its original value. If it is False, that is, not to keep the original value, you can pass: The py:meth:`set_change_missing_valueT_to` method specifies a value for it.

    In addition, this class also provides methods for exporting reclassification mapping table data as XML strings and XML files, and methods for importing XML strings or files. When multiple input raster data needs to apply the same classification range, they can be exported as a reclassification mapping table file.
    When the subsequent data is classified, the reclassification mapping table file is directly imported, and the imported raster data can be processed in batches. For the format and label meaning of the raster reclassification mapping table file, please refer to the to_xml method.


    """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.change_missing_value_to": """float: Return the specified value of the grid that is not within the specified interval or single value.""",

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.change_no_value_to": """float: Return the specified value of no-value data """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.from_dict": """
        Read the reclassification mapping table information from the dict object

        :param dict values: dict object containing reclassification mapping table information
        :return: self
        :rtype: ReclassMappingTable
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.from_xml": """
        Import the parameter value stored in the XML format string into the mapping table data, and return a new object.

        :param str xml: XML format string
        :return: Raster reclassification mapping table object
        :rtype: ReclassMappingTable
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.from_xml_file": """
        Import the mapping table data from the saved XML format mapping table file and return a new object.

        :param str xml_file: XML file
        :return: Raster reclassification mapping table object
        :rtype: ReclassMappingTable
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.is_retain_missing_value": """bool: Whether the data in the source dataset that is not in the specified interval or outside the single value retain the original value""",

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.is_retain_no_value": """bool: Return whether to keep the non-valued data in the source dataset as non-valued. """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.make_from_dict": """
        Read the reclassification mapping table information from the dict object to construct a new object

        :param dict values: dict object containing reclassification mapping table information
        :return: reclassification mapping table object
        :rtype: ReclassMappingTable
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.reclass_type": """ReclassType: Return the type of raster reclassification""",

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.segments": """list[ReclassSegment]: Return the set of reclassification intervals. Each ReclassSegment is an interval range or the correspondence between an old value and a new value.""",

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.set_change_missing_value_to": """
        Set the specified value of the grid that is not within the specified interval or single value. If :py:meth:`is_retain_no_value` is True, this setting is invalid.

        :param float value: the specified value of the grid that is not within the specified interval or single value
        :return: self
        :rtype: ReclassMappingTable
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.set_change_no_value_to": """
        Set the specified value of no-value data. When :py:meth:`is_retain_no_value` is True, this setting is invalid.

        :param float value: the specified value of no value data
        :return: self
        :rtype: ReclassMappingTable
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.set_reclass_type": """
        Set the grid reclassification type

        :param value: Raster reclassification type, the default value is UNIQUE
        :type value: ReclassType or str
        :return: self
        :rtype: ReclassMappingTable
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.set_retain_missing_value": """
        Set whether the data in the source dataset that is not outside the specified interval or single value retain the original value.

        :param bool value: Whether the data in the source dataset that is not outside the specified interval or single value retain the original value.
        :return: self
        :rtype: ReclassMappingTable
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.set_retain_no_value": """
        Set whether to keep the no-value data in the source dataset as no-value. Set whether to keep the no-value data in the source dataset as no-value.
        -When the set_retain_no_value method is set to True, it means to keep the no-value data in the source dataset as no-value;
        -When the set_retain_no_value method is set to False, it means that the no-value data in the source dataset is set to the specified value (:py:meth:`set_change_no_value_to`)

        :param bool value:
        :return: self
        :rtype: ReclassMappingTable
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.set_segments": """
        Set reclassification interval collection

        :param value: Reclassification interval collection. When the value is str, it is supported to use';' to separate multiple ReclassSegments, and each ReclassSegment uses',' to separate the start value, end value, new value and partition type. E.g:
                        '0,100,50,CLOSEOPEN; 100,200,150,CLOSEOPEN'
        :type value: list[ReclassSegment] or str
        :return: self
        :rtype: ReclassMappingTable
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.to_dict": """
        Output current information to dict

        :return: a dictionary object containing current information
        :rtype: dict
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.to_xml": """
        Output current object information as xml string

        :return: xml string
        :rtype: str
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassMappingTable.to_xml_file": """
        This method is used to write the parameter settings of the reclassification mapping table object into an XML file, which is called a raster reclassification mapping table file, and its suffix is .xml. The following is an example of a raster reclassification mapping table file:

        The meaning of each label in the reclassification mapping table file is as follows:

        -<SmXml:ReclassType></SmXml:ReclassType> tag: reclassification type. 1 means single value reclassification, 2 means range reclassification.
        -<SmXml:SegmentCount></SmXml:SegmentCount> tag: reclassification interval collection, count parameter indicates the number of reclassification levels.
        -<SmXml:Range></SmXml:Range> tag: reclassification interval, the reclassification type is single value reclassification, the format is: interval start value-interval end value: new value-interval type. For the interval type, 0 means left open and right closed, 1 means left closed and right open.
        -<SmXml:Unique></SmXml:Unique> tag: reclassification interval, reclassification type is range reclassification, the format is: original value: new value.
        -<SmXml:RetainMissingValue></SmXml:RetainMissingValue> tag: whether to retain the original value of unrated cells. 0 means not reserved, 1 means reserved.
        -<SmXml:RetainNoValue></SmXml:RetainNoValue> tag: Whether the no-value data remains no-value. 0 means not to keep, 0 means not to keep.
        -<SmXml:ChangeMissingValueTo></SmXml:ChangeMissingValueTo> tag: the specified value of the ungraded cell.
        -<SmXml:ChangeNoValueTo></SmXml:ChangeNoValueTo> tag: the specified value for no value data.


        :param str xml_file: xml file path
        :type xml_file:
        :return: Return True if export is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment": """
    Raster reclassification interval class. This class is mainly used for the related settings of reclassification interval information, including the start value and end value of the interval.

    This class is used to set the parameters of each reclassification interval in the reclassification mapping table during reclassification. The attributes that need to be set are different for different reclassification types.

    -When the reclassification type is single value reclassification, you need to use the :py:meth:`set_start_value` method to specify the single value of the source raster that needs to be re-assigned, and use the :py:meth:`set_new_value` method to set the value The corresponding new value.
    -When the reclassification type is range reclassification, you need to use the :py:meth:`set_start_value` method to specify the starting value of the source raster value range that needs to be re-assigned, and use the :py:meth:`set_end_value` method to set the range End value,
      And through the :py:meth:`set_new_value` method to set the new value corresponding to the interval, you can also use the :py:meth:`set_segment_type` method to set the interval type is "left open and right closed" or "left closed and right open".

    """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.__init__": """
        Construct a grid reclassified interval object

        :param float start_value: the starting value of the grid reclassification interval
        :param float end_value: the end value of the grid reclassification interval
        :param float new_value: the interval value of the grid reclassification or the new value corresponding to the old value
        :param segment_type: Raster reclassification interval type
        :type segment_type: ReclassSegmentType or str
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.end_value": """float: the end value of the raster reclassification interval""",

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.from_dict": """
        Read information from dict

        :param values: a dict containing ReclassSegment information
        :type values: dict
        :return: self
        :rtype: ReclassSegment
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.make_from_dict": """
        Read information from dict to construct ReclassSegment object

        :param values: a dict containing ReclassSegment information
        :type values: dict
        :return: Raster reclassification interval object
        :rtype: ReclassSegment
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.new_value": """float: the interval value of the grid reclassification or the new value corresponding to the old value""",

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.segment_type": """ReclassSegmentType: Raster reclassification interval type""",

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.set_end_value": """
        The end value of the grid reclassification interval

        :param float value: the end value of the grid reclassification interval
        :return: self
        :rtype: ReclassSegment
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.set_new_value": """
        The interval value of the grid reclassification or the new value corresponding to the old value

        :param float value: The interval value of the grid reclassification or the new value corresponding to the old value
        :return: self
        :rtype: ReclassSegment
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.set_segment_type": """
        Set the type of grid reclassification interval

        :param value: Raster reclassification interval type
        :type value: ReclassSegmentType or str
        :return: self
        :rtype: ReclassSegment
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.set_start_value": """
        Set the starting value of the grid reclassification interval

        :param float value: the starting value of the grid reclassification interval
        :return: self
        :rtype: ReclassSegment
        """,

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.start_value": """float: the starting value of the grid reclassification interval""",

    "iobjectspy._jsuperpy.analyst.sa.ReclassSegment.to_dict": """
        Output current object information to dict

        :return: dict object containing current object information
        :rtype: dict
        """,

    "iobjectspy._jsuperpy.analyst.sa.StatisticsField": """
    Statistics on the field. Mainly used for: py:meth:`summary_points`
    """,

    "iobjectspy._jsuperpy.analyst.sa.StatisticsField.__init__": """
        Initialization object

        :param str source_field: the name of the field being counted
        :param stat_type: stat type
        :type stat_type: StatisticsFieldType or str
        :param str result_field: result field name
        """,

    "iobjectspy._jsuperpy.analyst.sa.StatisticsField.result_field": """str: result field name """,

    "iobjectspy._jsuperpy.analyst.sa.StatisticsField.set_result_field": """
        Set the result field name

        :param str value: result field name
        :return: self
        :rtype: StatisticsField
        """,

    "iobjectspy._jsuperpy.analyst.sa.StatisticsField.set_source_field": """
        Set the name of the field to be counted

        :param str value: field name
        :return: self
        :rtype: StatisticsField
        """,

    "iobjectspy._jsuperpy.analyst.sa.StatisticsField.set_stat_type": """
        Set field statistics type

        :param value: field statistics type
        :type value: StatisticsFieldType or str
        :return: self
        :rtype: StatisticsField
        """,

    "iobjectspy._jsuperpy.analyst.sa.StatisticsField.source_field": """str: the name of the field to be counted""",

    "iobjectspy._jsuperpy.analyst.sa.StatisticsField.stat_type": """StatisticsFieldType: field statistics type""",

    "iobjectspy._jsuperpy.analyst.sa.VisibleResult": """
    Visibility analysis result class.

    This class gives the results of the visual analysis between the observation point and the observed point. If it is not visible, it will also give relevant information about the obstacle point.
    """,

    "iobjectspy._jsuperpy.analyst.sa.VisibleResult.barrier_alter_height": """float: The recommended maximum height of the obstacle point. If the grid value (ie elevation) of the cell on the grid surface where the obstacle point is located is modified to be less than or equal to this value, the point will no longer obstruct the line of sight, 
                                                                                    but note that it does not mean that there are no other obstacle points after the point. The grid value can be modified through the set_value() method of the DatasetGrid class""",

    "iobjectspy._jsuperpy.analyst.sa.VisibleResult.barrier_point": """Point3D: The coordinate value of the obstacle point. If the observation point and the observed point are not visible, the return value of this method is the first obstacle point between the observation point and the observed point. If the observation point and the observed point are visible, 
    the obstacle point coordinates will take the default value. """,

    "iobjectspy._jsuperpy.analyst.sa.VisibleResult.from_point_index": """int: The index value of the observation point. If the visibility analysis is performed between two points, the index value of the observation point is 0.""",

    "iobjectspy._jsuperpy.analyst.sa.VisibleResult.to_point_index": """int: The index value of the observed point. If the visibility analysis is performed between two points, the index value of the observed point is 0. """,

    "iobjectspy._jsuperpy.analyst.sa.VisibleResult.visible": """bool: Whether the observation point and the observed point pair are visible or not""",

    "iobjectspy._jsuperpy.analyst.sa.aggregate_grid": """

    Raster data aggregation, Return the result raster dataset.
    The raster aggregation operation is a process of reducing the raster resolution by an integer multiple to generate a new raster with a coarser resolution. At this time, each pixel is aggregated from a group of pixels in the original raster data, 
    and its value is determined by the value of the original raster contained in it. It can be the sum, maximum, minimum, and average of the raster. Value, median. If it is reduced by n (n is an integer greater than 1) times, the number of rows and columns 
    of the aggregated grid is 1/n of the original grid, that is, the cell size is n times the original. Aggregation can achieve the purpose of eliminating unnecessary information or deleting minor errors by generalizing the data.

    Note: If the number of rows and columns of the original raster data is not an integer multiple of scale, use the is_expanded parameter to handle the fraction.

    -If is_expanded is true, add a number to the zero to make it an integer multiple. The raster values of the expanded range are all non-valued. Therefore, the range of the result dataset will be larger than the original.

    -If is_expanded is false, if the fraction is removed, the range of the result dataset will be smaller than the original.

    :param input_data: The specified raster dataset for aggregation operation.
    :type input_data: DatasetGrid or str
    :param int scale: The ratio of the specified grid size between the result grid and the input grid. The value is an integer value greater than 1.
    :param aggregation_type: aggregation operation type
    :type aggregation_type: AggregationType
    :param bool is_expanded: Specify whether to deal with fractions. When the number of rows and columns of the original raster data is not an integer multiple of the scale, fractions will appear at the grid boundary.
    :param bool is_ignore_no_value: The calculation method of the aggregation operation when there is no value data in the aggregation range. If it is True, use the rest of the grid values in the aggregation range except no value for calculation; if it is False, the aggregation result is no value.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.aggregate_points": """
    Cluster the point dataset and use the density clustering algorithm to return the clustered category or the polygon formed by the same cluster.
    To cluster the spatial position of the point set, use the density clustering method DBSCAN, which can divide the regions with sufficiently high density into clusters, and can find clusters of arbitrary shapes in the spatial data with noise. 
    It defines a cluster as the largest collection of points that are connected in density. DBSCAN uses threshold e and MinPts to control the generation of clusters. Among them, the area within the radius e of a given object is called the e-neighborhood of the object. 
    If the e-neighborhood of an object contains at least the minimum number of MinPtS objects, the object is called the core object. Given a set of objects D, if P is in the e-neighborhood of Q, and Q is a core object, we say that the object P is directly density reachable from the object Q. 
    DBSCAN looks for clusters by checking the e-domain of each point in the data. If the e-domain of a point P contains more than MinPts points, a new cluster with P as the core object is created, and then DBSCAN repeatedly Look for objects whose density is directly reachable from these core objects 
    and join the cluster until no new points can be added.

    :param input_data: input point dataset
    :type input_data: DatasetVector or str
    :param int min_pile_point: The threshold for the number of density clustering points, which must be greater than or equal to 2. The larger the threshold value, the harsher the conditions for clustering into a cluster.
    :param float distance: The radius of density clustering.
    :param unit: The unit of the density cluster radius.
    :type unit: Unit or str
    :param str class_field: The field in the input point dataset used to store the result of density clustering. If it is not empty, it must be a valid field name in the point dataset.
                            The field type is required to be INT16, INT32 or INT64. If the field name is valid but does not exist, an INT32 field will be created.
                            If the parameter is valid, the cluster category will be saved in this field.
    :param out_data: result datasource information. The result datasource information cannot be empty with class_field at the same time. If the result datasource is valid, the result area object will be generated.
    :type out_data: Datasource or DatasourceConnectionInfo or st
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The result dataset or the name of the dataset. If the input result datasource is empty, a boolean value will be returned. True means clustering is successful, False means clustering fails.
    :rtype: DatasetVector or str or bool


    >>> result = aggregate_points('E:/data.udb/point', 4, 100,'Meter','SmUserID', out_data='E:/aggregate_out.udb')

    """,

    "iobjectspy._jsuperpy.analyst.sa.altitude_statistics": """
    Elevation statistics: Count the grid values corresponding to each point in the two-dimensional point dataset, and generate a three-dimensional point dataset. The Z value of the three-dimensional point object is the elevation value of the grid pixel being counted.

    :param point_data: two-dimensional point dataset
    :type point_data: DatasetVector or str
    :param grid_data: grid dataset to be counted
    :type grid_data: DatasetGrid or str
    :param out_data: The datasource used to store the result data.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: the name of the result dataset
    :type out_dataset_name: str
    :return: Statistical 3D dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.are_points_visible": """
    Multi-point visibility analysis is to determine whether multiple points can be viewed in pairs.
    Multi-point visibility analysis is based on the grid surface to calculate whether the observation point and the observed point are both visible. For visibility analysis between two points, please refer to the introduction of another overloaded method isVisible method.

    If there are m observation points and n observed points, there will be m * n observation combinations. The analysis result is returned through an array of VisibleResult objects, each VisibleResult
    object includes whether the corresponding two points are visible. If they are not visible, the first obstacle point will be given, and the suggested elevation value of the point so that the point no longer obstructs the line of sight.

    Note: If the elevation of the specified observation point is less than the elevation value of the corresponding position on the current grid surface, the elevation value of the observation point will be automatically set to the elevation of the corresponding position on the current grid surface.

    :param input_data: The specified raster surface dataset used for visibility analysis.
    :type input_data: DatasetGrid or str
    :param from_points: The specified starting point for visibility analysis, that is, the observation point
    :type from_points: list[Point3D]
    :param to_points: The specified end point for visibility analysis, that is, the observed point.
    :type to_points: list[Point3D]
    :return: the result of the visibility analysis
    :rtype: list[VisibleResult]
    """,

    "iobjectspy._jsuperpy.analyst.sa.area_solar_radiation_days": """
    Calculate the total amount of solar radiation in a multi-day area, that is, the solar radiation of each grid in the entire DEM range. Need to specify the start time, end time, start date, and end date of each day.

    :param grid_data: DEM grid data to be calculated for solar radiation
    :type grid_data: DatasetGrid or str
    :param latitude: the average latitude of the area to be calculated
    :type latitude: float
    :param start_day: start date, it can be a string in the format "%Y-%m-%d", if it is an int, it means the day of the year
    :type start_day: datetime.date or str or int
    :param end_day: end date, can be a string in the format "%Y-%m-%d", if it is int, it means the day of the year
    :type end_day: datetime.date or str or int
    :param hour_start: The starting time point. If you enter float, you can enter a value in the range of [0,24], which means the hour in the day. You can also enter a datetime.datatime or "%H:%M:%S" format string
    :type hour_start: float or str or datetime.datetime
    :param hour_end: the end time point, if you enter float, you can enter a value in the range of [0,24], which means the hour in the day. You can also enter a datetime.datatime or "%H:%M:%S" format string
    :type hour_end: float or str or datetime.datetime
    :param int day_interval: interval in days, the unit is day
    :param float hour_interval: hour interval, the unit is hour.
    :param float transmittance: The transmittance of solar radiation through the atmosphere, the value range is [0,1].
    :param float z_factor: elevation zoom factor
    :param out_data: The datasource used to store the result data.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_total_grid_name: The name of the total radiation result dataset, the dataset name must be legal
    :param str out_direct_grid_name: The name of the direct radiation result dataset. The dataset name must be legal, and the interface will not automatically obtain a valid dataset name
    :param str out_diffuse_grid_name: The name of the scattered radiation result dataset. The dataset name must be legal, and the effective dataset name will not be automatically obtained in the interface
    :param str out_duration_grid_name: The name of the dataset for the duration of direct solar radiation. The name of the dataset must be legal, and the interface will not automatically obtain a valid dataset name
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Return a tuple of four elements:

               * The first one is the total radiation result dataset,
               * If the name of the direct radiation result dataset is set, the second one is the direct radiation result dataset, otherwise it is None,
               * If you set the name of the scattered radiation result dataset, the third one is the scattered radiation result dataset, otherwise it is None
               * If you set the name of the result dataset of the direct sun duration, the fourth one is the result dataset of the direct sun duration, otherwise it is None

    :rtype: tuple[DatasetGrid] or tuple[str]
    """,

    "iobjectspy._jsuperpy.analyst.sa.area_solar_radiation_hours": """
    To calculate the solar radiation within a day, you need to specify the start time, end time and start date as the date to be calculated

    :param grid_data: DEM grid data to be calculated for solar radiation
    :type grid_data: DatasetGrid or str
    :param latitude: the average latitude of the area to be calculated
    :type latitude: float
    :param day: The specified date to be calculated. It can be a string in the format "%Y-%m-%d". If it is an int, it means the day of the year.
    :type day: datetime.date or str or int
    :param hour_start: The starting time point. If you enter float, you can enter a value in the range of [0,24], which means the hour in the day. You can also enter a datetime.datatime or "%H:%M:%S" format string
    :type hour_start: float or str or datetime.datetime
    :param hour_end: the end time point, if you enter float, you can enter a value in the range of [0,24], which means the hour in the day. You can also enter a datetime.datatime or "%H:%M:%S" format string
    :type hour_end: float or str or datetime.datetime
    :param float hour_interval: hour interval, the unit is hour.
    :param float transmittance: The transmittance of solar radiation through the atmosphere, the value range is [0,1].
    :param float z_factor: elevation zoom factor
    :param out_data: The datasource used to store the result data.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_total_grid_name: The name of the total radiation result dataset, the dataset name must be legal
    :param str out_direct_grid_name: The name of the direct radiation result dataset. The dataset name must be legal, and the interface will not automatically obtain a valid dataset name
    :param str out_diffuse_grid_name: The name of the scattered radiation result dataset. The dataset name must be legal, and the effective dataset name will not be automatically obtained in the interface
    :param str out_duration_grid_name: The name of the dataset for the duration of direct solar radiation. The name of the dataset must be legal, and the interface will not automatically obtain a valid dataset name
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Return a tuple of four elements:

               * The first one is the total radiation result dataset,
               * If the name of the direct radiation result dataset is set, the second one is the direct radiation result dataset, otherwise it is None,
               * If you set the name of the scattered radiation result dataset, the third one is the scattered radiation result dataset, otherwise it is None
               * If you set the name of the result dataset of the direct sun duration, the fourth one is the result dataset of the direct sun duration, otherwise it is None

    :rtype: tuple[DatasetGrid] or tuple[str]
    """,

    "iobjectspy._jsuperpy.analyst.sa.boundary_clean": """
    Boundary cleanup, return the result raster dataset.
    Smooth the boundaries between regions by expanding and contracting. All areas less than three pixels in the x and y directions will be changed.

    The following figure is a schematic diagram of boundary cleaning:

    .. image:: ../image/BoundaryClean.png


    :param source_grid: The specified dataset to be processed. The input raster must be of integer type.
    :type source_grid: DatasetGrid or str
    :param sort_type: Sort method. Specify the sort type to be used in smoothing. Including NOSORT, DESCEND, ASCEND three methods.
    :type sort_type: BoundaryCleanSortType or str
    :param is_run_two_times: Is the number of smoothing processes occurring twice? True means to perform the expansion-contraction process twice, perform expansion and contraction according to the sorting type, 
                             and then use the opposite priority to perform one more contraction and expansion; False means to perform one expansion and contraction according to the sorting type.
    :type is_run_two_times: bool
    :param out_data: The specified datasource for storing the result dataset.
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param out_dataset_name: the name of the result dataset
    :type out_dataset_name: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result raster dataset
    :rtype: DatasetGrid
    """,

    "iobjectspy._jsuperpy.analyst.sa.build_lake": """
    To dig a lake, that is, to modify the elevation value of the DEM dataset in the area of the polygon dataset to the specified value.
    Lake digging refers to displaying lake information on the DEM dataset based on the existing lake surface data. As shown in the figure below, after digging the lake, the grid value of DEM at the corresponding position of the lake surface data becomes the specified elevation value, and the grid value of the entire lake area is the same.

    .. image:: ../image/BuildLake.png

    :param dem_grid: The specified DEM raster dataset of the lake to be dug.
    :type dem_grid: DatasetGrid or str
    :param lake_data: The designated lake area is a polygon dataset.
    :type lake_data: DatasetVector or str
    :param elevation: The elevation field of the specified lake area or the specified elevation value. If it is str, the field type is required to be numeric. If it is specified as None or an empty string, or the specified field does not exist in the lake area dataset, the lake will be dug according to the minimum elevation 
                    on the DEM grid corresponding to the lake area boundary. The unit of the elevation value is the same as that of the DEM raster dataset.
    :type elevation: str or float
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Return True if successful, otherwise False
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.sa.build_terrain": """
    Create terrain based on the specified terrain construction parameter information.
    DEM (Digital Elevation Model, Digital Elevation Model) is mainly used to describe the spatial distribution of regional landforms. It is a digital terrestrial model (DTM) whose ground characteristics are elevation and elevation.
    It is usually formed by data interpolation by measuring elevation points (or sampling elevation points from contour lines). This method is used to construct terrain, that is, to generate DEM raster by interpolation for point or line datasets with elevation information.

    .. image:: ../image/BuildTerrain_1.png

    The source_datas parameter can be used to specify the dataset used to construct the terrain. It supports only elevation points, only contour lines, and supports both elevation points and contour lines.


    :param source_datas: The point dataset and line dataset used to construct, and the elevation field of the dataset. The coordinate system of the dataset is required to be the same.
    :type source_datas: dict[DatasetVector,str] or dict[str,str]
    :param lake_dataset: The lake surface dataset. In the result dataset, the elevation value in the area of the lake surface dataset is smaller than the elevation value of the neighboring neighbors.
    :type lake_dataset: DatasetVector or str
    :param str lake_altitude_field: the elevation field of the lake surface dataset
    :param clip_data: Set the dataset used for clipping. When constructing the terrain, only the DEM results in the clipping area are retained, and the parts outside the area are given no value.

                      .. image:: ../image/BuildTerrainParameter_1.png

    :type clip_data: DatasetVector or str
    :param erase_data: The dataset used for erasing. When building the terrain, the resultant DEM raster value in the erased area has no value. Only valid when interpolate_type is set to TIN.

                       .. image:: ../image/BuildTerrainParameter_2.png

    :type erase_data: DatasetVector or str
    :param interpolate_type: Terrain interpolation type. The default value is IDW.
    :type interpolate_type: TerrainInterpolateType or str
    :param float resample_len: sampling distance. Only valid for line dataset. The unit is consistent with the unit of the line dataset used to construct the terrain. Only valid when interpolate_type is set to TIN.
                         First, resample the line dataset to filter out some dense nodes, and then generate the TIN model to improve the generation speed.
    :param float z_factor: elevation zoom factor
    :param bool is_process_flat_area: Whether to deal with flat areas. Contour generation DEM can better deal with mountain tops and valleys, and point generation DEM can also deal with flat areas, but the effect is not as good as contour generation DEM processing. 
                                      The main reason is that the result of judging flat areas based on points is relatively rough.
    :param encode_type: encoding method. For raster datasets, currently supported encoding methods are unencoded, SGL, and LZW
    :type encode_type: EncodeType or str
    :param pixel_format: the pixel format of the result dataset
    :type pixel_format: PixelFormat or str
    :param float cell_size: The size of the grid cell of the result dataset. If specified as 0 or a negative number, the system will use L/500 (L is the diagonal length of the rectangle corresponding to the area range of the source dataset) as the cell Grid size.
    :param out_data: The datasource used to store the result data.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: the name of the result dataset
    :type out_dataset_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: Dataset or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.calculate_aspect": """
    Calculate the aspect and return the aspect raster dataset, which is the aspect map.
    Slope direction refers to the direction of the slope surface, which represents the steepest downslope direction somewhere on the terrain surface. The slope direction reflects the direction the slope faces. The slope direction of any slope can be any direction from 0 to 360 degrees, so the result range of slope direction calculation
     is 0 to 360 degrees. Calculate clockwise from true north (0 degrees)

    :param input_data: The specified raster dataset of the aspect to be calculated
    :type input_data: DatasetGrid or str
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.calculate_hill_shade": """
    The three-dimensional shaded map refers to a raster map that reflects the undulations of the terrain by simulating the umbra and falling shadows of the actual ground surface. By using a hypothetical light source to illuminate the ground surface and combining the slope and aspect information obtained from the raster data, the gray value of each pixel is obtained. The gray value of the slope facing the light source is higher, 
    and the gray value of the back light source is lower. It is a shaded area, which visually shows the topography and topography of the actual surface. The hillshade map calculated from raster data often has a very realistic three-dimensional effect, so it is called a three-dimensional shaded map.

    .. image:: ../image/CalculateHillShade.png

    The three-dimensional shaded map has important value in describing the three-dimensional condition of the surface and terrain analysis. When other thematic information is superimposed on the three-dimensional shaded map, the application value and intuitive effect of the three-dimensional shaded map will be improved.

    When generating a three-dimensional shaded image, you need to specify the position of the imaginary light source, which is determined by the azimuth and height angle of the light source. The azimuth angle determines the direction of the light source, and the elevation angle is the angle of inclination when the light source is illuminated. For example, when the azimuth angle of the light source is 315 degrees and the elevation angle is 45 degrees, 
    its relative position to the ground is shown in the figure below.

    .. image:: ../image/CalculateHillShade_1.png

    FIG dimensional shading of three types: rendering shadows, rendering and shading effects, through the through: py: class: `ShadowMode` specified class.

    :param input_data: The specified raster dataset of the 3D shaded image to be generated
    :type input_data: DatasetGrid or str
    :param shadow_mode: The rendering type of the 3D shaded image
    :type shadow_mode: ShadowMode or str
    :param float azimuth: The azimuth angle of the specified light source. Used to determine the direction of the light source, starting from the true north direction line where the light source is located, in a clockwise direction to the angle between the light source and the target direction line, the range is 0-360 degrees, 
                          and the true north direction is 0 degrees, in a clockwise direction Increment.

                          .. image:: ../image/Azimuth.png

    :param float altitude_angle: The altitude angle of the specified light source. Used to determine the inclination angle of the light source, it is the angle between the direction line of the light source and the target and the horizontal plane, the range is
                                 0-90 degrees. When the height angle of the light source is 90 degrees, the light source is orthorectified to the ground.

                                 .. image:: ../image/AltitudeAngle.png

    :param float z_factor: The specified elevation zoom factor. This value refers to the unit conversion coefficient of the grid value (Z coordinate, that is, the elevation value) relative to the X and Y coordinates in the grid. Usually, in calculations where X, Y, and Z are all involved, the elevation value needs to be multiplied by an elevation scaling factor to make the three units consistent. For example, the unit in the X and Y directions is meters, and the unit in the Z direction is feet. Since 1 foot is equal to 0.3048 meters, you need to specify a zoom factor of 0.3048. If it is set to 1.0, it means no scaling.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.calculate_ortho_image": """
    Generate orthographic 3D images according to the given color set.

    Orthoimages use digital differential correction technology to obtain the reasonable sunshine intensity of the current point through the elevation of neighboring grids, and perform orthoimage corrections.

    :param input_data: The specified DEM grid of the 3D orthoimage to be calculated.
    :type input_data: DatasetGrid or str
    :param colors: The set of colors after 3D projection. If the input is a dict, it indicates the corresponding relationship between the elevation value and the color value.
                It is not necessary to list all the raster values (elevation values) and their corresponding colors of the grid to be calculated in the elevation color comparison table. For the elevation values not listed in the elevation color comparison table, the color in the result image will pass Plug it out.
    :type colors: Colors or dict[float,tuple]
    :param no_value_color: color of non-value grid
    :type no_value_color: tuple or int
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.calculate_profile": """
    Profile analysis, view the profile of the DEM grid along the line according to a given line, and return the profile line and sampling point coordinates.
    Given a straight line or broken line, view the longitudinal section of the DEM grid along this line, which is called profile analysis. The result of profile analysis consists of two parts: profile line and sampling point collection.

    * Sampling point

    Profile analysis needs to select some points along a given line, and show the profile effect through the elevation and coordinate information of these points. These points are called sampling points. The sampling points are selected according to the following rules,
    Can be combined with the following figure to understand.

        -Only one sampling point is selected in each cell of a given route;
        -The nodes of a given route are all taken as sampling points;
        -If the route passes and the node is not in the cell, the intersection of the line with the larger of the two center lines of the cell is taken as the sampling point.

    .. image:: ../image/CalculateProfile_1.png

    * Collection of profile line and sampling point coordinates

    The profile line is one of the results of the profile analysis. It is a two-dimensional line (:py:class:`GeoLine` ). Its nodes correspond to the sampling points one-to-one. The X value of the node represents the current sampling point to the starting point of the given line (Also the first sampling point) straight line distance, Y value is the elevation of the current sampling point. 
    The sampling point collection gives the positions of all sampling points, and a two-dimensional collection line object is used to store these points. There is a one-to-one correspondence between the profile line and the sampling point collection. Combining the profile line and the sampling point collection can know the elevation at a certain position and the distance from the starting 
    point of the analysis.

    The following figure shows a schematic diagram of a cross-sectional line drawn in a two-dimensional coordinate system with the X value of the profile line on the horizontal axis and the Y value of the vertical axis. Through the profile line, you can intuitively understand the elevation and topography of the terrain along a given line.

    .. image:: ../image/CalculateProfile_2.png

    Note: The specified line must be within the range of the DEM grid dataset, otherwise the analysis may fail. If the sampling point is located on a grid with no value, the elevation of the corresponding point on the profile line is 0.

    :param input_data: The specified DEM grid for profile analysis.
    :type input_data: DatasetGrid or str
    :param line: The specified line is a line segment or polyline. The profile analysis gives the profile along the line.
    :type line: GeoLine
    :return: Profile analysis result, profile line and sampling point collection.
    :rtype: tuple[GeoLine, GeoLine]
    """,

    "iobjectspy._jsuperpy.analyst.sa.calculate_slope": """
    Calculate the slope and return the slope raster dataset, which is the slope map. Slope is the angle formed by the tangent plane at a certain point on the ground surface and the horizontal plane. The larger the slope value, the steeper the terrain

    note:
        When calculating the slope, the unit of the raster value (ie elevation) to be calculated is required to be the same as the unit of the x and y coordinates. If they are inconsistent, they can be adjusted by the elevation scaling factor (corresponding to the zFactor parameter in the method).
        However, note that when the conversion between the elevation value unit and the coordinate unit cannot be adjusted by a fixed value, the data needs to be processed by other means. One of the most common cases is when the DEM grid uses a geographic coordinate system,
        The unit is degrees, and the unit of elevation value is meters. At this time, it is recommended to perform projection conversion on the DEM raster and convert the x and y coordinates to plane coordinates.

    :param input_data: the specified raster dataset to be calculated slope
    :type input_data: DatasetGrid or str
    :param slope_type: unit type of slope
    :type slope_type: SlopeType or str
    :param float z_factor: The specified elevation zoom factor. This value refers to the unit conversion coefficient of the grid value (Z coordinate, that is, the elevation value) relative to the X and Y coordinates in the grid. Usually, in calculations where X, Y, and Z are all involved, the elevation value needs to be multiplied by an elevation scaling factor to make the three units consistent. For example, the unit in the X and Y directions is meters, and the unit in the Z direction is feet. Since 1 foot is equal to 0.3048 meters, you need to specify a zoom factor of 0.3048. If it is set to 1.0, it means no scaling.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str

    """,

    "iobjectspy._jsuperpy.analyst.sa.calculate_view_shed": """
    Single-point visual field analysis is to analyze the visual range of a single observation point.
    Single-point visual field analysis is to find the area that can be observed within a given range (determined by the observation radius and the observation angle) for a given observation point on the raster surface dataset, that is, to The scope of the fixed-point visibility area. The result of the analysis is a raster dataset, in which the visible area keeps the raster value of the original raster surface, and other areas have no value.

    As shown in the figure below, the green point in the figure is the observation point, and the blue area superimposed on the original grid surface is the result of the visual field analysis.

    .. image:: ../image/CalculateViewShed.png

    Note: If the elevation of the specified observation point is less than the elevation value of the corresponding position on the current grid surface, the elevation value of the observation point will be automatically set to the elevation of the corresponding position on the current grid surface.

    :param input_data: The specified raster surface dataset used for visual domain analysis.
    :type input_data: DatasetGrid or str
    :param Point3D view_point: The specified view point position.
    :param float start_angle: The specified starting observation angle, in degrees, with the true north direction being 0 degrees and rotating clockwise. Specify a negative value or greater than 360 degrees, and it will be automatically converted to the range of 0 to 360 degrees.
    :param float view_angle: The specified viewing angle, the unit is degrees, and the maximum value is 360 degrees. The observation angle is based on the starting angle, that is, the viewing angle range is [starting angle, starting angle + observation angle]. For example, if the starting angle is 90 degrees and the observation angle is 90 degrees, the actual observation angle is from 90 degrees to 180 degrees. But note that when specifying 0 or a negative value, regardless of the value of the starting angle, the viewing angle range is 0 to 360 degrees
    :param float view_radius: Specified viewing radius. This value limits the size of the field of view. If the observation radius is less than or equal to 0, it means no limit. The unit is meters
    :param out_data: The specified datasource used to store the result dataset
    :type out_data: Datasource or str
    :param str out_dataset_name: the name of the specified result dataset
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: single-point visual domain analysis result dataset
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.calculate_view_sheds": """
    Multi-point visual field analysis, that is, analyze the visual range of multiple observation points, which can be a common visual field or a non-common visual field.
    Multi-point visual field analysis is to analyze the visual field of each observation point in a given observation point set based on the grid surface, and then calculate the intersection of the visual fields of all observation points according to the specified visual field type (Referred to as "common visual field") or union (referred to as "non-common visual field"), and output the result to a raster dataset, where the visual area maintains the raster value of the original raster surface, Other areas have no value.

    As shown in the figure below, the green point in the figure is the observation point, and the blue area superimposed on the original grid surface is the result of the visual field analysis. The picture on the left shows the common visual field of three observation points, and the picture on the right shows the non-common visual field of three observation points.

    .. image:: ../image/CalculateViewShed_1.png

    Note: If the elevation of the specified observation point is less than the elevation value of the corresponding position on the current grid surface, the elevation value of the observation point will be automatically set to the elevation of the corresponding position on the current grid surface.

    :param input_data: The specified raster surface dataset used for visual domain analysis.
    :type input_data: DatasetGrid or str
    :param view_points: The set of specified observation points.
    :type view_points: list[Point3D]
    :param start_angles: The set of starting observation angles specified, corresponding to the observation point one by one. The unit is degree, and the direction of true north is 0 degree, and the rotation is clockwise. Specify a negative value or greater than 360 degrees, and it will be automatically converted to the range of 0 to 360 degrees.
    :type start_angles: list[float]
    :param view_angles: The set of specified observation angles, corresponding to the observation point and the starting observation angle one-to-one, the unit is degree, and the maximum value is 360 degrees. The observation angle is based on the starting angle, that is, the viewing angle range is [starting angle, starting angle + observation angle]. For example, if the starting angle is 90 degrees and the observation angle is 90 degrees, the actual observation angle is from 90 degrees to 180 degrees. :type view_angles: list[float]
    :param view_radiuses: The specified observation radius set, which corresponds to the observation point one by one. This value limits the size of the field of view. If the observation radius is less than or equal to 0, it means no limit. The unit is meters.
    :type view_radiuses: list[float]
    :param view_shed_type: The type of the specified visual field, which can be the intersection of the visual fields of multiple observation points, or the union of the visual fields of multiple observation points.
    :type view_shed_type: ViewShedType or str
    :param out_data: The specified datasource used to store the result dataset
    :type out_data: Datasource or str
    :param str out_dataset_name: the name of the specified result dataset
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Multi-point visual domain analysis result dataset.
    :rtype: DatasetGrid
    """,

    "iobjectspy._jsuperpy.analyst.sa.clip_raster": """
    The raster or image dataset is cropped, and the result is stored as a new raster or image dataset. Sometimes, our research scope or region of interest is small and only involves a part of the current raster data. 
    At this time, we can crop the raster data, that is, use a GeoRegion object as the crop region to crop the raster data and extract the region The internal (external) raster data generates a new dataset. In addition, 
    you can also choose to perform precise cropping or display cropping.

    :param input_data: The specified dataset to be cropped. It supports raster datasets and image datasets.
    :type input_data: DatasetGrid or DatasetImage or str
    :param clip_region: clipping region
    :type clip_region: GeoRegion or Rectangle
    :param bool is_clip_in_region: Whether to clip the dataset in the clipping region. If True, the dataset in the cropping area will be cropped; if False, the dataset outside the cropping area will be cropped.
    :param bool is_exact_clip: Whether to use precise clipping. If it is True, it means that the raster or image dataset is clipped using precise clipping, and False means that it uses display clipping:

                                -When using display cropping, the system will divide into blocks according to the size of pixels (see DatasetGrid.block_size_option, DatasetImage.block_size_option methods for details),
                                  Crop the raster or image dataset. At this time, only the data in the crop area is retained, that is, if the boundary of the crop area does not coincide with the boundary of the cell, then the cell will be divided.
                                  The part located in the clipping area will remain; the grid outside the clipping area and within the total range of the block where the part of the grid is clipped will still have grid values, but will not be displayed. This method is suitable for cutting big data.

                                -When using precise cropping, the system will determine whether to keep the cell at the boundary of the crop area according to the position of the center point of the cell covered by the crop area. If you use the in-area clipping method, the center point of the cell is in the clipping area and it will be retained, otherwise it will not be retained.

    :param out_data: the datasource where the result dataset is located or directly generate the tif file
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: The name of the result dataset. If it is set to generate tif file directly, this parameter is invalid.
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name or third-party image file path.
    :rtype: DatasetGrid or DatasetImage or str

    >>> clip_region = Rectangle(875.5, 861.2, 1172.6, 520.9)
    >>> result = clip_raster(data_dir +'example_data.udb/seaport', clip_region, True, False, out_data=out_dir +'clip_seaport.tif')
    >>> result = clip_raster(data_dir +'example_data.udb/seaport', clip_region, True, False, out_data=out_dir +'clip_out.udb')

    """,

    "iobjectspy._jsuperpy.analyst.sa.clip_vector": """
    The vector dataset is cropped and the result is stored as a new vector dataset.

    :param input_data: The specified vector dataset to be cropped. It supports point, line, surface, text, and CAD dataset.
    :type input_data: DatasetVector or str
    :param GeoRegion clip_region: the specified clipping region
    :param bool is_clip_in_region: Specify whether to clip the dataset in the clipping region. If it is True, the dataset in the cropping area will be cropped; if it is False, the dataset outside the cropping area will be cropped.
    :param bool is_erase_source: Specify whether to erase the crop area. If it is True, it means the crop area will be erased. If it is False, the crop area will not be erased.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.compute_features_envelope": """
    Calculate the rectangular area of the geometric object

    :param input_data: The dataset to be analyzed. Only line dataset and surface dataset are supported.
    :type input_data: DatasetVector or str
    :param bool is_single_part: Whether to split sub-objects when there is a combined line or combined surface. The default is True, split sub-objects.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: The result dataset, Return the range of each object. A new field "ORIG_FID" is added to the result dataset to save the ID value of the input object.
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.compute_min_distance": """
    The closest distance calculation. Calculate the minimum value of the distance between each object in the "calculated record set" and all objects in the query range in the "reference record set" (ie, the closest distance), and save the closest distance information to a new attribute table Data collection.
    The closest distance calculation function is used to calculate the distance from each object in the "calculated record set" (called the "computed object") to all the objects in the query range (called the "reference object") in the "reference record set" The minimum value in, which is the closest distance, the result of the calculation is a pure attribute table dataset, which records the distance information from the "computed object" to the nearest "reference object", and is stored using three attribute fields, namely: Source_ID (The SMID of the "computed object"), depending on the type of the reference object, it may be Point_ID, Line_ID, Region_ID (the SMID of the "reference object") and Distance (the distance between the previous two). If the object is calculated with a plurality of reference test objects with the shortest distance, the attribute table corresponding add multiple records.

    * Supported data types

      The "computed record set" only supports two-dimensional point record sets, and the "reference record set" can be a record set obtained from two-dimensional point, line, and surface dataset and two-dimensional network dataset. From the two-dimensional network dataset, you can obtain a record set with arcs, or a record set with nodes (obtained from a subset of the network dataset). These two types of record sets can be used as "reference record sets". Find the nearest edge or the nearest node.

      "Calculated record set" and "reference record set" can be the same record set, or different record sets queried from the same dataset. In these two cases, the distance from the object to itself will not be calculated.

    * Query range

      The query range is composed of a minimum distance and a maximum distance specified by the user. It is used to filter the "reference objects" that do not participate in the calculation, that is, starting from the "calculated object", only the distance between the minimum distance and the maximum distance (including Equal to) the "reference object" involved in the calculation. If the query range is set from "0" to "-1", it means calculating the closest distance to all objects in the "reference record set".

      As shown in the figure below, the red dot comes from the "calculated record set", the square comes from the "reference record set", and the pink area represents the query range, and only the blue square within the query range participates in the closest distance calculation, which means this example The result of the calculation only contains the SMID and distance value of the red dot and the closest blue square

      .. image:: ../image/ComputeDistance.png

    * Precautions:

      * The dataset to which "calculated record set" and "reference record set" belong must have the same coordinate system.

      * As shown in the figure below, the distance from the point to the line object is the minimum distance from the calculated point to the entire line object, that is, the shortest distance between the point found on the line and the calculated point; similarly, the distance from the point to the area object is the calculated point The minimum distance to the entire boundary of the area object.

        .. image:: ../image/ComputeDistance_1.png

      * When calculating the distance between two objects, the distance is 0 when it contains or (partially) overlaps. For example, if a point object is on an online object, the distance between the two is 0.

    :param source: The specified record set to be calculated. Only supports two-dimensional point record set and dataset
    :type source: DatasetVector or Recordset or str
    :param reference: The specified reference record set. Support two-dimensional point, line, area record set and dataset
    :type reference: DatasetVector or Recordset or str
    :param min_distance: The minimum distance of the specified query range. The value range is greater than or equal to 0. The unit is the same as the unit of the dataset to which the calculated record set belongs.
    :type min_distance: float
    :param max_distance: The maximum distance of the specified query range. The value range is a value greater than 0 and -1. When set to -1, it means that the maximum distance is not limited. The unit is the same as the unit of the dataset to which the calculated record set belongs.
    :type max_distance: float
    :param out_data: The specified datasource used to store the result attribute table dataset.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: The name of the specified result attribute table dataset.
    :type out_dataset_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: DatasetVector
    """,

    "iobjectspy._jsuperpy.analyst.sa.compute_point_aspect": """
    Calculate the aspect of the specified point on the DEM grid. The aspect of the specified point on the DEM grid is calculated in the same way as the aspect map (calculate_aspect method), which is that the cell where the point is located and the surrounding phase
    The 3 Ã— 3 plane formed by the eight adjacent cells is used as the calculation unit, and the horizontal elevation change rate and the vertical elevation change rate are calculated by the third-order inverse distance square weight difference method to obtain the aspect. For more introduction, please refer to the :py:meth:`calculate_aspect` method.

    note:
        When the cell of the specified point has no value, the calculation result is -1, which is different from generating an aspect map; when the specified point is outside the range of the DEM grid dataset, the calculation result is -1.

    :param input_data: The specified raster dataset of the aspect to be calculated
    :type input_data: DatasetGrid or str
    :param Point2D specified_point: The specified geographic coordinate point.
    :return: The aspect of the specified point. The unit is degrees.
    :rtype: float
    """,

    "iobjectspy._jsuperpy.analyst.sa.compute_point_slope": """
    Calculate the slope at the specified point on the DEM grid.
    The slope at a specified point on the DEM grid is calculated in the same way as the slope map (calculate_slope method). The 3 Ã— 3 plane formed by the cell where the point is located and the eight adjacent cells around it is used as the calculation unit. 
    The slope is calculated by calculating the horizontal elevation change rate and the vertical elevation change rate through the third-order inverse distance square weight difference method. For more introduction, please refer to the calculate_slope method.

    note:
        When the cell of the specified point has no value, the calculation result is -1, which is different from generating a slope map; when the specified point is outside the range of the DEM grid dataset, the calculation result is -1.

    :param input_data: The specified raster dataset of the aspect to be calculated
    :type input_data: DatasetGrid or str
    :param Point2D specified_point: The specified geographic coordinate point.
    :param slope_type: Specified slope unit type. It can be expressed in degrees, radians, or percentages. Taking the angle used as an example, the result range of the slope calculation is 0 to 90 degrees.
    :type slope_type: SlopeType or str
    :param float z_factor: The specified elevation zoom factor. This value refers to the unit transformation coefficient of the grid value (Z coordinate, that is, the elevation value) relative to the X and Y coordinates in the DEM grid. Usually, in calculations where X, Y, and Z are all involved, the elevation value needs to be multiplied by an elevation scaling factor to make the three units consistent. For example, the unit in the X and Y directions is meters, and the unit in the Z direction is feet. Since 1 foot is equal to 0.3048 meters, you need to specify a zoom factor of 0.3048. If it is set to 1.0, it means no scaling.
    :return: The slope at the specified point. The unit is the type specified by the type parameter.
    :rtype: float
    """,

    "iobjectspy._jsuperpy.analyst.sa.compute_range_distance": """
    Range distance calculation. Calculate the distance from each object in the "calculated record set" to each object in the query range in the "reference record set", and save the distance information to a new attribute table dataset.

    This function is used to calculate the distance from each object in record set A to each object in the query range in record set B. Record set A is called "computed record set", and the objects in it are called "computed object" , Record set B is called "reference record set", and the objects in it are called "reference objects". "Calculated record set" and "reference record set" can be the same record set, or different record sets queried from the same dataset. In these two cases, the distance from the object to itself will not be calculated.

    The query range is composed of a minimum distance and a maximum distance. It is used to filter the "reference objects" that do not participate in the calculation, that is, starting from the "calculated object", only those whose distance is between the minimum distance and the maximum distance (including equals) The "reference object" participates in the calculation.

    As shown in the figure below, the red dot is the "calculated object", the square is the "reference object", and the pink area represents the query range. Only the blue squares within the query range participate in the distance calculation, that is to say, the calculation in this example The result only contains the SMID and distance values of the red dot and the blue square in the pink area.

    .. image:: ../image/ComputeDistance.png

    The result of the range distance calculation is a pure attribute table dataset, which records the distance information from the "computed object" to the "reference object", and is stored in three attribute fields: Source_ID (SMID of the "computed object"), Depending on the type of the reference object, it may be Point_ID, Line_ID, Region_ID (the SMID of the "reference object"), and Distance (the distance between the previous two).

    Precautions:

     * The dataset to which "calculated record set" and "reference record set" belong must have the same coordinate system.

     * As shown in the figure below, the distance from the point to the line object is the minimum distance from the calculated point to the entire line object, that is, the shortest distance between the point found on the line and the calculated point; similarly, the distance from the point to the area object is the calculated point The minimum distance to the entire boundary of the area object.

       .. image:: ../image/ComputeDistance_1.png

     * When calculating the distance between two objects, the distance is 0 when it contains or (partially) overlaps. For example, if a point object is on an online object, the distance between the two is 0.


    :param source: The specified record set to be calculated. Only supports two-dimensional point record set or dataset
    :type source: DatasetVector or Recordset or str
    :param reference: The specified reference record set. Only supports 2D point, line, area record set or dataset
    :type reference: DatasetVector or Recordset or str
    :param min_distance: The minimum distance of the specified query range. The value range is greater than or equal to 0. The unit is the same as the unit of the dataset to which the calculated record set belongs.
    :type min_distance: float
    :param max_distance: The maximum distance of the specified query range. The value range is greater than or equal to 0, and must be greater than or equal to the minimum distance. The unit is the same as the unit of the dataset to which the calculated record set belongs.
    :type max_distance: float
    :param out_data: The specified datasource used to store the result attribute table dataset.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: The name of the specified result attribute table dataset.
    :type out_dataset_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: DatasetVector
    """,

    "iobjectspy._jsuperpy.analyst.sa.compute_range_raster": """
    Calculate the natural breakpoint break value of the raster cell value

    :param input_data: raster dataset
    :type input_data: DatasetGrid or str
    :param count: the number of natural segments
    :type count: int
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The break value of the natural segmentation (including the maximum and minimum values of the pixel)
    :rtype: Array
    """,

    "iobjectspy._jsuperpy.analyst.sa.compute_range_vector": """
    Calculate vector natural breakpoint interrupt value

    :param input_data: vector dataset
    :type input_data: DatasetVector or str
    :param value_field: standard field of the segment
    :type value_field: str
    :param count: the number of natural segments
    :type count: int
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The break value of the natural segment (including the maximum and minimum values of the attribute)
    :rtype: Array
    """,

    "iobjectspy._jsuperpy.analyst.sa.compute_surface_area": """
    Calculate the surface area, that is, calculate the total surface area of the three-dimensional surface fitted by the DEM grid in the selected polygon area.

    :param input_data: Specifies the DEM grid of the surface area to be calculated.
    :type input_data: DatasetGrid or str
    :param GeoRegion region: the specified polygon used to calculate the surface area
    :return: The value of the surface area. The unit is square meter. Return -1 to indicate that the calculation failed.
    :rtype: float
    """,

    "iobjectspy._jsuperpy.analyst.sa.compute_surface_distance": """
    Calculate the grid surface distance, that is, calculate the surface distance along the specified line segment or polyline segment on the three-dimensional surface fitted by the DEM grid.

    note:
        -The distance measured by surface measurement is on the curved surface, so it is larger than the value on the flat surface.
        -When the line used for measurement exceeds the range of the DEM grid, the line object will be clipped according to the range of the dataset, and the surface distance will be calculated according to the part of the line within the range of the dataset.

    :param input_data: The specified DEM grid of the surface distance to be calculated.
    :type input_data: DatasetGrid or str
    :param GeoLine line: The two-dimensional line used to calculate the surface distance.
    :return: The value of the surface distance. The unit is meters.
    :rtype: float
    """,

    "iobjectspy._jsuperpy.analyst.sa.compute_surface_volume": """
    Calculate the surface volume, that is, calculate the volume in the space between the three-dimensional surface fitted by the DEM grid in the selected polygon area and a reference plane.

    :param input_data: DEM grid of the volume to be calculated.
    :type input_data: DatasetGrid or str
    :param GeoRegion region: The polygon used to calculate the volume.
    :param float base_value: The value of the base plane. The unit is the same as the grid value unit of the DEM grid to be calculated.
    :return: The value of the specified datum plane. The unit is the same as the grid value unit of the DEM grid to be calculated.
    :rtype: float
    """,

    "iobjectspy._jsuperpy.analyst.sa.cost_distance": """
    According to the given parameters, a cost distance grid, a cost direction grid and a cost allocation grid are generated.

    In practical applications, the straight-line distance often cannot meet the requirements. For example, the straight-line distance from B to the nearest source A is the same as the straight-line distance from C to the nearest source A. If the traffic on the BA section is congested and the traffic on the CA section is smooth, 
    the time consumption must be different; in addition, the path corresponding to the straight-line distance It is often not feasible to reach the nearest source. For example, when you encounter obstacles such as rivers and mountains, you need to detour, and then you need to consider the distance.

    The method generates a corresponding cost from the source raster grid dataset and time-consuming, consume direction of the grid (optional) and consumption costs allocation grid (optional). The source data can be vector data (point, line, area) or raster data.
    For raster data, cells other than the identified source are required to have no value.

     * The value of the cost distance grid represents the minimum cost value from the cell to the nearest source (it can be various types of cost factors, or a weighted cost factor of interest). Nearest source
       It is the source that costs the least to reach all sources in the current cell. The cells with no value in the cost raster will still have no value in the output cost distance raster.

       The calculation method for the cost of a cell to reach the source is to start from the center of the cell to be calculated, and multiply the distance traveled by the least cost path to the nearest source on each cell by the value of the corresponding cell on the cost grid. 
       The value accumulation is the cost value from the cell to the source. Therefore, the calculation of the cost distance is related to the cell size and the cost grid. In the following schematic diagram,
       The cell size (cell_size) of the source raster and the cost raster are both 2, and the minimum cost route for the cell (2,1) to the source (0,0) is shown in the red line on the right:

       .. image:: ../image/CostDistance_1.png

       Then the minimum cost (that is, the cost distance) for cell (2,1) to reach the source is:

       .. image:: ../image/CostDistance_2.png

     * The value of the cost direction grid expresses the travel direction of the least costly path from the cell to the nearest source. In the cost direction grid, there are a total of eight possible directions of travel (true north, true south, true west, true east, northwest, southwest, southeast, and northeast), 
     and these eight directions are coded using eight integers from 1 to 8 ,As shown below. Note that the cell where the source is located has a value of 0 in the consumption direction grid, and the cells with no value in the consumption grid will be assigned a value of 15 in the output consumption direction grid.

       .. image:: ../image/CostDistance_3.png

     * The value of the cost allocation grid is the value of the nearest source of the cell (when the source is a raster, it is the value of the nearest source; when the source is a vector object, it is the SMID of the nearest source). distance. Cells with no value in the cost grid will still have no value in the 
       output cost allocation grid.

       The figure below is a schematic diagram of the generated distance. Among them, on the cost grid, the blue arrow is used to mark the travel route of the cell to the nearest source, and the value of the cost direction grid indicates the travel direction of the least cost route from the current cell to the 
       nearest source.

       .. image:: ../image/CostDistance_4.png

    The figure below is an example of generating a cost-distance raster, where the source dataset is a point dataset, and the cost raster is the reclassification result of the slope raster of the corresponding area. The cost-distance raster, cost-direction raster and cost allocation are generated Grid.

    .. image:: ../image/CostDistance.png

    :param input_data: Generate the source dataset of the distance raster. The source refers to the research object or features of interest, such as schools, roads, or fire hydrants. The dataset that contains the source is the source dataset. The source dataset can be
                        Point, line, and area datasets can also be raster datasets. The raster in the raster dataset with valid values is the source, and if there is no value, it is considered that the location has no source.
    :type input_data: DatasetVector or DatasetGrid or str
    :param DatasetGrid cost_grid: Cost grid. The grid value cannot be negative. The dataset is a raster dataset, and the value of each cell represents the unit cost when passing through this cell.
    :param float max_distance: The maximum distance of the generated distance grid, the calculation result of the grid greater than this distance is no value. If the shortest distance between cell A of a certain grid and the nearest source is greater than this value, the value of this grid in the result dataset will take no value.
    :param float cell_size: The resolution of the result dataset, which is an optional parameter for generating a distance grid
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_distance_grid_name: The name of the result distance grid dataset. If the name is empty, a valid dataset name will be automatically obtained.
    :param str out_direction_grid_name: the name of the direction raster dataset, if it is empty, no direction raster dataset will be generated
    :param str out_allocation_grid_name: the name of the allocated raster dataset, if it is empty, the allocated raster dataset will not be generated
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: If the generation is successful, return the result dataset or a tuple of dataset names, where the first is the distance raster dataset, the second is the direction raster dataset, and the third is the assigned raster dataset. If not set The name of the direction raster dataset and the name of the assigned raster dataset, 
             the corresponding value is None
    :rtype: tuple[DataetGrid] or tuple[str]
    """,

    "iobjectspy._jsuperpy.analyst.sa.cost_path": """
    According to the cost distance grid and cost direction grid, analyze the shortest path grid from the target to the nearest source.
    This method calculates the shortest path of each target object to the nearest source based on the given target dataset, and the cost distance grid and cost direction grid obtained by the function of "generate cost distance grid", that is, the minimum cost path. This method does not need to specify the dataset where the source is located,
     because the location of the source can be reflected in the distance grid and the direction grid, that is, the cell with the grid value of 0. The generated shortest path raster is a binary raster, a cell with a value of 1 represents a path, and other cells have a value of 0.

    For example, take a shopping mall (a point dataset) as the source and each residential area (a polygon dataset) as the target, and analyze how to reach the nearest shopping mall from each residential area. The realization process is, first of all
    Generate a distance grid and a direction grid for the source (shopping mall), and then use the residential area as the target area. Through the shortest path analysis, the shortest path from each residential area (target) to the nearest shopping mall (source) is obtained. The
    The shortest path has two meanings: through the straight-line distance grid and the straight-line direction grid, the smallest straight-line distance path will be obtained; through the cost distance grid and the cost direction grid, the least costly path will be obtained.

    Note that in this method, the input cost distance grid and cost direction grid must be matched, that is to say, both should be generated at the same time using the "generate cost distance grid" function. In addition, there are three ways to calculate the shortest path: pixel path, area path and single path. \
    For specific meanings, please refer to the :py:class:`.ComputeType` class.

    :param input_data: The dataset where the target is located. It can be a point, line, area, or raster dataset. If it is raster data, the cells other than the identification target are required to have no value.
    :type input_data: DatasetVector or DatasetGrid or DatasetImage or str
    :param distance_dataset: Expense distance raster dataset.
    :type distance_dataset: DatasetGrid or str
    :param direction_dataset: consumption direction raster dataset
    :type direction_dataset: DatasetGrid or str
    :param compute_type: the calculation method of the grid distance shortest path analysis
    :type compute_type: ComputeType or str
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.cost_path_line": """
    According to the given parameters, calculate the least costly path between the source point and the target point (a two-dimensional vector line object). This method is used to calculate the minimum cost path between the source point and the target point according to the given source point, target point and cost grid

    The figure below is an example of calculating the minimum cost path between two points. In this example, the reclassification result of the slope of the DEM grid is used as the cost grid to analyze the least costly path between the given source point and the target point.

    .. image:: ../image/CostPathLine.png

    :param Point2D source_point: the specified source point
    :param Point2D target_point: the specified target point
    :param DatasetGrid cost_grid: Cost grid. The grid value cannot be negative. The dataset is a raster dataset, and the value of each cell represents the unit cost when passing through this cell.
    :param smooth_method: The method of smoothing the resulting route when calculating the shortest path between two points (source and target)
    :type smooth_method: SmoothMethod or str
    :param int smooth_degree: When calculating the shortest path between two points (source and target), smooth the resulting route.
                                The greater the smoothness value, the greater the smoothness value, and the higher the smoothness of the resulting vector line. It is valid when smooth_method is not NONE. The effective value of smoothness is related to the smoothing method. The smoothing methods include B-spline method and angle grinding method:
                                -When the smoothing method is B-spline method, the effective value of smoothness is an integer greater than or equal to 2, and the recommended value range is [2,10].
                                -When the smoothing method is the angle grinding method, the smoothness represents the number of angle grinding in one smoothing process, and it is effective when set to an integer greater than or equal to 1
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :param barrier_regions: Obstacle surface dataset or surface object, which will bypass the obstacle surface during analysis
    :type barrier_regions: DatasetVector or str or GeoRegion or list[GeoRegion]
    :return: Return the line object representing the shortest path and the cost of the shortest path
    :rtype: tuple[GeoLine,float]
    """,

    "iobjectspy._jsuperpy.analyst.sa.create_buffer": """
    Create a buffer of vector datasets or recordsets.

    Buffer analysis is the process of generating one or more regions around space objects, using one or more distance values from these objects (called buffer radius) as the radius. Buffer can also be understood as an influence or service range of spatial objects.

    The basic object of buffer analysis is point, line and surface. SuperMap supports buffer analysis for two-dimensional point, line, and area datasets (or record sets) and network datasets. Among them, when performing buffer analysis on the network dataset, the edge segment is buffered. The type of buffer can analyze single buffer (or simple buffer) and multiple buffer. The following takes a simple buffer as an example to introduce the buffers of point, line and surface respectively.

    * Point buffer
      The point buffer is a circular area generated with the point object as the center and the given buffer distance as the radius. When the buffer distance is large enough, the buffers of two or more point objects may overlap. When selecting the merge buffer, the overlapping parts will be merged, and the resulting buffer is a complex surface object.

      .. image:: ../image/PointBuffer.png

    * Line buffer
      The buffer of the line is a closed area formed by moving a certain distance to both sides of the line object along the normal direction of the line object, and joining with the smooth curve (or flat) formed at the end of the line. Similarly, when the buffer distance is large enough, the buffers of two or more line objects may overlap. The effect of the merge buffer is the same as the merge buffer of points.

      .. image:: ../image/LineBuffer.png

      The buffer widths on both sides of the line object can be inconsistent, resulting in unequal buffers between left and right; you can also create a single-sided buffer only on one side of the line object. Only flat buffers can be generated at this time.

      .. image:: ../image/LineBuffer_1.png

    * Surface buffer

      The surface buffer is generated in a similar way to the line buffer. The difference is that the surface buffer only expands or contracts on one side of the surface boundary. When the buffer radius is positive, the buffer expands to the outside of the boundary of the area object; when it is negative, it shrinks inward. Similarly, when the buffer distance is large enough, the buffers of two or more line objects may overlap. You can also choose the merge buffer, the effect is the same as the merge buffer of points.

      .. image:: ../image/RegionBuffer.png

    * Multiple buffers refer to the creation of buffers with corresponding data volume around the geometric objects according to the given buffer radius. For line objects, you can also create unilateral multiple buffers, but note that the creation of network dataset is not supported.

      .. image:: ../image/MultiBuffer.png


    Buffer analysis is often used in GIS spatial analysis, and is often combined with overlay analysis to jointly solve practical problems. Buffer analysis has applications in many fields such as agriculture, urban planning, ecological protection, flood prevention and disaster relief, military, geology, and environment.

    For example, when expanding a road, you can create a buffer zone for the road according to the widening width of the road, and then superimpose the buffer layer and the building layer, and find the buildings that fall into the buffer zone and need to be demolished through overlay analysis; another example, to protect the environment And arable land, buffer analysis can be performed on wetland, forest, grassland and arable land, and industrial construction is not allowed in the buffer zone.

    Description:

    * For area objects, it is best to go through topology check before doing buffer analysis to rule out inter-plane intersections. The so-called intra-plane intersection refers to the intersection of the area object itself, as shown in the figure, the number in the figure represents the area object Node order.

    .. image:: ../image/buffer_regioninter.png

    * Explanation of "negative radius"

        * If the buffer radius is numeric, only surface data supports negative radius;
        * If the buffer radius is a field or field expression, if the value of the field or field expression is negative, the absolute value is taken for point and line data; for area data, if the buffer is merged, the absolute value is taken, if If it is not merged, it will be treated as a negative radius.


    :param input_data: The specified source vector record set for creating the buffer is a dataset. Support point, line, area dataset and record set.
    :type input_data: Recordset or DatasetVector or str
    :param distance_left: (left) the distance of the buffer. If it is a string, it indicates the field where the (left) buffer distance is located, that is, each geometric object uses the value stored in the field as the buffer radius when creating the buffer. For line objects, it represents the radius of the left buffer area, for point and area objects, it represents the buffer radius.
    :type distance_left: float or str
    :param distance_right: The distance of the right buffer. If it is a string, it means the field where the right buffer distance is located. That is, each line geometry object uses the value stored in the field as the right buffer radius when creating the buffer. This parameter is only valid for line objects.
    :type distance_right: float or str
    :param unit: Buffer distance radius unit, only distance unit is supported, angle and radian unit are not supported.
    :type unit: Unit or str
    :param end_type: The end type of the buffer. It is used to distinguish whether the endpoint of the line object buffer analysis is round or flat. For point or area objects, only round head buffer is supported
    :type end_type: BufferEndType or str
    :param int segment: The number of semicircular edge segments, that is, how many line segments are used to simulate a semicircle, must be greater than or equal to 4.
    :param bool is_save_attributes: Whether to preserve the field attributes of the object for buffer analysis. This parameter is invalid when the result face dataset is merged. That is, it is valid when the isUnion parameter is false.
    :param bool is_union_result: Whether to merge the buffers, that is, whether to merge all the buffer areas generated by each object of the source data and return. For area objects, the area objects in the source dataset are required to be disjoint.
    :param out_data: The datasource to store the result data
    :type out_data: Datasource
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.create_line_one_side_multi_buffer": """
    Create single-sided multiple buffers for vector line datasets. Please refer to: py:meth:`create_buffer` for buffer introduction.
    Single-sided multiple buffers of a line means that multiple buffers are generated on one side of the online object. The left side refers to the left side of the node sequence direction along the line object, and the right side refers to the right side of the node sequence direction.

    .. image:: ../image/LineOneSideMultiBuffer.png

    :param input_data: The specified source vector dataset for creating multiple buffers. Only support line dataset or line record set
    :type input_data: DatasetVector or Recordset
    :param radius: The specified multiple buffer radius list. The unit is specified by the unit parameter.
    :type radius: list[float] or tuple[float] or str
    :param bool is_left: Whether to generate the left buffer. Set to True to generate a buffer on the left side of the line, otherwise generate a buffer on the right side.
    :param unit: The specified buffer radius unit.
    :type unit: BufferRadiusUnit
    :param int segment: specified edge segment fitting number
    :param bool is_save_attributes: Whether to preserve the field attributes of the object for buffer analysis. This parameter is invalid when the result face dataset is merged, that is, it is valid when is_union_result is False.
    :param bool is_union_result: Whether to merge the buffers, that is, whether to merge all the buffer areas generated by each object of the source data and return.
    :param bool is_ring: Whether to generate a ring buffer. Set to True, when generating multiple buffers, the outer buffer is a ring-shaped area adjacent to the inner data; set to False, the outer buffer is an area containing the inner data.
    :param out_data: The datasource to store the result data
    :type out_data: Datasource
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.create_multi_buffer": """
    Create multiple buffers for vector datasets. For buffer introduction, please refer to: py:meth:`create_buffer`

    :param input_data: The specified source vector dataset or record set for creating multiple buffers. Support point, line, area dataset and network dataset. Analyzing the network dataset is to buffer the edges in it.
    :type input_data: DatasetVector or Recordset
    :param radius: The specified multiple buffer radius list. The unit is specified by the unit parameter.
    :type radius: list[float] or tuple[float]
    :param unit: The specified buffer radius unit.
    :type unit: BufferRadiusUnit or str
    :param int segment: Specified edge segment fitting number.
    :param bool is_save_attributes: Whether to preserve the field attributes of the object for buffer analysis. This parameter is invalid when the result face dataset is merged, that is, it is valid when is_union_result is False.
    :param bool is_union_result: Whether to merge the buffers, that is, whether to merge all the buffer areas generated by each object of the source data and return.
    :param bool is_ring: Whether to generate a ring buffer. Set to True, when generating multiple buffers, the outer buffer is a ring-shaped area adjacent to the inner data; set to False, the outer buffer is an area containing the inner data.
    :param out_data: The datasource to store the result data
    :type out_data: Datasource
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.create_thiessen_polygons": """
    Create Tyson polygons.
    The Dutch climatologist AH Thiessen proposed a method of calculating the average rainfall based on the rainfall of discretely distributed weather stations, that is, connecting all adjacent weather stations into a triangle, making the vertical bisectors of each side of these triangles.
    Therefore, several vertical bisectors around each weather station form a polygon. Use the rainfall intensity of a unique weather station contained in this polygon to represent the rainfall intensity in this polygonal area, and call this polygon the Thiessen polygon.

    Characteristics of Tyson polygons:

        -Each Tyson polygon contains only one discrete point data;
        -The distance from the point in the Tyson polygon to the corresponding discrete point is the closest;
        -The distance between the point on the edge of the Thiessen polygon and the discrete points on both sides is equal.
        -Tyson polygons can be used for qualitative analysis, statistical analysis, proximity analysis, etc. For example, the properties of discrete points can be used to describe the properties of the Thiessen polygon area; the data of discrete points can be used to calculate the data of the Thiessen polygon area
        -When judging which discrete points are adjacent to a discrete point, it can be directly derived from the Thiessen polygon, and if the Thiessen polygon is n-sided, it is adjacent to n discrete points; when a certain data point falls into When in a certain Thiessen polygon, it is closest to the corresponding discrete point, and there is no need to calculate the distance.


    Proximity analysis is one of the most basic analysis functions in the GIS field. Proximity analysis is used to discover certain proximity relationships between things. The method of proximity analysis provided by the proximity analysis class is to realize the establishment of Thiessen polygons, which is to establish the Thiessen polygons according to the provided point data, 
    so as to obtain the neighboring relationship between points. The Thiessen polygon is used to assign the surrounding area of the point in the point set to the corresponding point, so that any place located in the area owned by this point (that is, the Thiessen polygon associated with the point) is away from this point. It is smaller than the distance from other points. At the same time, 
    the established Thiessen polygon also satisfies all the theories of the above-mentioned Thiessen polygon method.

    How are Tyson polygons created? Use the following diagram to understand the process of creating a Tyson polygon:

        -Scan the point data of the Tyson polygon from left to right and from top to bottom. If the distance between a certain point and the previously scanned point is less than the given proximity tolerance, the analysis will ignore this point;
        -Establish an irregular triangulation based on all points that meet the requirements after scanning and checking, that is, constructing a Delaunay triangulation;
        -Draw the mid-perpendicular line of each triangle side. These mid-perpendicular lines form the sides of the Tyson polygon, and the intersection of the mid-perpendicular lines is the vertex of the corresponding Tyson polygon;
        -The point of the point used to create the Tyson polygon will become the anchor point of the corresponding Tyson polygon.


    :param input_data: The input point data, which can be a point dataset, a point record set or a list of :py:class:`.Point2D`
    :type input_data: DatasetVector or Recordset or list[Point2D]
    :param GeoRegion clip_region: The clipping region of the specified clipping result data. This parameter can be empty, if it is empty, the result dataset will not be cropped
    :param field_stats: The name of the statistical field and the corresponding statistical type, the input is a list, each element stored in the list is a tuple, the size of the tuple is 2, the first element is the name of the field to be counted, and the second element is statistic type.
                         When stats_fields is str, it is supported to set',' to separate multiple fields, such as "field1:SUM, field2:MAX, field3:MIN"
    :type field_stats: list[str,StatisticsType] or list[str,str] or str
    :param out_data: The datasource where the result area object is located. If out_data is empty, the generated Thiessen polygon surface geometry object will be directly returned
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: The name of the result dataset. It is valid only when out_data is not empty.
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: If out_data is empty, list[GeoRegion] will be returned, otherwise the result dataset or dataset name will be returned.
    :rtype: DatasetVector or str or list[GeoRegion]
    """,

    "iobjectspy._jsuperpy.analyst.sa.cut_fill_grid": """
    Raster fill and cut calculation refers to the calculation of the pixels corresponding to the two raster datasets before and after fill and cut.
    The surface of the earth often causes the migration of surface material due to the effects of deposition and erosion, which is manifested as the increase of surface material in some areas of the surface and the decrease of surface material in some areas. In engineering, the reduction of surface material is usually called "excavation", and the increase of surface material is called "filling".

    The calculation of raster fill and cut requires input of two raster datasets: the raster dataset before fill and cut and the raster dataset after fill and cut. Each pixel value of the generated result dataset is its two input datasets The change value of the corresponding pixel value. If the pixel value is positive, it means that the surface material at the pixel is reduced; if the pixel value is negative, it means that the surface material at the pixel is increasing. The calculation method of fill and excavation is shown in the figure below:

    .. image:: ../image/CalculationTerrain_CutFill.png

    It can be found from this figure that the result dataset = raster dataset before fill and excavation-raster dataset after fill and excavation.

    There are a few things to note about the two input raster datasets and the result dataset:

    -The two input raster datasets are required to have the same coordinates and projection system to ensure that the same location has the same coordinates. If the coordinate systems of the two input raster datasets are inconsistent, it is likely to produce incorrect results .

    -Theoretically, the spatial extent of the two input raster datasets is also the same. For two raster datasets with inconsistent spatial extents, only the results of surface filling and excavation in their overlapping areas are calculated.

    -When a cell in one of the raster datasets is a null value, the cell value in the calculation result dataset is also a null value.


    :param before_cut_fill_grid: the specified raster dataset before cut and fill
    :type before_cut_fill_grid: DatasetGrid or str
    :param after_cut_full_grid: The specified raster dataset after fill and cut.
    :type after_cut_full_grid: DatasetGrid or str
    :param out_data: The specified datasource to store the result dataset.
    :type out_data: Datasource or str
    :param out_dataset_name: The name of the specified result dataset.
    :type out_dataset_name: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: fill and excavation result information
    :rtype: CutFillResult
    """,

    "iobjectspy._jsuperpy.analyst.sa.cut_fill_oblique": """
    Calculation of slope filling and excavation.
    The incline fill and cut function is to count the amount of fill and cut required to create an incline on a terrain surface. The principle is similar to that of face selection, filling and digging.

    :param input_data: The specified raster dataset to be filled and excavated.
    :type input_data: DatasetGrid or str
    :param line3d: The specified filling and digging route
    :type line3d: GeoLine3D
    :param buffer_radius: The buffer radius of the specified fill and cut line. The unit is the same as the coordinate system unit of the raster dataset to be filled and excavated.
    :type buffer_radius: float
    :param is_round_head: Specify whether to use round head buffer to create a buffer for the fill and dig route.
    :type is_round_head: bool
    :param out_data: The specified datasource to store the result dataset
    :type out_data: Datasource or str
    :param out_dataset_name: The name of the specified result dataset.
    :type out_dataset_name: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: fill and excavation result information
    :rtype: CutFillResult
    """,

    "iobjectspy._jsuperpy.analyst.sa.cut_fill_region": """
    Calculation of selected face, fill and dig.
    When a undulating area needs to be flattened to the ground, the user can specify the undulating area and the elevation of the flattened ground, and use this method to perform surface selection, fill and excavation calculations, and calculate the filling area, 
    excavation area, and filling amount. And the amount of excavation.

    :param input_data: The specified raster dataset to be filled and excavated.
    :type input_data: DatasetGrid or str
    :param region: The designated fill and cut region.
    :type region: GeoRegion or Rectangle
    :param base_altitude: The resultant elevation of the specified fill and cut area. The unit is the same as the raster value unit of the raster dataset to be filled and excavated.
    :type base_altitude: float
    :param out_data: The specified datasource to store the result dataset.
    :type out_data: Datasource or str
    :param out_dataset_name: The name of the specified result dataset.
    :type out_dataset_name: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: fill and excavation result information
    :rtype: CutFillResult
    """,

    "iobjectspy._jsuperpy.analyst.sa.cut_fill_region3d": """
    Three-dimensional face fill and cut calculation.
    For a undulating area, you can calculate the area to be filled, the area of excavation, the amount of filling, and the amount of excavation based on the three-dimensional surface after the area is filled and excavated.

    :param input_data: The specified raster dataset to be filled and excavated.
    :type input_data: DatasetGrid or str
    :param region: The designated fill and cut region.
    :type region: GeoRegion3D
    :param out_data: The specified datasource to store the result dataset.
    :type out_data: Datasource or str
    :param out_dataset_name: The name of the specified result dataset.
    :type out_dataset_name: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: fill and excavation result information
    :rtype: CutFillResult
    """,

    "iobjectspy._jsuperpy.analyst.sa.density_interpolate": """
    Use the point density interpolation method to interpolate the point dataset or record set. Specific reference: py:meth:`interpolate` and:py:class:`.InterpolationDensityParameter`

    :param input_data: point dataset or point record set that needs interpolation analysis
    :type input_data: DatasetVector or str or Recordset
    :param str z_value_field: The name of the field that stores the value used for interpolation analysis. Interpolation analysis does not support text type fields.
    :param pixel_format: Specify the pixels stored in the result raster dataset, BIT64 is not supported
    :type pixel_format: PixelFormat or str
    :param float resolution: the resolution used during interpolation
    :param float search_radius: Find the search radius of the points involved in the operation. The unit is the same as the unit of the point dataset (or the dataset to which the record set belongs) used for interpolation. The search radius determines the search range of the points involved in the calculation. When calculating the unknown value of a certain position, the position will be the center of the circle, and the search_radius will be the radius. The sampling points within this range will participate in the calculation, that is, the position of the The predicted value is determined by the value of the sampling points in the range.
    :param int expected_count: The number of points expected to participate in the interpolation operation
    :param Rectangle bounds: The range of interpolation analysis, used to determine the range of running results
    :param float z_value_scale: The scaling ratio of the interpolation analysis value
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.dissolve": """
    Fusion refers to combining objects with the same fusion field value into a simple object or a complex object. Suitable for line objects and area objects. Sub-objects are the basic objects that make up simple objects and complex objects. A simple object consists of a sub-object,
    That is, the simple object itself; the complex object is composed of two or more sub-objects of the same type.

    :param input_data: The vector dataset to be fused. Must be a line dataset or a polygon dataset.
    :type input_data: DatasetVector or str
    :param dissolve_type: dissolve type
    :type dissolve_type: DissolveType or str
    :param dissolve_fields: Dissolve fields. Only records with the same field value of the dissolve field will be dissolved. When dissolve_fields is str, support setting',' to separate multiple fields, for example "field1,field2,field3"
    :type dissolve_fields: list[str] or str
    :param field_stats: The name of the statistical field and the corresponding statistical type. stats_fields is a list, each element in the list is a tuple, the first element of the tuple is the field to be counted, and the second element is the statistics type.
                         When stats_fields is str, it is supported to set',' to separate multiple fields, such as "field1:SUM, field2:MAX, field3:MIN"
    :type field_stats: list[tuple[str,StatisticsType]] or list[tuple[str,str]] or str
    :param str attr_filter: The filter expression of the object when the dataset is fused
    :param float tolerance: fusion tolerance
    :param bool is_null_value_able: Whether to deal with objects whose fusion field value is null
    :param bool is_preprocess: Whether to perform topology preprocess
    :param out_data: The datasource where the result data is saved. If it is empty, the result dataset is saved to the datasource where the input dataset is located.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str


    >>> result = dissolve('E:/data.udb/zones','SINGLE','SmUserID','Area:SUM', tolerance=0.000001, out_data='E:/dissolve_out.udb')

    """,

    "iobjectspy._jsuperpy.analyst.sa.divide_math_analyst": """
    Grid division operation. Divide the raster values of the two input raster datasets pixel by pixel. For the specific use of raster algebraic operations, refer to: py:meth:`expression_math_analyst`

    If the input two pixel types (PixelFormat) are integer raster datasets, then the integer type result dataset will be output; otherwise, the floating point result dataset will be output. If the pixel type accuracy of the two input raster datasets is different, 
    the pixel type of the result dataset of the operation is consistent with the higher accuracy of the two.

    :param first_operand: The specified first raster dataset.
    :type first_operand: DatasetGrid or str
    :param second_operand: The specified second raster dataset.
    :type second_operand: DatasetGrid or str
    :param GeoRegion user_region: The valid calculation region specified by the user. If it is None, it means that all areas are calculated. If the ranges of the dataset involved in the operation are inconsistent, the intersection of the ranges of all dataset will be used as the calculation area.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.dual_line_to_center_line": """

    Extract the center line from the double-line record set or dataset according to the given width.
    This function is generally used to extract the centerline of a two-lane road or river. The double lines are required to be continuous and parallel or basically parallel. The extraction effect is as shown below.

    .. image:: ../image/DualLineToCenterLine.png

    note:

     * Double lines are generally two-line roads or two-line rivers, which can be line data or surface data.
     * The max_width and min_width parameters are used to specify the maximum width and minimum width of the double line in the record set, and are used to extract the center line of the double line between the minimum and maximum width. The centerline is not extracted for the double lines that are less than the minimum width and the part greater than the maximum width, and the double lines that are greater than the maximum width are retained, and the double lines that are less than the minimum width are discarded.
     * For two-lane roads or complex intersections in two-lane rivers, such as five-forks and six-forks, or where the maximum and minimum widths of the two-lane differ greatly, the extracted results may not be ideal.

    :param source_line: The specified two-line record set or dataset. It is required to be a dataset or record set of polygon type.
    :type source_line: DatasetVector or Recordset or str
    :param max_width: The maximum width of the specified double line. Requires a value greater than 0. The unit is the same as the dataset to which the double-line record set belongs.
    :type max_width: float
    :param min_width: The minimum width of the specified double line. Requires a value greater than or equal to 0. The unit is the same as the dataset to which the double-line record set belongs.
    :type min_width: float
    :param out_data: The specified datasource used to store the result centerline dataset.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: The name of the specified result centerline dataset.
    :type out_dataset_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset object or result dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.edge_match": """
    The edge of the map frame is automatically connected to the two two-dimensional line dataset.

    :param source: Connect the edge source dataset. It can only be a two-dimensional line dataset.
    :type source: DatasetVector
    :param target: Param target data. It can only be a two-dimensional line dataset, which has the same coordinate system as the edge source data.
    :type target: DatasetVector
    :param edge_match_mode: Edge matching mode.
    :type edge_match_mode: EdgeMatchMode or str
    :param tolerance: Param tolerance. The unit is the same as the unit of the dataset to be edged.
    :type tolerance: float
    :param is_union: Whether to merge the edges.
    :type is_union: bool
    :param edge_match_line: The edge line of the data edge match. It is used to calculate the intersection when the edge connection method is the intersection position and EdgeMatchMode.THE_INTERSECTION.
                            If it is not set, the intersection will be calculated automatically according to the dataset range.
                            After setting the edge line, the endpoints of the objects that are associated with the edge will be as close to the edge line as possible.
    :type edge_match_line: GeoLine
    :param out_data: The datasource where the associated data is located.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: The name of the dataset to which the associated data is connected.
    :type out_dataset_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: If the edge connection dataset is set and the edge connection is successful, the edge connection dataset object or dataset name will be returned. If no edge connection dataset is set, no edge connection dataset will be generated, 
             and whether the connection is successful will be returned.
    :rtype: DatasetVector or str or bool
    """,

    "iobjectspy._jsuperpy.analyst.sa.eliminate": """
    Fragmented polygon merging, that is, the polygons in the dataset smaller than the specified area are merged into adjacent polygons. Currently only supports merging broken polygons into the adjacent polygon with the largest area.

    In the process of data production and processing, or after superimposing inaccurate data, some fragmented and useless polygons may be generated, called broken polygons. You can merge these broken polygons into adjacent polygons through the "Merge broken polygons" function, 
    or delete isolated broken polygons (polygons that do not intersect or tangent to other polygons) to simplify the data.

    Generally, polygons whose area is much smaller than other objects in the dataset are considered "broken polygons", usually between one millionth and one millionth of the largest area in the same dataset, but the minimum polygon tolerancecan be set according to the needs of actual research. 
     In the data shown in the figure below, there are many useless broken polygons on the boundaries of larger polygons.

    .. image:: ../image/Eliminate_1.png

    The figure below is the result of "merging broken polygons" on the data. Compared with the figure above, it can be seen that the broken polygons have been merged into the adjacent larger polygons.

    .. image:: ../image/Eliminate_2.png

    note:

        * This method is suitable for situations where two faces have a common boundary, and the common boundary will be removed after processing.
        * After merging broken polygons, the number of objects in the dataset may be reduced.


    :param source: The specified dataset to be merged by broken polygons. Only supports vector 2D surface datasets. Specifying other types of datasets will throw an exception.
    :type source: DatasetVector or str
    :param region_tolerance: The specified minimum polygon tolerance. The unit is the same as the area calculated by the system (SMAREA field). Compare the value of the SMAREA field with the tolerance value, and polygons smaller than this value will be eliminated. The value range is greater than or equal to 0. Specifying a value less than 0 will throw an exception.
    :type region_tolerance: float
    :param vertex_tolerance: The specified node tolerance. The unit is the same as the unit of the dataset for merging broken polygons. If the distance between two nodes is less than this tolerance value, the two nodes will be automatically merged into one node during the merging process. The value range is greater than or equal to 0. Specifying a value less than 0 will throw an exception.
    :type vertex_tolerance: float
    :param is_delete_single_region: Specify whether to delete isolated small polygons. If true, the isolated small polygon will be deleted, otherwise it will not be deleted.
    :type is_delete_single_region: bool
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :param group_fields: group fields, only polygons with the same field value can be merged
    :type group_fields: list[str] or tuple[str] or str
    :param priority_fields: Priority fields of the merged object, valid when the grouping field is not empty. The user can specify multiple priority fields or not, if the priority field is specified, the order of the fields will be followed.
                            When the attribute field value of the merged polygon is equal to the attribute field value of the adjacent polygon, it will be merged to the corresponding polygon. If not equal, the field value of the next priority field will be compared.
                            If all the priority field values are not equal, it will be merged into the adjacent polygon with the largest area by default.

                            For example, the user specifies three priority fields of A, B, and C
                             -When the value of the A field of the merged polygon F1 is equal to the value of the A field of the adjacent object F2, F1 is merged into F2
                             -If field A is not equal, compare the value of field B. If the value of field B of F1 is equal to the value of field B of adjacent object F2, but the value of field A of F1 is also equal to the value of field A of F3, then F1 is merged To F3, because the first field has a higher priority.
                             -If there are two objects F2 and F3 whose A field value is equal to F1's A field value, the polygon with the largest area is used by default, that is, if Area(F2)> Area(F3), then F1 is merged into F2, otherwise merged Go to F3.

                            When the priority field is empty, the maximum area principle is used, that is, the small polygons (the merged polygons) will be merged into the polygon with the largest area.
    :type priority_fields: list[str] or tuple[str] or str
    :return: Return True if the integration is successful, False if it fails
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.sa.eliminate_specified_regions": """
    Specify the ID of the polygon to be merged, and perform the operation of merging broken polygons. For related introduction about merging broken polygons, please refer to:py:meth:`.eliminate` for details.

    :param source: The specified dataset to be merged by broken polygons. Only supports vector 2D surface datasets. Specifying other types of datasets will throw an exception.
    :type source: DatasetVector or str
    :param small_region_ids: Specify the ID of the small polygon to be merged. If the specified object finds a neighboring object that meets the requirements, it will be merged into the neighboring object, and the small polygon will be deleted.
    :type small_region_ids: int or list[int] or tuple[int]
    :param float vertex_tolerance: The specified node tolerance. The unit is the same as the unit of the dataset for merging broken polygons. If the distance between the two nodes is less than this tolerance limit, the merging process will automatically
                                   Automatically merge these two nodes into one node. The value range is greater than or equal to 0. Specifying a value less than 0 will throw an exception.
    :param exclude_region_ids: Specify the IDs of the polygons to be excluded, that is, the IDs of the objects that are not involved in the operation.
    :type exclude_region_ids: int or list[int] or tuple[int]
    :param group_fields: group fields, only polygons with the same field value can be merged
    :type group_fields: list[str] or tuple[str] or str
    :param priority_fields: Priority fields of the merged object, valid when the grouping field is not empty. The user can specify multiple priority fields or not, if the priority field is specified, the order of the fields will be followed.
                            When the attribute field value of the merged polygon is equal to the attribute field value of the adjacent polygon, it will be merged to the corresponding polygon. If not equal, the field value of the next priority field will be compared.
                            If all the priority field values are not equal, the wait will be merged into the adjacent polygon with the largest area or the polygon with the largest common boundary by default.

                            For example, the user specifies three priority fields of A, B, and C
                             -When the value of the A field of the merged polygon F1 is equal to the value of the A field of the adjacent object F2, F1 is merged into F2
                             -If field A is not equal, compare the value of field B. If the value of field B of F1 is equal to the value of field B of adjacent object F2, but the value of field A of F1 is also equal to the value of field A of F3, then F1 is merged To F3, because the first field has a higher priority.
                             -If the A field value of two objects F2 and F3 is equal to the value of F1 field A, the polygon with the largest area or the polygon with the largest common boundary will be used by default.

                            When the priority field is empty, the principle of maximum area is used, that is, small polygons (merged polygons) will be merged on the polygon with the largest area or the polygon with the largest common boundary.
    :type priority_fields: list[str] or tuple[str] or str
    :param bool is_max_border: Set whether to merge objects with the maximum boundary method:
                               -If True, the specified small polygons will be merged into the longest adjacent common boundary polygon
                               -If False, the specified small polygons will be merged into the adjacent polygon with the largest area.
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Return True if the integration is successful, False if it fails
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.sa.expand": """
    Expand, return the result raster dataset.
    Expand the specified grid area by the specified number of pixels. The specified area value is regarded as the foreground area, and the remaining area values are regarded as the background area. In this way, the foreground area can be extended to the background area.
    Valueless pixels will always be treated as background pixels, so adjacent pixels of any value can be expanded to non-valued pixels, and non-valued pixels will not be expanded to adjacent pixels.

    note:

    -When there is only one type of area value, expand the value;
    -When there are multiple types of area values, the closest distance is expanded first;
    -In the case of equal distances, calculate the contribution value of each area value and expand the maximum total contribution value (the contribution value calculation method of the 4-neighborhood method and the 8-neighborhood method are different);
    -If the distance and contribution value are equal, the extended pixel value is the smallest.

    The following figure is an expanded schematic diagram:

    .. image:: ../image/expand.png

    :param source_grid: The specified dataset to be processed. The input raster must be of integer type.
    :type source_grid: DatasetGrid or str
    :param neighbour_number_method: The number of neighborhood pixels, here refers to the method used to expand the selected area. There are two expansion methods based on distance, that is, 4 pixels up, down, left, and right as neighboring pixels (FOUR), 
                                    and based on mathematical morphology, that is, 8 neighboring pixels are used as neighboring pixels (EIGHT).
    :type neighbour_number_method: NeighbourNumber or str
    :param cell_number: generalization amount. The number of pixels to be expanded in each specified area, similar to the specified number of runs, where the result of the previous run is the input of the subsequent iteration, and 
                        the value must be an integer greater than 1.
    :type cell_number: int
    :param zone_values: zone values. The cell area value to be expanded.
    :type zone_values: list[int]
    :param out_data: The specified datasource for storing the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param out_dataset_name: The name of the specified result dataset.
    :type out_dataset_name: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result raster dataset
    :rtype: DatasetGrid
    """,

    "iobjectspy._jsuperpy.analyst.sa.expression_math_analyst": """
    Raster algebra operation class. Used to provide mathematical operations and functional operations on one or more raster datasets.

    The idea of raster algebraic operation is to use algebraic viewpoints to analyze geographical features and phenomena in space. In essence, it is to perform mathematical operations and functional operations on multiple raster datasets (DatasetGrid). The pixel value of the result raster is calculated from the value of one or more input pixels 
    at the same position of the raster through algebraic rules.

    Many functions in raster analysis are based on raster algebra operations. As the core content of raster analysis, raster algebra operations are very versatile and can help us solve various types of practical problems. For example, in the calculation of the amount of fill and excavation in a construction project, 
    the DEM grid before and after the implementation of the project can be subtracted from the result grid to obtain the elevation difference before and after the construction, and the pixel value of the result grid Multiplying the actual area represented by the pixel, you can know the amount of filling and excavation of the project; 
    another example, if you want to extract the area with the average rainfall of 20 mm and 50 mm across the country in 2000, you can pass The relational expression of "20<average annual rainfall<50" is obtained by computing the raster data of annual average rainfall.

    There are two main ways to perform raster algebra operations through this type of method:

        -Use the basic calculation methods provided by this class. This class provides six methods for basic operations, including plus (addition), minus (subtraction), multiply (multiplication),
          divide (division operation), to_int (rounding operation) and to_float (floating point operation). Using these methods can complete the arithmetic operation of one or more grid data corresponding to the grid value. 
          For relatively simple calculations, you can call these methods multiple times, such as (A/B)-(A/C).
        -Execute calculation expressions. Using expressions can not only implement operator operations on one or more raster datasets, but also perform functional operations. Operators include arithmetic operators, relational operators and Boolean operators,
          Arithmetic operations mainly include addition (+), subtraction (-), multiplication (*), and division (/); Boolean operations mainly include and (And), or (Or), exclusive or (Xor), and not (Not); relations Operations mainly include
          =, <, >, <>, >=, <=. Note that there are three possible output results for Boolean operations and relational operations: true=1, false=0, and no value (as long as there is an input value of no value, the result is no value).

    In addition, it also supports 21 commonly used function operations, as shown in the following figure:

    .. image:: ../image/MathAnalyst_Function.png


    Perform raster algebraic operation expressions and support custom expression raster operations. Through custom expressions, arithmetic operations, conditional operations, logical operations, functional operations (common functions, trigonometric functions), and compound operations can be performed.
    The composition of raster algebraic operation expressions needs to follow the following rules:

        -The operation expression should be a string of the form:

            [DatasourceAlias1.Raster1] + [DatasourceAlias2.Raster2]
            Use "[datasource alias.dataset name]" to specify the raster dataset participating in the operation; pay attention to use square brackets to enclose the name.

        -Raster algebraic operation supports four operators ("+", "-", "*", "/"), conditional operators (">", ">=", "<", "<=" ," <>", "==" ), logical operators ("|", "&", "Not()", "^") and some common mathematical functions ("abs()", "acos()", "asin()", "atan()", "acot()", "cos()", "cosh()", "cot()", "exp()", "floor()", "mod (,)", "ln()", "log()", "pow(,)", "sin()", "sinh()", "sqrt()", "tan()", "tanh ()", "Isnull()", "Con(,,)", "Pick(,,,..)").
        -The functions in the expression of algebraic operations can be nested, and the grid results calculated by the conditional operator are all binary values (such as greater than, less than, etc.), that is, the ones that meet the conditions are replaced by 1, and those that are not satisfied are used. Instead of 0, if you want to use other values to represent the values that meet the conditions and those that do not meet the conditions, you can use the condition extraction function Con(,,). For example: "Con(IsNull([SURFACE_ANALYST.Dem3]) ,100,Con([SURFACE_ANALYST.Dem3]> 100,[SURFACE_ANALYST.Dem3] ,-9999)) ", the meaning of this expression is: raster dataset Dem3 In the datasource aliased as SURFACE_ANALYST, change the grid with no value to 100. In the remaining grids, the value greater than 100 remains unchanged, and the value less than or equal to 100 is changed to -9999.
        -If there are negative values less than zero in the raster calculation, please add parentheses, such as: [DatasourceAlias1.Raster1]-([DatasourceAlias2.Raster2]).
        -In the expression, the operand connected by the operator can be a raster dataset, or a number or a mathematical function.
        -The argument of a mathematical function can be a numeric value, a certain dataset, or an operation expression of one dataset or multiple dataset.
        -The expression must be a single-line expression without carriage return.
        -The expression must contain at least one input raster dataset.

    note:

        -If the pixel types (PixelFormat) of the two datasets involved in the calculation are different, the pixel type of the result dataset of the calculation is consistent with the higher precision of the two. For example, if one is a 32-bit integer and the other is a single-precision floating-point type, then after the addition operation, the pixel type of the result dataset will be a single-precision floating-point type.
        -For the no-value data in the raster dataset, if no value is ignored, the result will still be no value regardless of the operation; if no value is not ignored, it means that no value will participate in the operation. For example, two raster datasets A and B are added together. A cell in A has no value with a value of -9999, and B corresponds to a cell with a value of 3000. If no value is ignored, the cell value of the calculation result is -6999 .

    :param str expression: Custom raster operation expression.
    :param pixel_format: The pixel format of the specified result dataset. Note that if the accuracy of the specified pixel type is lower than the accuracy of the pixel type of the raster dataset involved in the operation, the operation result may be incorrect.
    :type pixel_format: PixelFormat or str
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param bool is_ingore_no_value: Whether to ignore raster data without value. true means to ignore the non-valued data, that is, the non-valued grid does not participate in the operation.
    :param GeoRegion user_region: The valid calculation region specified by the user. If it is None, it means that all areas are calculated. If the ranges of the datasets involved in the operation are inconsistent, the intersection of the ranges of all datasets 
                                  will be used as the calculation area.
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str

    """,

    "iobjectspy._jsuperpy.analyst.sa.flood": """
    Calculate the submerged area of the DEM grid based on the specified elevation.
    The calculation of the submerged area is based on the DEM raster data. According to a given submerged water elevation (specified by the parameter height), it is compared with the value of the DEM raster (ie, the elevation value), where the elevation value is lower than or equal to the given The cells of the water level are all divided into the submerged area, and then the submerged area is converted to vector surface output, and the source DEM data will not be changed. Through the submerged area area object, it is easy to calculate the submerged area and area.
    The figure below is an example of calculating the submerged area when the water level reaches 200, which is formed by superimposing the original DEM data and the vector dataset (purple area) of the submerged area

    .. image:: ../image/Flood.png

    Note: The area object returned by this method is the result of merging all submerged areas.

    :param input_data: The specified DEM data for the submerged area to be calculated.
    :type input_data: DatasetGrid or str
    :param height: The specified elevation value of the water level after submergence. The cells less than or equal to this value in the DEM data will be classified into the submerged area. The unit is the same as the grid value unit of the DEM grid to be analyzed.
    :type height: float
    :param region: Specified effective calculation region. After the area is designated, the flooded area is calculated only in the area.
    :type region: GeoRegion or Rectangle
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The area object after all the submerged areas are merged
    :rtype: GeoRegion
    """,

    "iobjectspy._jsuperpy.analyst.sa.grid_basic_statistics": """
    For basic statistical analysis of raster, you can specify the type of transformation function. It is used to perform basic statistical analysis on raster datasets, including maximum, minimum, average, and standard deviation.

    When the transformation function is specified, the data used for statistics is the value obtained after the function transformation of the original raster value.

    :param grid_data: grid data to be counted
    :type grid_data: DatasetGrid or str
    :param function_type: transformation function type
    :type function_type: FunctionType or str
    :param progress: function
    :type progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: basic statistical analysis results
    :rtype: BasicStatisticsAnalystResult
    """,

    "iobjectspy._jsuperpy.analyst.sa.grid_common_statistics": """
    Commonly used statistical analysis of raster, which compares a raster dataset row by row and column by row with one (or more) raster datasets or a fixed value according to a certain comparison method, and the comparison result is a "true" pixel value If it is 1, the value of the pixel that is "false" is 0.

    A note about no value:

     * When the grid of the source dataset to be counted has no value, if no value is ignored, the statistical result grid is also no value, otherwise the no value is used to participate in the statistics; when the grid of each comparison dataset has no value ,
       If no value is ignored, the statistics (calculation of the grid to be counted and the comparison dataset) are not included in the result, otherwise the no value is used for comparison.
     * When no value does not participate in the operation (that is, no value is ignored), the value of no value in the statistical result dataset is determined by the pixel format of the result raster and is the maximum pixel value. For example, the pixel format of the result raster dataset is PixelFormat. 
      UBIT8, that is, each pixel is represented by 8 bits, and the value of no value is 255. In this method, the pixel format of the result raster is determined by the number of comparison raster datasets. The corresponding relationship among the number of datasets obtained, the pixel format of the result raster, 
      and the non-valued value in the result raster is as follows:

    .. image:: ../image/CommonStatistics.png

    :param grid_data: The specified grid data to be counted.
    :type grid_data: DatasetGrid or str
    :param compare_datasets_or_value: The specified dataset collection or fixed value for comparison. When specifying a fixed value, the unit of the fixed value is the same as that of the raster dataset to be counted.
    :type compare_datasets_or_value: list[DatasetGrid] or list[str] or float
    :param compare_type: the specified comparison type
    :type compare_type: StatisticsCompareType or str
    :param is_ignore_no_value: Specify whether to ignore no value. If it is true, that is, no value is ignored, the no value in the calculation area will not participate in the calculation, and the result grid value is still no value; if it is false, the no value in the calculation area will participate in the calculation.
    :type is_ignore_no_value: bool
    :param out_data: The datasource used to store the result data.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: the name of the result dataset
    :type out_dataset_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: statistical result raster dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.grid_extract_isoline": """
    It is used to extract contour lines from a raster dataset and save the result as a dataset.

    Contours are smooth curves or polylines connected by a series of points with the same value, such as contour lines and isotherms. The distribution of contour lines reflects the change of values on the grid surface. The denser the distribution of contour lines, the more drastic changes in the surface value of the grid. For example, if it is a contour line, the denser the gradient, the steeper the slope. On the contrary, the slope is gentler. By extracting contour lines, locations with the same values of elevation, temperature, precipitation, etc. can be found, and the distribution of contour lines can also show steep and gentle areas of change.

    As shown below, the image above is the DEM raster data of a certain area, and the image below is the contour lines extracted from the image above. The elevation information of DEM raster data is stored in each raster unit. The raster has a size. The size of the raster depends on the resolution of the raster data, that is, each raster unit represents the corresponding on the actual ground. The size of the plot, therefore, raster data cannot accurately reflect the elevation information at each location, and vector data has relatively great advantages in this respect. Therefore, the contour lines are extracted from the raster data and the grid The grid data becomes vector data, which can highlight the details of the data for easy analysis. For example, from the contour data, you can clearly distinguish the steep and relaxed parts of the terrain, and you can distinguish the ridges and valleys.

    .. image:: ../image/SurfaceAnalyst_1.png

    .. image:: ../image/SurfaceAnalyst_2.png

    SuperMap provides two methods to extract isolines:

        * EExtract equidistant contour lines by setting datum_value and interval. This method is to calculate which elevation contours to extract in the two directions before and after the reference value at the interval of the equivalence distance.
         For example, for DEM raster data with an elevation range of 15-165, set the reference value to 50 and the equidistance to 20, then the elevations of the extracted contours are: 30, 50, 70, 90, 110, 130, and 150, respectively.
        * Specify a set of Z values through the expected_z_values method, and only extract contours/surfaces whose elevation is the value in the set. For example, if the elevation range of DEM raster data is 0-1000, and the Z value set is specified as [20,300,800],
         then the extracted result will only have three isolines of 20, 300, 800 or isosurfaces composed of the three.

    note:
        * If the attributes set by the above two methods are called at the same time, only the expected_z_values method is valid, that is, only the contour of the specified value is extracted. So 
          If you want to extract equidistant contours, you cannot call the expected_z_values method.


    :param extracted_grid: The parameters required for the specified extraction operation.
    :type extracted_grid: DatasetGrid or str
    :param float interval: equivalence interval, equivalence interval is the interval value between two isoline, must be greater than 0.
    :param datum_value: Set the reference value of the contour. The reference value and the interval (interval) jointly determine which elevation contours to extract. The reference value is used as an initial starting value to generate the contour, 
                        and it is calculated in two directions at the interval of the equivalence distance, so it is not necessarily the value of the minimum contour. For example, for DEM raster data with an elevation range of 220-1550, if the reference 
                        value is 500 and the equidistance is 50, the result of extracting the contour is: the minimum contour value is 250, and the maximum contour value is 1550.

                        When expected_z_values are set at the same time, only the values set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type datum_value: float

    :param expected_z_values: The set of Z values of expected analysis results. The Z value collection stores a series of values, which is the value of the contour to be extracted. That is, only the contours whose elevation values are in the 
                              Z value set will be extracted.
                              When datum_value is set at the same time, only the value set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type expected_z_values: list[float] or str
    :param resample_tolerance: The distance tolerance factor for resampling. By resampling the extracted contour lines, the final contour data extracted can be simplified. The resampling method that SuperMap uses when extracting contours/surfaces is the light barrier 
                               method (VectorResampleType.RTBEND), which requires a resampling distance tolerance for sampling control. Its value is obtained by multiplying the resampling distance tolerance coefficient by the source raster resolution, and the value is 
                               generally 0 to 1 times the source raster resolution.

                               The distance tolerance coefficient for resampling is 0 by default, that is, no sampling is performed to ensure the correct result, but by setting reasonable parameters, the execution speed can be accelerated. The larger the tolerance value, 
                               the fewer the control points at the boundary of the contour, and the intersection of the contour may occur at this time. Therefore, it is recommended that users first use the default values to extract contours.
    
    :type resample_tolerance: float
    :param smooth_method: the method used for smoothing
    :type smooth_method: SmoothMethod or str
    :param smoothness: Set the smoothness of the isoline or isosurface. A smoothness of 0 or 1 means no smoothing is performed. The larger the value, the higher the smoothness. When extracting contour lines, smoothness can be set freely
    :type smoothness: int
    :param clip_region: The specified clip region object. If you do not need to trim the operation result, you can use the None value to replace this parameter.
    :type clip_region: GeoRegion
    :param out_data: The datasource used to store the result dataset. If it is empty, it will directly return a list of contour objects.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: The name of the specified extraction result dataset.
    :type out_dataset_name: str
    :param progress: function
    :type progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The dataset or the name of the dataset obtained by extracting the contour, or a list of contour objects.
    :rtype: DatasetVector or str or list[GeoLine]
    """,

    "iobjectspy._jsuperpy.analyst.sa.grid_extract_isoregion": """
    Used to extract isosurfaces from raster datasets.

    SuperMap provides two methods to extract isosurfaces:

    * Extract equidistant isosurfaces by setting datum_value and interval. This method is to calculate which elevation contours to extract in the two directions before and after the reference value at the interval of the equivalence distance. 
      For example, for DEM raster data with an elevation range of 15-165, set the reference value to 50 and the equidistance to 20, then the elevations of the extracted contours are: 30, 50, 70, 90, 110, 130, and 150, respectively.
      
    * Specify a set of Z values through the expected_z_values method, and only extract the isosurface whose elevation is the value in the set. For example, DEM raster data with an elevation range of 0-1000,
      Specify the Z value set as [20,300,800], then the extracted result will only have an isosurface consisting of 20, 300, and 800.

    note:

     * If the attributes set by the above two methods are called at the same time, only the setExpectedZValues method is valid, that is, only the isosurface of the specified value is extracted.
       Therefore, if you want to extract equidistant isosurfaces, you cannot call the expected_z_values method.

    :param extracted_grid: DatasetGrid or str
    :type extracted_grid: The specified raster dataset to be extracted.
    :param float interval: equivalence interval, equivalence interval is the interval value between two isolines, must be greater than 0
    :param datum_value: Set the reference value of the contour. The reference value and the interval (interval) jointly determine which elevation isosurfaces are to be extracted. The reference value is used as an initial starting value for generating contour lines, 
                        and is calculated in two directions before and after the equivalence distance, so it is not necessarily the minimum isosurface value. For example, for DEM raster data with an elevation range of 220-1550, if the reference value is 500 and the 
                        equidistance is 50, the result of extracting the contour is: the minimum contour value is 250, and the maximum contour value is 1550.

                        When expected_z_values are set at the same time, only the values set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type datum_value: float
    :param expected_z_values: The set of Z values of expected analysis results. The Z value collection stores a series of values, which is the value of the contour to be extracted. That is, only the contours whose elevation 
                            values are in the Z value set will be extracted.
                              When datum_value is set at the same time, only the value set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type expected_z_values: list[float] or str
    :param resample_tolerance: The distance tolerance factor for resampling. By resampling the extracted contour lines, the final contour data extracted can be simplified. The resampling method that SuperMap uses when extracting 
                               contours/surfaces is the light barrier method (VectorResampleType.RTBEND), which requires a resampling distance tolerance for sampling control. Its value is obtained by multiplying the resampling distance 
                               tolerance coefficient by the source raster resolution, and the value is generally 0 to 1 times the source raster resolution.
                               
                               The distance tolerance coefficient for resampling is 0 by default, that is, no sampling is performed to ensure the correct result, but by setting reasonable parameters, the execution speed can be accelerated. 
                               The larger the tolerance value, the fewer the control points at the boundary of the contour, and the intersection of the contour may occur at this time. Therefore, it is recommended that users first use the default 
                               values to extract contours.
    :type resample_tolerance: float
    :param smooth_method: the method used for smoothing
    :type smooth_method: SmoothMethod or str
    :param smoothness: For isosurface extraction, the method of first extracting the isoline and then generating the isosurface is adopted. If the smoothness is set to 2, the intermediate result dataset, that is, 
                       the number of points of the isoline object will be 2 of the original dataset. When the smoothness setting value continues to increase, the number of points will increase exponentially by 2, 
                       which will greatly reduce the efficiency of isosurface extraction and may even lead to extraction failure.
                       
    :type smoothness: int
    :param clip_region: The specified clip region object.
    :type clip_region: GeoRegion
    :param out_data: The datasource used to store the result dataset. If it is empty, it will directly return the isosurface object list
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: The name of the specified extraction result dataset.
    :type out_dataset_name: str
    :param progress: function
    :type progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The dataset or dataset name obtained by extracting the isosurface, or the list of isosurface objects
    :rtype: DatasetVector or str or list[GeoRegion]
    """,

    "iobjectspy._jsuperpy.analyst.sa.grid_neighbour_statistics": """
    Statistical analysis of the grid neighborhood.

    Neighborhood statistical analysis is to count the pixels in the specified extended area of each pixel in the input dataset, 
    and use the result of the calculation as the value of the pixel. Statistical methods include: sum, maximum, minimum, mode, minority, median, etc., 
    please refer to the GridStatisticsMode enumeration type. The currently provided neighborhood range types (see NeighbourShapeType enumeration type) are: 
    rectangle, circle, ring, and sector.

    The figure below shows the principle of neighborhood statistics. Assuming that "sum" is used as the statistical method to do rectangular neighborhood statistics, the neighborhood size is 3Ã—3, then for the cell located in the second row and third column in the figure,
    Its value is determined by the sum of all pixel values in a 3Ã—3 rectangle that is diffused around it as the center.


    .. image:: ../image/NeighbourStatistics.png

    The application of neighborhood statistics is very extensive. E.g:

    * Calculate the biological species in each neighborhood (statistical method: species) on the grid representing the distribution of species species, so as to observe the species abundance in the area;
    * Calculate the slope difference in the neighborhood on the slope grid (statistical method: value range) to evaluate the terrain undulations in the area;

      .. image:: ../image/NeighbourStatistics_1.png

    * Neighborhood statistics are also used in image processing, such as counting the average value (called mean filtering) or median (called median filtering) in the neighborhood to achieve a smoothing effect, thereby removing noise or excessive details, etc. Wait.

      .. image:: ../image/NeighbourStatistics_2.png


    :param grid_data: The specified grid data to be counted.
    :type grid_data: DatasetGrid or str
    :param neighbour_shape: neighborhood shape
    :type neighbour_shape: NeighbourShape
    :param is_ignore_no_value: Specify whether to ignore no value. If it is true, that is, no value is ignored, the no value in the calculation area will not participate in the calculation, and the result grid value is still no value; if it is false, the no value in the calculation area will participate in the calculation.
    :type is_ignore_no_value: bool
    :param grid_stat_mode: Statistical method of neighborhood analysis
    :type grid_stat_mode: GridStatisticsMode or str
    :param unit_type: unit type of neighborhood statistics
    :type unit_type: NeighbourUnitType or str
    :param out_data: The datasource used to store the result data.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: the name of the result dataset
    :type out_dataset_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: statistical result raster dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.idw_interpolate": """
    Use IDW interpolation method to interpolate point dataset or record set. Specific reference: py:meth:`interpolate` and:py:class:`.InterpolationIDWParameter`

    :param input_data: point dataset or point record set that needs interpolation analysis
    :type input_data: DatasetVector or str or Recordset
    :param str z_value_field: The name of the field that stores the value used for interpolation analysis. Interpolation analysis does not support text type fields.
    :param pixel_format: Specify the pixels stored in the result raster dataset, BIT64 is not supported
    :type pixel_format: PixelFormat or str
    :param float resolution: the resolution used during interpolation
    :param search_mode: During interpolation operation, find the way to participate in the operation. Does not support QUADTREE
    :type search_mode: SearchMode or str
    :param float search_radius: Find the search radius of the points involved in the operation. The unit is the same as the unit of the point dataset (or the dataset to which the record set belongs) used for interpolation. The search radius determines the search range of the points involved in the calculation. When calculating the unknown value of a certain position, the position will be the center of the circle, and the search_radius will be the radius. The sampling points within this range will participate in the calculation, that is, the position of the The predicted value is determined by the value of the sampling points in the range.
                                If you set search_mode to KDTREE_FIXED_COUNT and specify the range of points involved in the search, when the number of points in the search range is less than the specified number of points, it is assigned a null value, and when the number of points in the search range is greater than the specified number of points, the nearest to the interpolation point is returned Specify the number of points for interpolation.
    :param int expected_count: The number of points expected to participate in the interpolation operation. If search_mode is set to KDTREE_FIXED_RADIUS, and the number of points participating in the interpolation operation is specified at the same time, when the number of points in the search range is less than the specified number of points, a null value is assigned.
    :param int power: The power of distance weight calculation. The lower the power value, the smoother the interpolation result, and the higher the power value, the more detailed the interpolation result. This parameter should be a value greater than 0. If you do not specify this parameter, the method sets it to 1 by default.
    :param Rectangle bounds: The range of interpolation analysis, used to determine the range of running results
    :param float z_value_scale: The scaling ratio of the interpolation analysis value
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.integrate": """
    Integration, to capture the nodes within the tolerance range together. Larger node tolerances may cause overlapping of features or deletion of surface and line objects, and may also cause nodes that are not expected to move.
    Therefore, when selecting the tolerance value, a reasonable tolerance value should be set according to the actual situation.

    Note: The integration function will directly modify the source dataset.

    :param source: The specified dataset to be integrated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param tolerance: The specified node tolerance.
    :type tolerance: float
    :param unit: The specified node tolerance unit.
    :type unit: Unit or str
    :param progress:
    :type progress: function
    :return: progress information processing function, please refer to:py:class:`.StepEvent`
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.sa.interpolate": """
    Interpolation analysis class. This class provides interpolation analysis function, which is used to interpolate discrete point data to obtain a raster dataset. Interpolation analysis can use limited sampling point data to predict the numerical situation around the sampling point through interpolation.
    In order to grasp the overall distribution of data in the study area, the discrete points sampled not only reflect the numerical value of their location, but also reflect the numerical distribution of the area.

    Why is interpolation required?

    Because of the spatial correlation between the geographical space elements, that is, things that are adjacent to each other tend to be homogeneous, that is, have the same or similar characteristics. For example, if it rains on one side of the street, then the other side of the street is In most cases, it must be raining. 
    If in a larger area, the climate of one township should be the same as the climate of another township that borders it, etc. Based on this reasoning, we can use the information of known locations. To indirectly obtain the information of other places adjacent to it, interpolation analysis is based on this idea, and it is 
    also one of the important application values of interpolation.

    Interpolating sampling point data in a certain area to generate raster data is actually rasterizing the research area according to a given grid size (resolution). Each grid unit in the raster data corresponds to a region. The value of a grid cell is calculated by some interpolation method from the value of its neighboring sampling points. 
    Therefore, it is possible to predict the numerical value around the sampling point, and then understand the value distribution of the entire area. Among them, the interpolation methods mainly include the inverse distance weight interpolation method, the Kriging interpolation method, and the radial basis function RBF (Radial Basis Function) 
    interpolation.
    The interpolation analysis function can predict the unknown value of any geographic point data, such as elevation, rainfall, chemical concentration, noise level and so on.


    :param input_data: point dataset or point record set that needs interpolation analysis
    :type input_data: DatasetVector or str or Recordset
    :param InterpolationParameter parameter: parameter information required by the interpolation method
    :param str z_value_field: The name of the field that stores the value used for interpolation analysis. Interpolation analysis does not support text type fields.
    :param pixel_format: Specify the pixels stored in the result raster dataset, BIT64 is not supported
    :type pixel_format: PixelFormat or str
    :param float z_value_scale: The scaling ratio of the interpolation analysis value
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.interpolate_points": """
    Perform interpolation analysis on the point array and return the analysis result

    :param points: point data that needs interpolation analysis
    :type points: list[Point2D]
    :param values: The values corresponding to the point array for interpolation analysis.
    :type values: list[float]
    :param InterpolationParameter parameter: parameter information required by the interpolation method
    :param pixel_format: Specify the pixels stored in the result raster dataset, BIT64 is not supported
    :type pixel_format: PixelFormat or str
    :param PrjCoordSys prj: The coordinate system of the point array. The generated result dataset also refers to this coordinate system.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param float z_value_scale: The scaling ratio of the interpolation analysis value
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    """,

    "iobjectspy._jsuperpy.analyst.sa.inverse_cut_fill": """
    Inverse calculation of fill and excavation, that is, calculate the elevation after fill and excavation according to the given fill or excavation volume
    Back-calculation is used to solve this kind of practical problem: the raster data before filling and excavation and the volume to be filled or excavated within the data range are known to derive the elevation value after filling or excavation.
     For example, a certain area of a construction site needs to be filled, and now it is known that a certain area can provide earthwork with a volume of V, at this time, using the inverse calculation to fill and excavate, you can calculate the elevation 
     of the construction area after filling this batch of soil into the construction area. Then it can be judged whether the construction requirements are met and whether it is necessary to continue filling.. Then it can be judged whether the construction requirements are met and whether it is necessary to continue filling.

    :param input_data: The specified raster data to be filled and excavated.
    :type input_data: DatasetGrid or str
    :param float volume: The specified fill or cut volume. The value is a value greater than 0. If set to less than or equal to 0, an exception will be thrown. The unit is square meters multiplied by the grid value unit of the grid to be filled and excavated.
    :param bool is_fill: Specify whether to perform fill calculation. If it is true, it means performing fill calculation, and false means performing excavation calculation.
    :param region: The designated fill and cut region. If it is None, fill and cut calculations are applied to the entire grid area.
    :type region: GeoRegion or Rectangle
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The elevation value after filling and digging. The unit is the same as the grid value unit of the grid to be filled and excavated.
    :rtype: float
    """,

    "iobjectspy._jsuperpy.analyst.sa.is_point_visible": """
    Two-point visibility analysis is to determine whether two points are mutually visible.
    Based on the grid surface, judging whether a given observation point and the observed point are visible or not is called visibility analysis between two points. 
    There are two results of visibility analysis between two points: visible and invisible. This method returns a VisibleResult object, which is used to return the 
    result of the visibility analysis between two points, that is, whether the two points are visible or not. If they are not visible, the first obstacle point that 
    obstructs the line of sight will be returned, and the obstacle will also be given. The suggested elevation value of the point so that the point no longer obstructs 
    the line of sight.

    :param input_data: The specified raster surface dataset used for visibility analysis.
    :type input_data: DatasetGrid or str
    :param from_point: The specified starting point for visibility analysis, that is, the observation point
    :type from_point: Point3D
    :param to_point: The specified end point for visibility analysis, that is, the observed point.
    :type to_point: Point3D
    :return: the result of the visibility analysis
    :rtype: VisibleResult
    """,

    "iobjectspy._jsuperpy.analyst.sa.kernel_density": """
    Perform kernel density analysis on the point dataset or line dataset, and return the analysis result.
    Kernel density analysis uses a kernel function to calculate the value per unit area within the neighborhood of a point or line. The result is a smooth surface with a large intermediate value and a small peripheral value, which drops to 0 at the boundary of the neighborhood.

    :param input_data: The point dataset or line dataset that needs nuclear density analysis.
    :type input_data: DatasetVector or str
    :param str value_field: The name of the field that stores the measured value used for density analysis. If None is passed, all geometric objects will be treated as 1. Text type fields are not supported.
    :param float search_radius: The search radius used to calculate the density in the neighborhood of the grid. The unit is the same as the unit of the dataset used for analysis. When calculating the unknown value of a certain grid position, 
                                the position will be taken as the center of the circle, and the value set by this attribute will be the radius. The sampling objects falling in this range will participate in the calculation, that is, the predicted 
                                value of the position will be determined by the range. Determined by the measured value of the internal sampling object. The larger the search radius, the smoother and more generalized the density grid generated. 
                                The smaller the value, the more detailed the information displayed in the generated grid.

    :param float resolution: The resolution of the raster data of the density analysis result
    :param Rectangle bounds: The range of density analysis, used to determine the range of the raster dataset obtained from the running result
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str

    >>> kernel_density(data_dir +'example_data.udb/taxi','passenger_count', 0.01, 0.001, out_data=out_dir +'density_result.udb'

    """,

    "iobjectspy._jsuperpy.analyst.sa.kriging_interpolate": """
    Use Kriging interpolation method to interpolate point dataset or record set. Specific reference: py:meth:`interpolate` and:py:class:`.InterpolationKrigingParameter`

    :param input_data: point dataset or point record set that needs interpolation analysis
    :type input_data: DatasetVector or str or Recordset
    :param str z_value_field: The name of the field that stores the value used for interpolation analysis. Interpolation analysis does not support text type fields.
    :param pixel_format: Specify the pixels stored in the result raster dataset, BIT64 is not supported
    :type pixel_format: PixelFormat or str
    :param float resolution: the resolution used during interpolation
    :param krighing_type: The algorithm type of interpolation analysis. Supports three settings: KRIGING, SimpleKRIGING, UniversalKRIGING, and KRIGING is used by default.
    :type krighing_type: InterpolationAlgorithmType or str
    :param search_mode: Search mode.
    :type search_mode: SearchMode or str
    :param float search_radius: Find the search radius of the points involved in the operation. The unit is the same as the unit of the point dataset (or the dataset to which the record set belongs) used for interpolation. The search radius determines the search range of the points involved in the calculation. 
                                When calculating the unknown value of a location, the location is the center of the circle, and search_radius is the radius. The sampling points within this range will participate in the calculation, that is, the prediction of the location The value is determined by the value of the 
                                sampling point in the range.
    :param int expected_count: The number of points expected to participate in the interpolation operation. When the search method is variable length search, it indicates the maximum number of points expected to participate in the operation.
    :param int max_point_count_in_node: The maximum number of points to find in a single block. When using QuadTree to find interpolation points, you can set the maximum number of points in a block.
    :param int max_point_count_for_interpolation: Set the maximum number of points involved in interpolation during block search. Note that this value must be greater than zero. When using QuadTree to find interpolation points, you can set the maximum number of points involved in interpolation
    :param variogram: Kriging (Kriging) interpolation type of semi-variable function. The default value is VariogramMode.SPHERICAL
    :type variogram: VariogramMode or str
    :param float angle: Rotation angle value in Kriging algorithm
    :param float mean: The average value of the interpolation field, that is, the sum of the interpolation field values of the sampling points divided by the number of sampling points.
    :param exponent: the order of the trend surface equation in the sample data used for interpolation
    :type exponent: Exponent or str
    :param float nugget: Nugget effect value.
    :param float range_value: Autocorrelation threshold.
    :param float sill: abutment value
    :param Rectangle bounds: The range of interpolation analysis, used to determine the range of running results
    :param float z_value_scale: The scaling ratio of the interpolation analysis value
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.line_of_sight": """
    Calculate the line of sight between two points, that is, calculate the visible and invisible parts of the line of sight from the observation point to the target point based on the terrain.
    According to the ups and downs of the terrain, calculating which segments of the line of sight from the observation point to the target point are visible or invisible is called calculating the line of sight between two points. The line between the observation point and the target point is called the line of sight.
    The line of sight can help understand which locations can be seen at a given point, and can serve for tourism route planning, the site selection of radar stations or signal transmission stations, and military activities such as the deployment of positions and observation posts.

    .. image:: ../image/LineOfSight.png

    The elevation of the observation point and the target point is determined by their Z value. When the Z value of the observation point or the target point is less than the elevation value of the corresponding cell on the grid surface, the grid value of the cell is used as the elevation of the observation 
    point or the target point to calculate the line of sight.

    The result of calculating the line of sight between two points is a two-dimensional line object array, the 0th element of the array is a visible line object, and the first element is an invisible line object. The length of the array may be 1 or 2. This is because the invisible line object may not exist. 
    At this time, the result array contains only one object, that is, the line-of-sight object. Since the visible line (or the invisible line) may be discontinuous, the visible or invisible line object may be a complex line object.

    :param input_data: The specified raster surface dataset.
    :type input_data: DatasetGrid or str
    :param from_point: The specified observation point is a three-dimensional point object.
    :type from_point: Point3D
    :param to_point: The specified target point is a three-dimensional point object.
    :type to_point: Point3D
    :return: The result is a two-dimensional line array
    :rtype: list[GeoLine]
    """,

    "iobjectspy._jsuperpy.analyst.sa.majority_filter": """
    Mode filtering, Return the result raster dataset.
    The cell value of the raster is replaced according to the mode of the adjacent cell value. The majority filter tool must meet two conditions to perform the replacement. 
    The number of adjacent pixels with the same value must be sufficient (up to half of all pixels or more), and these pixels must be continuous around the filter kernel. 
    The second condition is related to the spatial connectivity of the pixel, and the purpose is to minimize the damage to the spatial pattern of the pixel.

    Special cases:

    -Angular pixels: 2 adjacent pixels in the case of 4 neighborhoods, 3 adjacent pixels in the case of 8 neighborhoods. At this time, two or more consecutive same values can be replaced;
    -Edge pixels: In the case of 4 neighborhoods, there are 3 adjacent pixels. In this case, 2 consecutive pixels and more than the same value can be replaced; In the case of 8-neighborhood, there are 5 adjacent pixels. 
    At this time, 3 or more and at least one pixel must be on the edge to be replaced.
    -Equal to half: When two values are both half, it will not be replaced if one of the values is the same as the pixel, but not replaced at will.

    The figure below is a schematic diagram of mode filtering.

    .. image:: ../image/majorityFilter.png

    :param source_grid: The specified dataset to be processed. The input raster must be of integer type.
    :type source_grid: DatasetGrid or str
    :param neighbour_number_method: The number of neighborhood pixels. There are two selection methods: 4 pixels up, down, left, and right as adjacent pixels (FOUR), 
                                    and 8 adjacent pixels as adjacent pixels (EIGHT).
    :type neighbour_number_method: str or NeighbourNumber
    :param majority_definition: majority definition, that is, specify the number of adjacent (spatially connected) pixels that must have the same value before replacing, refer to:py:class:`.MajorityDefinition` for details.
    :type majority_definition: str or MajorityDefinition
    :param out_data: The specified datasource for storing the result dataset.
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param out_dataset_name: The name of the specified result dataset.
    :type out_dataset_name: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset
    :rtype: DatasetGrid
    """,

    "iobjectspy._jsuperpy.analyst.sa.minus_math_analyst": """
    Raster subtraction operation. Subtract the raster value of the second dataset from the raster value of the first raster dataset on a pixel-by-cell basis. When performing this operation, the order of the input raster dataset is important, and the order is different, and the result is usually different. For the specific use of raster algebraic operations, refer to: py:meth:`expression_math_analyst`

    If the input two pixel types (PixelFormat) are integer raster datasets, then the integer type result dataset will be output; otherwise, the floating point result dataset will be output. If the pixel type accuracy of the two input raster datasets is different, 
    the pixel type of the result dataset of the operation is consistent with the higher accuracy of the two.

    :param first_operand: The specified first raster dataset.
    :type first_operand: DatasetGrid or str
    :param second_operand: The specified second raster dataset.
    :type second_operand: DatasetGrid or str
    :param GeoRegion user_region: The valid calculation region specified by the user. If it is None, it means that all areas are calculated. If the ranges of the dataset involved in the operation are inconsistent, the intersection of the ranges of all dataset will be used as the calculation area.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str

    """,

    "iobjectspy._jsuperpy.analyst.sa.multiply_math_analyst": """
    Grid multiplication operation. Multiply the raster values of the two input raster datasets pixel by pixel. For the specific use of raster algebraic operations, refer to: py:meth:`expression_math_analyst`

    If the input two pixel types (PixelFormat) are integer raster datasets, then the integer type result dataset will be output; otherwise, the floating point result dataset will be output. 
    If the pixel type accuracy of the two input raster datasets is different, the pixel type of the result dataset of the operation is consistent with the higher accuracy of the two.
    
    :param first_operand: The specified first raster dataset.
    :type first_operand: DatasetGrid or str
    :param second_operand: The specified second raster dataset.
    :type second_operand: DatasetGrid or str
    :param GeoRegion user_region: The valid calculation region specified by the user. If it is None, it means that all areas are calculated. If the ranges of the dataset involved in the operation are inconsistent, the intersection of the ranges of all dataset will be used as the calculation area.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str

    """,

    "iobjectspy._jsuperpy.analyst.sa.nibble": """
    Nibble, return the result raster dataset.

    Replace the raster cell value within the mask with the value of the nearest neighbor. Nibble can assign the value of the nearest neighbor to the selected area in the raster, and can be used to edit areas in a raster with known data errors.

    Generally speaking, the valueless pixels in the mask grid define which pixels are nibbled. Any position in the input raster that is not within the mask will not be eaten away.

    The picture below is a schematic diagram of cannibalization:

    .. image:: ../image/nibble.png

    :param source_grid: The specified dataset to be processed. The input raster can be integer or floating point.
    :type source_grid: DatasetGrid or str
    :param mask_grid: The specified raster dataset as the mask.
    :type mask_grid: DatasetGrid or str
    :param zone_grid: The zone grid. If there is an area raster, the pixels in the mask will only be replaced by the nearest pixels (unmasked values) in the same area in the area raster. 
                      Area refers to the same value in the raster.
    :type zone_grid: DatasetGrid or str
    :param bool is_mask_no_value: Whether to select the non-valued pixels in the mask to be eaten away. True means that the valueless pixel is selected to be eroded, that is, the original grid value that has no value in 
                                  the mask is replaced with the value of the nearest neighbor, and the valued pixel remains unchanged in the original grid; False means that the valued pixel is selected to be eroded, that is, 
                                  the value of the original raster corresponding to the value in the mask is replaced with the value of the nearest neighboring area, and the valueless pixel remains unchanged in the original raster. 
                                  Generally use the first case more.
    :param bool is_nibble_no_value: Whether to modify the non-valued data in the original grid. True indicates that the valueless pixels in the input raster are still valueless in the output; False indicates that the valueless pixels in the 
                                    input raster in the mask can be cannibalized into valid output pixel values
    :param out_data: The specified datasource for storing the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param out_dataset_name: The name of the specified result dataset.
    :type out_dataset_name: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return:
    :rtype: DatasetGrid
    """,

    "iobjectspy._jsuperpy.analyst.sa.overlay": """
    Overlay analysis is used to perform various overlay analysis operations between the two input dataset or record sets, such as clip, erase, union, intersect, identity,xOR and update. 
    Overlay analysis is a very important spatial analysis function in GIS. It refers to the process of generating a new dataset through a series of set operations on two datasets under the unified spatial reference system. Overlay analysis is widely used in resource management, urban construction assessment, 
    land management, agriculture, forestry and animal husbandry, statistics and other fields. Therefore, through this superposition analysis class, the processing and analysis of spatial data can be realized, the new spatial geometric information required by the user can be extracted, and the attribute information 
    of the data can be processed.

        -The two dataset for overlay analysis are called the input dataset (called the first dataset in SuperMap GIS), and its type can be point, line, area, etc.; the other is called overlay The dataset of the dataset (referred to as the second dataset in SuperMap GIS) is generally a polygon type.
        -It should be noted that the polygon dataset or record set itself should avoid including overlapping areas, otherwise the overlay analysis results may be wrong.
        -The data for overlay analysis must be data with the same geographic reference, including input data and result data.
        -In the case of a large amount of data for overlay analysis, it is necessary to create a spatial index on the result dataset to improve the display speed of the data
        -All the results of overlay analysis do not consider the system fields of the dataset

    requires attention:
        -When source_input is a dataset, overlay_input can be a dataset, a record set, and a list of surface geometry objects
        -When source_input is a record set, overlay_input can be a dataset, a record set, and a list of surface geometric objects
        -When source_input is a list of geometric objects, overlay_input can be a list of datasets, record sets and surface geometric objects
        -When source_input is a list of geometric objects, valid result datasource information must be set


    :param source_input: The source data of the overlay analysis, which can be a dataset, a record set, or a list of geometric objects. When the overlay analysis mode is update, xor and union, the source data only supports surface data.
                         When the overlay analysis mode is clip, intersect, erase and identity, the source data supports point, line and surface.
    :type source_input: DatasetVector or Recordset or list[Geometry]
    :param overlay_input: The overlay data involved in the calculation must be surface type data, which can be a dataset, a record set, or a list of geometric objects
    :type overlay_input: DatasetVector or Recordset or list[Geometry]
    :param overlay_mode: overlay analysis mode
    :type overlay_mode: OverlayMode or str
    :param source_retained: The fields that need to be retained in the source dataset or record set. When source_retained is str, support setting',' to separate multiple fields, for example "field1,field2,field3"
    :type source_retained: list[str] or str
    :param overlay_retained: The fields that need to be retained for the overlay data involved in the calculation. When overlay_retained is str, it is supported to set',' to separate multiple fields, such as "field1,field2,field3".
                             Invalid for CLIP and ERASE
    :type overlay_retained: list[str] or str
    :param float tolerance: Tolerance value of overlay analysis
    :param out_data: The datasource where the result data is saved. If it is empty, the result dataset is saved to the datasource where the overlay analysis source dataset is located.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :param output_type: The type of the result dataset. For the intersection of faces, you can choose to return a point dataset.
    :type output_type: str or OverlayAnalystOutputType
    :param bool is_support_overlap_in_layer: Whether to support objects with overlapping faces in the dataset. 
                                             The default is False, that is, it is not supported. If there is overlap in the face dataset, the overlay analysis result may have errors. 
                                             If it is set to True, a new algorithm will be used for calculation to support the recurrence of overlap in the face dataset
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.path_line": """
    According to the distance grid and the direction grid, the shortest path (a two-dimensional vector line object) from the target point to the nearest source is analyzed. This method analyzes the shortest path from a given target point to the nearest source based on the distance grid and the direction grid. The distance grid and the direction grid can be a cost distance grid and a cost direction grid, or a surface distance grid and a surface direction grid.

        -When the distance grid is a cost distance grid and the direction grid is a cost direction grid, this method calculates the least cost path. The cost distance grid and cost direction grid can be generated by the costDistance method. Note that this method requires both to be the result of the same generation.
        -When the distance grid is a surface distance grid and the direction grid is a surface direction grid, this method calculates the shortest surface distance path. The surface distance grid and the surface direction grid can be generated by the surfaceDistance method. Similarly, this method requires both to be the result of the same generation.

    The location of the source can be reflected in the distance grid and the direction grid, that is, the cell with a grid value of 0. There can be one source or multiple sources. When there are multiple sources, the shortest path is the path from the destination point to its nearest source.

    The following figure shows the source, surface grid, cost raster and target point. The cost raster is the result of reclassification after calculating the slope of the surface raster.

    .. image:: ../image/PathLine_2.png

    Use the source and surface grids as shown in the figure above to generate the surface distance grid and the surface direction grid, and then calculate the shortest surface distance path from the target point to the nearest source; use the source and cost grid to generate the cost distance grid and cost direction grid Grid, and then calculate the least costly path from the target point to the nearest source. The resulting path is shown in the figure below:

    .. image:: ../image/PathLine_3.png


    :param Point2D target_point: The specified target point.
    :param DatasetGrid distance_dataset: The specified distance grid. It can be a cost distance grid or a surface distance grid.
    :param DatasetGrid direction_dataset: The specified direction grid. Corresponding to the distance grid, it can be a consumption direction grid or a surface direction grid.
    :param smooth_method: The method of smoothing the resulting route when calculating the shortest path between two points (source and target)
    :type smooth_method: SmoothMethod or str
    :param int smooth_degree: When calculating the shortest path between two points (source and target), smooth the resulting route.
                                The greater the smoothness value, the greater the smoothness value, and the higher the smoothness of the resulting vector line. It is valid when smooth_method is not NONE. The effective value of smoothness is related to the smoothing method. The smoothing methods include B-spline method and angle grinding method:
                                -When the smoothing method is B-spline method, the effective value of smoothness is an integer greater than or equal to 2, and the recommended value range is [2,10].
                                -When the smoothing method is the angle grinding method, the smoothness represents the number of angle grinding in one smoothing process, and it is effective when set to an integer greater than or equal to 1
    :return: Return the line object representing the shortest path and the cost of the shortest path
    :rtype: tuple[GeoLine,float]
    """,

    "iobjectspy._jsuperpy.analyst.sa.plus_math_analyst": """
    Grid addition operation. Add the raster values of the two input raster datasets pixel by pixel. For the specific use of raster algebraic operations, refer to: py:meth:`expression_math_analyst`

    If the input two pixel types (PixelFormat) are integer raster datasets, then the integer type result dataset will be output; otherwise, the floating point result dataset will be output. If the pixel type accuracy of the two input raster datasets is different, 
    the pixel type of the result dataset of the operation is consistent with the higher accuracy of the two.

    :param first_operand: The specified first raster dataset.
    :type first_operand: DatasetGrid or str
    :param second_operand: The specified second raster dataset.
    :type second_operand: DatasetGrid or str
    :param GeoRegion user_region: The valid calculation region specified by the user. If None, the calculation represents the entire area, if the operation involved in the range of inconsistent dataset, the dataset used all ranges calculated as the intersection region domain.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.point3ds_extract_isoline": """
    It is used to extract contour lines from a set of 3D points and save the result as a dataset. The realization principle of the method is to first use the three-dimensional information (elevation or temperature, etc.) 
    stored in the point set, that is, data other than the coordinate information of the point, to perform interpolation analysis on the point data to obtain a raster dataset (the intermediate result of the method implementation, 
    The raster value is single-precision floating-point type), and then the contours are extracted from the raster dataset.

    Point data extraction isoline introduction reference: py:meth:`point_extract_isoline`

    note:

     * When extracting contours (surfaces) from point data (point dataset/record set/three-dimensional point collection), if the resolution of the intermediate result raster obtained by interpolation is too small, it will cause the extraction of contours (surfaces) to fail . 
       Here is a judgment method: divide the length and width of the Bounds of the point data by the set resolution, which is the number of rows and columns of the intermediate result grid. If any of the number of rows and columns is greater than 10000, it is considered that 
       the resolution is set too small , The system will throw an exception at this time
       the resolution is set too small , The system will throw an exception at this time

    :param extracted_points: Specifies the point string of the contour to be extracted. The points in the point string are three-dimensional points. Each point stores X, Y coordinate information and only one three-dimensional information (for example: elevation information, etc.).
    :type extracted_points: list[Point3D]
    :param resolution: The resolution of the specified intermediate result (raster dataset).
    :type resolution: float
    :param float interval: equivalence interval, equivalence interval is the interval value between two isolines, must be greater than 0
    :param terrain_interpolate_type: terrain interpolation type.
    :type terrain_interpolate_type: TerrainInterpolateType or str
    :param datum_value: Set the reference value of the contour. The reference value and the interval (interval) jointly determine which elevation contours to extract. The reference value is used as an initial starting value to generate the contour, and it is calculated in two directions 
                        at the interval of the equivalence distance, so it is not necessarily the value of the minimum contour. For example, for DEM raster data with an elevation range of 220-1550, if the reference value is 500 and the equidistance is 50, the result of extracting the contour is: 
                        the minimum contour value is 250, and the maximum contour value is 1550.

                        When expected_z_values are set at the same time, only the values set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type datum_value: float
    :param expected_z_values: The set of Z values of expected analysis results. The Z value collection stores a series of values, which is the value of the contour to be extracted. That is, only the contours whose elevation 
                              values are in the Z value set will be extracted.
                              When datum_value is set at the same time, only the value set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type expected_z_values: list[float] or str
    :param resample_tolerance: The distance tolerance factor for resampling. By resampling the extracted contour lines, the final contour data extracted can be simplified. The resampling method that SuperMap uses when extracting contours/surfaces 
                               is the light barrier method (VectorResampleType.RTBEND), which requires a resampling distance tolerance for sampling control. Its value is obtained by multiplying the resampling distance tolerance coefficient by the 
                               source raster resolution, and the value is generally 0 to 1 times the source raster resolution.
                               
                               The distance tolerance coefficient for resampling is 0 by default, that is, no sampling is performed to ensure the correct result, but by setting reasonable parameters, the execution speed can be accelerated. 
                               The larger the tolerance value, the fewer the control points at the boundary of the contour, and the intersection of the contour may occur at this time. Therefore, it is recommended that users first use the default 
                               values to extract contours.
    :type resample_tolerance: float
    :param smooth_method: the method used for smoothing
    :type smooth_method: SmoothMethod or str
    :param smoothness: Set the smoothness of the isoline or isosurface. A smoothness of 0 or 1 means no smoothing is performed. The larger the value, the higher the smoothness. When extracting contour lines, the smoothness can be set freely;
    :type smoothness: int
    :param clip_region: The specified clip region object.
    :type clip_region: GeoRegion
    :param out_data: The datasource used to store the result dataset. If it is empty, it directly Return a list of contour objects
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: The name of the specified extraction result dataset.
    :type out_dataset_name: str
    :param progress: function
    :type progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The dataset or the name of the dataset obtained by extracting the contour, or the list of contour objects
    :rtype: DatasetVector or str or list[GeoLine]
    """,

    "iobjectspy._jsuperpy.analyst.sa.point3ds_extract_isoregion": """
    It is used to extract the isosurface from the 3D point set and save the result as a dataset. The realization principle of the method is to first use the third-dimensional information (elevation or temperature, etc.) stored in the point set, that is, 
    data other than the coordinate information of the point, and use the IDW interpolation method (InterpolationAlgorithmType.IDW) to perform interpolation analysis on the point data to obtain the grid. Grid dataset (the intermediate result of the method, 
    the raster value is single-precision floating point type), and then the isosurface is extracted from the raster dataset.

    Point data extraction isosurface introduction, refer to: py:meth:`points_extract_isoregion`

    :param extracted_points: Specifies the point string of the isosurface to be extracted. The points in the point string are three-dimensional points. Each point stores X, Y coordinate information and only one third-dimensional information (for example: elevation information, etc.) .
    :type extracted_points: list[Point3D]
    :param resolution: the resolution of the specified intermediate result (raster dataset)
    :type resolution: float
    :param float interval: equivalence interval, equivalence interval is the interval value between two isolines, must be greater than 0
    :param terrain_interpolate_type: The specified terrain interpolation type.
    :type terrain_interpolate_type: TerrainInterpolateType or str
    :param datum_value: Set the reference value of the contour. The reference value and the interval (interval) jointly determine which elevation isosurfaces are to be extracted. The reference value is used as an initial starting value for generating contour lines, 
                        and is calculated in two directions before and after the equivalence distance, so it is not necessarily the minimum isosurface value. For example, for DEM raster data with an elevation range of 220-1550, if the reference value is 500 and the 
                        equidistance is 50, the result of extracting the contour is: the minimum contour value is 250, and the maximum contour value is 1550.

                        When expected_z_values are set at the same time, only the values set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type datum_value: float
    :param expected_z_values: TThe set of Z values of expected analysis results. The Z value collection stores a series of values, which is the value of the contour to be extracted. That is, only the contours whose elevation values are 
                              in the Z value set will be extracted.
                              
                              When datum_value is set at the same time, only the value set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type expected_z_values: list[float] or str
    :param resample_tolerance: The distance tolerance factor for resampling. By resampling the extracted contour lines, the final contour data extracted can be simplified. The resampling method that SuperMap uses when extracting contours/surfaces 
                               is the light barrier method (VectorResampleType.RTBEND), which requires a resampling distance tolerance for sampling control. Its value is obtained by multiplying the resampling distance tolerance coefficient by the 
                               source raster resolution, and the value is generally 0 to 1 times the source raster resolution.
                               
                               The distance tolerance coefficient for resampling is 0 by default, that is, no sampling is performed to ensure the correct result, but by setting reasonable parameters, the execution speed can be accelerated. 
                               The larger the tolerance value, the fewer the control points at the boundary of the contour, and the intersection of the contour may occur at this time. Therefore, it is recommended that users first use the default
                                values to extract contours.
    :type resample_tolerance: float
    :param smooth_method: the method used for smoothing
    :type smooth_method: SmoothMethod or str
    :param smoothness: Set the smoothness of the isosurface. A smoothness of 0 or 1 means no smoothing is performed. The larger the value, the higher the smoothness.
                       For isosurface extraction, the method of first extracting the isoline and then generating the isosurface is adopted. If the smoothness is set to 2, 
                       the intermediate result dataset, that is, the number of points of the isoline object will be 2 of the original dataset. When the smoothness setting 
                       value continues to increase, the number of points will increase exponentially by 2, which will greatly reduce the efficiency of isosurface extraction 
                       and may even lead to extraction failure.
    :type smoothness: int
    :param clip_region: The specified clip region object.
    :type clip_region: GeoRegion
    :param out_data: The datasource used to store the result dataset. If it is empty, it will directly return the isosurface object list
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: The name of the specified extraction result dataset.
    :type out_dataset_name: str
    :param progress: function
    :type progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The dataset or dataset name obtained by extracting the isosurface, or the list of isosurface objects
    :rtype: DatasetVector or str or list[GeoRegion]
    """,

    "iobjectspy._jsuperpy.analyst.sa.point_density": """
    Perform point density analysis on the point dataset and return the analysis result.
    Simple point density analysis is to calculate the value per unit area within the specified neighborhood shape of each point. The calculation method is the specified measurement value divided by the neighborhood area. Where the neighbors of the points overlap, their density values are also added.
    The density of each output raster is the sum of the density values of all neighborhoods superimposed on the raster. The unit of the result raster value is the reciprocal of the square of the original dataset unit, that is, if the original dataset unit is meters, the unit of the result raster 
    value is per square meter. Note that for geographic coordinate datasets, the unit of the result raster value is "per square degree", which is meaningless.

    :param input_data: The point dataset or line dataset that needs nuclear density analysis.
    :type input_data: DatasetVector or str
    :param str value_field: The name of the field that stores the measured value used for density analysis. If None is passed, all geometric objects will be treated as 1. Text type fields are not supported.
    :param float resolution: The resolution of the raster data of the density analysis result
    :param neighbour_shape: Find the shape of the neighborhood for calculating the density. If the input value is str, the required format is:
                            -'CIRCLE,radius', such as'CIRCLE, 10'
                            -'RECTANGLE,width,height', such as'RECTANGLE,5.0,10.0'
                            -'ANNULUS,inner_radius,outer_radius', such as'ANNULUS,5.0,10.0'
                            -'WEDGE,radius,start_angle,end_angle', such as'WEDGE,10.0,0,45'
    :type neighbour_shape: NeighbourShape or str
    :param neighbour_unit: The unit type of neighborhood statistics. You can use grid coordinates or geographic coordinates.
    :type neighbour_unit: NeighbourUnitType or str
    :param Rectangle bounds: The range of density analysis, used to determine the range of the raster dataset obtained from the running result
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str


    >>> point_density(data_dir +'example_data.udb/taxi','passenger_count', 0.0001,'CIRCLE,0.001','MAP', out_data=out_dir +'density_result.udb')

    """,

    "iobjectspy._jsuperpy.analyst.sa.point_extract_isoline": """
    It is used to extract contour lines from a point dataset and save the result as a dataset. The realization principle of the method is similar to the method of "extracting isolines from the point dataset", the difference is that,
    The object of operation here is a point dataset. Therefore, the implementation process is to first use the IDW interpolation method ('InterpolationAlgorithmType.IDW`) to perform interpolation analysis on the point data in the point dataset to obtain the raster dataset
     (the intermediate result of the method implementation, The raster value is single-precision floating-point type), and then the contours are extracted from the raster dataset.

    The points in the point data are scattered, and the point data can represent the location information very well, but the other attribute information of the point itself cannot be expressed. For example, the elevation information of a large number of sampling points in a certain research area has been obtained, 
    as follows As shown (above), from the map, we canâ€™t see the trend of the ups and downs of the terrain. We canâ€™t see where the terrain is steep or where the terrain is flat. If we use the principle of contour lines, the information contained in the data of these points can be equal The value line is expressed in 
    the form of connecting adjacent points with the same elevation value to form the contour map shown in the figure below, then the terrain information about this area is clearly displayed. The contours extracted from different point data have different meanings, mainly based on the information represented by the point data. 
    If the value of the point represents temperature, then the extracted contour is the isotherm; if the value of the point represents rainfall, then The extracted isoline is the isoprecipitation line, and so on.

    .. image:: ../image/SurfaceAnalyst_3.png

    .. image:: ../image/SurfaceAnalyst_4.png

    note:

     * When extracting contours (surfaces) from point data (point dataset/record set/three-dimensional point collection), if the resolution of the intermediate result raster obtained by interpolation is too small, 
     it will cause the extraction of contours (surfaces) to fail . Here is a judgment method: divide the length and width of the Bounds of the point data by the set resolution, which is the number of rows and columns 
     of the intermediate result grid. If any of the number of rows and columns is greater than 10000, it is considered that the resolution is set too small , The system will throw an exception at this time

    :param extracted_point: The specified point dataset or record set to be extracted
    :type extracted_point: DatasetVector or str or Recordset
    :param z_value_field: The specified field name for extraction operation. When extracting contours, the value in this field will be used to perform interpolation analysis on the point dataset.
    :type z_value_field: str
    :param resolution: The resolution of the specified intermediate result (raster dataset).
    :type resolution: float
    :param float interval: equivalence interval, equivalence interval is the interval value between two isolines, must be greater than 0
    :param terrain_interpolate_type: terrain interpolation type.
    :type terrain_interpolate_type: TerrainInterpolateType or str
    :param datum_value: Set the reference value of the contour. The reference value and the interval (interval) jointly determine which elevation contours to extract. 
                         The reference value is used as an initial starting value to generate the contour, and it is calculated in two directions at the interval of the equivalence distance, 
                         so it is not necessarily the value of the minimum contour. For example, for DEM raster data with an elevation range of 220-1550, if the reference value is 500 and the 
                         equidistance is 50, the result of extracting the contour is: the minimum contour value is 250, and the maximum contour value is 1550.

                        When expected_z_values are set at the same time, only the values set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type datum_value: float
    :param expected_z_values: The set of Z values of expected analysis results. The Z value collection stores a series of values, which is the value of the contour to be extracted. That is, only the contours whose elevation 
                              values are in the Z value set will be extracted.
                              When datum_value is set at the same time, only the value set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type expected_z_values: list[float] or str
    :param resample_tolerance: The distance tolerance factor for resampling. By resampling the extracted contour lines, the final contour data extracted can be simplified. The resampling method used by SuperMap when extracting contours/surfaces 
                               is the light barrier method (VectorResampleType.RTBEND), which requires a resampling distance tolerance for sampling control. Its value is obtained by multiplying the resampling distance tolerance coefficient by the 
                               source raster resolution, and the value is generally 0 to 1 times the source raster resolution.

                               The distance tolerance coefficient for resampling is 0 by default, that is, no sampling is performed to ensure the correct result, but by setting reasonable parameters, the execution speed can be accelerated.
                                The larger the tolerance value, the fewer the control points at the boundary of the contour, and the intersection of the contour may occur at this time. Therefore, it is recommended that users first use the default
                                 values to extract contours.
    :type resample_tolerance: float
    :param smooth_method: the method used for smoothing
    :type smooth_method: SmoothMethod or str
    :param smoothness: Set the smoothness of the isoline or isosurface. A smoothness of 0 or 1 means no smoothing is performed. The larger the value, the higher the smoothness. When extracting contour lines, smoothness can be set freely
    :type smoothness: int
    :param clip_region: The specified clip region object.
    :type clip_region: GeoRegion
    :param out_data: The datasource used to store the result dataset. If it is empty, it will directly return a list of contour objects.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: The name of the specified extraction result dataset.
    :type out_dataset_name: str
    :param progress: function
    :type progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The dataset or the name of the dataset obtained by extracting the contour, or the list of contour objects
    :rtype: DatasetVector or str or list[GeoLine]
    """,

    "iobjectspy._jsuperpy.analyst.sa.points_extract_isoregion": """
    Used to extract isosurfaces from point dataset. The realization principle of the method is to first use the IDW interpolation method (InterpolationAlgorithmType.IDW) to perform interpolation analysis on the point dataset.
    Obtain the raster dataset (the intermediate result of the method, the raster value is single-precision floating point), and then extract the isolines from the raster dataset, and finally the isosurface is formed by the isolines.

    An isosurface is a surface that is closed by adjacent isolines. The change of the isosurface can intuitively indicate the change between adjacent contours, such as elevation, temperature, precipitation, pollution or atmospheric pressure, etc.,
     to express with the isosurface is very intuitive and effective. The effect of isosurface distribution is the same as the distribution of contour lines, and it also reflects the changes on the grid surface. The denser the isosurface distribution 
     indicates greater changes in the grid surface value, and vice versa. The value changes less; the narrower the isosurface, the greater the change in the raster surface value, and the opposite, the less the change in the raster surface value.

    As shown below, the above picture is a point dataset that stores elevation information, and the picture below is an isosurface extracted from the above point dataset. From the isosurface data, the undulations of the terrain can be clearly analyzed.
    The denser the iso-surface, the narrower the area, the steeper the terrain, on the contrary, the sparser the iso-surface, and the wider the area, the more relaxed the terrain, with less change.

    .. image:: ../image/SurfaceAnalyst_5.png

    .. image:: ../image/SurfaceAnalyst_6.png

    note:

     * When extracting isosurfaces from point data (point dataset/record set/three-dimensional point collection), if the resolution of the intermediate result raster obtained by interpolation is too small, the isosurface extraction will fail. 
     Here is a judgment method: use the length and width of the Bounds of the point data to be divided by the set resolution, which is the number of rows and columns of the intermediate result grid. If any of the number of rows and columns is greater than 10000, 
     it is considered that the resolution is set too small , The system will throw an exception at this time.

    :param extracted_point: The specified point dataset or record set to be extracted
    :type extracted_point: DatasetVector or str or Recordset
    :param z_value_field: The specified field name for extraction operation. When extracting the isosurface, the value in this field will be used to perform interpolation analysis on the point dataset.
    :type z_value_field: str
    :param float interval: equivalence interval, equivalence interval is the interval value between two isolines, must be greater than 0
    :param resolution: The resolution of the specified intermediate result (raster dataset).
    :type resolution: float
    :param terrain_interpolate_type: The specified terrain interpolation type.
    :type terrain_interpolate_type: TerrainStatisticType
    :param datum_value: Set the reference value of the contour. The reference value and the interval (interval) jointly determine which elevation isosurfaces are to be extracted.
                        The reference value is used as an initial starting value for generating contour lines, and is calculated in two directions before and after the equivalence distance, 
                        so it is not necessarily the minimum isosurface value. For example, for DEM raster data with an elevation range of 220-1550, if the reference value is 500 and the equidistance is 50, 
                        the result of extracting the contour is: the minimum contour value is 250, and the maximum contour value is 1550.

                        When expected_z_values are set at the same time, only the values set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type datum_value: float
    :param expected_z_values: The set of Z values of expected analysis results. The Z value collection stores a series of values, which is the value of the contour to be extracted. That is, only the contours whose elevation 
                              values are in the Z value set will be extracted.
                              When datum_value is set at the same time, only the value set by expected_z_values will be considered, that is, only contour lines whose elevation is these values will be extracted.
    :type expected_z_values: list[float] or str
    :param resample_tolerance: The distance tolerance factor for resampling. By resampling the extracted contour lines, the final contour data extracted can be simplified. The resampling method used by SuperMap when extracting contours/surfaces is the light barrier method
                            (VectorResampleType.RTBEND), which requires a resampling distance tolerance for sampling control. Its value is obtained by multiplying the resampling distance tolerance coefficient by the source raster resolution, and the value is generally 0 to 
                              1 times the source raster resolution.
                              
                               The distance tolerance coefficient for resampling is 0 by default, that is, no sampling is performed to ensure the correct result, but by setting reasonable parameters, the execution speed can be accelerated. The larger the tolerance value, 
                               the fewer the control points at the boundary of the contour, and the intersection of the contour may occur at this time. Therefore, it is recommended that users first use the default values to extract contours.
                               
    :type resample_tolerance: float
    :param smooth_method: the method used for smoothing
    :type smooth_method: SmoothMethod or str
    :param smoothness: Set the smoothness of the isosurface. A smoothness of 0 or 1 means no smoothing is performed. The larger the value, the higher the smoothness.
                       For isosurface extraction, the method of first extracting the isoline and then generating the isosurface is adopted. If the smoothness is set to 2, 
                       the intermediate result dataset, that is, the number of points of the isoline object will be 2 of the original dataset. When the smoothness setting 
                       value continues to increase, the number of points will increase exponentially by 2, which will greatly reduce the efficiency of isosurface extraction 
                       and may even lead to extraction failure.
    :type smoothness: int
    :param clip_region: The specified clip region object.
    :type clip_region: GeoRegion
    :param out_data: The datasource used to store the result dataset. If it is empty, it will directly return the isosurface object list
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: The name of the specified extraction result dataset.
    :type out_dataset_name: str
    :param progress: function
    :type progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: The dataset or dataset name obtained by extracting the isosurface, or the list of isosurface objects
    :rtype: DatasetVector or str or list[GeoRegion]
    """,

    "iobjectspy._jsuperpy.analyst.sa.radar_shield_angle": """
    According to the topographic map and the radar center point, return the point dataset with the largest radar occlusion angle in each position. The azimuth is the angle between clockwise and true north.

    :param input_data: deleted dataset or DEM
    :type input_data: DatasetGrid or str or list[DatasetGrid] or list[str]
    :param view_point: A three-dimensional point object, which represents the coordinates of the radar center point and the height between the radar center and the ground.
    :type view_point: Point3D
    :param float start_angle: The starting angle of the radar azimuth, the unit is degrees, the true north direction is 0 degrees, and the rotation is clockwise. The range is 0 to 360 degrees. If set to less than 0, the default value
                              Is 0; if the value is greater than 360, the default is 360.
    :param float end_angle: The end angle of the radar azimuth, the unit is degree, the maximum is 360 degrees. The viewing angle is based on the starting angle, that is, the viewing angle range is [starting angle, ending angle).
                            The value must be greater than the starting angle. If the value is less than or equal to 0, it means [0,360).
    :param float view_radius: Observation range, in meters. If it is set to less than 0, it means the entire topographic map range.
    :param float interval: The azimuth interval, that is, how many degrees to return a radar masking point. The value must be greater than 0 and less than 360.
    :param out_data: target datasource.
    :type out_data: Datasource or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: funtion
    :return: The returned 3D point dataset, Z represents the terrain height of the point. This dataset records the point with the largest radar occlusion angle in each azimuth, and adds the field "ShieldAngle",
             "ShieldPosition" and "RadarDistance" respectively record the radar shielding angle, the angle between the point and the true north direction, and the distance between the point and the radar center.
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.raster_mosaic": """
    Raster dataset mosaic. Supports raster datasets and image datasets.

    Mosaic of raster data refers to combining two or more raster data into one raster data according to geographic coordinates. Sometimes because the area to be studied and analyzed is very large, or the target objects of interest are widely distributed, and multiple raster datasets or multiple images are involved, mosaicking is required. 
    The figure below shows the mosaic of six adjacent raster data into one data.

    .. image:: ../image/Mosaic_1.png

    When performing raster data mosaic, you need to pay attention to the following points:

     * The raster to be mosaiced must have the same coordinate system
       Mosaic requires that all raster datasets or image datasets have the same coordinate system, otherwise the mosaic result may be wrong. It is possible to unify all coordinate systems with mosaic grids through projection 
       conversion before mosaicking.

     * Treatment of overlapping areas
       When mosaicking, there are often overlapping areas between two or more raster data (as shown in the figure below, the areas in the red frame of the two images overlap). At this time, it is necessary to specify the 
       value method for the grid of the overlapping area. SuperMap provides five overlapping area value methods. Users can choose the appropriate method according to actual needs. For details, see the :py:class:`.RasterJoinType` class.

       .. image:: ../image/Mosaic_2.png

     * Explanation of non-value and background color and its tolerance
       There are two types of raster data to be mosaicked: raster dataset and image dataset. For raster datasets, this method can specify non-valued and non-valued tolerances. 
       For image datasets, this method can specify the background color and its tolerances.

       * The data to be mosaicked is a raster dataset:

          * When the data to be mosaicked is a raster dataset, the cells whose raster value is the value specified by the back_or_no_value parameter, 
          and the cells within the tolerance range specified by the back_tolerance parameter are considered as no value, and these cells will not Participate 
          in the calculation during mosaic (calculation of the overlapping area), and the original non-valued cells of the raster are no longer non-valued data 
          and participate in the calculation.

          * It should be noted that the tolerance of no value is the tolerance of the value of no value specified by the user, and has nothing to do with the original no value in the grid.

       * The data to be mosaicked is an image dataset

          * When the data to be mosaicked is an image dataset, the cells whose raster value is the value specified by the back_or_no_value parameter, and the cells within the tolerance range specified by the 
          back_tolerance parameter are regarded as the background color, and these cells do not participate in mosaicking Calculation. For example, if the value of no value is specified as a and the tolerance of no value is specified as b, 
          the cells with the grid value in the range of [a-b,a+b] will not participate in calculation.

          * Note that the grid value in the image dataset represents a color. The raster values of the image dataset correspond to RGB colors, so if you want to set a certain color as the background color,
            The value specified for the back_or_no_value parameter should be the value after the color (RGB value) is converted to a 32-bit integer, and the system will perform the corresponding conversion according to the pixel format.

          * The setting of the tolerance value of the background color is the same as the specification of the value of the background color: the tolerance value is a 32-bit integer value, which is converted into three tolerances corresponding 
          to the background color R, G, and B inside the system. Limit, for example, the color specified as the background color is (100,200,60), the specified tolerance limit is 329738, the RGB value corresponding to this value is (10,8,5), 
          then the value is (90,192,55) and The colors between (110,208,65) are regarded as background colors and are not included in the calculation.

    note:

    When two or more high-pixel format rasters are mosaicked into a low-pixel format raster, the resulting raster value may exceed the value range and cause errors. Therefore, this operation is not recommended.


    :param inputs: The specified dataset to be mosaicked.
    :type inputs: list[DatasetGrid] or list[DatasetImage] list[str] or str
    :param back_or_no_value: The specified grid background color or value without value. You can use a float or tuple to represent an RGB or RGBA value
    :type back_or_no_value: float or tuple
    :param back_tolerance: The specified grid background color or tolerance without value. You can use a float or tuple to represent an RGB or RGBA value
    :type back_tolerance: float or tuple
    :param join_method: The specified mosaic method, that is, the value method of overlapping area during mosaic.
    :type join_method: RasterJoinType or str
    :param join_pixel_format: The pixel format of the specified mosaic result raster data.
    :type join_pixel_format: RasterJoinPixelFormat or str
    :param float cell_size: The cell size of the specified mosaic result dataset.
    :param encode_type: The encoding method of the specified mosaic result dataset.
    :type encode_type: EncodeType or str
    :param valid_rect: The valid range of the specified mosaic result dataset.
    :type valid_rect: Rectangle
    :param out_data: The specified datasource information used to store the mosaic result dataset
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: The name of the specified mosaic result dataset.
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: mosaic result dataset
    :rtype: Dataset
    """,

    "iobjectspy._jsuperpy.analyst.sa.raster_to_vector": """
    Convert the raster dataset to a vector dataset by specifying the conversion parameter settings.

    :param input_data: The raster dataset or image dataset to be converted
    :type input_data: DatasetGrid or DatasetImage or str
    :param str value_field: The field where the value is stored in the result vector dataset
    :param out_dataset_type: The result dataset type, supporting point, line and area dataset. When the result dataset type is line data aggregation, is_thin_raster, smooth_method, smooth_degree are valid.
    :type out_dataset_type: DatasetType or str
    :param back_or_no_value: Set the background color of the raster or a value indicating no value, which is only valid when the raster is converted to a vector. Allow users to specify a value to identify those cells that do not need to be converted:

                              -When the converted raster data is a raster dataset, the cells whose raster value is the specified value are regarded as no value, these cells will not be converted, and the original no value of the raster will be regarded as a valid value To participate in the conversion.
                              -When the converted raster data is an image dataset, the cells whose raster value is the specified value are regarded as the background color, so they will not participate in the conversion.

                             It should be noted that the raster value in the image dataset represents a color or color index value, which is related to its pixel format (PixelFormat). For BIT32, UBIT32, RGBA, RGB and BIT16

                             Format image dataset, its raster value corresponds to RGB color, you can use a tuple or int to represent RGB value or RGBA value

                             For image datasets in UBIT8 and UBIT4 format, the raster value corresponds to the index value of the color. Therefore, the value that should be set for this attribute is the index value of the color that is regarded as the background color.
    :type back_or_no_value: int or tuple
    :param back_or_no_value_tolerance: The tolerance of the grid background color or the tolerance of no value, which is only valid when the grid is converted to a vector. Used to cooperate with the back_or_no_value method (specify the grid no value or background color) to jointly determine which values in the raster data will not be converted:

                                        -When the converted raster data is a raster dataset, if the value specified as a valueless is a and the specified tolerance of no value is b, the raster value is within the range of [ab,a+b] cells were view of no value. It should be noted that the tolerance of no value is the tolerance of the value of no value specified by the user, and has nothing to do with the original no value in the grid.
                                        -When the converted raster data is an image dataset, the tolerance value is a 32-bit integer value or tuple, and the tuple is used to represent the RGB value or RGBA value.
                                        -The meaning of this value is related to the pixel format of the image dataset: for an image dataset whose raster value corresponds to RGB color, this value is converted into three tolerance values corresponding to R, G, and B within the system.
                                          For example, the color specified as the background color is (100,200,60), the specified tolerance value is 329738, and the corresponding RGB value of this value is (10,8,5), then the value is between (90,192,55) and (110,208, 65)
                                          The colors in between are all background colors; for an image dataset whose raster value is the color index value, the tolerance value is the tolerance of the color index value, and the grid values within the tolerance range are regarded as the background color.

    :type back_or_no_value_tolerance: int or float or tuple
    :param specifiedvalue: The specified raster value when the raster is converted to a vector by value. Only the raster with this value is converted to a vector.
    :type specifiedvalue: int or float or tuple
    :param specifiedvalue_tolerance: the tolerance of the specified raster value when the raster is converted to a vector by value
    :type specifiedvalue_tolerance: int or float or tuple
    :param valid_region: valid region for conversion
    :type valid_region: GeoRegion or Rectangle
    :param bool is_thin_raster: Whether to perform raster refinement before conversion.
    :param smooth_method: smooth method, only valid when the raster is converted to vector line data
    :type smooth_method: SmoothMethod or str
    :param int smooth_degree: Smoothness. The greater the smoothness value, the greater the smoothness value, and the higher the smoothness of the resulting vector line. It is valid when smooth_method is not NONE. The effective value of smoothness is related to the smoothing method. The smoothing methods include B-spline method and angle grinding method:

                                -When the smoothing method is B-spline method, the effective value of smoothness is an integer greater than or equal to 2, and the recommended value range is [2,10].
                                -When the smoothing method is the angle grinding method, the smoothness represents the number of angle grinding in one smoothing process, and it is effective when set to an integer greater than or equal to 1

    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str

    """,

    "iobjectspy._jsuperpy.analyst.sa.rbf_interpolate": """
    Use the radial basis function (RBF) interpolation method to interpolate the point dataset or record set. Specific reference: py:meth:`interpolate` and:py:class:`.InterpolationRBFParameter`

    :param input_data: point dataset or point record set that needs interpolation analysis
    :type input_data: DatasetVector or str or Recordset
    :param str z_value_field: The name of the field that stores the value used for interpolation analysis. Interpolation analysis does not support text type fields.
    :param pixel_format: Specify the pixels stored in the result raster dataset, BIT64 is not supported
    :type pixel_format: PixelFormat or str
    :param float resolution: the resolution used during interpolation
    :param search_mode: Search mode.
    :type search_mode: SearchMode or str
    :param float search_radius: Find the search radius of the points involved in the operation. The unit is the same as the unit of the point dataset (or the dataset to which the record set belongs) used for interpolation. The search radius determines the search range of the points involved in the calculation. When calculating the unknown value of a location, the location will be the center of the circle and the search_radius will be the radius. All sampling points within this range will participate in the calculation, that is, the prediction of the location The value is determined by the value of the sampling point in the range.
    :param int expected_count: The number of points expected to participate in the interpolation operation. When the search method is variable length search, it indicates the maximum number of points expected to participate in the operation.
    :param int max_point_count_in_node: The maximum number of points to find in a single block. When using QuadTree to find interpolation points, you can set the maximum number of points in a block.
    :param int max_point_count_for_interpolation: Set the maximum number of points involved in interpolation during block search. Note that this value must be greater than zero. When using QuadTree to find interpolation points, you can set the maximum number of points involved in interpolation
    :param float smooth: smoothing coefficient, the value range is [0,1]
    :param float tension: Tension coefficient
    :param Rectangle bounds: The range of interpolation analysis, used to determine the range of running results
    :param float z_value_scale: The scaling ratio of the interpolation analysis value
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str

    """,

    "iobjectspy._jsuperpy.analyst.sa.reclass_grid": """
    Raster data is reclassified and the result raster dataset is returned.
    Raster reclassification is to reclassify the raster values of the source raster data and assign values according to new classification standards. The result is to replace the original raster values of the raster data with new values. For known raster data, sometimes it is necessary to reclassify it in order to make it easier to see the trend, find the rule of raster value, or to facilitate further analysis:

        -Through reclassification, the new value can be used to replace the old value of the cell to achieve the purpose of updating the data. For example, when dealing with changes in land types, assign new grid values to wasteland that has been cultivated as cultivated land;
        -Through reclassification, a large number of grid values can be grouped and classified, and cells in the same group are given the same value to simplify the data. For example, categorize dry land, irrigated land, and paddy fields as agricultural land;
        -Through reclassification, a variety of raster data can be classified according to uniform standards. For example, if the factors affecting the location of a building include soil and slope, the input raster data of soil type and slope can be reclassified according to the grading standard of 1 to 10, which is convenient for further location analysis;
        -Through reclassification, you can set some cells that you don't want to participate in the analysis to have no value, or you can add new measured values to the cells that were originally no value to facilitate further analysis and processing.

    For example, it is often necessary to perform slope analysis on the raster surface to obtain slope data to assist in terrain-related analysis. But we may need to know which grade the slope belongs to instead of the specific slope value, to help us understand the steepness of the terrain, so as to assist in further analysis, such as site selection and road paving. At this time, you can use reclassification to divide different slopes into corresponding classes.

    :param input_data: The specified dataset used for raster resampling. Support image dataset, including multi-band images
    :type input_data: DatasetImage or DatasetGrid or str
    :param re_pixel_format: The storage type of the raster value of the result dataset
    :type re_pixel_format: ReclassPixelFormat
    :param segments: Reclassification interval collection. Reclassification interval collection. When segments are str, it is supported to use';' to separate multiple ReclassSegments, and each ReclassSegment uses',' to separate the start value, end value, new value and partition type. For example: '0,100,50,CLOSEOPEN; 100,200,150,CLOSEOPEN'
    :type segments: list[ReclassSegment] or str
    :param reclass_type: raster reclass type
    :type reclass_type: ReclassType or str
    :param bool is_retain_no_value: Whether to keep the no-value data in the source dataset as no-value
    :param float change_no_value_to: The specified value of no value data. When is_retain_no_value is set to False, the setting is valid, otherwise it is invalid.
    :param bool is_retain_missing_value: Whether the data in the source dataset that is not in the specified interval or outside the single value retain the original value
    :param float change_missing_value_to: The specified value of the grid that is not within the specified interval or single value. When is_retain_no_value is set to False, the setting is valid, otherwise it is invalid.
    :param ReclassMappingTable reclass_map: Raster reclassification mapping table class. If the object is not empty, use the value set by the object to reclassify the grid.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or DatasetImage or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.region_group": """
    Regional grouping.
    Record the identification of the connected area to which each pixel in the output belongs, and the system assigns a unique number to each area. 
    In simple terms, connect connected pixels with the same value to form an area and number it. The first area of the scan is assigned a value of 1, 
    the second area is assigned a value of 2, and so on, until all areas have been assigned. Scanning will proceed from left to right and top to bottom.

    The following figure is a schematic diagram of regional grouping:

    .. image:: ../image/regionGroup.png

    :param source_grid: The specified dataset to be processed. The input raster must be of integer type.
    :type source_grid: DatasetGird or str
    :param neighbour_number_method: The number of neighborhood pixels. There are two selection methods: up, down, left and right 4 pixels as adjacent pixels (FOUR), and adjacent 8 pixels as adjacent pixels (EIGHT).
    :type neighbour_number_method: str or NeighbourNumber
    :param bool is_save_link_value: Whether to keep the original value of the corresponding grid. If set to true, the SourceValue item is added to the attribute table to connect the original value of each pixel of the input raster; if the original value of each area is no longer needed, 
                                    it can be set to false, which will speed up the processing.
    :param bool is_link_by_neighbour: Whether to connect based on neighborhood. When set to true, connect the pixels to form an area according to the 4-neighborhood or 8-neighborhood method; when set to false, the excluded value must be set. 
                                     At this time, all connected areas except for the excluded value can form an area
    :param int exclude_value: Exclude value. The excluded raster value does not participate in the counting. On the output raster, the position of the cell containing the excluded value is assigned a value of 0. If the exclusion value is set, 
                                there is no connection information in the result attribute table.
    :param out_data: The specified datasource for storing the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param out_dataset_name: The name of the specified result dataset
    :type out_dataset_name: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result raster dataset and attribute table
    :rtype: tuple[DatasetGrid, DatasetVector]
    """,

    "iobjectspy._jsuperpy.analyst.sa.region_to_center_line": """
    Extracting the centerline of a polygon dataset or record set is generally used to extract the centerline of a river.

    This method is used to extract the center line of the area object. If the surface contains an island hole, the island hole will be bypassed during extraction and the shortest path will be used to bypass it. As shown below.

    .. image:: ../image/RegionToCenterLine_1.png

    If the area object is not a simple long strip, but has a bifurcated structure, the extracted center line is the longest segment. As shown below.

    .. image:: ../image/RegionToCenterLine_2.png


    :param region_data: The specified region record set or region dataset of the center line to be extracted
    :type region_data: Recordset or DatasetVector
    :param out_data: result datasource information or datasource object
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: the name of the result centerline dataset
    :type out_dataset_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset object or result dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.resample_raster": """
    Raster data is resampled and the result dataset is returned.

    After the raster data has undergone geometric operations such as registration, correction, projection, etc., the center position of the raster pixel will usually change. Its position in the input raster is not necessarily an integer row and column number, so it needs to be based on the output raster Based on the position of each grid in the input grid, the input grid is resampled according to certain rules, the grid value is interpolated, and a new grid matrix is established. When performing algebraic operations between raster data of different resolutions, the raster size needs to be unified to a specified resolution, and the raster needs to be resampled at this time.

    There are three common methods for raster resampling: nearest neighbor method, bilinear interpolation method and cubic convolution method. For a more detailed introduction to these three resampling methods, please refer to the ResampleMode class.

    :param input_data: The specified dataset used for raster resampling. Support image dataset, including multi-band images
    :type input_data: DatasetImage or DatasetGrid or str
    :param float new_cell_size: the cell size of the specified result grid
    :param resample_mode: Resampling calculation method
    :type resample_mode: ResampleMode or str
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetImage or DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.resample_vector": """
    Resample vector datasets, support line datasets, area datasets and network datasets. Vector data resampling is to remove some nodes according to certain rules to achieve the purpose of simplifying the data (as shown in the figure below).
    The result may be different due to the use of different resampling methods. SuperMap provides two resampling methods, please refer to:py:class:`.VectorResampleType`

    .. image:: ../image/VectorResample.png

    This method can resample line datasets, surface datasets and network datasets. When resampling the surface dataset, the essence is to resample the boundary of the surface object. For the common boundary of multiple area objects, 
    if topological preprocessing is performed, the common boundary of one of the polygons is resampled only once, the common boundary of other polygons will be adjusted according to the result of the polygon re-sampling to make it fit, so There will be no gaps.

    Note: When the resampling tolerance is too large, the correctness of the data may be affected, such as the intersection of two polygons at the common boundary.

    :param input_data: The vector dataset that needs to be resampled, support line dataset, surface dataset and network dataset
    :type input_data: DatasetVector or str
    :param float distance: Set the resampling distance. The unit is the same as the dataset coordinate system unit. The resampling distance can be set to a floating-point value greater than 0. But if the set value is less than the default value, the default value will be used. The larger the set re-sampling tolerance, the more simplified the sampling result data
    :param resample_type: Resampling method. Resampling supports the haphazard sampling algorithm and Douglas algorithm. Specific reference: py:class:`.VectorResampleType`. The aperture sampling is used by default.
    :type resample_type: VectorResampleType or str
    :param bool is_preprocess: Whether to perform topology preprocess. It is only valid for face datasets. If the dataset is not topologically preprocessed, it may cause gaps, unless it can be ensured that the node coordinates of the common line of two adjacent faces in the data are exactly the same.
    :param float tolerance: Node capture tolerance when performing topology preprocessing, the unit is the same as the dataset unit.
    :param bool is_save_small_geometry: Whether to keep small objects. A small object refers to an object with an area of 0, and a small object may be generated during the resampling process. true means to keep small objects, false means not to keep.
    :param out_data: The radius of the result datasource. If this parameter is empty, the original data will be sampled directly, that is, the original data will be changed. If this parameter is not empty, the original data will be copied to this datasource first,
                     Then sample the copied dataset. The datasource pointed to by out_data can be the same as the datasource where the source dataset is located.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: The name of the result dataset. It is valid only when out_data is not empty.
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :param bool is_save_topology: whether to save the object topology
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.shrink": """
    Shrink and return the result raster dataset.
    Shrink the selected area by the specified number of pixels by replacing the value of the area with the value of the most frequently occurring pixel in the neighborhood. The specified area value is regarded as the foreground area, 
    and the remaining area values are regarded as the background area. In this way, the pixels in the background area can be used to replace the pixels in the foreground area.

    note:

    -When there are multiple values for shrinkage, take the one that appears most frequently, and take a random value if the number of multiple values is the same;
    -Two adjacent areas are pixels to be contracted, so there is no change on the boundary;
    -No value is a valid value, that is, pixels adjacent to no value data may be replaced with no value.

    The following figure is a schematic diagram of shrinkage:

    .. image:: ../image/shrink.png

    :param source_grid: The specified dataset to be processed. The input raster must be of integer type.
    :type source_grid: DatasetGrid or str
    :param neighbour_number_method: The number of neighborhood pixels, here refers to the method used to shrink the selected area. There are two shrinking methods based on distance, that is, four pixels up, down, left, and right are used as neighboring pixels (FOUR), and based on mathematical morphology,
                                     that is, eight neighboring pixels are used as neighboring pixels (EIGHT).
    :type neighbour_number_method: NeighbourNumber or str
    :param cell_number: generalization amount. The number of pixels to shrink, similar to the specified number of runs, where the result of the previous run is the input of subsequent iterations, and the value must be an integer greater than 0.
    :type cell_number: int
    :param zone_values: zone values. The cell area value to be contracted.
    :type zone_values: list[int]
    :param out_data: The specified datasource for storing the result dataset.
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param out_dataset_name: The name of the specified result dataset.
    :type out_dataset_name: str
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result raster dataset
    :rtype: DatasetGrid
    """,

    "iobjectspy._jsuperpy.analyst.sa.simplify_building": """
    Right-angle polygon fitting of surface objects
    If the distance from a series of continuous nodes to the lower bound of the minimum area bounding rectangle is greater than height_threshold, and the total width of the nodes is greater than width_threshold, then the continuous nodes are fitted.

    :param source_data: the face dataset to be processed
    :type source_data: DatasetVector or str
    :param float width_threshold: The threshold value from the point to the left and right boundary of the minimum area bounding rectangle
    :param float height_threshold: The threshold value from the point to the upper and lower boundary of the minimum area bounding rectangle
    :param bool save_failed: Whether to save the source area object when the area object fails to be orthogonalized. If it is False, the result dataset does not contain the failed area object.
    :param out_data: The datasource used to store the result dataset.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.slice_grid": """
    Natural segmentation and reclassification is suitable for unevenly distributed data.

    Jenks natural interruption method:

    The reclassification method uses the Jenks natural discontinuity method. The Jenks natural discontinuity method is based on the natural grouping inherent in the data. 
    This is a form of variance minimization grading. The discontinuity is usually uneven, and the discontinuity is selected where the value changes drastically, so this 
    method can appropriately group similar values and enable Maximize the difference between each class. The Jenks discontinuous point classification method puts similar 
    values (clustering values) in the same category, so this method is suitable for unevenly distributed data values.

    :param input_data: The specified raster dataset to be reclassified.
    :type input_data: DatasetGrid or str
    :param int number_zones: The number of zones to reclassify the raster dataset.
    :param int base_output_zones: The value of the lowest zone in the result raster dataset
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str


    Set the number of grading regions to 9, and divide the minimum to maximum raster data to be graded into 9 naturally. The lowest area value is set to 1, and the value after reclassification is increased by 1 as the starting value.

    >>> slice_grid('E:/data.udb/DEM', 9, 1,'E:/Slice_out.udb')


    """,

    "iobjectspy._jsuperpy.analyst.sa.smooth_vector": """
    Smooth vector datasets, support line datasets, area datasets and network datasets

    * Smooth purpose

        When there are too many line segments on the boundary of a polyline or polygon, it may affect the description of the original feature, and no further processing or analysis is used, or the display and printing effect is not ideal, so the data needs to be simplified. Simplified method
        generally include resampling (:py:meth:`resample_vector`) and smoothing. Smoothing is a method of replacing the original polyline with a curve or straight line segment by adding nodes. It should be noted that after smoothing the polyline,
        Its length usually becomes shorter, and the direction of the line segment on the polyline will also change significantly, but the relative position of the two endpoints will not change; the area of the area object will usually become smaller after smoothing.

    * Setting of smoothing method and smoothing coefficient

        This method uses B-spline method to smooth the vector dataset. For an introduction to the B-spline method, please refer to the SmoothMethod class. The smoothness coefficient (corresponding to the smoothness parameter in the method) affects the degree of smoothness,
        The larger the smoothing coefficient, the smoother the result data. The recommended range of smoothness coefficient is [2,10]. This method supports smoothing of line dataset, surface dataset and network dataset.

        * Set the smoothing effect of different smoothing coefficients on the line dataset:

        .. image:: ../image/Smooth_1.png

        * Set the smoothing effect of different smoothing coefficients on the face dataset:

        .. image:: ../image/Smooth_2.png


    :param input_data: dataset that needs to be smoothed, support line dataset, surface dataset and network dataset
    :type input_data: DatasetVector or str
    :param int smoothness: The specified smoothness coefficient. A value greater than or equal to 2 is valid. The larger the value, the more the number of nodes on the boundary of the line object or area object, and the smoother it will be. The recommended value range is [2,10].
    :param out_data: The radius of the result datasource. If this parameter is empty, the original data will be smoothed directly, that is, the original data will be changed. If this parameter is not empty, the original data will be copied to this datasource first,
                     Then smooth the copied dataset. The datasource pointed to by out_data can be the same as the datasource where the source dataset is located.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: The name of the result dataset. It is valid only when out_data is not empty.
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :param bool is_save_topology: whether to save the object topology
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.straight_distance": """
    According to the given parameters, a straight-line distance grid, a straight-line direction grid and a straight-line distribution grid are generated.

    This method is used to generate corresponding straight-line distance grids, straight-line direction grids (optional) and straight-line distribution grids (optional) for the source dataset. The area scope of the three result datasets is consistent with the scope of the source dataset. The source data for generating the straight-line distance raster can be vector data (point, line, area) or raster data. 
    For raster data, cells other than the identification source are required to have no value.

    * The value of the straight-line distance grid represents the Euclidean distance from the cell to the nearest source (ie, the straight-line distance). The nearest source is the source with the shortest straight-line distance between the current cell and all sources. For each cell, the line connecting its center to the center of the source is the distance from the cell to the source. 
    The calculation method is to calculate the two right-angled sides of the right triangle formed by the two, so the straight-line distance is only calculated It is related to the cell size (ie resolution). The figure below is a schematic diagram of straight-line distance calculation, where the cell size of the source grid (cell_size) is 10.

      .. image:: ../image/StraightDistance_1.png

      Then the distance L from the cell in the third row and third column to the source is:

      .. image:: ../image/StraightDistance_2.png

    * The value of the straight line direction grid represents the azimuth angle from the cell to the nearest source, in degrees. Take the true east direction as 90 degrees, the true south as 180 degrees, the true west as 270 degrees, and the true north as 360 degrees. The range is 0-360 degrees, and the grid value of the corresponding source is specified as 0 degrees.

    * The value of the straight line distribution grid is the value of the nearest source of the cell (when the source is a raster, it is the value of the nearest source; when the source is a vector object, it is the SMID of the nearest source), so the grid is allocated from the straight line You can know which is the nearest source of each cell.

    The figure below is a schematic diagram of generating a straight line distance. The cell size is 2.

    .. image:: ../image/StraightDistance_3.png

    The straight-line distance grid is usually used to analyze the situation where there is no obstacle or equivalent cost in the route passed. For example, when a rescue plane flies to the nearest hospital, there is no obstacle in the air, so the cost of which route is the same is the same. The grid can determine the distance from the location of the rescue aircraft to the surrounding hospitals; according to the straight-line distribution grid, the nearest hospital to the location of the rescue aircraft can be obtained; the straight-line direction grid can determine the location of the nearest hospital at the location of the rescue aircraft .

    However, in the example of a rescue vehicle driving to the nearest hospital, because there are various types of obstacles on the surface, the cost of using different routes is not the same. In this case, the cost distance grid needs to be used for analysis. For the cost distance grid, please refer to the CostDistance method.

    The following figure is an example of generating a straight-line distance grid, where the source dataset is a point dataset, and a straight-line distance grid, a straight-line direction grid, and a straight-line distribution grid are generated.

    .. image:: ../image/StraightDistance.png


    Note: When the minimum bounds of the dataset is in some special cases, the Bounds of the result dataset shall be selected according to the following rules:

    * When the height and width of the Bounds of the source dataset are both 0 (for example, there is only one vector point), the height and width of the Bounds of the result dataset are both the left boundary value (Left) and the lower boundary value of the source dataset Bounds (Right) The one with the smaller absolute value of the two.
    * When the Bounds height of the source dataset is 0 but the width is not 0 (for example, there is only one horizontal line), the Bounds height and width of the result dataset are equal to the width of the source dataset Bounds.
    * When the Bounds width of the source dataset is 0 and the height is not 0 (for example, there is only one vertical line), the height and width of the Bounds of the result dataset are equal to the height of the source dataset Bounds.


    :param input_data: Generate the source dataset of the distance raster. The source refers to the research object or features of interest, such as schools, roads, or fire hydrants. The dataset that contains the source is the source dataset. The source dataset can be
                        Point, line, and area datasets can also be raster datasets. The raster in the raster dataset with valid values is the source, and if there is no value, it is considered that the location has no source.
    :type input_data: DatasetVector or DatasetGrid or DatasetImage or str
    :param float max_distance: The maximum distance of the generated distance grid, the calculation result of the grid greater than this distance is no value. If the shortest distance between cell A of a certain grid and the nearest source is greater than this value, the value of this grid in the result dataset will take no value.
    :param float cell_size: The resolution of the result dataset, which is an optional parameter for generating a distance grid
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_distance_grid_name: The name of the result distance grid dataset. If the name is empty, a valid dataset name will be automatically obtained.
    :param str out_direction_grid_name: the name of the direction raster dataset, if it is empty, no direction raster dataset will be generated
    :param str out_allocation_grid_name: the name of the allocated raster dataset, if it is empty, the allocated raster dataset will not be generated
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: If the generation is successful, return the result dataset or a tuple of dataset names, where the first is the distance raster dataset, the second is the direction raster dataset, 
             and the third is the assigned raster dataset. If not set The name of the direction raster dataset and the name of the assigned raster dataset, the corresponding value is None
    :rtype: tuple[DataetGrid] or tuple[str]
    """,

    "iobjectspy._jsuperpy.analyst.sa.summary_points": """
    Dilute the point dataset according to the specified distance, that is, use one point to represent all points within the specified distance. This method supports different units, and can choose the method of point thinning, and it can also do statistics on the original point set of thinning points.
    In the result dataset resultDatasetName, two new fields, SourceObjID and StatisticsObjNum, will be created. The SourceObjID field stores the point object obtained after thinning in the original dataset
    The SmID, StatisticsObjNum in represents the number of all points represented by the current point, including the point being thinned out and itself.

    :param input_data: point dataset to be thinned
    :type input_data: DatasetVector or str or Recordset
    :param float radius: The radius of the thinning point. Take any one of the coordinates, the coordinates of all points within the radius of the point coordinates of landmark expressed through this point. Note that the unit of the radius of the thinning point should be selected.
    :param unit: The unit of the radius of the thinning point.
    :type unit: Unit or str
    :param stats: Make statistics on the original point set of the dilute points. Need to set the field name of the statistics, the field name of the statistics result and the statistics mode. When the array is empty, it means no statistics. When stats is str, support setting with';'
                  Separate multiple StatisticsFields, each StatisticsField use',' to separate'source_field,stat_type,result_name', for example:
                  'field1,AVERAGE,field1_avg; field2,MINVALUE,field2_min'
    :type stats: list[StatisticsField] or str
    :param bool is_random_save_point: Whether to save the dilute points randomly. True means to randomly select a point from the point set within the thinning radius to save, False means to take the point with the smallest sum of distances from all points in the point set in the thinning radius.
    :param bool is_save_attrs: whether to retain attribute fields
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.surface_distance": """
    According to the given parameters, a surface distance grid, a surface direction grid and a surface allocation grid are generated. This method generates corresponding surface distance grid, surface direction grid (optional) and surface allocation grid (optional) according to the source dataset and surface grid.
     The source data can be vector data (point, line, area) or raster data. For raster data, cells other than the identification source are required to have no value.

    * The value of the surface distance grid represents the shortest distance from the cell on the surface grid to the surface of the nearest source. The nearest source refers to the source with the shortest surface distance from the current cell to all sources. The cells with no value in the surface raster will still have no value in the output surface distance raster.
      The calculation method of the surface distance d from the current cell (set to g1) to the next cell (set to g2) is:

      .. image:: ../image/SurfaceDistance_1.png

      Among them, b is the difference between the grid value of g1 (ie elevation) and the grid value of g2; a is the linear distance between the center points of g1 and g2, and its value considers two cases, when g2 is adjacent to g1 When one of the top, bottom, left, 
      and right cells of a, the value of a is equal to the cell size; when g2 is one of the four cells diagonally adjacent to g1, the value of a is the cell size multiplied by the root No. 2.
      
      The distance value from the current cell to the nearest source is the surface distance value along the shortest path. In the diagram below, the cell size (CellSize) of the source grid and the surface grid are both
      1. The shortest surface path of cell (2,1) to source (0,0) is shown by the red line in the right figure:

      .. image:: ../image/SurfaceDistance_2.png

      Then the shortest surface distance of cell (2,1) to the source is:

      .. image:: ../image/SurfaceDistance_3.png

    * The value of the surface direction grid expresses the travel direction of the shortest surface distance path from the cell to the nearest source. In the surface direction grid, there are eight possible directions of travel (true north,
      True South, True West, True East, Northwest, Southwest, Southeast, Northeast), use the eight integers from 1 to 8 to encode these eight directions, as shown in the figure below. Note that the cell where the source is located has a value of 0 in the surface orientation grid, and the cell with no value in the surface grid will be assigned a value of 15 in the output surface orientation grid.

      .. image:: ../image/CostDistance_3.png

    * The value of the surface allocation grid is the value of the nearest source of the cell (when the source is a raster, it is the value of the nearest source; when the source is a vector object, it is the SMID of the nearest source). The shortest surface distance. The cells with no value in the surface raster will still have no value in the output surface allocation raster.
      The figure below is a schematic diagram of the generated surface distance. Among them, on the surface grid, according to the result surface direction grid, the blue arrow is used to mark the travel direction of the cell to the nearest source.

      SurfaceDistance_4.png

    Through the above introduction, we can understand that by combining the surface distance grid and the corresponding direction and distribution grid, we can know which source is the nearest to each cell on the surface grid, what is the surface distance and how to reach the nearest source.

    Note that you can specify the maximum upslope angle (max_upslope_degrees) and the maximum downslope angle (max_downslope_degree) when generating the surface distance, so as to avoid passing through cells whose upslope angle exceeds the specified value when looking for the nearest source. 
    Traveling from the current cell to the next cell with a higher elevation is an uphill. The uphill angle is the angle between the uphill direction and the horizontal plane. If the uphill angle is greater than the given value, this direction of travel will not be considered; The cell travels 
    to the next cell whose elevation is less than the current elevation. The downward slope angle is the angle between the downward slope direction and the horizontal plane. Similarly, if the downward slope angle is greater than the given value, this direction of travel will not be considered. 
    If the current cell cannot find the nearest source due to the limitation of the up and down slope angle, the value of the cell in the surface distance grid is no value, and it is also no value in the direction grid and the distribution grid.

    The following figure is an example of generating a surface distance grid, where the source dataset is a point dataset, and the surface grid is a DEM grid of the corresponding area. The surface distance grid, surface direction grid and surface allocation grid are generated.

    .. image:: ../image/SurfaceDistance.png


    :param input_data: Generate the source dataset of the distance raster. The source refers to the research object or features of interest, such as schools, roads, or fire hydrants. The dataset that contains the source is the source dataset. The source dataset can be
                        Point, line, surface dataset may be a set of raster data, the raster dataset having has the raster effective value of the source, then no value for that position is not regarded as a source.
    :type input_data: DatasetVector or DatasetGrid or DatasetImage or str
    :param surface_grid_dataset: surface grid
    :type surface_grid_dataset: DatasetGrid or str
    :param float max_distance: The maximum distance of the generated distance grid, the calculation result of the grid greater than this distance is no value. If the shortest distance between cell A of a certain grid and the nearest source is greater than this value, the value of this grid in the result dataset will take no value.
    :param float cell_size: The resolution of the result dataset, which is an optional parameter for generating a distance grid
    :param float max_upslope_degrees: Maximum uphill angle. The unit is degree, and the value range is greater than or equal to 0. The default value is 90 degrees, that is, the uphill angle is not considered. If the maximum uphill angle is specified, 
                                      the uphill angle of the terrain will be considered when choosing the route. Moving from the current cell to the next cell with higher elevation is the uphill, and the uphill angle is the angle between the uphill 
                                      direction and the horizontal plane. If the uphill angle is greater than the given value, this direction of travel will not be considered, that is, the given route will not pass through the area where the uphill angle 
                                      is greater than this value. It is conceivable that there may be no eligible routes due to the setting of this value. In addition, because the slope is expressed in the range of 0 to 90 degrees, although it can be specified 
                                      as a value greater than 90 degrees, the effect is the same as that of specifying 90 degrees, that is, the upward slope angle is not considered.
    :param float max_downslope_degree: Set the maximum downslope angle. The unit is degree, and the value range is greater than or equal to 0.
                                      If the maximum downhill angle is specified, the downhill angle of the terrain will be considered when choosing the route. Traveling from the current cell to the next cell whose elevation is less than the current elevation is downhill, 
                                      and the downhill angle is the angle between the downhill direction and the horizontal plane. If the downhill angle is greater than the given value, this direction of travel will not be considered, that is, the given route will not pass 
                                      through the area where the downhill angle is greater than this value. It is conceivable that there may be no eligible routes due to the setting of this value. In addition, because the slope is expressed in the range of 0 to 90 degrees, 
                                      although it can be specified as a value greater than 90 degrees, the effect is the same as the specified 90 degrees, that is, the downslope angle is not considered.
                                      
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_distance_grid_name: The name of the result distance grid dataset. If the name is empty, a valid dataset name will be automatically obtained.
    :param str out_direction_grid_name: the name of the direction raster dataset, if it is empty, no direction raster dataset will be generated
    :param str out_allocation_grid_name: the name of the allocated raster dataset, if it is empty, the allocated raster dataset will not be generated
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: If the generation is successful, return the result dataset or a tuple of dataset names, where the first is the distance raster dataset, the second is the direction raster dataset, and the third is the assigned raster dataset. 
             If not set The name of the direction raster dataset and the name of the assigned raster dataset, the corresponding value is None
    :rtype: tuple[DataetGrid] or tuple[str]
    """,

    "iobjectspy._jsuperpy.analyst.sa.surface_path_line": """
    According to the given parameters, calculate the shortest surface distance path between the source point and the target point (a two-dimensional vector line object). This method is used to calculate the shortest surface distance path between the source point and the target point according to the given source point, target point and surface grid.

    Setting the maximum upslope angle (max_upslope_degrees) and the maximum downslope angle (max_downslope_degree) can make the analyzed route not pass through too steep terrain.
    Note, however, that if you specify the up and down slope angle limit, you may not get the analysis result, which is related to the value of the maximum up and down slope angle and the terrain expressed by the surface grid. 
    The following figure shows the shortest path of the surface distance when the maximum upslope angle and the maximum downslope angle are set to 5 degrees, 10 degrees, and 90 degrees respectively (that is, there is no restriction on the up and down slope angle), 
    due to the restriction on the up and down slope angle , So the shortest path of the surface distance is based on the premise that the maximum up and down slope angle is not exceeded.

    .. image:: ../image/SurfacePathLine.png

    :param Point2D source_point: The specified source point.
    :param Point2D target_point: The specified target point.
    :param surface_grid_dataset: surface grid
    :type surface_grid_dataset: DatasetGrid or str
    :param float max_upslope_degrees: Maximum upslope angle. The unit is degree, and the value range is greater than or equal to 0. The default value is 90 degrees, that is, the uphill angle is not considered.
                                      If the maximum uphill angle is specified, the uphill angle of the terrain will be considered when choosing the route. Moving from the current cell to the next cell with higher elevation is the uphill, 
                                      and the uphill angle is the angle between the uphill direction and the horizontal plane. If the uphill angle is greater than the given value, this direction of travel will not be considered, that is, 
                                      the given route will not pass through the area where the uphill angle is greater than this value. It is conceivable that there may be no eligible routes due to the setting of this value. In addition, 
                                      because the slope is expressed in the range of 0 to 90 degrees, although it can be specified as a value greater than 90 degrees, the effect is the same as that of specifying 90 degrees, that is, the upward slope angle is not considered.
    :param float max_downslope_degree: Set the maximum downslope angle. The unit is degree, and the value range is greater than or equal to 0.
                                      If the maximum downhill angle is specified, the downhill angle of the terrain will be considered when choosing the route. Traveling from the current cell to the next cell whose elevation is less than 
                                      the current elevation is downhill, and the downhill angle is the angle between the downhill direction and the horizontal plane. If the downhill angle is greater than the given value, this direction of travel 
                                      will not be considered, that is, the given route will not pass through the area where the downhill angle is greater than this value. It is conceivable that there may be no eligible routes due to the setting of this value. 
                                      In addition, since the slope is expressed in the range of 0 to 90 degrees, although it can be specified as a value greater than 90 degrees, the effect is the same as the specified 90 degrees, that is, the downslope angle is not considered.
    :param smooth_method: The method of smoothing the resulting route when calculating the shortest path between two points (source and target)
    :type smooth_method: SmoothMethod or str
    :param int smooth_degree: When calculating the shortest path between two points (source and target), smooth the resulting route.
                                The greater the smoothness value, the greater the smoothness value, and the higher the smoothness of the resulting vector line. It is valid when smooth_method is not NONE. The effective value of smoothness is related to the smoothing method. The smoothing methods include B-spline method and angle grinding method:
                                -When the smoothing method is B-spline method, the effective value of smoothness is an integer greater than or equal to 2, and the recommended value range is [2,10].
                                -When the smoothing method is the angle grinding method, the smoothness represents the number of angle grinding in one smoothing process, and it is effective when set to an integer greater than or equal to 1
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :param barrier_regions: Obstacle surface dataset or surface object, which will bypass the obstacle surface during analysis
    :type barrier_regions: DatasetVector or GeoRegion or list[GeoRegion]
    :return: Return the line object representing the shortest path and the cost of the shortest path
    :rtype: tuple[GeoLine,float]
    """,

    "iobjectspy._jsuperpy.analyst.sa.thin_raster": """
    Raster refinement is usually used before converting the raster to vector line data.

    The refinement of raster data can reduce the number of cells used to identify linear features in raster data, thereby improving the speed and accuracy of vectorization. 
    It is generally used as the preprocessing before raster to line vector data to make the conversion effect better. For example, a scanned contour map may use 5 or 6 cells to display the width of a contour line. 
    After the refinement process, the width of the contour line is displayed in only one cell, which is beneficial for more Vectorize well.

    .. image:: ../image/ThinRaster.png

    Explanation about no value/background color and its tolerance:

    When performing grid refinement, users are allowed to identify those cells that do not need to be refined. For raster datasets, these values are determined by the no value and its tolerance; for image datasets, it is determined by the background color and its tolerance.

    * When the raster dataset is refined, the cell whose raster value is the value specified by the back_or_no_value parameter is regarded as no value and does not participate in the refinement, and the original no value of the raster will be used as a valid value to participate in the refinement ï¼›
      At the same time, the cells within the tolerance of no value specified by the back_or_no_value_tolerance parameter do not participate in the refinement. For example, specify the value of no value as a, and specify the tolerance of no value as b,
      Then the cells whose grid value is in the range of [ab,a+b] will not participate in the refinement.

    *  When the image dataset is refined, the cells whose raster value is the specified value are regarded as the background color and do not participate in the refinement; at the same time, the cells within the tolerance range of the background color 
    specified by the back_or_no_value_tolerance parameter are not Participate in refinement.

    It should be noted that the raster value in the image dataset represents a color value. Therefore, if you want to set a certain color as the background color, the value specified for the back_or_no_value parameter should be the color (RGB value) converted to a 32-bit integer. 
    The value after the type will be converted accordingly within the system according to the pixel format. The tolerance of the background color is also a 32-bit integer value. This value is converted into three tolerance values corresponding to R, G, and B within the system. 
    For example, the color designated as the background color is (100,200,60), the designated tolerance value is 329738, and the value corresponds to RGB If the value is (10,8,5), the colors between (90,192,55) and (110,208,65) will not participate in the refinement.

    Note: For raster datasets, if the specified value without value is outside the range of the raster dataset to be refined, the analysis will fail and None will be returned.

    :param source: The specified raster dataset to be refined. Support image dataset.
    :type source: DatasetImage or DatasetGrid or str
    :param back_or_no_value: Specify the background color of the grid or a value indicating no value. You can use an int or tuple to represent an RGB or RGBA value.
    :type back_or_no_value: int or tuple
    :param back_or_no_value_tolerance: The tolerance of the grid background color or the tolerance of no value. You can use a float or tuple to represent an RGB or RGBA value.
    :type back_or_no_value_tolerance: float or tuple
    :param out_data: The datasource used to store the result data.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: the name of the result dataset
    :type out_dataset_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: Dataset or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.thin_raster_bit": """
    The rasterized linear features are refined by reducing the pixel width of the feature. This method is a refinement method for processing binary images. If it is not a binary image, it will be processed as a binary image first, and only the background color needs to be specified Values other than the background color are values that need to be refined. This method is the fastest.

    :param input_data: The specified raster dataset to be refined. Support image dataset.
    :type input_data: DatasetImage or DatasetGrid or str
    :param back_or_no_value: Specify the background color of the grid or a value indicating no value. You can use an int or tuple to represent an RGB or RGBA value.
    :type back_or_no_value: int or tuple
    :param bool is_save_as_grid: Whether to save as a raster dataset, True means to save as a raster dataset, False to save as the original data type (raster or image). Saving as a raster dataset is convenient for vectorization of specified values during raster vectorization, which is convenient for obtaining line data quickly.
    :param out_data: The datasource used to store the result data.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: the name of the result dataset
    :type out_dataset_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: Dataset or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.to_float_math_analyst": """
      Raster floating point operations. Convert the raster value of the input raster dataset to floating point. If the input raster value is double-precision floating-point type, the result raster value after floating-point operation is also converted into single-precision floating-point type.

      :param input_data: The specified first raster dataset.
      :type input_data: DatasetGrid or str
      :param GeoRegion user_region: The valid calculation region specified by the user. If it is None, it means that all areas are calculated. If the ranges of the dataset involved in the operation are inconsistent, the intersection of the ranges of all dataset will be used as the calculation area.
      :param out_data: The datasource where the result dataset is located
      :type out_data: Datasource or DatasourceConnectionInfo or str
      :param str out_dataset_name: result dataset name
      :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
      :return: result dataset or dataset name
      :rtype: DatasetGrid or str

    """,

    "iobjectspy._jsuperpy.analyst.sa.to_int_math_analyst": """
      Grid rounding operation. Provides rounding operations on the raster values of the input raster dataset. The result of the rounding operation is to remove the decimal part of the raster value and only keep the integer of the raster value. If the input raster value is an integer type, the result of the rounding operation is the same as the input raster value.

      :param input_data: The specified first raster dataset.
      :type input_data: DatasetGrid or str
      :param GeoRegion user_region: The valid calculation region specified by the user. If it is None, it means that all areas are calculated. If the ranges of the dataset involved in the operation are inconsistent, the intersection of the ranges of all dataset will be used as the calculation area.
      :param out_data: The datasource where the result dataset is located
      :type out_data: Datasource or DatasourceConnectionInfo or str
      :param str out_dataset_name: result dataset name
      :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
      :return: result dataset or dataset name
      :rtype: DatasetGrid or str

    """,

    "iobjectspy._jsuperpy.analyst.sa.update_attributes": """
    Update the attributes of the vector dataset, and update the attributes in source_data to the target_data dataset according to the spatial relationship specified by spatial_relation.
    For example, if you have a piece of point data and surface data, you need to average the attribute values in the point dataset, and then write the value to the surface object that contains the points. This can be achieved by the following code:

    >>> result = update_attributes('ds/points','ds/zones','WITHIN', [('trip_distance','mean'), ('','count')])

    The spatial_relation parameter refers to the spatial relationship between the source dataset (source_data) and the target updated dataset (target_data).

    :param source_data: The source dataset. The source dataset provides attribute data, and the attribute values in the source dataset are updated to the target dataset according to the spatial relationship.
    :type source_data: DatasetVector or str
    :param target_data: target dataset. The dataset to which the attribute data is written.
    :type target_data: DatasetVector or str
    :param spatial_relation: Spatial relationship type, the spatial relationship between the source data (query object) and the target data (query object), please refer to:py:class:`SpatialQueryMode`
    :type spatial_relation: SpatialQueryMode or str
    :param update_fields: Field statistical information. There may be multiple source data objects that satisfy the spatial relationship with the target data object. It is necessary to summarize the attribute field values of the source data, and write the statistical results into the target dataset as a list, each in the list The element is a tuple, the size of the tuple is 2, 
                         the first element of the tuple is the name of the field to be counted, and the second element of the tuple is the statistical type.
    :type update_fields: list[tuple(str,AttributeStatisticsMode)] or list[tuple(str,str)] or str
    :param interval: node tolerance
    :type interval: float
    :return: Whether the attribute update was successful. Return True if the update is successful, otherwise False.
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.sa.vector_to_raster": """
    Convert a vector dataset to a raster dataset by specifying the conversion parameter settings.

    :param input_data: The vector dataset to be converted. Support point, line and area dataset
    :type input_data: DatasetVector or str
    :param str value_field: The field for storing raster values in the vector dataset
    :param clip_region: effective region for conversion
    :type clip_region: GeoRegion or Rectangle
    :param float cell_size: the cell size of the result raster dataset
    :param pixel_format: If the vector data is converted to a raster dataset with pixel formats of UBIT1, UBIT4 and UBIT8, the objects with a value of 0 in the vector data will be lost in the result raster.
    :type pixel_format: PixelFormat or str
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :param float no_value: No value of raster dataset
    :param bool is_all_touched: Whether to convert all the grids in contact with the polyline, the default is True. If False, the brezenhams rasterization method is used.
    :return: result dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.sa.zonal_statistics_on_raster_value": """
    Raster zoning statistics. In the method, the value data is a raster dataset, and the band data can be vector or raster data.

    Raster zoning statistics is a statistical method to count the values of cells in a region, and assign the statistical values in each region to all cells covered by the region to obtain the result grid. Raster zoning statistics involves two kinds of data, value data and band data. The value data is the raster data to be counted, and the band data is the data identifying the statistical area, which can be raster or vector area data. The following figure shows the algorithm of using grid band data for banding statistics, where the gray cells represent no value data.

    .. image:: ../image/ZonalStatisticsOnRasterValue_1.png

    When the band data is a raster dataset, the consecutive cells with the same raster value are regarded as a band (area); when the band data is a vector polygon dataset, it is required to have a field that identifies the band in the attribute table, with the value To distinguish different bands, if the identification values of two or more area objects (which can be adjacent or not) are the same, they will be counted as one band when performing banding statistics, that is, in the result grid , The grid values at the corresponding positions of these area objects are the statistical values of the grid values of all cells within the range of these area objects.

    The results of zoning statistics include two parts: one is the grid of zoning statistics, the grid value in each band is the same, that is, the value calculated according to the statistical method; the second is a record of statistical information in each band Attribute table, including ZONALID (identification with band), PIXELCOUNT (number of cells in band), MININUM (minimum), MAXIMUM (maximum), RANGE_VALUE (range), SUM_VALUE (sum), MEAN (average), STD (Standard deviation), VARIETY (kind), MAJORITY (mode), MINORITY (minority), MEDIAN (median) and other fields.

    Let's use an example to understand the application of band statistics.

      1. As shown in the figure below, the left picture is the DEM raster value, which is used as value data, and the right picture is the administrative division of the corresponding area, which is used as the band data for band statistics;

      .. image:: ../image/ZonalStatisticsOnRasterValue_2.png

      2. Using the above data, use the maximum value as the statistical method to perform zoning statistics. The result includes the result grid as shown in the figure below and the corresponding statistical information attribute table (omitted). In the result grid, the grid values in each band are equal, that is, the largest grid value in the value grid within the band range, that is, the elevation value. This example counts the highest elevation in each administrative area of the region.

      .. image:: ../image/ZonalStatisticsOnRasterValue_3.png


    Note that the pixel type (PixelFormat) of the result grid of the zoning statistics is related to the specified zoning statistics type (set by the setStatisticsMode method of the ZonalStatisticsAnalystParameter class):

    ã€€* When the statistical type is VARIETY, the result raster pixel type is BIT32;
    ã€€* When the statistical type is the maximum (MAX), minimum (MIN), and range (RANGE), the pixel type of the result raster is consistent with the source raster;
    ã€€* When the statistical type is average (MEAN), standard deviation (STDEV), sum (SUM), mode (MAJORITY), minimum (MINORITY), median (MEDIAN), the pixel type of the result raster is DOUBLE .

    :param value_data: value data to be counted
    :type value_data: DatasetGrid or str
    :param zonal_data: The zonal dataset to be counted. Only raster datasets or vector polygon datasets with pixel format (PixelFormat) UBIT1, UBIT4, UBIT8 and UBIT16 are supported.
    :type zonal_data: DatasetGrid or DatasetVector or str
    :param str zonal_field: The field used to identify the band in the vector band data. The field type only supports 32-bit integers.
    :param bool is_ignore_no_value: Whether to ignore no-value data in statistics. If it is True, it means that the grid with no value is not involved in the calculation; if it is False, it means that there is no value involved in the calculation, and the result is still no value
    :param grid_stat_mode: zoning statistics type
    :type grid_stat_mode: GridStatisticsMode or str
    :param out_data: The datasource used to store the result data.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param out_dataset_name: the name of the result dataset
    :type out_dataset_name: str
    :param out_table_name: The name of the analysis result attribute table
    :type out_table_name: str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: return a tuple, tuple has two elements, the first is the result dataset or name, the second is the result attribute table dataset or name
    :rtype: tuple[DatasetGrid, DatasetGrid] or tuple[str,str]
    """,

    "iobjectspy._jsuperpy.analyst.ss": """
Spatial Statistics Module
""",

    "iobjectspy._jsuperpy.analyst.ss.AnalyzingPatternsResult": """
    Analysis mode result class. This class is used to obtain the results of the analysis mode calculation, including the result index, expectation, variance, Z score and P value.
    """,

    "iobjectspy._jsuperpy.analyst.ss.AnalyzingPatternsResult.expectation": """float: the expected value in the analysis mode result""",

    "iobjectspy._jsuperpy.analyst.ss.AnalyzingPatternsResult.index": """float: Moran index or GeneralG index in the analysis mode result""",

    "iobjectspy._jsuperpy.analyst.ss.AnalyzingPatternsResult.p_value": """float: P value in the analysis mode result""",

    "iobjectspy._jsuperpy.analyst.ss.AnalyzingPatternsResult.variance": """float: the variance value in the analysis mode result""",

    "iobjectspy._jsuperpy.analyst.ss.AnalyzingPatternsResult.z_score": """float: Z score in the analysis mode result""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeEstimateMethod": """
    :var BShadeEstimateMethod.TOTAL: Total method, that is, according to the ratio of the sample to the population.
    :var BShadeEstimateMethod.MEAN: Mean method, which is based on the ratio of the sample mean to the overall mean.
    """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeEstimationResult": """BShadeEstimationResult""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeEstimationResult.dataset": """DatasetVector: BShade estimation result dataset""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeEstimationResult.to_dict": """
        Convert to dict.

        :return: A dictionary object used to describe the estimation result of BShade.
        :rtype: dict[str, object]
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeEstimationResult.variance": """float: estimated variance""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeEstimationResult.weights": """list[float]: weight array """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSampleNumberMethod": """
    :var BShadeEstimateMethod.FIXED: Use a fixed number of fields.
    :var BShadeEstimateMethod.RANGE: Use range field sampling number.
    """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter": """
    BShade sampling parameters.

    The simulated annealing algorithm will be used in the sampling process, which will contain multiple parameters of the simulated annealing algorithm. The simulated annealing algorithm is used to find the minimum value of the function.
    """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.bshade_estimate_method": """BS hadeEstimateMethod: BShade estimation method""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.bshade_sample_number_method": """BShadeSampleNumberMethod: BShade sampling number method""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.cool_rate": """float: """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.initial_temperature": """float: initial temperature""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.max_consecutive_rejection": """int: Maximum number of consecutive rejections""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.max_full_combination": """int: Maximum number of field combinations""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.max_success": """int: the maximum number of successes in a temperature""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.max_try": """int: Maximum number of attempts """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.min_energy": """float: minimum energy, ie stop energy""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.min_temperature": """float: minimum temperature, that is, stop temperature""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.select_sample_number": """int: select the number of samples""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.select_sample_range_lower": """int: lower limit of range sampling number""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.select_sample_range_step": """int: range sampling step""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.select_sample_range_upper": """int: upper limit of range sampling number""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_bshade_estimate_method": """
        Set the BShade estimation method. That is to calculate the sample according to the total or average value

        :param value: BShade estimation method, the default value is TOTAL
        :type value: BShadeEstimateMethod or str
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_bshade_sample_number_method": """
        Set the BShade sampling number method. The default value is FIXED

        :param value: BShade sampling number method
        :type value: BShadeSampleNumberMethod or str
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_cool_rate": """
        Set annealing rate

        :param float value: annealing rate
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_initial_temperature": """
        Set the starting temperature

        :param float value: starting temperature
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_max_consecutive_rejection": """
        Set the maximum number of consecutive rejections

        :param int value: Maximum number of consecutive rejections
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_max_full_combination": """
        Set the maximum number of field combinations

        :param int value: Maximum number of field combinations
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_max_success": """
        Set the maximum number of successes within a temperature

        :param int value: Maximum number of successes
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_max_try": """
        Set the maximum number of attempts

        :param int value: Maximum number of attempts
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_min_energy": """
        Set minimum energy, that is, stop energy

        :param float value: minimum energy, ie stop energy
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_min_temperature": """
        Set minimum temperature, that is, stop temperature

        :param float value: minimum temperature, ie stop temperature
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_select_sample_number": """
        Set the number of selected samples

        :param int value: select the number of samples
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_select_sample_range_l": """
        Set the lower limit of the range sampling number

        :param int value: lower limit of range sampling number
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_select_sample_range_step": """
        Set range sampling step

        :param int value: Range sampling step
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingParameter.set_select_sample_range_u": """
        Set the upper limit of the number of range samples

        :param int value: The upper limit of the range sampling number
        :return: self
        :rtype: BShadeSamplingParameter
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingResult": """BShade SamplingResult""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingResult.estimate_variance": """float: estimated variance""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingResult.sample_number": """int: number of sampling fields""",

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingResult.solution_names": """list[str]: field name array """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingResult.to_dict": """
        Convert to dict.

        :return: A dictionary object used to describe the results of BShade sampling
        :rtype: dict[str, object]
        """,

    "iobjectspy._jsuperpy.analyst.ss.BShadeSamplingResult.weights": """list[float]: weight array """,

    "iobjectspy._jsuperpy.analyst.ss.GWR": """
    Introduction to spatial relationship modeling:

     * Users can solve the following problems through spatial relationship modeling:

       * Why does a certain phenomenon continue to occur, and what factors cause this situation?
       * What are the factors that cause a certain accident rate to be higher than expected? Is there any way to reduce the accident rate in the entire city or in a specific area?
       * Modeling a phenomenon to predict values at other locations or other times?

     * Through regression analysis, you can model, examine and study spatial relationships, which can help you explain many factors behind the observed spatial model. For example, the linear relationship is positive or
       negative; for a positive relationship, that is, there is a positive correlation, a variable increases with the increase of another variable; conversely, a variable decreases with the increase of another variable; or the two variables have no relationship.


    Geographically weighted regression analysis.

    * Geographically weighted regression analysis result information includes a result dataset and a summary of geographically weighted regression results (see GWRSummary category).
    * The result dataset includes cross validation (CVScore), predicted value (Predicted), regression coefficient (Intercept, C1_interpretation field name), residual (Residual), standard error
      (StdError), coefficient standard error (SE_Intercept, SE1_interpretation field name), pseudo t value (TV_Intercept, TV1_interpretation field name) and Studentised residual (StdResidual), etc.

    Description:

      * Geographically weighted regression analysis is a local form of linear regression for spatial change relationships, which can be used to study the relationship between spatial change dependent and independent variables. 
        Model the relationship between the data variables associated with geographic elements, so that you can predict unknown values or better understand the key factors that can affect the variables to be modeled. 
        The regression method allows you to verify the spatial relationship and measure the stability of the spatial relationship.
      * Cross-validation (CVScore): Cross-validation does not include the regression point itself when estimating the regression coefficient, that is, only performs the regression calculation based on the data points around the regression point. 
        This value is the difference between the estimated value and the actual value obtained in cross-validation for each regression point, and the sum of their squares is the CV value. As a model performance indicator.
      * Predicted: These values are estimated values (or fitted values) obtained by geographically weighted regression.
      * Regression coefficient (Intercept): It is the regression coefficient of the geographically weighted regression model. It is the regression intercept of the regression model, indicating that all explanatory variables are the predicted value of the dependent variable when it is zero.
      * Regression coefficient (C1_explained field name): It is the regression coefficient of the explanatory field, indicating the strength and type of the relationship between the explanatory variable and the dependent variable. If the regression coefficient is positive, 
        The relationship between the explain variable and the dependent variable is positive; on the contrary, there is a negative relationship. If the relationship is strong, the regression coefficient is relatively large; when the relationship is weak, the regression coefficient is close to 0.
      * Residual: These are the unexplainable parts of the dependent variable, which are the difference between the estimated value and the actual value. The average value of the standardized residual is 0 and the standard deviation is 1. Residuals can be used to determine the degree of fit of the model. 
       Small residuals indicate that the model fits well and can explain most of the predicted values, indicating that this regression equation is effective.
      * Standard Error (StdError): The standard error of the estimate, used to measure the reliability of each estimate. A smaller standard error indicates that the smaller the difference between the fitted value and the actual value, the better the model fitting effect.
      * Coefficient standard errors (SE_Intercept, SE1_interpretation field name): These values are used to measure the reliability of each regression coefficient estimate. If the standard error of the coefficient is smaller than the actual coefficient, the reliability of the estimated value will be higher. 
        A larger standard error may indicate a local multicollinearity problem.
      * Pseudo t value (TV_Intercept, TV1_interpretation field name): It is the significance test of each regression coefficient. When the T value is greater than the critical value, the null hypothesis is rejected, and the regression coefficient is significant, that is, the estimated regression coefficient 
        is reliable; when the T value is less than the critical value, the null hypothesis is accepted and the regression coefficient is not significant.
      * Studentised residual (StdResidual): The ratio of the residual error to the standard error. This value can be used to judge whether the data is abnormal. If the data is in the (-2, 2) interval, it indicates that the data has normality and uniformity of variance; if the data exceeds (-2, 2) The interval 
        indicates that the data is abnormal data, and there is no homogeneity of variance and normality.


    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param explanatory_fields: a collection of explanatory field names
    :type explanatory_fields: list[str] or str
    :param str model_field: the name of the modeling field
    :param kernel_function: kernel function type
    :type kernel_function: KernelFunction or str
    :param band_width_type: Bandwidth determination method
    :type band_width_type: BandWidthType or str
    :param float distance_tolerance: bandwidth range
    :param kernel_type: bandwidth type
    :type kernel_type: KernelType or str
    :param int neighbors: The number of neighbors. It is valid only when the bandwidth type is set to: py:attr:`.KernelType.ADAPTIVE` and the width determination method is set to: py:attr:`.BandWidthType.BANDWIDTH`.
    :param out_data: The datasource used to store the result dataset
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :param prediction_dataset: Prediction dataset
    :type prediction_dataset: DatasetVector or str
    :param dict[str,str] explanatory_fields_matching: Forecast dataset field mapping. 
                                                      Represents the corresponding relationship between the model's explanatory field name and the predicted dataset field name. Each explanatory field should have a corresponding field in the prediction dataset. 
                                                      If no correspondence is set, all fields in the explanatory variable array must exist in the prediction dataset.
    :param str out_predicted_name: The name of the prediction result dataset
    :return: Return a three-element tuple, the first element of the tuple is :py:class:`.GWRSummary`, 
    the second element is the geographically weighted regression result dataset and the third element is the geographically weighted regression prediction result dataset
    :rtype: tuple[GWRSummary, DatasetVector, DatasetVector]
    """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary": """
    Summary category of geographically weighted regression results. This category gives a summary of the results of geographically weighted regression analysis, such as bandwidth, adjacent number, residual sum of squares, AICc, and determination coefficient.
    """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary.AIC": """float: AIC in the summary of geographically weighted regression results. Similar to AICc, it is a standard to measure the goodness of model fitting. It can weigh the complexity of the estimated model and the goodness of the model fitting data. 
                When evaluating the model, both simplicity and accuracy are considered. It shows that increasing the number of free parameters improves the goodness of the fit. AIC encourages the fit of the data, but overfitting should be avoided as much as possible. Therefore, priority is given to 
                those with a smaller AIC value, which is to find a model that can best explain the data but contains the fewest free parameters. """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary.AICc": """float: AICc in the summary of geographically weighted regression results. When data increases, AICc converges to AIC, which is also a measure of model performance, which is helpful for comparison Different regression models.
                  Considering the complexity of the model, a model with a lower AICc value will better fit the observed data. AICc is not an absolute measure of goodness of fit, but it is very useful for comparing models that use the same dependent variable and have different explanatory variables. 
                  If the difference between the AICc values of the two models is greater than 3, the model with the lower AICc value will be regarded as the better model. """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary.Edf": """float: The effective degrees of freedom in the summary of geographically weighted regression results. The difference between the number of data and the effective number of parameters (EffectiveNumber), not necessarily an integer, Available
                  To calculate multiple diagnostic measurements. A model with a larger degree of freedom will have a poorer fit and can better reflect the true situation of the data, and the statistics will become more reliable; otherwise,
                  The fitting effect will be better, but it cannot better reflect the true situation of the data, the independence of the model data is weakened, and the degree of association increases. """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary.R2": """float: The coefficient of determination (R2) in the summary of geographically weighted regression results. The coefficient of determination is a measure of goodness of fit, and its value is in the range of 0.0 and 1.0 Internal change, the larger the value, the better the model.
                 This value can be interpreted as the proportion of the variance of the dependent variable covered by the regression model. The denominator calculated by R2 is the sum of the squares of the dependent variable value. Adding an explanatory variable will not change the denominator but will change the numerator. 
                 This will improve the model fit, but it may also be false. """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary.R2_adjusted": """float: The coefficient of determination for correction in the summary of geographically weighted regression results. The calculation of the corrected coefficient of determination will normalize the numerator and denominator according to their degrees of freedom. 
                  This has the effect of compensating the number of variables in the model, because the corrected R2 value is usually smaller than the R2 value. However, when performing a correction, the interpretation of this value cannot be used as a proportion of the explained variance.
                  The effective value of the degrees of freedom is a function of bandwidth, so AICc is the preferred way to compare models. """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary.band_width": """float: The bandwidth range in the summary of geographically weighted regression results.

                   * The bandwidth range used for each local estimation, which controls the degree of smoothing in the model. Usually, you can choose the default bandwidth range by setting the bandwidth determination method (kernel_type)
                   : py:attr:`.BandWidthType.AICC` or :py:attr:`.BandWidthType.CV`, both of these options will try to identify the best bandwidth range.

                   * Since the "optimal" conditions are different for AIC and CV, both will get the relative optimal AICc value and CV value, and therefore usually get different optimal values.

                   * The accurate bandwidth range can be provided by setting the bandwidth type (kernel_type) method.
        """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary.effective_number": """float: The number of effective parameters in the summary of geographically weighted regression results. It reflects the trade-off between the variance of the estimated value and the deviation of the estimated value of the coefficient. This value Related to the choice of bandwidth,
                  Can be used to calculate multiple diagnostic measurements. For larger bandwidths, the effective number of coefficients will be close to the actual number of parameters, and local coefficient estimates will have smaller variances.
                  But the deviation will be very large; for a smaller bandwidth, the effective number of coefficients will be close to the number of observations, and the local coefficient estimate will have a larger variance, 
                  but the deviation will become smaller. """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary.neighbours": """int: the number of neighbors in the summary of geographically weighted regression results.

                 * The number of neighbors used for each local estimation, which controls the degree of smoothing in the model. Usually, you can choose the default adjacent point value by setting the bandwidth determination method (kernel_type)
                   Method selection: py:attr:`.BandWidthType.AICC` or :py:attr:`.BandWidthType.CV`, both of these options will try to identify the best adaptive number of adjacent points.

                 * Since the "optimal" conditions are different for AIC and CV, both will get the relative optimal AICc value and CV value, and therefore usually get different optimal values.

                 * The precise number of adaptive adjacent points can be provided by setting the bandwidth type (kernel_type) method.

                """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary.residual_squares": """float: The sum of squared residuals in the summary of geographically weighted regression results. The residual sum of squares is the sum of the squares of the actual value and the estimated value (or fitted value). The smaller the measured value, the better the model fits the observation data, 
    that is, the better the fit. """,

    "iobjectspy._jsuperpy.analyst.ss.GWRSummary.sigma": """float: The estimated standard deviation of the residuals in the summary of geographically weighted regression results. The estimated standard deviation of the residual is the residual sum of squares divided by the square root of the effective degrees of freedom of the residual. 
     The smaller the statistical value, the better the model fitting effect. """,

    "iobjectspy._jsuperpy.analyst.ss.GeographicalDetectorResult": """
    Geographic detector result class, used to obtain the results of geographic detector calculation, including factor detector, ecological detector, interaction detector, risk detector analysis results.
    """,

    "iobjectspy._jsuperpy.analyst.ss.GeographicalDetectorResult.ecological_detector_result": """pandas.DataFrame: Ecological detector analysis result. Ecological detector is used to compare whether the influence of two factors X1 and X2 on the spatial distribution of attribute Y is significantly different , Measured by F statistic.

                             .. image:: ../image/GeographicalDetectorFformula.png

                             """,

    "iobjectspy._jsuperpy.analyst.ss.GeographicalDetectorResult.factor_detector_result": """pandas.DataFrame: factor detector analysis result. Detecting the spatial divergence of Y and detecting how much a factor X explains the spatial divergence of attribute Y Measured with q value.

                             .. image:: ../image/GeographicalDetectorQformula.png

                             The value range of q is [0,1]. The larger the value, the more obvious the spatial differentiation of y. If the stratification is generated by the independent variable X, the larger the value of q, the more consistent the spatial distribution of X and Y ,
                             The stronger the explanatory power of the independent variable X to the attribute Y, the weaker it is on the contrary. In extreme cases, a q value of 1 indicates that in the layer of X, the variance of Y is 0, that is, the factor X completely controls the spatial distribution of Y.
                             A value of 0 means that the variance of Y after stratification by X is equal to the variance of Y without stratification, and Y is not differentiated by X, that is, the factor X and Y have no relationship. The q value means that X explains 100q% of Y.
        """,

    "iobjectspy._jsuperpy.analyst.ss.GeographicalDetectorResult.interaction_detector_result": """InteractionDetectorResult: InteractionDetectorResult: Interaction probe analysis results. Identify the interaction between different risk factors Xs, that is, whether the combination of factors X1 and X2 will increase or decrease the explanatory power of the dependent variable Y, 
                                     or whether the effects of these factors on Y are independent of each other? The evaluation method is to first calculate the q value of two factors X1 and X2 to Y: q(Y|X1) and q(Y|X2). Then superimpose the new layer formed by the tangency of the two layers of variables X1 and X2, and calculate the q value of X1âˆ©X2 to Y: q(Y|X1âˆ©X2).
                                      Finally, compare the values of q(Y|X1), q(Y|X2) and q(Y|X1âˆ©X2) to determine the interaction.

                                       -q(X1âˆ©X2) <Min(q(X1),q(X2)) nonlinearity reduction
                                       -Min(q(X1),q(X2)) <q(X1âˆ©X2) <Max(q(X1),q(X2)) Single-factor nonlinearity reduction
                                       -q(X1âˆ©X2)> Max(q(X1),q(X2)) two-factor enhancement
                                       -q(X1âˆ©X2) = q(X1) + q(X2) independent
                                       -q(X1âˆ©X2)> q(X1) + q(X2) nonlinear enhancement
        """,

    "iobjectspy._jsuperpy.analyst.ss.GeographicalDetectorResult.risk_detector_result": """RiskDetectorResult: Risk area detector analysis result. It is used to judge whether there is a significant difference in the attribute mean between two sub-regions, using t statistic to test.

                               .. image:: ../image/GeographicalDetectorTformula.png

        """,

    "iobjectspy._jsuperpy.analyst.ss.GeographicalDetectorResult.variables": """list[str]: Geographical detector explanatory variable """,

    "iobjectspy._jsuperpy.analyst.ss.IncrementalResult": """
    Incremental spatial autocorrelation result class. This class is used to obtain the results of incremental spatial autocorrelation calculations, including the resultant incremental distance, Moran index, expectation, variance, Z score, and P value.
    """,

    "iobjectspy._jsuperpy.analyst.ss.IncrementalResult.distance": """float: incremental distance in incremental spatial autocorrelation results""",

    "iobjectspy._jsuperpy.analyst.ss.IncrementalResult.expectation": """float: the expected value in the analysis mode result""",

    "iobjectspy._jsuperpy.analyst.ss.IncrementalResult.index": """float: Moran index or GeneralG index in the analysis mode result""",

    "iobjectspy._jsuperpy.analyst.ss.IncrementalResult.p_value": """float: P value in the analysis mode result""",

    "iobjectspy._jsuperpy.analyst.ss.IncrementalResult.variance": """float: the variance value in the analysis mode result""",

    "iobjectspy._jsuperpy.analyst.ss.IncrementalResult.z_score": """float: Z score in the analysis mode result""",

    "iobjectspy._jsuperpy.analyst.ss.InteractionDetectorResult": """
    The analysis result of the interaction detector is used to obtain the analysis result obtained by the interaction detector on the data, including the description of the interaction between different explanatory variables and the analysis result matrix.
    The user cannot create this object.
    """,

    "iobjectspy._jsuperpy.analyst.ss.InteractionDetectorResult.descriptions": """list[str]: Description of interaction detector results. Evaluate whether different explanatory variables will increase or decrease the explanatory power of the dependent variable when they work together, 
    or whether the effects of these factors on the dependent variable are independent of each other. The types of interaction between the two explanatory variables on the dependent variable include: non-linear weakening, single factor Non-linear weakening, two-factor enhancement, 
    independent and non-linear enhancement. """,

    "iobjectspy._jsuperpy.analyst.ss.InteractionDetectorResult.interaction_values": """pandas.DataFrame: Interaction detector analysis result values.""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary": """
    The general least squares result summary class. This category gives a summary of the results of ordinary least squares analysis, such as distribution statistics, statistical probability, AICc, and coefficient of determination.
    """,

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.AIC": """float: AIC in the summary of ordinary least squares results. Similar to AICc, it is a standard to measure the goodness of model fitting. It can weigh the complexity of the estimated model and the goodness of the model fitting data. 
    When evaluating the model, both simplicity and accuracy are considered. It shows that increasing the number of free parameters improves the goodness of the fit. AIC encourages the fit of the data, but overfitting should be avoided as much as possible. 
    Therefore, priority is given to those with a smaller AIC value, which is to find a model that can best explain the data but contains the fewest free parameters.""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.AICc": """float: AICc in the summary of ordinary least squares results. When data increases, AICc converges to AIC, which is also a measure of model performance, which helps Compare different regression models.
        Considering the complexity of the model, a model with a lower AICc value will better fit the observed data. AICc is not an absolute measure of goodness of fit, but it is very useful for comparing models that use the same dependent variable and have different explanatory variables. 
        If the difference between the AICc values of the two models is greater than 3, the model with the lower AICc value will be regarded as the better model. """,

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.F_dof": """int: The degree of freedom of the joint F statistic in the summary of ordinary least squares results. """,

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.F_probability": """float: The probability of the joint F statistic in the summary of ordinary least squares results. """,

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.JB_dof": """int: The degree of freedom of the Jarque-Bera statistic in the summary of ordinary least squares results. """,

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.JB_probability": """float: the probability of the Jarque-Bera statistic in the summary of ordinary least squares results""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.JB_statistic": """float: The Jarque-Bera statistic in the summary of ordinary least squares results. Jarque-Bera statistics can evaluate the deviation of the model and are used to indicate whether the residuals are normally distributed. 
    The null hypothesis tested is that the residuals are normally distributed. For a confidence level of 95%, the probability of the joint F statistic is less than 0.05, indicating that the model is statistically significant, the regression will not be normally distributed, 
    and the model is biased.
        . """,

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.KBP_dof": """int: Koenker (Breusch-Pagan) statistic degrees of freedom in the summary of ordinary least squares results. """,

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.KBP_probability": """float: the probability of the Koenker (Breusch-Pagan) statistic in the summary of ordinary least squares results""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.KBP_statistic": """float: Koenker (Breusch-Pagan) statistics in the summary of ordinary least squares results. Koenker (Breusch-Pagan) statistics can assess the steady state of the model and are used to determine whether the explanatory variable of the model 
    has a consistent relationship with the dependent variable in both geographic space and data space. The tested null hypothesis is that the tested model is stable. For the 95% confidence level, the probability of the joint F statistic is less than 0.05, which indicates that the model has statistically 
    significant heteroscedasticity or non-steady state. When the test result is significant, you need to refer to the robustness coefficient standard deviation and probability to evaluate the effect of each explanatory variable. """,

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.R2": """float: The coefficient of determination (R2) in the summary of ordinary least squares results.""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.R2_adjusted": """float: the coefficient of determination for correction in the summary of ordinary least squares results""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.VIF": """list[float]: The variance expansion factor in the summary of ordinary least squares results""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.coefficient": """list[float]: The coefficient in the summary of ordinary least squares results. The coefficient represents the relationship and type between the explanatory variable and the dependent variable.""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.coefficient_std": """list[float]: Standard deviation of coefficients in the summary of ordinary least squares results""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.f_statistic": """float: The joint F statistic in the summary of ordinary least squares results. The joint F statistic is used to test the statistical significance of the entire model. 
    Only when the Koenker (Breusch-Pagan) statistic is not statistically significant, the joint F statistic is credible. The null hypothesis tested is that the explanatory variables in the model do not work. For a confidence level of 95%, 
    the probability of the joint F statistic is less than 0.05, which indicates that the model is statistically significant. """,

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.probability": """list[float]: probability of t distribution statistic in the summary of ordinary least squares results""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.robust_Pr": """list[float]: The probability of the robustness coefficient in the summary of ordinary least squares results.""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.robust_SE": """list[float]: Get the standard deviation of the robustness coefficient in the summary of ordinary least squares results.""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.robust_t": """list[float]: The distribution statistic of robustness coefficient t in the summary of ordinary least squares results.""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.sigma2": """float: The residual variance in the summary of ordinary least squares results.""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.std_error": """list[float]: Standard error in the summary of ordinary least squares results.""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.t_statistic": """list[float]: t distribution statistics in the summary of ordinary least squares results.""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.variable": """list[float]: The variable array in the summary of ordinary least squares results""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.wald_dof": """int: the degree of freedom of the joint chi-square statistic in the summary of ordinary least squares results""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.wald_probability": """float: the probability of the joint chi-square statistic in the summary of ordinary least squares results""",

    "iobjectspy._jsuperpy.analyst.ss.OLSSummary.wald_statistic": """float: The joint chi-square statistic in the summary of ordinary least squares results. 
    The combined chi-square statistic is used to test the statistical significance of the entire model. Only when the Koenker (Breusch-Pagan) statistic is statistically significant, 
    the joint F statistic is credible. The null hypothesis tested is that the explanatory variables in the model do not work. For a confidence level of 95%, the probability of the joint 
    F statistic is less than 0.05, which indicates that the model is statistically significant. """,

    "iobjectspy._jsuperpy.analyst.ss.RiskDetectorMean": """
    The risk detector result mean class is used to obtain the mean value of the results of different explanatory variable fields obtained by the risk area detector on the data.
    """,

    "iobjectspy._jsuperpy.analyst.ss.RiskDetectorMean.means": """list[float]: mean value of risk detector analysis results""",

    "iobjectspy._jsuperpy.analyst.ss.RiskDetectorMean.unique_values": """list[str]: Unique value of risk detector explanatory variable field """,

    "iobjectspy._jsuperpy.analyst.ss.RiskDetectorMean.variable": """str: risk detector explanatory variable name """,

    "iobjectspy._jsuperpy.analyst.ss.RiskDetectorResult": """The risk area detector analysis result class, used to obtain the analysis results obtained by the risk area detector on the data, including the average result and the result matrix """,

    "iobjectspy._jsuperpy.analyst.ss.RiskDetectorResult.means": """list[iobjectspy.RiskDetectorMean]: Mean value of detector results in risk area""",

    "iobjectspy._jsuperpy.analyst.ss.RiskDetectorResult.values": """list[pandas.DataFrame]: Risk detector analysis result value""",

    "iobjectspy._jsuperpy.analyst.ss.auto_correlation": """
    Analysis mode introduction:

        The analysis mode can assess whether a set of data forms a discrete spatial pattern, a clustered spatial pattern, or a random spatial pattern.

        * The data used for calculation in the analysis mode can be points, lines, and areas. For point, line and area objects, the centroid of the object is used in the distance calculation. The centroid of the object is the weighted average center of all sub-objects. The weighting term of the point object is 1 (that is, the centroid is itself), the weighting term of the line object is the length, and the weighting term of the area object is the area.
        * The analysis mode class adopts inferential statistics, and the "null hypothesis" will be established in the statistical test, assuming that the elements or the related values between the elements are all shown as random spatial patterns.
        * In the calculation of the analysis result, a P value will be given to indicate the correct probability of the "null hypothesis" to determine whether to accept the "null hypothesis" or reject the "null hypothesis".
        * In the calculation of the analysis result, a Z score will be given to indicate the multiple of the standard deviation to determine whether the data is clustered, discrete or random.
        * To reject the "Null Hypothesis", one must bear the risk of making the wrong choice (ie wrongly rejecting the "Null Hypothesis").

          The following table shows the uncorrected critical P value and critical Z score under different confidence levels:

          .. image:: ../image/AnalyzingPatterns.png

        * Users can solve the following problems through analysis mode:

            * Does the feature in the dataset or the value associated with the feature in the dataset have spatial clustering?
            * Will the degree of clustering of the dataset change over time?

        Analysis modes include spatial autocorrelation analysis (:py:func:`auto_correlation` ), average nearest neighbor analysis (:py:func:`average_nearest_neighbor` ),
        High and low value cluster analysis (:py:func:`high_or_low_clustering` ), incremental spatial autocorrelation analysis (:py:func:`incremental_auto_correlation` ), etc.

    Perform spatial autocorrelation analysis on the vector dataset, and return the spatial autocorrelation analysis result. The results returned by spatial autocorrelation include Moran index, expectation, variance, z score, P value,
    See: py:class:`.AnalyzingPatternsResult` class.

    .. image:: ../image/AnalyzingPatterns_autoCorrelation.png


    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param str assessment_field: The name of the assessment field. Only numeric fields are valid.
    :param concept_model: Conceptual model of spatial relationship. Default value: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`.
    :type concept_model: ConceptualizationModel or str
    :param distance_method: distance calculation method type
    :type distance_method: DistanceMethod or str
    :param float distance_tolerance: Cut off distance tolerance. Only for the conceptualization model set to: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`,
                                     :py:attr:`.ConceptualizationModel.INVERSEDISTANCESQUARED`,
                                     :py:attr:`.ConceptualizationModel.FIXEDDISTANCEBAND`,
                                     :py:attr:`.ConceptualizationModel.ZONEOFINDIFFERENCE` is valid.

                                     Specify the break distance for the "Reverse Distance" and "Fixed Distance" models. "-1" means that the default distance is calculated and applied. 
                                     The default value is to ensure that each feature has at least one adjacent feature; "0" means that no distance is applied, and each feature is an adjacent feature.
    :param float exponent: Inverse distance power exponent. Only for the conceptualization model set to: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`,
                                     :py:attr:`.ConceptualizationModel.INVERSEDISTANCESQUARED`,
                                     :py:attr:`.ConceptualizationModel.ZONEOFINDIFFERENCE` is valid.
    :param int k_neighbors: The number of neighbors. The K nearest elements around the target feature are neighbors. Only valid when the conceptualization model is set to: py:attr:`.ConceptualizationModel.KNEARESTNEIGHBORS`.
    :param bool is_standardization: Whether to standardize the spatial weight matrix. If standardize, each one will be divided by the weight of the line and.
    :param str weight_file_path: file path of spatial weight matrix
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: spatial autocorrelation result
    :rtype: AnalyzingPatternsResult
    """,

    "iobjectspy._jsuperpy.analyst.ss.average_nearest_neighbor": """

    Perform average nearest neighbor analysis on the vector dataset and return the average nearest neighbor analysis result array.

    * The results returned by average nearest neighbors include nearest neighbor index, expected average distance, average observation distance, z score, P value, please refer to: py:class:`.AnalyzingPatternsResult` class.

    * The area of the given study area must be greater than or equal to 0; if the area of the study area is equal to 0, the minimum area bounding rectangle of the input dataset will be automatically generated, and the area of the rectangle will be used for calculation.
      The default value is: 0.

    * The distance calculation method type can specify the distance calculation method between adjacent elements (see: py:class:`.DistanceMethod`). If the input dataset is a geographic coordinate system, the chord measurement method will be used to
      Calculate the distance. For any two points on the surface of the earth, the chord distance between the two points is the length of the straight line connecting the two points through the earth.


    .. image:: ../image/AnalyzingPatterns_AverageNearestNeighbor.png


    For the introduction of analysis mode, please refer to: py:func:`auto_correlation`

    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param float study_area: study area area
    :param distance_method: distance calculation method
    :type distance_method: DistanceMethod or str
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: average nearest neighbor analysis result
    :rtype: AnalyzingPatternsResult
    """,

    "iobjectspy._jsuperpy.analyst.ss.bshade_estimation": """

    BShade forecast

    :param source_dataset: source dataset
    :type source_dataset: DatasetVector or str
    :param historical_dataset: historical dataset
    :type historical_dataset: DatasetVector or str
    :param source_data_fields: source dataset data field name collection
    :type source_data_fields: list[str] or tuple[str] or str
    :param historical_fields: Historical dataset data field name collection
    :type historical_fields: list[str] or tuple[str] or str
    :param estimate_method: Estimate method. It includes two methods: total and average.
    :type estimate_method: BShadeEstimateMethod or str
    :param out_data: The datasource of the result dataset
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: The name of the output dataset.
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: analysis result
    :rtype: BShadeEstimationResult
    """,

    "iobjectspy._jsuperpy.analyst.ss.bshade_sampling": """
    BShade sampling.

    :param historical_dataset: historical dataset.
    :type historical_dataset: DatasetVector or str
    :param historical_fields: Historical dataset data field name collection.
    :type historical_fields: list[str] or tuple[str] or str
    :param BShadeSamplingParameter parameter: Parameter setting.
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Analysis result.
    :rtype: list[BShadeSamplingResult]
    """,

    "iobjectspy._jsuperpy.analyst.ss.build_weight_matrix": """
    Construct the spatial weight matrix.

     * The spatial weight matrix file is designed to generate, store, reuse and share a conceptual model of the spatial relationship between a set of elements. The file is created in a binary file format, and the element relationship
       Stored as a sparse matrix.

     * This method will generate a spatial weight matrix file, the file format is â€˜*.swmbâ€™. The generated spatial weight matrix file can be used for analysis, 
     as long as the spatial relationship conceptualization model is set to :py:attr:`.ConceptualizationModel.SPATIALWEIGHTMATRIXFILE` and the full path of the created 
     spatial weight matrix file is specified by the weight_file_path parameter.

    :param source: The dataset of the spatial weight matrix to be constructed, supporting points, lines and surfaces.
    :type source: DatasetVector or str
    :param str unique_id_field: Unique ID field name, must be a numeric field.
    :param str file_path: The path to save the spatial weight matrix file.
    :param concept_model: conceptual model
    :type concept_model: ConceptualizationModel or str
    :param distance_method: distance calculation method type
    :type distance_method: DistanceMethod or str
    :param float distance_tolerance: Cut off distance tolerance. Only for the conceptualization model set to: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`,
                                     :py:attr:`.ConceptualizationModel.INVERSEDISTANCESQUARED`,
                                     :py:attr:`.ConceptualizationModel.FIXEDDISTANCEBAND`,
                                     :py:attr:`.ConceptualizationModel.ZONEOFINDIFFERENCE` is valid.

                                     Specify the break distance for the "Reverse Distance" and "Fixed Distance" models. "-1" means that the default distance is calculated and applied.
                                      The default value is to ensure that each feature has at least one adjacent feature; "0" means that no distance is applied, and each feature is an adjacent feature

    :param float exponent: Inverse distance power exponent. Only for the conceptualization model set to: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`,
                           :py:attr:`.ConceptualizationModel.INVERSEDISTANCESQUARED`,
                           :py:attr:`.ConceptualizationModel.ZONEOFINDIFFERENCE` is valid.

    :param int k_neighbors: The number of neighbors. Only valid when the conceptualization model is set to: py:attr:`.ConceptualizationModel.KNEARESTNEIGHBORS`.
    :param bool is_standardization: Whether to standardize the spatial weight matrix. If normalized, each weight will be divided by the sum of the row.
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: If the spatial weight matrix is constructed, return True, otherwise return False
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.ss.cluster_outlier_analyst": """
    Introduction to cluster distribution:

        The cluster distribution can identify a set of statistically significant hotspots, cold spots, or spatial outliers.

        The data used to calculate the cluster distribution can be points, lines, and areas. For point, line and area objects, the centroid of the object is used in the distance calculation. The centroid of the object is the weighted average center of all sub-objects. 
        The weighting term of the point object is 1 (that is, the centroid is itself), the weighting term of the line object is the length, and the weighting term of the area object is the area.

        Users can solve the following problems through clustering distribution calculation:

            1. Where do clusters or cold spots and hot spots appear?
            2. Where do the spatial outliers appear?
            3. Which elements are very similar?

        Clustering distribution includes clustering and outlier analysis (:py:func:`cluster_outlier_analyst`), hot spot analysis (:py:func:`hot_spot_analyst`),
        Optimized hot spot analysis (:py:func:`optimized_hot_spot_analyst`) etc.


    Clustering and outlier analysis, return result vector dataset.

     * The result dataset includes local Moran index (ALMI_MoranI), z score (ALMI_Zscore), P value (ALMI_Pvalue) and clustering and outlier type (ALMI_Type).
     * Both z-score and P-value are measures of statistical significance, which are used to judge whether to reject the "null hypothesis" on a factor-by-element basis. The confidence interval field will identify statistically significant clusters and outliers. 
     If the Z score of a feature is a high positive value, it means that the surrounding features have similar values (high or low), and the cluster and outlier type fields will represent statistically significant high-value clusters as " HH", 
     the statistically significant low-value cluster is expressed as "LL"; if the Z score of the element is a low negative value, it means that there is a statistically significant spatial data outlier, cluster And the outlier type field will indicate that 
     low-value elements surround high-value elements as "HL", and high-value elements around low-value elements as "LH".
     * When is_FDR_adjusted is not set, statistical significance is based on the P value and Z field. Otherwise, the key P value to determine the confidence level will be reduced to take into account multiple testing and spatial dependence.

     .. image:: ../image/ClusteringDistributions_clusterOutlierAnalyst.png


    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param str assessment_field: The name of the assessment field. Only numeric fields are valid.
    :param concept_model: Conceptual model of spatial relationship. Default value: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`.
    :type concept_model: ConceptualizationModel or str
    :param distance_method: distance calculation method type
    :type distance_method: DistanceMethod or str
    :param float distance_tolerance: Cut off distance tolerance. Only for the conceptualization model set to: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`,
                                     :py:attr:`.ConceptualizationModel.INVERSEDISTANCESQUARED`,
                                     :py:attr:`.ConceptualizationModel.FIXEDDISTANCEBAND`,
                                     :py:attr:`.ConceptualizationModel.ZONEOFINDIFFERENCE` is valid.

                                     Specify the break distance for the "Reverse Distance" and "Fixed Distance" models. "-1" means that the default distance is calculated and applied. The default value is to ensure that each feature has at least one adjacent feature; 
                                     "0" means that no distance is applied, and each feature is an adjacent feature.

    :param float exponent: Inverse distance power exponent. Only for the conceptualization model set to: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`,
                                     :py:attr:`.ConceptualizationModel.INVERSEDISTANCESQUARED`,
                                     :py:attr:`.ConceptualizationModel.ZONEOFINDIFFERENCE` is valid.
    :param bool is_FDR_adjusted: Whether to perform FDR (false discovery rate) correction. If the FDR (false discovery rate) correction is performed, the statistical significance will be based on the false discovery rate correction, otherwise, the statistical significance will be based on the P value and z-score fields.
    :param int k_neighbors: The number of neighbors. The K nearest elements around the target feature are neighbors. Only valid when the conceptualization model is set to: py:attr:`.ConceptualizationModel.KNEARESTNEIGHBORS`.
    :param bool is_standardization: Whether to standardize the spatial weight matrix. If normalized, each weight will be divided by the sum of the row.
    :param str weight_file_path: file path of spatial weight matrix
    :param out_data: result datasource
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.collect_events": """

    Collect events and convert event data into weighted data.

     * The result point dataset contains a Counts field, which stores the sum of all centroids of each unique position.

     * Collecting events will only process objects with exactly the same centroid coordinates, and only one centroid will be retained and the remaining duplicate points will be removed.

     * For point, line and area objects, the centroid of the object will be used in the distance calculation. The centroid of the object is the weighted average center of all sub-objects. The weighting term of the point object is 1 (that is, the centroid is itself),
       The weighting term for line objects is length, and the weighting term for area objects is area.


    :param source: The dataset to be collected. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param out_data: The datasource used to store the result point dataset.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: The name of the result point dataset.
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.density_based_clustering": """
    DBSCAN implementation of density clustering

    According to the given search radius (search_distance) and the minimum number of points to be included in the range (min_pile_point_count), this method connects the areas of the spatial point data that are dense enough and similar in space, and eliminates noise interference to achieve better clustering effect.

    :param input_data: The specified vector dataset to be clustered, supporting point dataset.
    :type input_data: DatasetVector or str
    :param min_pile_point_count: The minimum number of points contained in each category
    :type min_pile_point_count: int
    :param search_distance: the distance to search for the neighborhood
    :type search_distance: int
    :param unit: unit of search distance
    :type unit: Unit
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.geographical_detector": """
    Perform geographic detector analysis on the data and return the results of the geographic detector.
    The results returned by the geographic detector include the analysis results of factor detectors, ecological detectors, interaction detectors, and risk detectors

    Geodetector is a set of statistical methods to detect spatial differentiation and reveal the driving force behind it. The core idea is based on the assumption that if an independent variable has an important influence on a dependent variable
    Therefore, the spatial distribution of the independent variable and the dependent variable should be similar. Geographic differentiation can be expressed by classification algorithms, such as environmental remote sensing classification, or it can be determined based on experience, such as the Hu Huanyong line.
    Geographic detectors are good at analyzing type quantities, and for sequential quantities, ratio quantities or interval quantities, as long as they are appropriately discretized, they can also be used for statistical analysis.
    Therefore, geographic detectors can detect both numerical data and qualitative data, which is a major advantage of geographic detectors. Another unique advantage of geodetector is to detect the interaction of two factors on the dependent variable. The general identification method of interaction is to add the product of two factors to the regression model to test its statistical significance. 
    However, the interaction of two factors is not necessarily a multiplicative relationship.
    By calculating and comparing the q value of each single factor and the q value of the superposition of the two factors, the geographic detector can judge whether there is an interaction between the two factors, and whether the interaction is strong or weak, direction, linear or
    Non-linearity etc. The superposition of two factors includes both the multiplication relationship and other relationships. As long as there is a relationship, it can be tested.

    :param input_data: vector dataset to be calculated
    :type input_data: DatasetVector or str
    :param str model_field: modeling field
    :param explanatory_fields: explanatory variable array
    :type explanatory_fields: list[str] or str
    :param bool is_factor_detector: Whether to calculate factor detector
    :param bool is_ecological_detector: Whether to calculate the ecological detector
    :param bool is_interaction_detector: Whether to calculate the interaction detector
    :param bool is_risk_detector: whether to perform risk detection
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Geodetector result
    :rtype: GeographicalDetectorResult
    """,

    "iobjectspy._jsuperpy.analyst.ss.hierarchical_density_based_clustering": """
    HDBSCAN implementation of density clustering

    This method is an improvement of the DBSCAN method, and only the minimum number of points (min_pile_point_count) in the given spatial neighborhood is required. On the basis of DBSCAN, different search radius is calculated and the most stable spatial clustering distribution is selected as the density clustering result.

    :param input_data: The specified vector dataset to be clustered, supporting point dataset.
    :type input_data: DatasetVector or str
    :param min_pile_point_count: The minimum number of points contained in each category
    :type min_pile_point_count: int
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.high_or_low_clustering": """
    Perform high and low value cluster analysis on the vector dataset, and return the high and low value cluster analysis results. The results returned by high and low value clustering include GeneralG index, expectation, variance, z score, P value,
    See: py:class:`.AnalyzingPatternsResult` class.

    .. image:: ../image/AnalyzingPatterns_highOrLowClustering.png

    For the introduction of analysis mode, please refer to: py:func:`auto_correlation`


    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param str assessment_field: The name of the assessment field. Only numeric fields are valid.
    :param concept_model: Conceptual model of spatial relationship. Default value: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`.
    :type concept_model: ConceptualizationModel or str
    :param distance_method: distance calculation method type
    :type distance_method: DistanceMethod or str
    :param float distance_tolerance: Cut off distance tolerance. Only for the conceptualization model set to: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`,
                                     :py:attr:`.ConceptualizationModel.INVERSEDISTANCESQUARED`,
                                     :py:attr:`.ConceptualizationModel.FIXEDDISTANCEBAND`,
                                     :py:attr:`.ConceptualizationModel.ZONEOFINDIFFERENCE` is valid.

                                     Specify the break distance for the "Reverse Distance" and "Fixed Distance" models. "-1" means that the default distance is calculated and applied. The default value is to ensure that each feature has at least one adjacent feature;
                                      "0" means that no distance is applied, and each feature is an adjacent feature.

    :param float exponent: Inverse distance power exponent. Only for the conceptualization model set to: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`,
                                     :py:attr:`.ConceptualizationModel.INVERSEDISTANCESQUARED`,
                                     :py:attr:`.ConceptualizationModel.ZONEOFINDIFFERENCE` is valid.
    :param int k_neighbors: The number of neighbors. The K nearest elements around the target feature are neighbors. Only valid when the conceptualization model is set to: py:attr:`.ConceptualizationModel.KNEARESTNEIGHBORS`.
    :param bool is_standardization: Whether to standardize the spatial weight matrix. If normalized, each weight will be divided by the sum of the row.
    :param str weight_file_path: file path of spatial weight matrix
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: high and low value clustering results
    :rtype: AnalyzingPatternsResult
    """,

    "iobjectspy._jsuperpy.analyst.ss.hot_spot_analyst": """
    Hot spot analysis, return result vector dataset.

     * The result dataset includes z score (Gi_Zscore), P value (Gi_Pvalue) and confidence interval (Gi_ConfInvl).

     * Both z-score and P-value are measures of statistical significance, which are used to judge whether to reject the "null hypothesis" on a factor-by-element basis. The confidence interval field will identify statistically significant hot and cold spots. 
     Elements with confidence intervals of +3 and -3 reflect statistical significance with a confidence of 99%, elements with confidence intervals of +2 and -2 reflect statistical significance with a confidence of 95%, and The elements with confidence intervals 
     of +1 and -1 reflect statistical significance with a confidence of 90%, while the clustering of elements with confidence intervals of 0 has no statistical significance.

     * Without setting the is_FDR_adjusted method, statistical significance is based on the P value and Z field. Otherwise, the key P value for determining the confidence level will be reduced to take into account multiple tests and spatial dependence.

    .. image:: ../image/ClusteringDistributions_hotSpotAnalyst.png


    For introduction to cluster distribution, refer to:py:func:`cluster_outlier_analyst`

    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param str assessment_field: The name of the assessment field. Only numeric fields are valid.
    :param concept_model: Conceptual model of spatial relationship. Default value: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`.
    :type concept_model: ConceptualizationModel or str
    :param distance_method: distance calculation method type
    :type distance_method: DistanceMethod or str
    :param float distance_tolerance: Cut off distance tolerance. Only for the conceptualization model set to: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`,
                                     :py:attr:`.ConceptualizationModel.INVERSEDISTANCESQUARED`,
                                     :py:attr:`.ConceptualizationModel.FIXEDDISTANCEBAND`,
                                     :py:attr:`.ConceptualizationModel.ZONEOFINDIFFERENCE` is valid.

                                    Specify the break distance for the "Reverse Distance" and "Fixed Distance" models. "-1" means that the default distance is calculated and applied. The default value is to ensure that each feature has at least one adjacent feature; 
                                    "0" means that no distance is applied, and each feature is an adjacent feature.

    :param float exponent: Inverse distance power exponent. Only for the conceptualization model set to: py:attr:`.ConceptualizationModel.INVERSEDISTANCE`,
                           :py:attr:`.ConceptualizationModel.INVERSEDISTANCESQUARED`,
                           :py:attr:`.ConceptualizationModel.ZONEOFINDIFFERENCE` is valid.
    :param bool is_FDR_adjusted: Whether to perform FDR (false discovery rate) correction. If the FDR (false discovery rate) correction is performed, the statistical significance will be based on the false discovery rate correction, otherwise, the statistical significance will be based on the P value and z-score fields.
    :param int k_neighbors: The number of neighbors. The K nearest elements around the target feature are neighbors. Only valid when the conceptualization model is set to: py:attr:`.ConceptualizationModel.KNEARESTNEIGHBORS`.
    :param bool is_standardization: Whether to standardize the spatial weight matrix. If normalized, each weight will be divided by the sum of the row.
    :param str self_weight_field: The name of its own weight field. Only numeric fields are valid.
    :param str weight_file_path: file path of spatial weight matrix
    :param out_data: result datasource
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.incremental_auto_correlation": """
    Perform incremental spatial autocorrelation analysis on the vector dataset, and return an array of incremental spatial autocorrelation analysis results. The results returned by incremental spatial autocorrelation include incremental distance, Moran index, expectation, variance, z-score, P-value,
    See: py:class:`.IncrementalResult` class.

    Incremental spatial autocorrelation will run the spatial autocorrelation method for a series of incremental distances (refer to: py:func:`auto_correlation`), and the spatial relationship conceptual model defaults to a fixed distance
    Model (see: py:attr:`.ConceptualizationModel.FIXEDDISTANCEBAND`)

    For the introduction of analysis mode, please refer to: py:func:`auto_correlation`

    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param str assessment_field: The name of the assessment field. Only numeric fields are valid.
    :param float begin_distance: The starting distance of incremental spatial autocorrelation analysis.
    :param distance_method: distance calculation method type
    :type distance_method: DistanceMethod or str
    :param float incremental_distance: distance increment, the distance between each analysis of incremental spatial autocorrelation.
    :param int incremental_number: The number of incremental distance segments. Specify the number of times to analyze the dataset for incremental spatial autocorrelation. The value range is 2 ~ 30.
    :param bool is_standardization: Whether to standardize the spatial weight matrix. If normalized, each weight will be divided by the sum of the row.
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Incremental spatial autocorrelation analysis result list.
    :rtype: list[IncrementalResult]
    """,

    "iobjectspy._jsuperpy.analyst.ss.measure_central_element": """
    About spatial measurement:

        The data used to calculate the spatial metric can be points, lines, and areas. For point, line and area objects, the centroid of the object is used in the distance calculation. The centroid of the object is the weighted average center of all sub-objects. 
        The weighting term of the point object is 1 (that is, the centroid is itself), the weighting term of the line object is the length, and the weighting term of the area object is the area.

        Users can solve the following problems through spatial measurement calculations:

            1. Where is the center of the data?

            2. What is the shape and direction of the data distribution?

            3. How is the data distributed?

        Spatial measurement includes central element (:py:func:`measure_central_element` ), direction distribution (:py:func:`measure_directional` ),
        Standard distance (:py:func:`measure_standard_distance` ), direction average (:py:func:`measure_linear_directional_mean` ),
        Mean center (:py:func:`measure_mean_center` ), median center (:py:func:`measure_median_center` ), etc.

    Calculate the central element of the vector data and return the result vector dataset.

     * The central element is the object that has the smallest cumulative distance from the centroid of all other objects and is located at the center.

     * If the group field is set, the result vector dataset will contain the "group field name_Group" field.

     * In fact, there may be multiple central elements with the smallest cumulative distance from the centroid of all other objects, but the central element method will only output the object with the smallest SmID field value.

    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param str group_field: the name of the grouping field
    :param str weight_field: the name of the weight field
    :param str self_weight_field: the name of its own weight field
    :param distance_method: distance calculation method type
    :type distance_method: DistanceMethod or str
    :param stats_fields: The type of statistical fields. It is a dictionary type. The key of the dictionary type is the field name, and the value is the statistical type.
    :type stats_fields: list[tuple[str,SpatialStatisticsType]] or list[tuple[str,str]] or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result vector dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.measure_directional": """
    Calculate the direction distribution of the vector data and return the result vector dataset.

     * The direction distribution is the standard deviation ellipse obtained by calculating the standard deviation of the x and y coordinates as the axis based on the average center of the centroid of all objects (weighted, weighted).

     * The x and y coordinates of the center of the standard deviation ellipse, two standard distances (half-major axis and semi-minor axis), and the direction of the ellipse are stored in CircleCenterX,
       CircleCenterY, SemiMajorAxis, SemiMinorAxis, RotationAngle fields. If the grouping field is set, the result vector dataset will contain
       "Group field name_Group" field.

     * The direction of the ellipse. The positive value in the RotationAngle field indicates a positive ellipse (the direction of the semi-major axis is the X-axis direction, and the direction of the semi-minor axis is the Y-axis direction)) is rotated counterclockwise, and a negative value indicates
       The positive ellipse rotates clockwise.

     * The output ellipse size has three levels: Single (one standard deviation), Twice (two standard deviations) and Triple (three standard deviations). For details, please refer to: py:class:`.EllipseSize` class.

     * The standard deviation ellipse algorithm used to calculate the direction distribution was proposed by D. Welty Lefever in 1926 to measure the direction and distribution of data. First determine the center of the ellipse, that is, the average center (weight, weighted); 
     then determine the direction of the ellipse; finally determine the length of the major axis and the minor axis.

     .. image:: ../image/MeasureDirection.png


    For an introduction to spatial measurement, please refer to:py:func:`measure_central_element`


    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param str group_field: group field name
    :param ellipse_size: ellipse size type
    :type ellipse_size: EllipseSize or str
    :param stats_fields: The type of statistical fields, which is a list type. The list stores a tuple of 2 elements. The first element of the tuple is the field to be counted, and the second element is the statistical type.
    :type stats_fields: list[tuple[str,SpatialStatisticsType]] or list[tuple[str,str]] or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result vector dataset
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.measure_linear_directional_mean": """

    Calculate the directional average of the line dataset and return the result vector dataset.

     * The average linear direction is based on the average center point of the centroid of all line objects as its center, and the length is equal to the average length, orientation, or direction of all input line objects.
      Use the start point and end point to determine the direction) the calculated average bearing or the line object created by the average direction.

     * The average center x and y coordinates, average length, compass angle, direction average, and circle variance of the line object are respectively stored in AverageX, AverageY, and AverageY in the result vector dataset
       AverageLength, CompassAngle, DirectionalMean, CircleVariance fields. If the grouping field is set, the result vector dataset will contain
       "Group field name_Group" field.

     * The compass angle (CompassAngle) field of the line object means clockwise rotation based on true north; the DirectionalMean field means counterclockwise rotation based on true east; 
     CircleVariance means direction or azimuth deviation The degree of the average value of the direction. If the input line objects have very similar (or identical) directions, the value will be very small, 
     and vice versa.


     .. image:: ../image/MeasureLinearDirectionalMean.png


    For an introduction to spatial measurement, please refer to:py:func:`measure_central_element`

    :param source: The dataset to be calculated. Is the line dataset.
    :type source: DatasetVector or str
    :param str group_field: group field name
    :param str weight_field: weight field name
    :param bool is_orientation: Whether to ignore the direction of the start and end points. When it is False, the order of the start point and the end point will be used when calculating the directional average; when it is True, the order of the start point and the end point will be ignored.
    :param stats_fields: The type of statistical fields, which is a list type. The list stores a tuple of 2 elements. The first element of the tuple is the field to be counted, and the second element is the statistical type.
    :type stats_fields: list[tuple[str,SpatialStatisticsType]] or list[tuple[str,str]] or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.measure_mean_center": """
    Calculate the average center of the vector data and return the result vector dataset.

     * The average center is a point constructed based on the average x and y coordinates of the entered centroids of all objects.

     * The x and y coordinates of the average center are respectively stored in the SmX and SmY fields in the result vector dataset. If the group field is set, the result vector dataset will contain the "group field name_Group" field.

     .. image:: ../image/MeasureMeanCenter.png


    For an introduction to spatial measurement, please refer to:py:func:`measure_central_element`

    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param str group_field: group field
    :param str weight_field: weight field
    :param stats_fields: The type of statistical fields, which is a list type. The list stores a tuple of 2 elements. The first element of the tuple is the field to be counted, and the second element is the statistical type.
    :type stats_fields: list[tuple[str,SpatialStatisticsType]] or list[tuple[str,str]] or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.measure_median_center": """

    Calculate the median center of the vector data and return the result vector dataset.

     * The median center is based on the input centroids of all objects, using an iterative algorithm to find the point with the smallest Euclidean distance to the centroids of all objects.

     * The x and y coordinates of the median center are stored in the SmX and SmY fields in the result vector dataset, respectively. If the grouping field is set, the result vector dataset will contain
       "Group field name_Group" field.

     * In fact, there may be multiple points with the smallest distance from the centroid of all objects, but the median center method will only return one point.

     * The algorithm used to calculate the median center is the iterative weighted least squares method (Weiszfeld algorithm) proposed by Kuhn, Harold W. and Robert E. Kuenne in 1962, 
     and then further generalized by James E. Burt and Gerald M. Barber. First, the average center (weighted, weighted) is used as the starting point, and the candidate points are obtained by the weighted least square method. 
     The candidate points are re-used as starting points and substituted into the calculation to obtain new candidate points. The calculation is performed iteratively until the candidate points reach the European style of the centroid of all objects The distance is the smallest.

     .. image:: ../image/MeasureMedianCenter.png

    For an introduction to spatial measurement, please refer to:py:func:`measure_central_element`

    :param source: The dataset to be calculated. It can be a point, line, or area dataset.
    :type source: DatasetVector or str
    :param str group_field: group field
    :param str weight_field: weight field
    :param stats_fields: The type of statistical fields, which is a list type. The list stores a tuple of 2 elements. The first element of the tuple is the field to be counted, and the second element is the statistical type.
    :type stats_fields: list[tuple[str,SpatialStatisticsType]] or list[tuple[str,str]] or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.measure_standard_distance": """

    Calculate the standard distance of vector data and return the result vector dataset.

     * The standard distance is a circle obtained by calculating the standard distance of the x and y coordinates as the radius based on the average center of the centroid of all objects (weighted, weighted) as the center of the circle.

     * The x and y coordinates of the center of the circle and the standard distance (radius of the circle) are respectively stored in the CircleCenterX, CircleCenterY, and StandardDistance fields in the result vector dataset. 
     If the group field is set, the result vector dataset will contain the "group field name_Group" field.

     * The output circle size has three levels: Single (one standard deviation), Twice (two standard deviations) and Triple (three standard deviations). For details, please refer to: py:class:`.EllipseSize` enumeration type.

     .. image:: ../image/MeasureStandardDistance.png

    For an introduction to spatial measurement, please refer to:py:func:`measure_central_element`

    :param source: The dataset to be calculated. Line dataset
    :type source: DatasetVector or str
    :param str group_field: group field
    :param str weight_field: weight field
    :param ellipse_size: ellipse size type
    :type ellipse_size: EllipseSize or str
    :param stats_fields: The type of statistical fields, which is a list type. The list stores a tuple of 2 elements. The first element of the tuple is the field to be counted, and the second element is the statistical type.
    :type stats_fields: list[tuple[str,SpatialStatisticsType]] or list[tuple[str,str]] or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.optimized_hot_spot_analyst": """
    Optimized hotspot analysis, return result vector dataset.

     * The result dataset includes z score (Gi_Zscore), P value (Gi_Pvalue) and confidence interval (Gi_ConfInvl). For details, please refer to: py:func:`hot_spot_analyst` method results.

     * Both z-score and P-value are measures of statistical significance, which are used to judge whether to reject the "null hypothesis" on a factor-by-element basis. 
     The confidence interval field will identify statistically significant hot and cold spots. Elements with confidence intervals of +3 and -3 reflect statistical significance with a confidence of 99%, 
     elements with confidence intervals of +2 and -2 reflect statistical significance with a confidence of 95%, and confidence intervals are +1 and -1 The elements of reflect statistical significance with a confidence of 90%, 
     while the clustering of elements with a confidence interval of 0 has no statistical significance.

     * If the analysis field is provided, the hot spot analysis will be performed directly; if the analysis field is not provided, the provided aggregation method (see: py:class:`AggregationMethod`) 
     will be used to aggregate all input event points to obtain the count, and then execute as an analysis field Hot spot analysis.

     * When performing hot spot analysis, the default conceptualization model is: py:attr:`.ConceptualizationModel.FIXEDDISTANCEBAND`, false discovery rate (FDR) is True,
       Statistical significance will use the false discovery rate (FDR) correction method to automatically balance multiple testing and spatial dependence.

     .. image:: ../image/ClusteringDistributions_OptimizedHotSpotAnalyst.png

    For introduction to cluster distribution, refer to:py:func:`cluster_outlier_analyst`

    :param source: The dataset to be calculated. If the evaluation field is set, it can be a point, line, or area dataset; otherwise, it must be a point dataset.
    :type source: DatasetVector or str
    :param str assessment_field: The name of the assessment field.
    :param aggregation_method: aggregation method. If the analysis field is not set, the aggregation method provided for optimized hot spot analysis is required.

                               * If set to: py:attr:`.AggregationMethod.AGGREGATIONPOLYGONS`, aggregate_polygons must be set
                               * If set to: py:attr:`.AggregationMethod.NETWORKPOLYGONS`, if bounding_polygons is set, use
                                 bounding_polygons is used for aggregation. If bounding_polygons is not set, the geographic extent of the point dataset is used for aggregation.
                               * If set to: py:attr:`.AggregationMethod.SNAPNEARBYPOINTS`, aggregating_polygons and bounding_polygons are invalid.

    :type aggregation_method: AggregationMethod or str
    :param aggregating_polygons: aggregating event points to obtain a polygon dataset of event counts. If the analysis field (assessment_field) is not provided and aggregation_method
                                 When set to: py:attr:`.AggregationMethod.AGGREGATIONPOLYGONS`, it provides a polygon dataset that aggregates event points to obtain event counts.
                                 If the evaluation field is set, this parameter is invalid.
    :type aggregating_polygons: DatasetVector or str
    :param bounding_polygons: The boundary polygon dataset of the area where the event point occurs. Must be a polygon dataset. If the analysis field (assessment_field) is not provided and aggregation_method
                              When set to: py:attr:`.AggregationMethod.NETWORKPOLYGONS`, the boundary surface dataset of the area where the incident occurred is provided.
    :type bounding_polygons: DatasetVector or str
    :param out_data: result datasource information
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.ordering_density_based_clustering": """
    OPTICS implementation of density clustering

    Based on DBSCAN, this method additionally calculates the reachable distance of each point, and obtains the clustering result based on the ranking information and clustering coefficient (cluster_sensitivity). This method is not very sensitive to the search radius (search_distance) and the minimum number of points to be included in the range (min_pile_point_count). The main decision result is the clustering coefficient (cluster_sensitivity)

    Concept definition:
    -Reachable distance: Take the maximum value of the core distance of the core point and the distance from its neighboring points.
    -Core point: A point is within the search radius, and the number of points is not less than the minimum number of points contained in each category (min_pile_point_count).
    -Core distance: The minimum distance at which a certain point becomes a core point.
    -Clustering coefficient: an integer ranging from 1 to 100, which is a standard quantification of the number of clustering categories. When the coefficient is 1, the clustering category is the least and 100 is the most.

    :param input_data: The specified vector dataset to be clustered, supporting point dataset.
    :type input_data: DatasetVector or str
    :param min_pile_point_count: The minimum number of points contained in each category
    :type min_pile_point_count: int
    :param search_distance: the distance to search for the neighborhood
    :type search_distance: int
    :param unit: unit of search distance
    :type unit: Unit
    :param cluster_sensitivity: clustering coefficient
    :type cluster_sensitivity: int
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.ss.ordinary_least_squares": """
    Ordinary least squares method.
    The ordinary least squares analysis result information includes a result dataset and a summary of ordinary least squares results.
    The result dataset includes predicted value (Estimated), residual (Residual), standardized residual (StdResid), etc.

    Description:

    -Estimated: These values are estimated values (or fitted values) obtained by ordinary least squares.
    -Residual: These are the unexplainable parts of the dependent variable. They are the difference between the estimated value and the actual value. The average value of the standardized residual is 0 and the standard deviation is 1. Residuals can be used to determine the degree of fit of the model. Small residuals indicate that the model fits well and can explain most of the predicted values, indicating that this regression equation is effective.
    -Standardized residual (StdResid): the ratio of the residual to the standard error. This value can be used to determine whether the data is abnormal. If the data are all in the (-2, 2) interval, it indicates that the data has normality and homogeneity of variance; If the data exceeds the (-2, 2) interval, it indicates that the data is abnormal data, and there is no homogeneity of variance and normality.


    :param input_data: The specified dataset to be calculated. It can be a point, line, or area dataset.
    :type input_data: DatasetVector or str
    :param explanatory_fields: a collection of explanatory field names
    :type explanatory_fields: list[str] or str
    :param model_field: the name of the modeling field
    :type model_field: str
    :param out_data: The specified datasource used to store the result dataset.
    :type out_data: Datasource or str
    :param out_dataset_name: The specified result dataset name
    :type out_dataset_name: str
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Return a tuple, the first element of the tuple is the least squares result dataset or dataset name, the second element is the least squares result summary
    :rtype: tuple[DatasetVector, OLSSummary] or tuple[str, OLSSummary]
    """,

    "iobjectspy._jsuperpy.analyst.ss.spa_estimation": """
    Single point geographic estimation (SPA)

    :param source_dataset: source dataset
    :type source_dataset: DataetVector or str
    :param reference_dataset: reference dataset
    :type reference_dataset: DataetVector or str
    :param str source_unique_id_field: unique ID field name of the source dataset
    :param str source_data_field: source dataset data field name
    :param str reference_unique_id_field: unique field name of the reference dataset
    :param reference_data_fields: reference dataset data field name collection
    :type reference_data_fields: list[str] or tuple[str] or str
    :param out_data: The datasource of the result dataset
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: The name of the output dataset.
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result dataset
    :rtype: DatasetVector
    """,

    "iobjectspy._jsuperpy.analyst.ss.weight_matrix_file_to_table": """
    The spatial weight matrix file is converted into an attribute table.

    The result attribute table contains the source unique ID field (UniqueID), neighbors unique ID field (NeighborsID), and weight field (Weight).

    :param str file_path: The path of the spatial weight matrix file.
    :param out_data: The datasource used to store the result attribute table
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: name of result attribute table
    :param progress: progress information, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: The result attribute table dataset or dataset name.
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.terrain": """
Hydrological analysis module
""",

    "iobjectspy._jsuperpy.analyst.terrain.basin": """
    About hydrological analysis:

    * Hydrological analysis is based on the Digital Elevation Model (DEM) raster data to establish a water system model, which is used to study the hydrological characteristics of the watershed and simulate the surface hydrological process, and to make predictions for the future surface hydrological conditions. Hydrological analysis models can help us analyze the scope of floods, locate runoff pollution sources, predict the impact of landform changes on runoff, etc., and are widely used in many industries and fields such as regional planning, agriculture and forestry, disaster prediction, road design, etc.

    * The confluence of surface water is largely determined by the shape of the surface, and DEM data can express the spatial distribution of regional topography, and has outstanding advantages in describing watershed topography, such as watershed boundaries, slope and aspect, and river network extraction. So it is very suitable for hydrological analysis.

    * The main contents of hydrological analysis provided by SuperMap include filling depressions, calculating flow direction, calculating flow length, calculating cumulative water catchment, watershed division, river classification, connecting water system, and water system vectorization.

        * The general process of hydrological analysis is:

          .. image:: ../image/HydrologyAnalyst_2.png

        * How to obtain the grid water system?

          Many functions in hydrological analysis need to be based on raster water system data, such as vector water system extraction (:py:func:`stream_to_line` method), river classification (:py:func:`stream_order` method),
          Connect the water system (::py:func:`stream_link` method), etc.

          Generally, raster water system data can be extracted from the cumulative water catchment grid. In the cumulative water catchment grid, the larger the value of the cell, the larger the cumulative water catchment in the area. 
          Cells with higher cumulative water catchment can be regarded as river valleys. Therefore, by setting a threshold, cells with cumulative water catchment greater than this value can be extracted, and these cells constitute a grid water system. 
          It is worth noting that this value may be different for river valleys of different levels and valleys of the same level in different regions. Therefore, the determination of the threshold value needs to be determined based on the actual topography of the study area and through continuous experiments.

          In SuperMap, the raster water system used for further analysis (extracting vector water system, river classification, connecting water system, etc.) is required to be a binary raster. This can be achieved through raster algebraic operations to make it greater than or equal to the cumulative water catchment threshold The cell of is 1, 
          otherwise it is 0, as shown in the figure below.

          .. image:: ../image/HydrologyAnalyst_3.png

          Therefore, the process of extracting raster water systems is as follows:

           1. Obtain the cumulative water catchment grid, which can be achieved by the :py:func:`flow_accumulation` method.
           2. By using the raster algebraic operation :py:func:`expression_math_analyst` method to perform relational calculation on the cumulative water catchment grid, the raster water system data that meets the requirements can be obtained. 
           Assuming that the threshold is set to 1000, the operation expression is: "[Datasource.FlowAccumulationDataset]>1000". In addition, using the Con(x,y,z) function can also get the desired result, that is, the expression is: 
           "Con([Datasource.FlowAccumulationDataset]>1000,1,0)".


    Calculate the basin basin based on the flow direction grid. Basin is a catchment area, which is one of the ways to describe a watershed.

    Calculating watershed basins is a process of assigning a unique basin to each cell based on flow direction data. As shown in the figure below, watershed basins are one of the ways to describe watersheds, showing all grids that are connected to each other and are in the same watershed basin.

    .. image:: ../image/Basin.png


    :param direction_grid: flow direction raster dataset.
    :type direction_grid: DatasetGrid or str
    :param out_data: The datasource to store the result dataset
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: raster dataset or dataset name of the basin
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.terrain.build_quad_mesh": """
    Mesh a single simple area object.
    The fluid problem is a continuity problem. In order to simplify its research and the convenience of modeling and processing, the study area is discretized. The idea is to establish a discrete grid. The grid division is to section the continuous physical area. Divide it into several grids and determine the nodes in each grid. Use a value in the grid to replace the basic situation of the entire grid area. The grid is used as a carrier for calculation and analysis, and its quality is good or bad. It has an important influence on the accuracy and calculation efficiency of the later numerical simulation.

    Steps of meshing:

     1. Data preprocessing, including removing duplicate points, etc. Given a reasonable tolerance, removing duplicate points makes the final meshing result more reasonable, and there will be no phenomena 
     that seem to have multiple lines starting from one point (actually duplicate points).

     2. Polygon decomposition: For complex polygonal areas, we use the method of block and stepwise division to construct the grid, divide a complex irregular polygon area into multiple simple single-connected areas, and then execute each single-connected area In the grid division procedure, 
     the grids of the sub-regions are spliced together to form the division of the entire region.

     3. Choose four corner points: These 4 corner points correspond to the 4 vertices on the calculation area of the mesh, and their choice will affect the result of the division. 
     The choice should be as close as possible to the four vertices of the quadrilateral in the original area, and the overall flow potential should be considered.

        .. image:: ../image/SelectPoint.png

     4. In order to make the divided mesh present the characteristics of a quadrilateral, the vertex data (not on the same straight line) constituting the polygon need to participate in the network formation.

     5. Perform simple area meshing.

    Note: Simple polygon: any straight lines or edges in the polygon will not cross.

        .. image:: ../image/QuadMeshPart.png

    Description:

     RightTopIndex is the index number of the upper right corner, LeftTopIndex is the index number of the upper left corner, RightBottomIndex is the index number of the lower right corner, LeftBottomIndex
      is the index number of the lower left corner. Then nCount1=(RightTopIndex- LeftTopIndex+1) and nCount2=(RightBottomIndex- LeftBottomIndex+1),
     If: nCount1 is not equal to nCount2, the program does not process it.

    For related introduction of hydrological analysis, please refer to:py:func:`basin`


    :param quad_mesh_region: region object for meshing
    :type quad_mesh_region: GeoRegion
    :param Point2D left_bottom: The coordinates of the lower left corner of the polygon of the meshed area. Four corner points selection basis: 4 corner points correspond to the 4 vertices on the calculation area of the mesh,
                                The choice will affect the results of the subdivision. The choice should be as close as possible to the four vertices of the quadrilateral in the original area, while considering the overall flow potential.
    :param Point2D left_top: The coordinates of the upper left corner of the polygon of the meshed area
    :param Point2D right_bottom: coordinate of the lower right corner of the polygon of the meshed area
    :param Point2D right_top: The coordinates of the upper right corner of the polygon of the meshed area
    :param int cols: The number of nodes in the column direction of the mesh. The default value is 0, which means it will not participate in the processing; if it is not 0, but if the value is less than the maximum number of points in the polygon column direction minus one, 
                     the maximum number of points in the polygon column direction minus one is used as the number of columns (cols); if it is greater than the polygon column If the maximum number of points in the direction is subtracted by one, points will be automatically 
                     added to make the number of column directions cols.
                     For example: if the user wants to divide a rectangular area object into 2*3 (height*width)=6 small rectangles, the number of column directions (cols) is 3.
    :param int rows: The number of nodes in the row direction of the mesh. The default value is 0, which means it will not participate in the processing; if it is not 0, but the value is less than the maximum number of points in the polygon row direction minus one, 
                      the maximum number of points in the polygon row direction minus one is used as the number of rows; if it is greater than the polygon row direction If the maximum number of points is subtracted by one, points will be automatically added to make 
                      the number of rows in the direction of rows. For example: if the user wants to divide a rectangular area object into 2*3 (height * width) = 6 small rectangles, the number of rows in the direction (rows) is 2.
    :param str out_col_field: The column attribute field name of the grid segmentation result object. This field is used to store the column number of the segmentation result object.
    :param str out_row_field: The row attribute field name of the grid segmentation result object. This field is used to store the row number of the segmentation result object.
    :param out_data: The datasource that stores the segmentation result dataset.
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: The name of the split result dataset.
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: The result dataset after splitting. The split faces are returned as sub-objects.
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.terrain.fill_sink": """
    Fill pseudo depressions with DEM raster data.
    A depression is an area where the surrounding grids are higher than it, and it is divided into natural depressions and pseudo depressions.

    ã€€* Natural depressions are actual depressions that reflect the true shape of the surface, such as glaciers or karst landforms, mining areas, potholes, etc., which are generally far less than pseudo depressions;
    ã€€* False depressions are mainly caused by errors caused by data processing and improper interpolation methods, which are very common in DEM raster data.

    When determining the flow direction, because the elevation of the depression is lower than the elevation of the surrounding grid, the flow direction in a certain area will all point to the depression, causing the water flow to gather in the depression and not flow out, causing the interruption of the water catchment network.
    Therefore, filling depressions is usually a prerequisite for reasonable flow direction calculations.

    After filling a certain depression, it is possible to generate new depressions. Therefore, filling depressions is a process of recognizing depressions and filling depressions until all depressions are filled and no new depressions are generated. 
    The figure below is a schematic cross-sectional view of the filled depression.

    .. image:: ../image/FillSink.png

    This method can specify a point or surface dataset to indicate the real depressions or depressions that need to be excluded, and these depressions will not be filled. Using accurate data of this type will obtain more real terrain without pseudo depressions, 
    making subsequent analysis more reliable.

    The data used to indicate depressions. If it is a point dataset, one or more of the points can be located in the depression. The ideal situation is that the point indicates the sinking point of the depression area; 
    if it is a polygon dataset, each surface The object should cover a depression area.

    You can use the exclude_area parameter to specify a point or area dataset to indicate the actual depressions or depressions to be excluded , and these depressions will not be filled. Use accurate such data,
    A more realistic topography without pseudo depressions will be obtained, making subsequent analysis more reliable. Data used to indicate depressions. If it is a point dataset, one or more of the points can be located in depressions.
    The ideal situation is that the point indicates the sink point of the depression area; if it is a polygon dataset, each area object should cover a depression area.

    If exclude_area is None, all depressions in the DEM grid will be filled, including pseudo depressions and real depressions


    For related introduction of hydrological analysis, please refer to:py:func:`basin`

    :param surface_grid: DEM data specified to fill the depression
    :type surface_grid: DatasetGrid or str
    :param exclude_area: The specified point or area data used to indicate known natural depressions or depressions to be excluded. If it is a point dataset, the area where one or more points are located is indicated as a depression;
                         If it is a polygon dataset, each polygon object corresponds to a depression area. If it is None, all depressions in the DEM grid will be filled, including pseudo depressions and real depressions
    :type exclude_area: DatasetVector or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: The name of the result dataset.
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: DEM raster dataset or dataset name without pseudo depressions. If filling the pseudo depression fails, None is returned.
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.terrain.flow_accumulation": """
    Calculate the cumulative water catchment volume based on the flow direction grid. The weighted dataset can be used to calculate the weighted cumulative water catchment.
    Cumulative water catchment refers to the cumulative amount of water flowing to all upstream cells of a cell, which is calculated based on flow direction data.

    The value of cumulative water catchment can help us identify river valleys and watersheds. The higher cumulative water catchment of the cell indicates that the terrain is low and can be regarded as a river valley; 0 indicates that the terrain is higher and may be a watershed. Therefore, the cumulative water catchment is the basis for extracting various characteristic parameters of the watershed (such as watershed area, perimeter, drainage density, etc.).

    The basic idea of calculating the cumulative water catchment is: assuming that there is a unit of water at each cell in the raster data, calculate the cumulative water volume of each cell in sequence according to the water flow direction diagram (excluding the current cellâ€™s Water volume).

    The figure below shows the process of calculating the cumulative water catchment from the direction of water flow.

    .. image:: ../image/FlowAccumulation_1.png

    The following figure shows the flow direction grid and the cumulative water catchment grid generated based on it.

    .. image:: ../image/FlowAccumulation_2.png

    In practical applications, the water volume of each cell is not necessarily the same, and it is often necessary to specify weight data to obtain the cumulative water catchment volume that meets the demand. After the weight data is used, in the calculation of the cumulative water catchment volume, the water volume of each cell is no longer a unit, but a value multiplied by the weight (the grid value of the weight dataset). For example, if the average rainfall in a certain period is used as the weight data, the calculated cumulative water catchment is the rainfall flowing through each cell in that period.

    Note that the weight grid must have the same range and resolution as the flow direction grid.


    For related introduction of hydrological analysis, please refer to:py:func:`basin`


    :param direction_grid: flow direction raster data.
    :type direction_grid: DatasetGrid or str
    :param weight_grid: weight grid data. Setting to None means that the weight dataset is not used.
    :type weight_grid: DatasetGrid or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: The name of the result dataset.
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Raster dataset or dataset name of cumulative water catchment. If the calculation fails, it Return None.
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.terrain.flow_direction": """
    Calculate the flow direction of DEM raster data. To ensure the correctness of the flow direction calculation, it is recommended to use the DEM raster data after filling the pseudo depressions.

    Flow direction, that is, the direction of water flow on the hydrological surface. Calculating flow direction is one of the key steps in hydrological analysis. Many functions of hydrological analysis need to be based on the flow direction grid, such as calculating cumulative water catchment, 
    calculating flow length and watershed, etc.
    
    SuperMap uses the maximum gradient method (D8, Deterministic Eight-node) to calculate the flow direction. This method calculates the steepest descent direction of the cell as the direction of water flow. 
    The ratio of the elevation difference between the center cell and the adjacent cells to the distance is called the elevation gradient. The steepest descent direction is the direction formed by the central cell and the cell with the largest elevation gradient, 
    that is, the flow direction of the central grid. The value of the flow direction of the cell is determined by encoding the 8 neighborhood grids around it. As shown in the figure below, if the flow direction of the center cell is to the left, 
    its flow direction is assigned a value of 16; if it flows to the right, it is assigned a value of 1.

    In SuperMap, by encoding the 8 neighborhood grids of the central grid (as shown in the figure below), the water flow direction of the central grid can be determined by one of the values. For example, if the flow direction of the center grid is left, 
    then its flow direction is assigned a value of 16; if it flows to the right, it is assigned a value of 1.

    .. image:: ../image/FlowDirection_1.png

    When calculating the flow direction, you need to pay attention to the processing of grid boundary cells. The cells located at the border of the grid are special. The forceFlowAtEdge parameter can be used to specify whether the flow direction is outward.
    If it is outward, the flow direction value of the boundary grid is shown in the figure below (left), otherwise, the cells on the boundary will be assigned no value, as shown in the figure below (right).

    .. image:: ../image/FlowDirection_2.png

    Calculate the flow direction of each grid of DEM data to get the flow direction grid. The following figure shows the flow direction raster generated based on DEM data without depressions.

    .. image:: ../image/FlowDirection_3.png


    For related introduction of hydrological analysis, please refer to:py:func:`basin`


    :param surface_grid: DEM data used to calculate flow direction
    :type surface_grid: DatasetGrid or str
    :param bool force_flow_at_edge: Specifies whether to force the flow direction of the grid at the boundary to be outward. If True, all cells at the edge of the DEM grid flow outward from the grid.
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: The name of the dataset where the result flows
    :param str out_drop_grid_name:  The name of the resultant elevation gradient raster dataset. Optional parameters. Used to calculate the intermediate result of the flow direction. 
                                    The ratio of the elevation difference between the center cell and the adjacent cells to the distance is called the elevation gradient. 
                                    As shown in the figure below, it is an example of flow direction calculation, in which an elevation gradient grid is generated

                                   .. image:: ../image/FlowDirection.png

    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Return a tuple of 2 elements, the first element is the result flow raster dataset or dataset name, if the result elevation gradient raster dataset name is set,
             The second element is the resultant elevation gradient raster dataset or dataset name, otherwise it is None
    :rtype: tuple[DatasetGrid,DatasetGrid] or tuple[str,str]
    """,

    "iobjectspy._jsuperpy.analyst.terrain.flow_length": """
    Calculate the flow length based on the flow direction grid, that is, calculate the distance from each cell along the flow direction to the start or end point of the flow direction. The weighted dataset can be used to calculate the weighted flow length.

    Flow length refers to the distance from each cell along the flow direction to the start or end point of its flow, including the length in the upstream and downstream directions. The length of water flow directly affects the speed of ground runoff,
    In turn, it affects the erodibility of ground soil, so it is of great significance in soil and water conservation, and is often used as an evaluation factor for soil erosion and soil erosion.

    The calculation of flow length is based on flow direction data, which indicates the direction of water flow. This dataset can be created by flow direction analysis; the weight data defines the flow resistance of each cell. 
    Flow length is generally used for flood calculations, and water flow is often hindered by many factors such as slope, soil saturation, vegetation cover, etc. At this time, modeling these factors requires a weighted dataset.

    There are two ways to calculate stream length:

     * Downstream: Calculate the longest distance from each cell along the flow direction to the catchment point of the downstream basin.
     * Upstream: Calculate the longest distance from each cell to the vertex of the upstream watershed along the flow direction.

    The following figure shows the flow length grids calculated downstream and upstream respectively:

    .. image:: ../image/FlowLength.png

    The weight data defines the flow resistance between each grid unit, and the flow length obtained by applying the weight is the weighted distance (that is, the distance is multiplied by the value of the corresponding weight grid). For example, when flow length analysis is applied to flood calculations, 
    flood flow is often hindered by many factors such as slope, soil saturation, vegetation cover, etc. At this time, modeling these factors requires a weighted dataset.

    Note that the weight grid must have the same range and resolution as the flow direction grid.

    For related introduction of hydrological analysis, please refer to:py:func:`basin`


    :param direction_grid: The specified flow direction raster data.
    :type direction_grid: DatasetGrid or str
    :param bool up_stream: Specify whether to calculate downstream or upstream. True means upstream upstream, False means downstream downstream.
    :param weight_grid: The specified weight grid data. Setting to None means that the weight dataset is not used.
    :type weight_grid: DatasetGrid or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: the name of the result stream long raster dataset
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result stream length raster dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.terrain.pour_points": """
    Generate a catchment point grid based on the flow direction grid and the cumulative water catchment grid.

    The catchment point is located on the boundary of the basin, usually the lowest point on the boundary. The water in the basin flows out from the catchment point, so the catchment point must have a higher cumulative water catchment volume. According to this feature, the catchment point can be extracted based on the cumulative catchment volume and flow direction grid.

    The determination of the catchment point requires a cumulative catchment threshold. The position in the cumulative catchment grid that is greater than or equal to the threshold will be used as a potential catchment point, and the catchment point's location is finally determined according to the flow direction. The determination of this threshold is very critical, affecting the number and location of water catchment points, as well as the size and scope of the sub-basin. A reasonable threshold requires consideration of various factors such as soil characteristics, slope characteristics, and climatic conditions within the basin, and is determined according to actual research needs, so it is more difficult.

    After the catchment grid is obtained, the flow direction grid can be combined to divide the watershed (:py:func:`watershed` method).

    For related introduction of hydrological analysis, please refer to:py:func:`basin`

    :param direction_grid: flow direction raster data
    :type direction_grid: DatasetGrid or str
    :param accumulation_grid: Accumulated water catchment grid data
    :type accumulation_grid: DatasetGrid or str
    :param int area_limit: Catchment volume limit value
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: the name of the result raster dataset
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: result raster dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.terrain.stream_link": """
    Connecting the water system means assigning a unique value to each river based on the grid water system and the flow direction grid.
    The connecting water system is based on the grid water system and the flow direction grid, and each river in the water system is assigned a unique value, and the value is an integer. The connected water system network records the connection information of water system nodes, reflecting
    the network structure of the water system.

    As shown in the figure below, after connecting the water system, each river section has a unique grid value. The red point in the figure is the intersection, that is, the location where the river section intersects the river section. The river section is part of the river, it connects
    two adjacent junctions, or connect a junction and a watershed, or connect a junction and a watershed. Therefore, the connecting water system can be used to determine the catchment point of the basin.

    .. image:: ../image/StreamLink_1.png

    The figure below is an example of connecting the water system.

    .. image:: ../image/StreamLink_2.png


    For related introduction of hydrological analysis, please refer to:py:func:`basin`

    :param stream_grid: raster water system data
    :type stream_grid: DatasetGrid or str
    :param direction_grid: flow direction raster data
    :type direction_grid: DatasetGrid or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: the name of the result raster dataset
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: The connected raster water system is a raster dataset. Return the result raster dataset or dataset name
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.terrain.stream_order": """
    The rivers are classified, and the grid water system is numbered according to the river class.

    The rivers in the basin are divided into main streams and tributaries. In hydrology, rivers are classified according to factors such as river flow and shape. In hydrological analysis, certain characteristics of the river can be inferred from the level of the river.

    This method is based on the grid water system and classifies rivers according to the flow direction grid. The value of the result grid represents the level of the river. The larger the value, the higher the level. SuperMap provides two kinds of rivers
    grading methods: Strahler method and Shreve method. For the introduction of these two methods, please refer to: py:class:`StreamOrderType` enumeration type.

    As shown in the figure below, it is an example of river classification. According to the Shreve river classification method, the rivers in this area are divided into 14 levels.

    .. image:: ../image/StreamOrder.png

    For related introduction of hydrological analysis, please refer to:py:func:`basin`

    :param stream_grid: raster water system data
    :type stream_grid: DatasetGrid or str
    :param direction_grid: flow direction raster data
    :type direction_grid: DatasetGrid or str
    :param order_type: Basin water system numbering method
    :type order_type: StreamOrderType or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: the name of the result raster dataset
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: The numbered raster watershed network is a raster dataset. Return the result dataset or dataset name.
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.terrain.stream_to_line": """
    Extract vector water system, that is, convert raster water system into vector water system.

    The extraction of the vector water system is a process of converting the raster water system into a vector water system (a vector line dataset) based on the flow direction grid. After obtaining the vector water system, you can perform various vector-based calculations.
     processing and spatial analysis, such as constructing water network. The figure below shows the DEM data and the corresponding vector water system.

    .. image:: ../image/StreamToLine.png

    The vector water system dataset obtained by this method retains the level and flow direction information of the river.

     * While extracting the vector water system, the system calculates the grade of each river, and automatically adds an attribute field named "StreamOrder" to the result dataset to store the value. The way of classification can be
       Set by the order_type parameter.

     * The flow direction information is stored in a field named "Direction" in the result dataset, which is represented by 0 or 1. 0 means that the flow direction is consistent with the geometric direction of the line object, 
     and 1 means that it is opposite to the geometric direction of the line object. The flow direction of the vector water system obtained by this method is the same as its geometric direction, that is, the value of the "Direction" field is all 0. 
     After constructing the water system network for the vector water system, this field can be used directly (or modified according to actual needs) as the flow direction field.

    For related introduction of hydrological analysis, please refer to:py:func:`basin`


    :param stream_grid: raster water system data
    :type stream_grid: DatasetGrid or str
    :param direction_grid: flow direction raster data
    :type direction_grid: DatasetGrid or str
    :param order_type: river classification method
    :type order_type: StreamOrderType or str
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: result vector water system dataset name
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: Vector water system dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.terrain.watershed": """

    Watershed segmentation, that is, the watershed basin that generates the designated watershed (catchment point raster dataset).

    The process of dividing a watershed into several sub-basins is called watershed division. Through the :py:meth:`basin` method, larger watersheds can be obtained, but in actual analysis, 
    it may be necessary to divide larger watersheds into smaller watersheds (called sub-basin).

    The first step in determining a watershed is to determine the catchment point of the catchment. Then, the division of a catchment also firstly needs to determine the catchment point of the sub-basin. 
    Different from using the basin method to calculate the basin, the catchment point of the sub-basin can be on the boundary of the grid or inside the grid. This method requires the input of a catchment point raster data, 
    which can be obtained by the catchment point extraction function (:py:meth:`pour_points` method). In addition, you can also use another overload method, input a two-dimensional point set representing the watershed to divide the watershed.

    For related introduction of hydrological analysis, please refer to:py:func:`basin`

    :param direction_grid: flow direction raster data
    :type direction_grid: DatasetGrid or str
    :param pour_points_or_grid: Raster data of catchment points or designated catchment points (two-dimensional point list). The catchment points use geographic coordinate units.
    :type pour_points_or_grid: DatasetGrid or str or list[Point2D]
    :param out_data: The datasource used to store the result dataset
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: The name of the raster dataset of the basin basin of the result catchment
    :param progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :type progress: function
    :return: the raster dataset or dataset name of the catchment basin
    :rtype: DatasetGrid or str
    """,

    "iobjectspy._jsuperpy.analyst.topo": """Topology Module""",

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions": """
    Topology preprocessing parameter class
    """,

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.__init__": """
        Construct topology preprocessing parameter class object

        :param bool arcs_inserted: whether to intersect between line segments to insert nodes
        :param bool vertex_arc_inserted: Whether to insert nodes between nodes and line segments
        :param bool vertexes_snapped: Whether to capture nodes
        :param bool polygons_checked: Whether to adjust the direction of the polygon
        :param bool vertex_adjusted: whether to adjust the node position
        """,

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.arcs_inserted": """bool: Whether to intersect between line segments to insert nodes""",

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.polygons_checked": """bool: Whether to adjust the orientation of the polygons""",

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.set_arcs_inserted": """
        Set whether to intersect between line segments to insert nodes

        :param bool value: Whether to intersect between line segments to insert nodes
        :return: self
        :rtype: PreprocessOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.set_polygons_checked": """
        Set whether to adjust the direction of the polygon

        :param bool value: Whether to adjust the direction of the polygon
        :return: self
        :rtype: PreprocessOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.set_vertex_adjusted": """
        Set whether to adjust the node position

        :param bool value: Whether to adjust the node position
        :return: self
        :rtype: PreprocessOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.set_vertex_arc_inserted": """
        Set whether to insert nodes between nodes and line segments

        :param bool value: Whether to insert nodes between nodes and line segments
        :return: self
        :rtype: PreprocessOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.set_vertexes_snapped": """
        Set whether to perform node capture

        :param bool value: Whether to perform node capture
        :return: self
        :rtype: PreprocessOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.vertex_adjusted": """bool: whether to adjust the node position""",

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.vertex_arc_inserted": """bool: Whether to insert nodes between nodes and line segments""",

    "iobjectspy._jsuperpy.analyst.topo.PreprocessOptions.vertexes_snapped": """bool: Whether to perform node capture""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions": """
    Topology processing parameter class. This class provides setting information about topology processing.

    If the node tolerance, short overshoot tolerance and long overhang tolerance are not set through the set_vertex_tolerance, set_overshoots_tolerance and set_undershoots_tolerance methods,
    Or set to 0, the system will use the corresponding tolerance value in the tolerance of the dataset for processing

    """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.__init__": """
        Construct topology processing parameter class

        :param bool pseudo_nodes_cleaned: Whether to remove false nodes
        :param bool overshoots_cleaned: Whether to remove short overshoots.
        :param bool redundant_vertices_cleaned: Whether to remove redundant points
        :param bool undershoots_extended: Whether to extend the long overhang.
        :param bool duplicated_lines_cleaned: Whether to remove duplicate lines
        :param bool lines_intersected: Whether to intersect edges.
        :param bool adjacent_endpoints_merged: Whether to merge adjacent endpoints.
        :param float overshoots_tolerance: Short overshoot tolerance, which is used to determine whether the overshoot is a short overshoot when removing the short overshoot.
        :param float undershoots_tolerance: Long suspension line tolerance, this tolerance is used to determine whether the suspension line extends when the long suspension line is extended. The unit is the same as the dataset unit for topological processing.
        :param float vertex_tolerance: node tolerance. The tolerance is used to merge adjacent endpoints, intersect edges, remove false nodes and remove redundant points. The unit is the same as the dataset unit for topological processing.
        :param Recordset filter_vertex_recordset: The filter point record set for edge intersection, that is, the point position line segment in this record set will not be interrupted by intersection.
        :param str arc_filter_string: The filter line expression for arc intersection. When intersecting edges, you can specify a field expression through this property, and the line objects that match the expression will not be interrupted.
                                      Whether the expression is valid is related to the filter_mode edge intersection filter mode
        :param filter_mode: The filtering mode of edge intersection.
        :type filter_mode: ArcAndVertexFilterMode or str
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.adjacent_endpoints_merged": """bool: Whether to merge adjacent endpoints""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.arc_filter_string": """str: The filter line expression for arc intersection. When edge intersection, this attribute can specify a field expression that conforms to the expression The line object of the formula will not be interrupted. Whether the expression is valid or not is related to the filter_mode arc intersection filter mode """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.duplicated_lines_cleaned": """bool: Whether to remove duplicate lines""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.filter_mode": """ArcAndVertexFilterMode: The filtering mode of arc intersection""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.filter_vertex_recordset": """Recordset: The record set of filtered points for arc intersection, that is, the point position and line segment in this record set will not be interrupted by intersection""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.lines_intersected": """bool: whether to intersect arcs""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.overshoots_cleaned": """bool: whether to remove short overhangs""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.overshoots_tolerance": """float: Short overhang tolerance, which is used to determine whether the overshoot is a short overhang when removing the short overhang""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.pseudo_nodes_cleaned": """bool: whether to remove false nodes""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.redundant_vertices_cleaned": """bool: Whether to remove redundant points""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_adjacent_endpoints_merged": """
        Set whether to merge adjacent endpoints.

        If the distance between the endpoints of multiple arcs is less than the node tolerance, then these points will be merged into a node whose position is the geometric average of the original points (that is, X and Y are the average of all original points X and Y respectively value).

        Used to determine the node tolerance of the neighboring endpoint, it can be set by :py:meth:`set_vertex_tolerance`, if it is not set or set to 0, the node tolerance in the dataset tolerance will be used.

        It should be noted that if there are two adjacent endpoints, the result of the merge will be a false node, and the operation of removing the false node is also required.

        :param bool value: Whether to merge adjacent endpoints
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_arc_filter_string": """
        Set the filter line expression for arc intersection.

        When intersecting arcs, you can specify a field expression through this property, and the line objects that match the expression will not be interrupted. For details, please refer to the :py:meth:`set_lines_intersected` method.

        :param str value: filter line expression for arc intersection
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_duplicated_lines_cleaned": """
        Set whether to remove duplicate lines

        Repeating line: If all the nodes of two arcs overlap in pairs, it can be considered as a repeating line. The judgment of repeated lines does not consider the direction.

        The purpose of removing duplicate lines is to avoid polygon objects with zero area when creating topological polygons. Therefore, only one of the duplicate line objects should be kept, and the redundant ones should be deleted.

        Usually, repeated lines are mostly caused by the intersection of arcs.

        :param bool value: Whether to remove duplicate lines
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_filter_mode": """
        Set the filtering mode of arc intersection

        :param value: The filtering mode of arc intersection
        :type value: ArcAndVertexFilterMode
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_filter_vertex_recordset": """
        Set the filter point record set for arc intersection, that is, the point position line segment in this record set will not be interrupted by intersection.

        If the filter point is on the line object or the distance to the line object is within the tolerance range, the line object will not be interrupted at the foot position of the filter point to the line object. For details, please refer to the :py:meth:`set_lines_intersected` method.

        Note: Whether the filter point record set is valid is related to the arc intersection filtering mode set by the :py:meth:`set_filter_mode` method. See also: py:class:`.ArcAndVertexFilterMode` class.

        :param Recordset value: The record set of filtering points for arc intersection
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_lines_intersected": """
        Set whether to perform arc intersection.

        Before the line data establishes the topological relationship, it is necessary to calculate the intersection of arcs first, and decompose it into several line objects according to the intersection point. Generally speaking, in the two-dimensional coordinate system, all line objects that intersect with other lines need to be interrupted from the intersection point. , Such as a crossroad. And this method is the basis of subsequent error handling methods.
        In practical applications, the method of completely interrupting the intersecting line segment does not meet the research needs in many cases. For example, if an elevated railway crosses a highway, it looks like two intersecting line objects in two-dimensional coordinates, but in fact they do not intersect.
        , If interrupted, it may affect further analysis. There are many similar practical scenarios in the transportation field, such as the intersection of rivers and traffic lines, the intricate overpasses in the city, etc., whether certain intersections are interrupted,
        It needs to be handled flexibly according to actual applications, and cannot be interrupted uniformly because of intersections on a two-dimensional plane.

        This situation can be achieved by setting the filter line expression (:py:meth:`set_arc_filter_string`) and the filter point record set (:py:meth:`set_vertex_filter_recordset`)
        to determine which line objects and which intersections are not interrupted:

          -Filter line expressions are used to query line objects that do not need to be interrupted
          -No interruption at the location of the point object in the filtered point record set

        These two parameters are used alone or in combination to form four filtering modes for arc intersection, and the other is not to filter. The filter mode is set by the :py:meth:`set_filter_mode` method. For the above example, using different filtering modes, the results of arc intersections are also different. For a detailed introduction to the filtering mode, please refer to the :py:class:`.ArcAndVertexFilterMode` class.

        Note: When performing arc intersection processing, you can use the :py:meth:`set_vertex_tolerance` method to set the node tolerance (if not set, the node tolerance of the dataset will be used) to determine whether the filter point is valid. If the distance from the filter point to the line object is within the set tolerance range, the line object will not be interrupted from the filter point to its vertical foot position.

        :param bool value: Whether to perform arc intersection
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_overshoots_cleaned": """
        Set whether to remove short suspension wires. Removal of the short suspension line means that if the length of a suspension line is less than the suspension line tolerance, the suspension line will be deleted when the short suspension line is removed. The short overshoot tolerance can be specified through the set_overshoots_tolerance method. If not specified, the short overshoot tolerance of the dataset will be used.

        Suspended line: If the end point of a line object is not connected with the end point of any other line object, this end point is called a hanging point. Line objects with hanging points are called hanging lines.

        :param bool value: Whether to remove short overhangs, True means to remove, False means not to remove.
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_overshoots_tolerance": """
        Set the short suspension wire tolerance, which is used to determine whether the suspension wire is a short suspension wire when the short suspension wire is removed. The unit is the same as the dataset unit for topological processing.

        The definition of "suspension line": If the endpoint of a line object is not connected to the endpoint of any other line object, then this endpoint is called a suspension point. Line objects with hanging points are called hanging lines.

        :param float value: short overhang tolerance
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_pseudo_nodes_cleaned": """
        Set whether to remove false nodes. The node is also called the arc connection point, and only the connection with at least three arcs can be called a node. If the arc connection point connects only one arc (in the case of an island) or two arcs (that is, it is the common end of the two arcs), then the node is called a false node

        :param bool value: Whether to remove false nodes, True means to remove, False means not to remove.
        :return: ProcessingOptions
        :rtype: self
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_redundant_vertices_cleaned": """
        Set whether to remove redundant points. When the distance between two nodes on any arc is less than the node tolerance, one of them is considered to be a redundant point, which can be removed during topology processing.

        :param bool value:: Whether to remove redundant points, True means to remove, False means not to remove.
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_undershoots_extended": """
        Set whether to extend the long suspension line. If a suspension line extends a specified length (suspension tolerance) according to its traveling direction and then has an intersection with an arc segment, the suspension line will be automatically extended to an arc segment after topology processing.
        It is called long suspension wire extension. The long overhang tolerance can be specified by the set_undershoots_tolerance method, if not specified, the long overhang tolerance of the dataset will be used.

        :param bool value: Whether to extend the long suspension
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_undershoots_tolerance": """
        Set the long suspension wire tolerance, which is used to judge whether the suspension wire extends when the long suspension wire is extended. The unit is the same as the dataset unit for topological processing.

        :param float value: long suspension tolerance
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.set_vertex_tolerance": """
        Set node tolerance. The tolerance is used to merge adjacent endpoints, intersect arcs, remove false nodes and remove redundant points. The unit is the same as the dataset unit for topological processing.

        :param float value: node tolerance
        :return: self
        :rtype: ProcessingOptions
        """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.undershoots_extended": """bool: Whether to extend the long suspension line""",

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.undershoots_tolerance": """float: Long suspension line tolerance, which is used to determine whether the suspension line extends when the long suspension line is extended. Unit and dataset for topology processing Same unit """,

    "iobjectspy._jsuperpy.analyst.topo.ProcessingOptions.vertex_tolerance": """float: node tolerance. This tolerance is used for adjacent endpoint merging, arc intersection, removing false nodes and removing redundant points. Unit and progress The dataset unit of the topology processing is the same """,

    "iobjectspy._jsuperpy.analyst.topo.pickup_border": """
    Extract the boundary of the surface (or line) and save it as a line dataset. If multiple faces (or lines) share a boundary (line segment), the boundary (line segment) will only be extracted once.

    It does not support the extraction of boundaries from overlapping faces.

    :param input_data: The specified polygon or line dataset.
    :type input_data: DatasetVector or str
    :param bool is_preprocess: Whether to perform topology preprocess
    :param extract_ids: The specified surface ID array, optional parameter, only the boundary of the surface object corresponding to the given ID array will be extracted.
    :type extract_ids: list[int] or str
    :param out_data: The datasource used to store the result dataset.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.topo.preprocess": """
    Perform topology preprocessing on the given topology dataset.

    :param inputs: Input dataset or record set. If it is a dataset, it cannot be read-only.
    :type inputs: DatasetVector or list[DatasetVector] or str or list[str] or Recordset or list[Recordset]
    :param bool arcs_inserted: whether to intersect between line segments to insert nodes
    :param bool vertex_arc_inserted: Whether to insert nodes between nodes and line segments
    :param bool vertexes_snapped: Whether to capture nodes
    :param bool polygons_checked: Whether to adjust the direction of the polygon
    :param bool vertex_adjusted: whether to adjust the node position
    :param precisions: The specified precision level array. The smaller the value of the accuracy level, the higher the accuracy of the corresponding record set and the better the data quality. When performing vertex capture, the points in the low-precision record set will be captured to the positions of the points in the high-precision record set. Array must be the same level of accuracy to be recorded the number of pre-set topology collection element and 11 correspond.
    :type precisions: list[int]
    :param float tolerance: The tolerance control required for the specified processing. The unit is the same as the record set unit for topology preprocessing.
    :param PreprocessOption options: Topology preprocess parameter class object, if this parameter is not empty, this parameter will be used first as a topology preprocess parameter
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: Whether the topology preprocessing is successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.topo.split_lines_by_regions": """
    Use area objects to divide line objects. Before extracting the left and right polygons of the line object (that is, the pickupLeftRightRegions() method), you need to call this method to divide the line object. Otherwise, a line object will correspond to multiple left (right) polygons.
    As shown in the figure below: line object AB, if you do not use area objects for segmentation, there will be two left polygons of AB, namely 1, 3; there are also two right polygons, namely 1 and 3, after the division operation, the line object AB is divided For AC and CB, there is only one left and right polygon respectively corresponding to AC and CB.

    .. image:: ../image/SplitLinesByRegions.png


    :param line_input: The specified line record set or dataset to be divided.
    :type line_input: DatasetVector or Recordset
    :param region_input: The specified region record set or dataset used to divide the line record set.
    :type region_input: DatasetVector or Recordset
    :param function progress: a function for processing progress information
    :return: Return True on success, False on failure.
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.topo.topology_build_regions": """
    It is used to construct a surface dataset through topological processing of a line dataset or a network dataset. Before doing topology construction, it is best to use topology processing:py:meth:`topology_processing` to perform topology processing on the dataset.

    :param input_data: The specified source dataset for polygon topology processing can only be a line dataset or a network dataset.
    :type input_data: DatasetVector or str
    :param out_data: The datasource used to store the result dataset.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.topo.topology_processing": """
    Perform topological processing on the given dataset according to the topological processing options. The original data will be directly modified.

    :param input_data: The dataset processed by the specified topology.
    :type input_data: DatasetVector or str
    :param bool pseudo_nodes_cleaned: Whether to remove false nodes
    :param bool overshoots_cleaned: Whether to remove short overshoots.
    :param bool redundant_vertices_cleaned: Whether to remove redundant points
    :param bool undershoots_extended: Whether to extend the long overhang.
    :param bool duplicated_lines_cleaned: Whether to remove duplicate lines
    :param bool lines_intersected: Whether to intersect arcs.
    :param bool adjacent_endpoints_merged: Whether to merge adjacent endpoints.
    :param float overshoots_tolerance: Short overshoot tolerance, which is used to determine whether the overshoot is a short overshoot when removing the short overshoot.
    :param float undershoots_tolerance: Long suspension line tolerance, this tolerance is used to determine whether the suspension line extends when the long suspension line is extended. The unit is the same as the dataset unit for topological processing.
    :param float vertex_tolerance: node tolerance. The tolerance is used to merge adjacent endpoints, intersect arcs, remove false nodes and remove redundant points. The unit is the same as the dataset unit for topological processing.
    :param Recordset filter_vertex_recordset: The filter point record set for arc intersection, that is, the point position line segment in this record set will not be interrupted by intersection.
    :param str arc_filter_string: The filter line expression for arc intersection. When intersecting arcs, you can specify a field expression through this property, and the line objects that match the expression will not be interrupted.
                                  Whether the expression is valid is related to the filter_mode arc intersection filter mode
    :param filter_mode: The filtering mode of arc intersection.
    :type filter_mode: ArcAndVertexFilterMode or str
    :param options: Topology processing parameter class. If options is not empty, topology processing will use the value set by this parameter.
    :type options: ProcessingOptions or None
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: Whether the topology processing is successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.topo.topology_validate": """
    Perform topological error check on the dataset or record set, and return the result dataset containing topological errors.

    The tolerance parameter of this method is used to specify the tolerance involved when using the topology rule specified by the rule parameter to check the dataset. For example, when using the "TopologyRule.LINE_NO_SHARP_ANGLE" rule check, the tolerance parameter is set to the sharp angle tolerance (an angle value).

    For the following topology check operator before calling this method to check the topology data, it is recommended to feed the corresponding data line topology preprocessing (i.e., call: py: meth: `preprocess` method), or the check result may not be correct:

        -REGION_NO_OVERLAP_WITH
        -REGION_COVERED_BY_REGION_CLASS
        -REGION_COVERED_BY_REGION
        -REGION_BOUNDARY_COVERED_BY_LINE
        -REGION_BOUNDARY_COVERED_BY_REGION_BOUNDARY
        -REGION_NO_OVERLAP_ON_BOUNDARY
        -REGION_CONTAIN_POINT
        -LINE_NO_OVERLAP_WITH
        -LINE_BE_COVERED_BY_LINE_CLASS
        -LINE_END_POINT_COVERED_BY_POINT
        -POINT_NO_CONTAINED_BY_REGION
        -POINT_COVERED_BY_LINE
        -POINT_COVERED_BY_REGION_BOUNDARY
        -POINT_CONTAINED_BY_REGION
        -POINT_BECOVERED_BY_LINE_END_POINT

    For the following topology inspection algorithms, a reference dataset or record set needs to be set:

        -REGION_NO_OVERLAP_WITH
        -REGION_COVERED_BY_REGION_CLASS
        -REGION_COVERED_BY_REGION
        -REGION_BOUNDARY_COVERED_BY_LINE
        -REGION_BOUNDARY_COVERED_BY_REGION_BOUNDARY
        -REGION_CONTAIN_POINT
        -REGION_NO_OVERLAP_ON_BOUNDARY
        -POINT_BECOVERED_BY_LINE_END_POINT
        -POINT_NO_CONTAINED_BY_REGION
        -POINT_CONTAINED_BY_REGION
        -POINT_COVERED_BY_LINE
        -POINT_COVERED_BY_REGION_BOUNDARY
        -LINE_NO_OVERLAP_WITH
        -LINE_NO_INTERSECT_OR_INTERIOR_TOUCH
        -LINE_BE_COVERED_BY_LINE_CLASS
        -LINE_NO_INTERSECTION_WITH
        -LINE_NO_INTERSECTION_WITH_REGION
        -LINE_EXIST_INTERSECT_VERTEX
        -VERTEX_DISTANCE_GREATER_THAN_TOLERANCE
        -VERTEX_MATCH_WITH_EACH_OTHER


    :param source_data: the dataset or record set to be checked
    :type source_data: DatasetVector or str or Recordset
    :param validating_data: The reference record set for checking. If the topology rule used does not need to refer to the record set, set to None
    :type validating_data: DatasetVector or str or Recordset
    :param rule: topology check type
    :type rule: TopologyRule or str
    :param float tolerance: The specified tolerance used for topology error checking. The unit is the same as the dataset unit for topological error checking.
    :param GeoRegion validate_region: the region to be checked, None, the whole topology dataset (validating_data) will be checked by default, otherwise, the validate_region region will be checked.
    :param out_data: The datasource where the result dataset is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result dataset or dataset name
    :rtype: DatasetVector or str
    """,

    "iobjectspy._jsuperpy.analyst.na3d": """
3D network analysis module
""",

    "iobjectspy._jsuperpy.analyst.na3d.BurstAnalystResult3D": """Burst analysis result class. Burst analysis results return key facilities, common facilities and arcs.""",

    "iobjectspy._jsuperpy.analyst.na3d.BurstAnalystResult3D.critical_nodes": """list[int]: Critical facilities that affect the upstream and downstream of the burst location in the burst analysis.
                      Critical facilities include two types of facilities:

                       1. All facilities in the upstream of the burst location that directly affect the burst location.
                       2. The downstream facilities are directly affected by the location of the burst pipe and have outflow (that is, the outflow degree is greater than 0).
        """,

    "iobjectspy._jsuperpy.analyst.na3d.BurstAnalystResult3D.edges": """list[int]: The arcs that affect the position of the burst pipe upstream and downstream, and the arcs affected by the position of the burst pipe. It is the key to two-way search from the burst position The arc to which facilities and general facilities are traversed.""",

    "iobjectspy._jsuperpy.analyst.na3d.BurstAnalystResult3D.normal_nodes": """list[int]: Ordinary facilities affected by the location of the burst tube in the burst tube analysis.
                      General facilities include three types of facilities:

                       1. Facilities that are directly affected by the location of the burst pipe and have no outflow (the outflow degree is 0).
                       2. All facilities A directly affected by the outflow arc of each upstream critical facility (excluding all critical facilities), and facility A needs to meet, 
                          The arc of influence from upstream key facilities to facility A has a common part with the arc of influence from key upstream and downstream facilities.
                       3. Facility A (critical facility 2 and ordinary facility 1) that is directly affected by the location of the burst pipe downstream of the location of the burst pipe, facility B that directly affects facility A in the upstream of facility A (excluding all critical facilities),
                       and requires It is satisfied that the influential arcs from facility A to facility B and the influential arcs of upstream and downstream key facilities have a common part.

        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D": """Facility network analysis class.

       Facilities network analysis class. It is one of the network analysis functions, mainly used for various connectivity analysis and tracking analysis.

       The facility network is a network with directions. That is, the medium (water flow, current, etc.) will flow in the network according to the rules of the network itself.

       The premise of facility network analysis is that a dataset for facility network analysis has been established. The basis for establishing a dataset for facility network analysis is to establish a network dataset. 
       On this basis, use the method: py:meth:`build_facility_network_directions_3d` The data information unique to the network dataset for facility network analysis, that is, to establish the flow direction for the network dataset, 
       so that the original network dataset has the most basic conditions for the facility network analysis. At this time, it can be carried out. Network analysis of various facilities.
    """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.__init__": """

        :param analyst_setting: Set the network analysis environment.
        :type analyst_setting: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.analyst_setting": """FacilityAnalystSetting3D: Facility Network Analysis Environment""",

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.burst_analyse": """
        Two-way tube explosion analysis, by specifying the arc of the tube, find the nodes in the upstream and downstream of the arc of the tube that directly affect the position of the tube and the nodes directly affected by the position of the tube.

        :param source_nodes: The specified facility node ID array. Can not be empty.
        :type source_nodes: list[int] or tuple[int]
        :param int edge_or_node_id: The specified edge ID or node ID, and the location of the tube burst.
        :param bool is_uncertain_direction_valid: Specifies whether the flow direction is not valid or not. Specify true to indicate that the uncertain flow direction is valid, and the analysis will continue when the uncertain flow direction is encountered; 
                                                  specify false, indicate that the uncertain flow direction is invalid, and the uncertain flow direction will stop and continue searching in that direction. When the value of the flow direction field is 2, 
                                                  it means that the flow direction of the arc segment is an uncertain flow direction.
        :param bool is_edge_id: Whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID.
        :return: Explosion tube analysis result
        :rtype: BurstAnalystResult3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.find_critical_facilities_down": """
        Downstream key facility search, that is, find the key downstream facility nodes of a given arc, and return the ID array of the key facility node and the downstream edge ID array affected by the given arc.
        In the search and analysis of downstream key facilities, we divide the nodes of the facility network into two types: ordinary nodes and facility nodes. The facility nodes are considered to be nodes that can affect network connectivity.
        For example, a valve in a water supply pipe network; ordinary nodes are nodes that do not affect network connectivity, such as fire hydrants or three links in the water supply pipe network.

        The downstream key facility search analysis will filter out the key nodes from the given facility nodes. These key nodes are the most basic nodes for maintaining connectivity between the analysis arc and its downstream, that is,
        After closing these key nodes, the analysis node cannot communicate with the downstream. At the same time, the result of this analysis also includes the union of downstream arcs affected by a given arc.

        The search method of key facility nodes can be summarized as follows: starting from the analysis arc and searching its downstream, the first facility node encountered in each direction is the key facility node to be searched.

        :param source_node_ids: The specified facility node ID array. Can not be empty.
        :type source_node_ids: list[int] or tuple[int]
        :param int edge_or_node_id: Specified analysis edge ID or node ID
        :param bool is_uncertain_direction_valid: Specifies whether the flow direction is not valid or not. Specify true to indicate that the uncertain flow direction is valid, and the analysis will continue when the uncertain flow direction is encountered; 
                                                  specify false, indicate that the uncertain flow direction is invalid, and the uncertain flow direction will stop and continue searching in that direction. When the value of the flow direction field is 2, 
                                                  it means that the flow direction of the arc segment is an uncertain flow direction.
        :param bool is_edge_id: Whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID.
        :return: facility network analysis result
        :rtype: FacilityAnalystResult3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.find_critical_facilities_up": """
        Upstream key facility search, that is, find the key facility nodes upstream of a given arc, and return the key node ID array and its downstream edge ID array.
        In the search and analysis of upstream key facilities, we divide the nodes of the facility network into two types : ordinary nodes and facility nodes . The facility nodes are considered to be the nodes that can affect network connectivity.
        For example, a valve in a water supply pipe network; ordinary nodes are nodes that do not affect network connectivity, such as fire hydrants or three links in the water supply pipe network. The upstream critical facility search and analysis needs to specify facility nodes and
        Analysis node, where the analysis node can be a facility node or an ordinary node.

        The upstream key facility search analysis will filter out the key nodes from the given facility nodes. These key nodes are the most basic nodes for maintaining connectivity between the analysis arc and its upstream, that is,
        After closing these key nodes, the analysis node cannot communicate with the upstream. At the same time, the result of the analysis also includes the union of the downstream arcs of the key nodes found.

        The search method of key facility nodes can be summarized as follows: starting from the analysis arc and tracing back to its upstream, the first facility node encountered in each direction is the key facility node to be searched.
        As shown in the figure below, starting from the analysis arc (red), the key facility nodes found include: 2, 8, 9, and 7. Nodes 4 and 11 are not the first facility node encountered in the backtracking direction.
        Therefore, it is not a critical facility node. As an illustration, only the upstream part of the analysis arc is given here, but note that the analysis results will also give the downstream arcs of key facility nodes 2, 8, 9 and 7.

        .. image:: ../image/findCriticalFacilitiesUp.png

        * Applications

        After a pipe burst occurs in the water supply network, all valves can be used as facility nodes, and the bursting pipe section or pipe point can be used as an analysis arc or analysis node to find and analyze upstream key facilities.
        Quickly find the minimum number of valves in the upstream that need to be closed. After closing these valves, the burst pipe section or pipe point no longer communicates with its upstream, thereby preventing the outflow of water and preventing the disaster from aggravating and
        Waste of resources. At the same time, the analysis shows that the union of the downstream arcs of the valve that needs to be closed, that is, the range of influence after the valve is closed, is used to determine the water stop area, and promptly notify and emergency measures.

        .. image:: ../image/FindClosestFacilityUp.png


        :param source_node_ids: The specified facility node ID array. Can not be empty.
        :type source_node_ids: list[int] or tuple[int]
        :param int edge_or_node_id: analysis edge ID or node ID
        :param bool is_uncertain_direction_valid: Specifies whether the flow direction is not valid or not. Specify true to indicate that the uncertain flow direction is valid, and the analysis will continue when the uncertain flow direction is encountered; 
                                                  specify false, indicate that the uncertain flow direction is invalid, and the uncertain flow direction will stop and continue searching in that direction. When the value of the flow direction field is 2, 
                                                  it means that the flow direction of the arc segment is an uncertain flow direction.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: facility network analysis result
        :rtype: FacilityAnalystResult3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.find_sink": """
        Find the sink according to a given node ID or edge ID, that is, starting from a given node (arc), find the downstream sink that flows out of the node according to the flow direction, and return the minimum cost for the given node to reach the sink The arcs, nodes, and costs included in the path.
        Starting from a given node, this method finds the downstream sink point that flows out of the node according to the flow direction. The result of the analysis is the arc, node and cost included in the minimum cost path from the node to the found sink.
        If there are multiple sinks in the network, the farthest sink will be searched, which is the sink with the least cost and the largest cost from a given node. In order to facilitate understanding, the realization process of this function can be divided into three steps:

         1. Starting from a given node, according to the flow direction, find all the sink points downstream of the node;
         2. Analyze the minimum cost path from a given node to each sink and calculate the cost;
         3. Select the path corresponding to the maximum cost calculated in the previous step as the result, and give the edge ID array, node ID array and the cost of the path on the path.

        Note: The node ID array in the analysis result does not include the analysis node itself.

        The figure below is a simple facility network. Arrows are used on the network arcs to mark the flow of the network, and the weights are marked next to the arcs. Perform search sink analysis for analysis node D. Know,
        Starting from node D and searching downwards according to the flow direction, there are 4 sinks in total. The least costly paths from node D to sink are: EHLG, EHLK, EHMS and EHMQR,
        According to the network resistance, that is, the weight of the arc, it can be calculated that the cost of the EHMQR path is 16.6, so the node R is the sink found.

        .. image:: ../image/FindSink.png

        :param int edge_or_node_id: node ID or edge ID
        :param str weight_name: The name of the weight field information object
        :param bool is_uncertain_direction_valid: Specifies whether the flow direction is not valid or not. Specify true to indicate that the uncertain flow direction is valid, and the analysis will continue when the uncertain flow direction is encountered; 
                                                  specify false, indicate that the uncertain flow direction is invalid, and the uncertain flow direction will stop and continue searching in that direction. When the value of the flow direction field is 2, 
                                                  it means that the flow direction of the arc segment is an uncertain flow direction.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: facility network analysis result
        :rtype: FacilityAnalystResult3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.find_source": """

        The given node ID or edge ID locate the source, i.e. from a given node (arc), check to the flowing find flows of the node network source, and return to the source to a given node the minimum cost The arcs, nodes, and costs included in the path.
        This method starts from a given node and finds the network source node (ie source point) that flows to the node according to the flow direction. The result of the analysis is the arc included in the least costly path from the found source to the given node, nodes and Costs.
         If there are multiple sources in the network, it will search for the farthest source that is the least expensive to reach a given node. In order to facilitate understanding, the realization process of this function can be divided into three steps:

         1. Starting from a given node, according to the flow direction, find all the source points upstream of the node;
         2. Analyze the minimum cost path for each source to reach a given node and calculate the cost;
         3. Select the path corresponding to the maximum cost calculated in the previous step as the result, and give the edge ID array, node ID array and the cost of the path on the path.

        Note: The node ID array in the analysis result does not include the analysis node itself.

        The figure below is a simple facility network. Arrows are used on the network arcs to mark the flow of the network, and the weights are marked next to the arcs. For the analysis node M, perform source search analysis. Know,
        Starting from node M and tracing upward according to the flow direction, there are 7 sources in total. The least costly paths from source to node M are: CHM, AEHM, BDEHM, FDEHM,
        JNM, INM, and PNM, according to the network resistance, which is the arc weight, can calculate that the cost of the BDEHM path is the largest, which is 18.4. Therefore, node B is the source found.

        .. image:: ../image/FindSource.png

        :param int edge_or_node_id: node ID or edge ID
        :param str weight_name: The name of the weight field information object
        :param bool is_uncertain_direction_valid: Specifies whether the flow direction is not valid or not. Specify true to indicate that the uncertain flow direction is valid, and the analysis will continue when the uncertain flow direction is encountered; 
                                                  specify false, indicate that the uncertain flow direction is invalid, and the uncertain flow direction will stop and continue searching in that direction. When the value of the flow direction field is 2, 
                                                  it means that the flow direction of the arc segment is an uncertain flow direction.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: facility network analysis result
        :rtype: FacilityAnalystResult3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.is_load": """
        Determine whether the network dataset model is loaded.

        :return: The network dataset model load Return True, otherwise it Return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.load": """
        Load the facility network model according to the facility network analysis environment settings.

        Note that in the following two situations, the load method must be called again to load the network model, and then analyze.
             -The parameters of the facility network analysis environment setting object have been modified, and the method needs to be called again, otherwise the modification will not take effect and the analysis result will be wrong;
             -Any modification to the network dataset used, including modifying the data in the network dataset, replacing the dataset, etc., needs to reload the network model, otherwise the analysis may go wrong.

        :return: Used to indicate the success of loading the facility network model. It Return true if it succeeds, otherwise it Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.set_analyst_setting": """
        Set up the environment for facility network analysis.

        The setting of facility network analysis environmental parameters directly affects the result of facility network analysis. The parameters required for facility network analysis include: 
        the dataset used for facility network analysis (that is, the network dataset that establishes the flow direction or the network dataset that establishes the flow direction and level at the same time, 
        that is to say, the method corresponds to: py:class : The network dataset specified by `FacilityAnalystSetting3D` must have flow direction or flow direction and level information), node ID field, edge ID field, 
        arc start node ID field, edge end node ID field, weight information , Distance tolerance from point to arc, obstacle node, obstacle arc, flow direction, etc.

        :param value: facility network analysis environment parameter
        :type value: FacilityAnalystSetting3D
        :return: self
        :rtype: FacilityAnalyst3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.trace_down": """
        Perform downstream tracking based on the given edge ID or node ID, that is, find the downstream of a given arc (node), and return the arc, node and total cost included in the downstream.
        Downstream tracking is the process of starting from a given node (or arc) and finding its downstream according to the flow direction. This method is used to find the downstream of a given arc, and the analysis results are the arcs, nodes, and costs flowing through the entire downstream.

        Downstream tracking is often used to analyze the scope of influence. E.g:

        -After the tap water supply pipeline bursts, all downstream pipelines at the location of the accident are tracked and analyzed by downstream, and then the affected water supply area is determined through spatial query, 
        so that timely notifications are issued and emergency measures are taken, such as a fire truck or a water company arranges for vehicles. Water supply to the water-cut area.

        -When it is found that a certain location of the river is polluted, downstream tracking can be used to analyze all the downstream river sections that may be affected, as shown in the figure below. Before the analysis, 
        according to the types of pollutants and emissions, combined with appropriate water quality management models, analyze the downstream river sections or locations that will not be polluted before the pollution is removed, 
        and set them as obstacles (set in FacilityAnalystSetting). When tracking downstream, the tracking stops when the obstacle is reached, which can narrow the scope of analysis. After determining the river sections that may be affected, 
        all water-using units and residential areas located near the resulting river sections are marked through spatial inquiry and analysis, a notice is issued in time, and emergency measures are taken to prevent further expansion of pollution hazards.

        :param int edge_or_node_id: node ID or edge ID
        :param str weight_name: The name of the weight field information object
        :param bool is_uncertain_direction_valid: Specifies whether the flow direction is not valid or not. Specify true to indicate that the uncertain flow direction is valid, and the analysis will continue when the uncertain flow direction is encountered; 
                                                  specify false, indicate that the uncertain flow direction is invalid, and the uncertain flow direction will stop and continue searching in that direction. When the value of the flow direction field is 2, 
                                                  it means that the flow direction of the arc segment is an uncertain flow direction.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: Facility network analysis result.
        :rtype: FacilityAnalystResult3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalyst3D.trace_up": """
        Perform upstream tracking based on a given node ID or edge ID, that is, find the upstream of a given node, and return the arc, node and total cost contained in the upstream.

        * Upstream and downstream

          For a node (or arc) of a facility network, the arc and the node through which resources in the network finally flow into the node (or arc) are called its upstream; 
          from the node (or arc) The arc and the network through which the arc flows out and finally flows into the sink point are called its downstream.

          Take the upstream and downstream of the node as an example. The figure below is a schematic diagram of a simple facility network, using arrows to mark the flow of the network.
           According to the flow direction, it can be seen that resources flow through nodes 2, 4, 3, 7, 8, and arcs 10, 9, 3, 4, and 8 and finally flow into node 10. Therefore, these nodes and arcs are called nodes. 
           The upstream of 10, the node among them is called its upstream node, and the arc is called its upstream arc. Similarly, resources flow out of node 10, flow through nodes 9, 11, and 12 and arcs 5, 7, and 11, 
           and finally flow out of the network. Therefore, these nodes and arcs are called the downstream of node 10. The point is called its downstream node, and the arc is called its downstream arc.

          .. image:: ../image/UpAndDown.png

        * Upstream tracking and downstream tracking

          Upstream tracking is the process of starting from a given node (or arc) and finding its upstream according to the flow direction. Similarly, downstream tracking starts from a given node (or arc), according to the flow direction,
          Find its downstream process. The FacilityAnalyst class provides methods for upstream or downstream tracking starting from a node or arc. The result of the analysis is the found upstream or downstream arc ID array, node ID array, and flow through the entire upstream or Downstream costs. 
          This method is used to find the upstream of a given arc.

        * Applications

          A common application of upstream tracking is to assist in locating the source of river water pollutants. Rivers are not only an important path for the earth's water cycle, but also the most important freshwater resource for mankind. Once a river is polluted, the source of pollution is not found and eliminated in time, 
          which may affect people's normal drinking water and health. Because the river flows from high to low under the influence of gravity, when the river is polluted, it should be considered that there may be pollution sources upstream, such as industrial wastewater discharge, domestic sewage discharge, pesticide and fertilizer pollution, etc. 
          The general steps for tracking the source of river water pollutants are generally:

            -When the monitoring data of the water quality monitoring station shows that the water quality is abnormal, first determine the location of the abnormality, and then find the arc or node where the location is (or the nearest) on the river network (network dataset), as the upstream tracking starting point;
            -If you know the normal water quality monitoring locations closest to the starting point in the upstream of the starting point, you can set these locations or the river section where they are located as obstacles, which can help further narrow the scope of the analysis. Because it can be considered that upstream of the normal location of water quality monitoring, it is impossible for the pollution source of this investigation to exist. After setting as an obstacle, perform upstream tracking analysis. After tracking to the location, it will not continue to track the upstream of the location;
            -Perform upstream tracking analysis to find all river sections that converge to the river section where the water quality abnormality occurs;
            -Use spatial query and analysis to find all possible pollution sources located near these river sections, such as chemical plants, garbage treatment plants, etc.;
            -Further screening of pollution sources based on the monitoring data of abnormal water quality;
            -Analyze the pollutant discharge load of the selected pollution sources and rank them according to their likelihood of causing pollution;
            -Conduct on-site investigations and research on possible pollution sources in order to finally determine the source of the pollution.


        :param int edge_or_node_id: node ID or edge ID
        :param str weight_name: The name of the weight field information object
        :param bool is_uncertain_direction_valid: Specifies whether the flow direction is not valid or not. Specify true to indicate that the uncertain flow direction is valid, and the analysis will continue when the uncertain flow direction is encountered; 
                                                  specify false, indicate that the uncertain flow direction is invalid, and the uncertain flow direction will stop and continue searching in that direction. When the value of the flow direction field is 2, 
                                                  it means that the flow direction of the arc segment is an uncertain flow direction.
        :param bool is_edge_id: whether edge_or_node_id represents the edge ID, True represents the edge ID, False represents the node ID
        :return: Facility network analysis result.
        :rtype: FacilityAnalystResult3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystResult3D": """
    Facility network analysis result class. This class is used to obtain the results of facility network analysis such as finding sources and sinks, upstream and downstream tracking, and finding routes, including result edge ID array, result node ID array, and cost.
    """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystResult3D.cost": """float: the cost of the facility network analysis result.
                  For different facility network analysis functions, the meaning of the return value of this method is different:

                  -Find Source: This value is the cost of the least costly path from the analysis arc or node to the source.
                  -Find sink: This value is the least costly path cost of analyzing arc or node to sink.
                  -Upstream Tracking: This value is the total cost of analyzing the arc or the arc included upstream of the node.
                  -Downstream Tracking: This value is the total cost of analyzing the arc or the arc included downstream of the node.
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystResult3D.edges": """list[int]: The edge ID array in the facility network analysis result.
                      For different facility network analysis functions, the meaning of the return value of this method is different:

                      -Find source: This value is the edge ID array of the arc included in the least costly path from the analysis arc or node to the source.
                      -Find sink: This value is the edge ID array of the arc included in the least costly path from the analyzed arc or node to the sink.
                      -Upstream Tracking: This value is the edge ID array of the arc included in the upstream of the analyzed arc or node.
                      -Downstream Tracking: This value is an array of edge IDs of the arcs included in the downstream of the analyzed arc or node.
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystResult3D.nodes": """list[int]: Node ID array in the facility network analysis result.
                      For different facility network analysis functions, the meaning of the return value of this method is different:

                      -Find Source: This value is the node ID array of the nodes included in the least costly path from the analysis arc or node to the source.
                      -Find sink: This value is the node ID array of the nodes included in the least costly path from the analyzed arc or node to the sink.
                      -Upstream Tracking: The value is the node ID array of the nodes included in the upstream of the analysis arc or node.
                      -Downstream tracking: This value is the node ID array of the nodes included in the downstream of the analysis arc or node.
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D": """
    Facilities network analysis environment setting class. Facilities network analysis environment setting class. This class is used to provide all the parameter information needed for facility network analysis.
    The setting of each parameter of the facility network analysis environment setting category directly affects the result of the analysis.
    """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.barrier_edge_ids": """list[int]: Barrier edge ID list """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.barrier_node_ids": """list[int]: ID list of barrier nodes """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.direction_field": """str: flow direction field""",

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.edge_id_field": """str: The field that marks the edge ID in the network dataset """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.f_node_id_field": """str: The field that marks the starting node ID of the arc in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.network_dataset": """DatasetVector: network dataset""",

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.node_id_field": """str: The field that identifies the node ID in the network dataset """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.set_barrier_edge_ids": """
        Set the ID list of barrier arcs

        :param value: ID list of barrier arc
        :type value: str or list[int]
        :return: self
        :rtype: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.set_barrier_node_ids": """
        Set the ID list of barrier nodes

        :param value: ID list of barrier node
        :type value: str or list[int]
        :return: self
        :rtype: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.set_direction_field": """
        Set flow direction field

        :param str value: flow direction field
        :return: self
        :rtype: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.set_edge_id_field": """
        Set the field that identifies the node ID in the network dataset

        :param str value: The field that marks the arc segment ID in the network dataset
        :return: self
        :rtype: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.set_f_node_id_field": """
        Set the field to mark the starting node ID of the arc in the network dataset

        :param str value: The field that marks the starting node ID of the arc in the network dataset
        :return: self
        :rtype: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.set_network_dataset": """
        Set up network dataset

        :param dt: network dataset
        :type dt: DatasetVetor or str
        :return: self
        :rtype: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.set_node_id_field": """
        Set the field of the network dataset to identify the node ID

        :param str value: The field that identifies the node ID in the network dataset
        :return: self
        :rtype: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.set_t_node_id_field": """
        Set the field to mark the starting node ID of the arc in the network dataset

        :param str value:
        :return: self
        :rtype: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.set_tolerance": """
        Set node tolerance

        :param float value: node tolerance
        :return: self
        :rtype: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.set_weight_fields": """
        Set weight field

        :param value: weight field
        :type value: list[WeightFieldInfo] or tuple[WeightFieldInfo]
        :return: self
        :rtype: FacilityAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.t_node_id_field": """str: The field that marks the starting node ID of the arc in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.tolerance": """float: node tolerance""",

    "iobjectspy._jsuperpy.analyst.na3d.FacilityAnalystSetting3D.weight_fields": """list[WeightFieldInfo]: weight field """,

    "iobjectspy._jsuperpy.analyst.na3d.NetworkSplitMode3D": """
    Construct a three-dimensional network dataset interruption mode. Used to control the mode of processing line-line breaks or dot-line breaks when building a network dataset

    :var NetworkSplitMode.NO_SPLIT: Do not interrupt
    :var NetworkSplitMode.LINE_SPLIT_BY_POINT: point to break the line
    :var NetworkSplitMode.LINE_SPLIT_BY_POINT_AND_LINE: break the line and the line, and click to break the line at the same time
    """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalyst3D": """
    Three-dimensional traffic network analysis class. This class is used to provide traffic network analysis functions based on 3D network dataset. Currently only the best path analysis is provided.

    Roads, railways, passages in buildings, mine tunnels, etc. can be simulated using transportation networks. Unlike facility networks, transportation networks have no direction, that is, circulation media (pedestrians or transmitted resources)
    can decide the direction, speed and destination by yourself. Of course, certain restrictions can also be imposed, such as setting traffic rules, such as one-way lanes, no-go lanes, etc.

    Three-dimensional traffic network analysis is based on the analysis of three-dimensional network datasets. It is an important part of three-dimensional network analysis. The best path analysis is currently provided. For transportation networks, especially those that cannot be clearly displayed on a two-dimensional plane, 
    such as the internal passages of buildings and mine tunnels, the three-dimensional network can more truly reflect the spatial topology and analysis results of the network.

    The general steps of 3D traffic network analysis:

    1. Construct a three-dimensional network dataset. According to research needs and existing data, choose a suitable network model construction method. SuperMap provides two methods for constructing three-dimensional network dataset. For details, please
       See: py:meth:`build_network_dataset_3d` or: py:meth:`build_network_dataset_know_relation_3d`.

    2. (Optional) It is recommended to perform a data check on the network dataset used for analysis (:py:meth:`validate_network_dataset_3d` ).

    3. Set the 3D traffic network analysis environment (set_analyst_setting method);

    4. Load the network model (load method);

    5. Use the various transportation network analysis methods provided by the TransportationAnalyst3D class to perform corresponding analysis.

    """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalyst3D.__init__": """
        Initialization object

        :param TransportationAnalystSetting3D analyst_setting: Traffic network analysis environment setting object
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalyst3D.analyst_setting": """TransportationAnalystSetting3D: Traffic network analysis environment setting object""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalyst3D.find_path": """
        Best path analysis.
        The best path analysis is used to find the best path through a given N points (N is greater than or equal to 2) in the network dataset. This best path has the following two characteristics:

        This path must pass through these N points in sequence in the order of the given N points, that is to say, the points passed in the best path analysis are in order;
        This path has the least cost. The cost is determined according to the weights specified by the traffic network analysis parameters. The weight can be length, time, road conditions, cost, etc., so the best path can be the 
        shortest path, the path with the least time, the path with the best traffic conditions, the path with the lowest cost, etc.

        There are two ways to specify the passing points to be analyzed:

        -Node method: Use: py:class:`TransportationAnalystParameter3D` class: py:meth:`TransportationAnalystParameter3D.set_nodes` method to specify the ID of the node passed by the best path analysis, at this time, the point passed in the analysis process is the corresponding network node , 
        And the order of passing points is the order of network nodes in this node ID array;
        
        -Arbitrary coordinate point method: through: py:class:`TransportationAnalystParameter3D` class: py:meth:`TransportationAnalystParameter3D.set_points`
        specifing the coordinates of the points passed by the best path analysis. At this time, the points passed during the analysis process are the corresponding coordinate point collections. The order of the passed points during the analysis process is the order of the coordinate points in the point collection.

        Note: Only one of the two methods can be used, not at the same time.

        :param TransportationAnalystParameter3D parameter: Transportation network analysis parameter object
        :return: Best path analysis result
        :rtype: TransportationAnalystResult3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalyst3D.load": """
        Load the network model.
        This method loads the network model according to the environmental parameters in the traffic network analysis environment setting (:py:class:`TransportationAnalystSetting3D`) object. 
        After setting the parameters of the traffic network analysis environment, the relevant parameters are modified. Only when this method is called, the traffic network analysis environment settings made will take effect in the process of traffic network analysis.

        :return: Return True if loading is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalyst3D.set_analyst_setting": """
        Set traffic network analysis environment setting object
        When using traffic network analysis to perform various traffic network analysis, you must first set the traffic network analysis environment, and you must first set the traffic network analysis environment

        :param TransportationAnalystSetting3D analyst_setting: Traffic network analysis environment setting object
        :return: self
        :rtype: TransportationAnalyst3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D": """
    Three-dimensional traffic network analysis parameter class.

    This class is used to set various parameters required for 3D traffic network analysis, such as the collection of nodes (or arbitrary points) passing by during analysis, weight information, obstacle points and obstacle arcs, and 
    whether the analysis result includes a collection of passing nodes, a collection of arcs, routing objects, etc.
    """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.barrier_edges": """list[int]: Barrier edge ID list """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.barrier_nodes": """list[int]: Barrier node ID list """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.barrier_points": """list[Point3D]: List of obstacle points""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.is_edges_return": """bool: Does the analysis result include passing arcs""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.is_nodes_return": """bool: Whether the analysis result contains passing nodes""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.is_routes_return": """bool: Return whether the analysis result contains a three-dimensional line (:py:class:`GeoLine3D`) object""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.is_stop_indexes_return": """bool: Whether to include the site index in the analysis result""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.nodes": """list[int]: Analysis path point """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.points": """list[Point3D]: Pass points during analysis""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.set_barrier_edges": """
        Set the barrier edge ID list. Optional. The obstacle arc specified here and the obstacle arc specified in the traffic network analysis environment (:py:class:`TransportationAnalystSetting`) 
        work together to analyze the traffic network.

        :param edges: list of obstacle edge IDs
        :type edges: list[int] or tuple[int]
        :return: self
        :rtype: TransportationAnalystParameter3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.set_barrier_nodes": """
        Set the list of barrier node IDs. Optional. The obstacle arc specified here and the obstacle arc specified in the traffic network analysis environment (:py:class:`TransportationAnalystSetting`) 
        work together to analyze the traffic network.

        :param nodes: Barrier node ID list
        :type nodes: list[int] or tuple[int]
        :return: self
        :rtype: TransportationAnalystParameter3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.set_barrier_points": """
        Set the coordinate list of obstacle nodes. Optional. The specified obstacle point can not be on the network (neither on the arc nor on the node). The analysis will be based on the distance tolerance (:py:attr:`.TransportationPathAnalystSetting.tolerance`)
         coming down the obstacle point to the nearest network. Currently, it supports best route analysis, nearest facility search, traveling salesman analysis, and logistics distribution analysis.

        :param points: list of coordinates of barrier nodes
        :type points: list[Point2D] or tuple[Point2D]
        :return: self
        :rtype: TransportationAnalystParameter3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.set_edges_return": """
        Set whether the passing arc is included in the analysis result

        :param bool value: Specify whether the passing arc is included in the analysis result. Set to True, after the analysis is successful, you can use the TransportationAnalystResult3D object
                            :py:attr:`TransportationAnalystResult3D.edges` method return the passing arc; if it is False, it Return None
        :return: self
        :rtype: TransportationAnalystParameter3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.set_nodes": """
        Set analysis route points. Required, but mutually exclusive with the :py:meth:`set_points` method. If set at the same time, only the last setting before the analysis is valid. 
        For example, if the node set is specified first, then the coordinate point set is specified, and then the analysis is performed. At this time, only the coordinate points are analyzed.

        :param nodes: ID of passing node
        :type nodes: list[int] or tuple[int]
        :return: self
        :rtype: TransportationAnalystParameter3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.set_nodes_return": """
        Set whether to include nodes in the analysis results

        :param bool value: Specify whether to include transit nodes in the analysis result. Set to True, after the analysis is successful, you can use the TransportationAnalystResult3D object
                            :py:attr:`TransportationAnalystResult3D.nodes` method Return the passing node; if it is False, it Return None
        :return: self
        :rtype: TransportationAnalystParameter3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.set_points": """
        Set the collection of passing points during analysis. Required, but mutually exclusive with the :py:meth:`set_nodes` method. If set at the same time, only the last setting before the analysis is valid. For example, first specify the node set, and then
        Specify a set of coordinate points and then analyze. At this time, only coordinate points are analyzed.

        If a point in the set of set waypoints is not within the range of the network dataset, the point will not participate in the analysis

        :param points: passing points
        :type points: list[Point3D] or tuple[Point3D]
        :return: self
        :rtype: TransportationAnalystParameter3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.set_routes_return": """
       Whether the analysis result contains a three-dimensional line (:py:class:`GeoLine3D`) object

        :param bool value: Specify whether to include routing objects. Set to True, after the analysis is successful, you can use the TransportationAnalystResult3D object
                           :Py:attr:`TransportationAnalystResult3D.route` Return the route object; if it is False, it Return None
        :return: self
        :rtype: TransportationAnalystParameter3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.set_stop_indexes_retu rn": """
        Set whether to include the site index in the analysis results

        :param bool value: Specify whether to include the site index in the analysis result. Set to True, after the analysis is successful, you can use the TransportationAnalystResult3D object
                            :py:attr:`TransportationAnalystResult3D.stop_indexes` method Return the site index; if it is False, it Return None
        :return: self
        :rtype: TransportationAnalystParameter3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.set_weight_name": """
        Set the name of the weight field information. If not set, the name of the first weight field information object in the weight field information set will be used by default

        :param str name: the name identifier of the weight field information
        :return: self
        :rtype: TransportationAnalystParameter3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystParameter3D.weight_name": """str: the name of the weight field information""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystResult3D": """
    3D traffic network analysis result class. This class is used to return the results of various three-dimensional traffic network analysis, including the route collection, the node collection through the analysis, the arc collection, the station collection and the weight collection
    And the cost of each site.
    """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystResult3D.edges": """list[int]: Return the set of the analysis results of the arcs. Note that the TransportAnalystParameter3D object must be: py:meth:`TransportationAnalystParameter3D.set_edges_return`
                      When the method is set to True, the analysis result will include the set of passing arcs, otherwise it will return None
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystResult3D.nodes": """list[int]: A collection of nodes that return the analysis results. Note that the :py:meth:`TransportationAnalystParameter3D.set_nodes_return` of the TransportationAnalystParameter3D object must be added
                      If the method is set to True, the analysis result will include the set of passing nodes, otherwise it will be an empty array. """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystResult3D.route": """GeoLineM: The routing object that Return the analysis result. Note that the :py:meth:`TransportationAnalystParameter3D.set_routes_return` of the TransportationAnalystParameter3D object must be added
                     If the method is set to true, the routing object will be included in the analysis result, otherwise it will return None""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystResult3D.stop_indexes": """list[int]: Return the site index. This array reflects the order of the sites after analysis. Note that the TransportationAnalystParameter3D object must be
                      The :py:meth:`TransportationAnalystParameter3D.set_stop_indexes_return` method is set to True, only when the analysis result
                      Contains the site index, otherwise an empty array.

                      -Best path analysis (:py:meth:`TransportationAnalyst3D.find_path` method):

                          -Node mode: For example, if the set analysis node ID is 1, 3, and 5, the order of the result path must be 1, 3, and 5, so the element value is 0, 1, 2,
                           that is, the order of the result path is set in the initial setting. The index in the point string.

                          -Coordinate point mode: If the analysis coordinate points are set to Pnt1, Pnt2, Pnt3, Because the sequence of the result path must be Pnt1, Pnt2, Pnt3, the element values are 0, 1, 2, that is, 
                          the index of the coordinate point sequence of the result path in the initial set coordinate point string.
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystResult3D.stop_weights": """list[float]: Return the cost (weight) between sites after sorting the sites by site index.
                        This method Return the cost between the station and the station. The station here refers to the analysis node or coordinate point, rather than all the nodes or coordinate points that the path passes.
                        The order of the sites associated with the weights returned by this method is consistent with the order of the site index values returned in the :py:attr:`stop_indexes` method.

                        -Optimal path analysis (:py:meth:`TransportationAnalyst3D.find_path` method): Assuming that the passing points 1, 2, 3 are specified, the two-dimensional elements are sequentially
                          as: 1 to 2 cost, 2 to 3 cost;
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystResult3D.weight": """float: the weight spent.""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D": """
    Traffic network analysis analysis environment.
    """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.__init__": """
        Initialization object

        :param network_dataset: network dataset
        :type network_dataset: DatasetVector or str
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.barrier_edge_ids": """list[int]: ID list of barrier edge segments""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.barrier_node_ids": """list[int]: ID list of barrier nodes """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.edge_filter": """str: edge filtering expression in traffic network analysis """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.edge_id_field": """str: The field that marks the edge ID in the network dataset """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.edge_name_field": """str: Road name field""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.f_node_id_field": """str: The field that marks the starting node ID of the edge in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.ft_single_way_rule_values": """list[str]: an array of strings used to represent forward one-way lines""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.network_dataset": """DatasetVector: network dataset""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.node_id_field": """str: The field that identifies the node ID in the network dataset """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.prohibited_way_rule_values": """list[str]: an array of strings representing prohibited lines""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.rule_field": """str: A field in the network dataset representing the traffic rules of the network arc""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_barrier_edge_ids": """
        Set the ID list of barrier edges

        :param value: ID list of barrier edge
        :type value: str or list[int]
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_barrier_node_ids": """
        Set the ID list of barrier nodes

        :param value: ID list of barrier node
        :type value: str or list[int]
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_edge_filter": """
        Set the edge filter expression in traffic network analysis

        :param value: edge filtering expression in traffic network analysis
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_edge_id_field": """
        Set the field that identifies the node ID in the network dataset

        :param str value: The field that marks the arc segment ID in the network dataset
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_edge_name_field": """
        Set road name field

        :param str value: Road name field
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_f_node_id_field": """
        Set the field to mark the starting node ID of the edge in the network dataset

        :param str value: The field that marks the starting node ID of the edge in the network dataset
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_ft_single_way_rule_values": """
        Set the array of strings used to represent the forward one-way line

        :param value: An array of strings used to represent the forward one-way line
        :type value: str or list[str]
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_network_dataset": """
        Set up a network dataset for optimal path analysis

        :param dataset: network dataset
        :type dataset: DatasetVetor or str
        :return: current object
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_node_id_field": """
        Set the field of the network dataset to identify the node ID

        :param str value: The field that identifies the node ID in the network dataset
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_prohibited_way_rule_values": """
        Set up an array of strings representing forbidden lines

        :param value: an array of strings representing the forbidden line
        :type value: str or list[str]
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_rule_field": """
        Set the fields in the network dataset that represent the traffic rules of the network edge

        :param str value: A field in the network dataset representing the traffic rules of the network edge
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_t_node_id_field": """
        Set the field to mark the starting node ID of the arc in the network dataset

        :param str value:
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_tf_single_way_rule_values": """
        Set up an array of strings representing reverse one-way lines

        :param value: an array of strings representing the reverse one-way line
        :type value: str or list[str]
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_tolerance": """
        Set node tolerance

        :param float value: node tolerance
        :return: current object
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_two_way_rule_values": """
        Set an array of strings representing two-way traffic lines

        :param value: An array of strings representing two-way traffic lines
        :type value: str or list[str]
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.set_weight_fields": """
        Set weight field

        :param value: weight field
        :type value: list[WeightFieldInfo] or tuple[WeightFieldInfo]
        :return: self
        :rtype: TransportationAnalystSetting3D
        """,

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.t_node_id_field": """str: The field that marks the starting node ID of the edge in the network dataset""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.tf_single_way_rule_values": """list[str]: an array of strings representing reverse one-way lines""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.tolerance": """float: node tolerance""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.two_way_rule_values": """list[str]: an array of strings representing two-way traffic lines""",

    "iobjectspy._jsuperpy.analyst.na3d.TransportationAnalystSetting3D.weight_fields": """list[WeightFieldInfo]: weight field """,

    "iobjectspy._jsuperpy.analyst.na3d.build_facility_network_directions_3d": """
    Create a flow direction for the network dataset based on the location of the source and sink in the specified network dataset. The network dataset that flows to the future can be used for various facility network analysis.
    A facility network is a network with directions. Therefore, after creating a network dataset, a flow direction must be created for it before it can be used for various facility network path analysis, connectivity analysis, upstream and downstream tracking, etc.

    Flow direction refers to the direction of resource flow in the network. The flow direction in the network is determined by the source and sink: resources always flow from the source to the sink. This method creates a flow direction for the network dataset through the given source and sink,
     as well as the facility network analysis parameter settings. After the flow direction is successfully created, two aspects of information will be written in the network dataset: flow direction and node type.

    * Flow direction

      The flow direction information will be written into the flow direction field of the subline dataset of the network dataset, and the field will be created if it does not exist.

      There are four values in the flow direction field: 0,1,2,3, the meaning of which is shown in the figure below. Take line AB as an example:

      0 means the flow direction is the same as the digitization direction. The digitization direction of the line segment AB is A-->B, and A is the source point, so the flow direction of AB is from A to B, which is the same as its digitization direction.

      1 means the flow direction is opposite to the digitization direction. The digitization direction of the line segment AB is A-->B, and A is the meeting point, so the flow direction of AB is from B to A, which is the opposite of its digitization direction.

      2 stands for invalid direction, also called uncertain flow direction. Both A and B are source points, so resources can flow from A to B, and from B to A, which constitutes an invalid flow.

      3 stands for disconnected edges, also called uninitialized direction. The line segment AB is not connected to the node where the source and sink are located, it is called a disconnected edge.

      .. image:: ../image/BuildFacilityNetworkDirections_1.png

    * Node type

      After establishing the flow direction, the system will also write the node type information into the node type field of the sub-point dataset of the specified network dataset. Node types are divided into source, sink, and ordinary nodes.
      The following table lists the value and meaning of the node type field:

      .. image:: ../image/BuildFacilityNetworkDirections_2.png


    :param network_dataset: The 3D network dataset of the flow direction to be created. The 3D network dataset must be modifiable.
    :type network_dataset: DatasetVector or str
    :param source_ids: The network node ID array corresponding to the source. Both sources and sinks are used to establish the flow of network dataset. The flow direction of the network dataset is determined by the location of the source and sink.
    :type source_ids: list[int] or tuple[int]
    :param sink_ids: sink ID array. The ID array of the network node corresponding to the sink. Both sources and sinks are used to establish the flow of network dataset. The flow direction of the network dataset is determined by the location of the source and sink.
    :type sink_ids: list[int] or tuple[int]
    :param str direction_field: flow direction field, used to save the flow direction information of the network dataset
    :param str node_type_field: The name of the node type field. The node type is divided into source node, intersection node, and ordinary node. This field is a field in the network node dataset. If it does not exist, create the field.
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: return true if created successfully, otherwise false
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.na3d.build_network_dataset_3d": """
    The network dataset is the data basis for network analysis. The 3D network dataset consists of two sub-dataset (a 3D line dataset and a 3D point dataset), which store the arcs and nodes of the network model respectively.
    It also describes the spatial topological relationship between arcs and arcs, arcs and nodes, and nodes and nodes.

    This method provides to construct a network dataset based on a single line dataset or a single line and a single point. If the user's dataset already has the correct network relationship, 
    you can directly build a network dataset through :py:meth:`build_network_dataset_known_relation_3d`.

    For the constructed network dataset, you can use :py:meth:`validate_network_dataset_3d` to check whether the network topology is correct.

    :param line: the line dataset used to construct the network dataset
    :type line: DatasetVector
    :param point: The point dataset used to construct the network dataset.
    :type point: DatasetVector
    :param split_mode: break mode, default is no break
    :type split_mode: NetworkSplitMode3D
    :param float tolerance: node tolerance
    :param line_saved_fields: Fields that need to be reserved in the line dataset
    :type line_saved_fields: str or list[str]
    :param point_saved_fields: The fields that need to be reserved in the point dataset.
    :type point_saved_fields: str or list[str]
    :param out_data: The datasource object that holds the result network dataset
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result 3D network dataset
    :rtype: DatasetVector
    """,

    "iobjectspy._jsuperpy.analyst.na3d.build_network_dataset_known_relation_3d": """
    According to the point, line data and the existing fields that express the topological relationship of arc nodes, a network dataset is constructed.
    When the line and point objects in the existing line and point dataset correspond to the arcs and nodes of the network to be constructed, and have information describing the spatial topological relationship between the two, that is, 
    the line dataset contains the edge ID and the edge starting point. Start node ID and end node ID fields. When the point dataset contains the node ID field of the point object, this method can be used to construct a network dataset.

    After successfully constructing a network dataset using this method, the number of result objects is consistent with the number of objects in the source data, that is, a line object in the line data is written as an arc, 
    and a point object in the point data is written as a node, and retain all non-system fields of the point and line datasets to the result dataset.

    For example, for pipeline and pipe point data collected for establishing a pipe network, the pipeline and pipe points are all identified by a unique fixed code. One of the characteristics of the pipe network is that the pipe points are only located at the two ends of the pipeline, 
    so the pipe points correspond to all the nodes of the pipe network to be constructed, and the pipeline corresponds to all the arcs of the pipe network to be constructed, and there is no need to be at the intersection of the pipeline and the pipeline. interrupt. 
    In the pipeline data, the pipe point information at both ends of the pipeline object is recorded, that is, the start pipe point code and the end pipe point code, which means that the pipeline and pipe point data already contain the information of the spatial topological relationship between the two, so it is suitable for use This method builds a network dataset.

    Note that the arc ID, arc start node ID, edge end node ID, and node ID fields of the network dataset constructed in this way are the fields specified when calling this method, and are no longer SmEdgeID, SmFNode, SmTNode, SmNodeID and other system fields. Specifically, 
    the corresponding fields can be obtained through the :py:meth:`.DatasetVector.get_field_name_by_sign` method of DatasetVector.

    :param line: 3D line dataset used to build network dataset
    :type line: str or DatasetVector
    :param point: 3D point dataset used to construct network dataset
    :type point: str or DatasetVector
    :param str edge_id_field: The field representing the edge ID in the specified line dataset. If it is specified as a null or empty string, or the specified field does not exist, SMID is automatically used as the edge ID.
                                Only 16-bit integer and 32-bit integer fields are supported.
    :param str from_node_id_field: The field representing the starting node ID of the edge in the specified line dataset. Only 16-bit integer and 32-bit integer fields are supported.
    :param str to_node_id_field: The field in the specified line dataset that represents the end node ID of the edge. Only 16-bit integer and 32-bit integer fields are supported.
    :param str node_id_field: The field representing the node ID in the specified point dataset. Only 16-bit integer and 32-bit integer fields are supported.
    :param out_data: The datasource object that holds the result network dataset
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param function progress: progress information processing function, please refer to:py:class:`.StepEvent`
    :return: result network dataset
    :rtype: DatasetVector
    """,

    "iobjectspy._jsuperpy.analyst.am": """
Address match
""",

    "iobjectspy._jsuperpy.analyst.am.AddressItem": """
    Chinese address fuzzy matching result class. The Chinese address fuzzy matching result class stores the detailed information of the query result that matches the input Chinese address, including the queried address, the dataset where the address is located, 
    the SmID of the address in the source dataset, the score value of the query result, and The geographic location information of the address.

    """,

    "iobjectspy._jsuperpy.analyst.am.AddressItem.address": """str: the matched address """,

    "iobjectspy._jsuperpy.analyst.am.AddressItem.address_as_tuple": """tuple[str]: the array form of the matched address """,

    "iobjectspy._jsuperpy.analyst.am.AddressItem.dataset_index": """int: The index of the dataset where the queried Chinese address is located""",

    "iobjectspy._jsuperpy.analyst.am.AddressItem.location": """Point2D: the geographic location of the queried address""",

    "iobjectspy._jsuperpy.analyst.am.AddressItem.record_id": """int: SMID corresponding to the queried address in the source dataset""",

    "iobjectspy._jsuperpy.analyst.am.AddressItem.score": """float: matching score result""",

    "iobjectspy._jsuperpy.analyst.am.AddressSearch": """
    Chinese address fuzzy matching class.

    Implementation process and precautions for fuzzy matching of Chinese addresses:

    1. Specify the directory of the address index created by the Chinese address library data, and create a Chinese address matching object;
    2. Call the match object, specify the city of the address to be searched, it must be the value in the city-level field in the Chinese address database, and then specify the Chinese address to be searched and the number of Return;
    3. The system performs word segmentation on the keywords to be matched, and then matches the content in the specified field in the specified dataset, and Return the matched result through certain operations.
    """,

    "iobjectspy._jsuperpy.analyst.am.AddressSearch.__init__": """
        Initialization object

        :param str search_directory: The directory where the address index is located
        """,

    "iobjectspy._jsuperpy.analyst.am.AddressSearch.is_valid_lowest_group_name": """
        Determine whether the specified name is legal as a three-level group name.

        :param str value: the name of the field to be judged
        :return: legally return True, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.am.AddressSearch.is_valid_secondary_group_name": """
        Determine whether the specified name is legal as a secondary group name.

        :param str value: the name of the field to be judged
        :return: legally return True, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.am.AddressSearch.is_valid_top_group_name": """
        Determine whether the specified name is legal as a first-level group name.

        :param str value: the name of the field to be judged
        :return: legally return True, otherwise return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.analyst.am.AddressSearch.match": """
        The addresses match. This method supports multithreading.

        :param str address: the address of the place name to be retrieved
        :param bool is_address_segmented: Whether the incoming Chinese address has been segmented, that is, it is segmented with the "*" separator.
        :param bool is_location_return: Whether the Chinese address fuzzy matching result object contains location information.
        :param int max_result_count: The maximum number of matching results for fuzzy matching of Chinese addresses
        :param str top_group_name: the first-level group name, provided that the first-level group field name is set when the data index is created
        :param str secondary_group_name: secondary group name, provided that the secondary group field name is set when the data index is created
        :param str lowest_group_name: three-level group name, provided that the three-level group field name is set when creating the data index
        :return: Chinese address fuzzy matching result collection
        :rtype: list[AddressItem]
        """,

    "iobjectspy._jsuperpy.analyst.am.AddressSearch.reverse_match": """
        Reverse address matching. This method supports multithreading.

        :param geometry: the specified point object
        :type geometry: GeoPoint or Point2D
        :param float distance: The specified search range.
        :param int max_result_count: The maximum number of matching results searched
        :return: Chinese address matching result collection
        :rtype: list[AddressItem]
        """,

    "iobjectspy._jsuperpy.analyst.am.AddressSearch.search_directory": """str: The directory where the address index is located""",

    "iobjectspy._jsuperpy.analyst.am.AddressSearch.set_search_directory": """
        Set the directory where the address index is located. The address index is created using the :py:meth:`build_address_indices` method.

        :param str search_directory: The directory where the address index is located
        :return: self
        :rtype: AddressSearch
        """,

    "iobjectspy._jsuperpy.analyst.am.build_address_indices": """
    Build an index file with matching addresses

    :param str output_directory: index file result output directory
    :param datasets: Save the address information, the dataset used to create the index
    :type datasets: list[DatasetVector] or tuple[DatasetVector]
    :param index_fields: The fields that need to be indexed, such as the detailed address field or address name, etc. The set of fields should exist in every dataset
    :type index_fields: str or list[str] or tuple[str]
    :param save_fields: Fields of additional information that needs to be stored. This information is not used for address matching, but will be returned in the address matching result.
    :type save_fields: str or list[str] or tuple[str]
    :param str top_group_field: The field name of the first level grouping, such as the name of each province.
    :param str secondary_group_field: The name of the secondary group, such as the name of each city.
    :param str lowest_group_field: The name of the three-level group, such as the name of each county.
    :param bool is_build_reverse_matching_indices: Whether to create an index for reverse address matching
    :param float bin_distance: The interval distance created by the reverse address matching index. The distance unit is consistent with the coordinate system.
    :param str dictionary_file: The address of the dictionary file. If it is empty, the default dictionary file will be used.
    :param bool is_append: Whether to append to the original index, if there is an index file in the specified output index file directory, if it is True, append to the original index file, but it is required
                           When adding new data, the structure of the new attribute table must be the same as that of the loaded data. If False, a new index file is created.
    :param bool is_traditional: whether it is Traditional Chinese.
    :return: Whether to create the index successfully
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.analyst.am.get_default_dictionary_file": """""",

    "iobjectspy._jsuperpy.analyst": """
The ananlyst module provides commonly used spatial data processing and analysis functions. Users can use the analyst module to perform buffer analysis (:py:meth:`create_buffer` ), overlay analysis (:py:meth:`overlay` ),
Create Thiessen polygons (:py:meth:`create_thiessen_polygons` ), topological facets (:py:meth:`topology_build_regions` ), density clustering (:py:meth:`kernel_density` ),
Interpolation analysis (:py:meth:`interpolate` ), raster algebra operations (:py:meth:`expression_math_analyst`) and other functions.


In all interfaces of the analyst module, the input data parameters are required to be dataset (:py:class:`.Dataset`, :py:class:`.DatasetVector`, :py:class:`.DatasetImage`, :py: class:`.DatasetGrid`) parameters,
Both accept direct input of a dataset object ( Dataset) or a combination of datasource alias and dataset name (for example,'alias/dataset_name','alias\\\dataset_name'), and also support datasource connection information and dataset name Combination (for example,'E:/data.udb/dataset_name').

    -Support setting dataset

        >>> ds = Datasource.open('E:/data.udb')
        >>> create_buffer(ds['point'], 10, 10, unit='Meter', out_data='E:/buffer_out.udb')

    -Supports setting the combination of dataset alias and dataset name

        >>> create_buffer(ds.alias +'/point' +, 10, 10, unit='Meter', out_data='E:/buffer_out.udb')
        >>> create_buffer(ds.alias +'\\point', 10, 10, unit='Meter', out_data='E:/buffer_out.udb')
        >>> create_buffer(ds.alias +'|point', 10, 10, unit='Meter', out_data='E:/buffer_out.udb')

    -Support setting udb file path and dataset name combination

        >>> create_buffer('E:/data.udb/point', 10, 10, unit='Meter', out_data='E:/buffer_out.udb')

    -Supports setting the combination of datasource connection information and dataset name. datasource connection information includes DCF files, xml strings, etc. For details, please refer to: py:meth:`.DatasourceConnectionInfo.make`

        >>> create_buffer('E:/data_ds.dcf/point', 10, 10, unit='Meter', out_data='E:/buffer_out.udb')

.. Note: When the datasource information is entered, the program will automatically open the datasource, but the datasource will not be automatically closed when the interface runs, that is, the opened datasource will be stored in the current workspace


In all the interfaces in the analyst module, the datasource (:py:class:`.Datasource`) is required for the output data parameters, all accept the Datasource object, which can also be the :py:class:`.DatasourceConnectionInfo` object.
At the same time, it also supports the alias of the datasource in the current workspace, and also supports the UDB file path, DCF file path, etc.

    -Support setting udb file path

        >>> create_buffer('E:/data.udb/point', 10, 10, unit='Meter', out_data='E:/buffer_out.udb')

    -Support setting datasource objects

        >>> ds = Datasource.open('E:/buffer_out.udb')
        >>> create_buffer('E:/data.udb/point', 10, 10, unit='Meter', out_data=ds)
        >>> ds.close()

    -Support setting datasource alias

        >>> ds_conn = DatasourceConnectionInfo('E:/buffer_out.udb', alias='my_datasource')
        >>> create_buffer('E:/data.udb/point', 10, 10, unit='Meter', out_data='my_datasource')


.. Note: If the input parameters of the output data are datasource connection information or UDB file path, etc., the program will automatically open the datasource. If it is a UDB datasource and does not exist locally, it will automatically create a new UDB datasource, but You need to ensure that the file directory where the UDB datasource is located exists and is writable.
          After the function is completed, if the datasource is automatically opened or created by the program, it will be automatically closed (different from the input data being Dataset, the datasource that is automatically opened in the input data will not be automatically closed). 
          Therefore, for some interfaces whose output result is a dataset, the name of the result dataset will be returned. If the data source object is passed in, the result dataset will be returned.

""",

"iobjectspy._jsuperpy.analyst.terrain.snap_pour_point" :"""
Capture catchment points. The catchment point is captured to the pixel with the largest accumulated flow within the specified range, and it is used to correct the catchment point data to the river.

    Catchment points can generally be used for the construction of bridges, bridges and culverts and other water conservancy facilities, but in practical applications, the catchment points are not always calculated, that is, use the :py:meth:`.pour_points` method, or other methods,
    For example, when the position in the vector map is converted to raster data, the catchment catchment function needs to be corrected at this time to ensure the maximum accumulated catchment volume.

    As with the catchment grid, after catching the catchment point, the flow direction grid can be further combined to divide the watershed (:py:meth:`.watershed` method).

    :param pour_point_or_grid: Catchment point dataset, only point dataset and raster dataset are supported
    :type pour_point_or_grid: DatasetGrid or DatasetVector or str
    :param accumulation_grid: a grid dataset of cumulative water catchment. It can be obtained by :py:meth:`.flow_accumulation`.
    :type accumulation_grid: DatasetGrid or str
    :param float snap_distance: Snap distance, capture the catchment point to the grid position of the maximum catchment volume within the range, and the distance is consistent with the specified catchment point data set unit.
    :param str pour_point_field: The field used to assign the location of the catchment point. When the catchment point dataset is a point dataset, you need to specify the catchment point raster value field.
                                The field type only supports integer type, if it is non-integer type, it will be forced to integer type.
    :param out_data: The data source used to store the result data set
    :type out_data: DatasourceConnectionInfo or Datasource or str
    :param str out_dataset_name: The name of the result data set.
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the raster dataset of the result watershed
    :rtype: DatasetGrid or str
""",
"iobjectspy._jsuperpy.analyst.sa.multilayer_overlay" :"""

Multi-layer overlay analysis supports overlay analysis of multiple data sets or multiple record sets.

    >>> ds = open_datasource('E:/data.udb')
    >>> input_dts = [ds['dltb_2017'], ds['dltb_2018'], ds['dltb_2019']]
    >>> result_dt = multilayer_overlay(input_ds,'intersect','OnlyID', 1.0e-7)
    >>> assert result_dt is not None
    True

    :param inputs: data set or record set participating in overlay analysis
    :type inputs: list[DatasetVector] or list[Recordset] or list[list[Geometry]]
    :param overlay_mode: Overlay analysis mode, only supports intersection (:py:attr:`OverlayMode.INTERSECT`) and merge (:py:attr:`OverlayMode.UNION`)
    :type overlay_mode: OverlayMode or str
    :param output_attribute_type: multi-layer overlay analysis field attribute return type
    :type output_attribute_type: OverlayOutputAttributeType or str
    :param float tolerance: node tolerance
    :param out_data: The data source where the result data is saved. If it is empty, the result data set is saved to the data source where the overlay analysis source data set is located. When the inputs are all arrays of geometric objects,
                     The data source for saving the result data must be set.
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return:
    :rtype:
""",
"iobjectspy._jsuperpy.analyst.sa.erase_and_replace_raster" :"""
Erase and fill the raster or image data set, that is, you can modify the raster value of the specified area.

    >>> region = Rectangle(875.5, 861.2, 1172.6, 520.9)
    >>> result = erase_and_replace_raster(data_dir +'example_data.udbx/seaport', region, (43,43,43))

    Process raster data::

    >>> region = Rectangle(107.352104894652, 30.1447395778174, 107.979276445055, 29.6558796240814)
    >>> result = erase_and_replace_raster(data_dir +'example_data.udbx/DEM', region, 100)

    :param input_data: raster or image dataset to be erased
    :type input_data: DatasetImage or DatasetGrid or str
    :param replace_region: erase region
    :type replace_region: Rectangle or GeoRegion
    :param replace_value: The replacement value of the erased area, use replace_value to replace the grid value in the specified erased area.
    :type replace_value: float or int or tuple[int,int,int]
    :param out_data: The data source where the result data set is located
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: result data set or data set name
    :rtype: DatasetGrid or DatasetImage or str
""",
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter" :"""
Cellular Automata Parameter Class Based on Multi-criteria Judgment
""",
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.end_cell_grid" :"""DatasetGrid: end year raster dataset""",

"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.global_value" :"""float: global factor influence ratio""",

"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.local_value" :"""float: neighborhood factor influence ratio""",

"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.ahp_comparison_matrix" :"""list[list[float]]: AHP consistency test judgment matrix """,

"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.cellular_automata_parameter" :"""CellularAutomataParameter: Cellular AutomataParameter""",

"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.alpha" :"""int: diffusion parameter""",
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.conversion_rules" :"""dict[int,bool]: Conversion rules """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.conversion_target" :"""int: conversion target """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.set_check_result":
    """
    Set whether to compare the inspection output result and the termination data. The default is False.

        :param bool value: Whether to compare the test output result and the termination data
        :return: self
        :rtype: MCECellularAutomataParameter
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.set_end_cell_grid":
    """
    Set the end year raster dataset.

        :param value: end year raster dataset
        :type value: DatasetGrid or str
        :return: self
        :rtype: MCECellularAutomataParameter
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.set_global_value":
    """
    Set the global factor influence ratio. The default value is 0.5. The sum of the influence ratios of global factors and domain factors is 1.

        :param float value: Global factors affect the ratio.
        :return: self
        :rtype: MCECellularAutomataParameter
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.set_local_value":
    """
    Set the influence ratio of neighborhood factors, the default value is 0.5. The sum of the influence ratios of neighborhood factors and global factors is 1

        :param float value: The influence ratio of neighborhood factors
        :return: self
        :rtype: MCECellularAutomataParameter
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.check_ahp_consistent":
    """
    Consistency test of analytic hierarchy process.

        >>> values = [[1, 0.33333343, 0.2, 3], [3, 1, 0.333333343, 3], [5, 3, 1, 5], [0.333333343, 0.333333343, 0.2, 1]]
        >>> MCECellularAutomataParameter.check_ahp_consistent(values)

        :param ahp_comparison_matrix: judgment matrix. If set to list, each element in list must be a list, and the element values â€‹â€‹are equal. If there is a numpy library in the system, you can
                     Enter a two-dimensional numpy array.
        :type ahp_comparison_matrix: list[list[float]] or numpy.ndarray
        :return: Return the weight array successfully, whether to return None
        :rtype: list[float]
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.set_ahp_comparison_matrix":
    """
    Set up the judgment matrix for the consistency test of the analytic hierarchy process.

        :param value: The judgment matrix for the consistency test of the analytic hierarchy process. If set to list, each element in list must be a list, and the element values â€‹â€‹are equal. If there is a numpy library in the system, you can
                     Enter a two-dimensional numpy array.
        :type value: list[list[float]] or numpy.ndarray
        :return: self
        :rtype: MCECellularAutomataParameter
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.set_cellular_automata_parameter":
    """
    Set cellular automata parameters.

        :param value: Cellular automata parameters
        :type value: CellularAutomataParameter
        :return: self
        :rtype: MCECellularAutomataParameter
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.set_alpha":
    """
    Set the diffusion parameters. Generally 1-10.

        :param int value: Diffusion parameter.
        :return: self
        :rtype: MCECellularAutomataParameter
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.set_conversion_rules":
    """
    Set up conversion rules. For example, in the change of land use, water area is non-convertible land, and farmland is convertible land.

        :param value: conversion rules
        :type value: dict[int,bool]
        :return: self
        :rtype: MCECellularAutomataParameter
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomataParameter.set_conversion_target":
    """
    Set conversion goals. For example, in the conversion of farmland to urban land, urban land is the conversion target.

        :param int value: conversion target
        :return: self
        :rtype: MCECellularAutomataParameter
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomata" :"""
Cellular automata based on multi-criteria judgment.
""",

"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomata.get_kappa":
    """
    Get the Kappa coefficient.

        :return: kappa coefficient. It is used for consistency check and can be used to measure the accuracy of cell conversion.
        :rtype: float
    """,
"iobjectspy._jsuperpy.analyst.sa.MCECellularAutomata.mce_cellular_automata":
    """
    Cellular automata based on multi-criteria judgment.

        >>> ds = open_datasource('/home/data/cellular.udbx')
        >>> para = CellularAutomataParameter()
        >>> para.set_cell_grid(ds['T2001'])
        >>> para.set_spatial_variable_grids((ds['x0'], ds['x1'], ds['x2'], ds['x3'], ds['x4']))
        >>> para.set_simulation_count(1000).set_iterations(10)
        >>> para.set_output_datasource(ds).set_output_dataset_name('result')
        >>> ahp_v = [[1, 0.33333343, 0.2, 3], [3, 1, 0.333333343, 3], [5, 3, 1, 5], [0.333333343, 0.333333343, 0.2, 1]]
        >>> assert MCECellularAutomataParameter.check_ahp_consistent(ahp_v) is not None
        [0.13598901557207943, 0.24450549432771368, 0.5430402884352277, 0.0764652016649792]
        >>>
        >>> mce_parameter = MCECellularAutomataParameter().set_cellular_automata_parameter(para)
        >>> mce_parameter.set_conversion_rules({2: False, 3: True, 4: False, 5: True})
        >>> mce_parameter.set_conversion_target(1).set_check_result(True).set_end_cell_grid(ds['T2006'])
        >>> mce_parameter.set_ahp_comparison_matrix(ahp_v).set_alpha(2)
        >>> def progress_function(step):
        >>> print('{}: {}'.format(step.title, step.message))
        >>>
        >>> result_grid = mce_parameter.mce_cellular_automata(mce_parameter, progress_func=progress_function)
        >>>

        :param parameter: Parameters of cellular automata based on multi-criteria judgment.
        :type parameter: MCECellularAutomataParameter
        :param out_data: The data source where the output result dataset is located.
        :type out_data: Datasource or str
        :param out_dataset_name: The name of the output data set.
        :type out_dataset_name: str
        :param progress_func: progress information processing function, please refer to :py:class:`.StepEvent`
        :type progress_func: function
        :param flush_func: Cellular automata flushing information processing function, please refer to :py:class:`.CellularAutomataFlushedEvent`
        :type flush_func: function
        :return: result raster dataset
        :rtype: DatasetGrid
    """,
"iobjectspy._jsuperpy.analyst.sa.create_random_points" :"""
Randomly generate points within the geometric object. When generating random points, you can specify the number of random points and the distance between the random points. When the number of random points and the minimum distance are specified at the same time, the minimum distance will be met first.
That is, the distance between the generated random points must be greater than the minimum distance, when the number may be less than the number of random points.

    >>> ds = open_datasource('E:/data.udb')
    >>> dt = ds['dltb']
    >>> polygon = dt.get_geometries('SmID == 1')[0]
    >>> points = create_random_points(polygon, 10)
    >>> print(len(points))
    10
    >>> points = create_random_points(polygon, 10, 1500)
    >>> print(len(points))
    9
    >>> assert compute_distance(points(0),points(1))> 1500
    True
    >>>
    >>> random_dataset = create_random_points(dt, 10, 1500, None, ds,'random_points', None)
    >>> print(random_dataset.type)
    'Point'


    :param dataset_or_geo: A geometric object or dataset used to create random points. When specified as a single geometric object, line and area geometric objects are supported.
                           When specified as a data set, data sets of point, line, and area types are supported.
    :type dataset_or_geo: GeoRegion or GeoLine or Rectangle or DatasetVector or str
    :param random_number: The number of random points or the name of the field where the number of random points is located. Only random points generated in the data set can be formulated as field names.
    :type random_number: str or float
    :param min_distance: The minimum distance or the field name of the minimum distance of the random point. When the random point distance value is None or 0, the generated random point does not consider the distance limit between two points.
                         When it is greater than 0, the distance between any two random points must be greater than the specified distance. At this time, the number of random points generated may not necessarily be equal to the specified number of random points.
                         Only random points generated in the data set can be formulated as field names.
    :type min_distance: str or float
    :param Rectangle clip_bounds: The range for generating random points, which can be None. When it is None, random points are generated in the entire data set or geometric object.
    :param out_data: The data source to store the result data
    :type out_data: Datasource
    :param str out_dataset_name: result data set name
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: The random point list or the data set where the random point is located. When a random point is generated in a geometric object, list[Point2D] will be returned. When a random point is generated in the data set, the data set will be returned.
    :rtype: list[Point2D] or DatasetVector or str
""",
"iobjectspy._jsuperpy.analyst.sa.regularize_building_footprint" :"""
Perform regularization processing on the area type building object to generate a regularized object covering the original area object.


    >>> ds = open_datasource('E:/data.udb')
    >>> dt = ds['building']
    >>> polygon = dt.get_geometries('SmID == 1')[0]

    Regularize the geometric objects, the offset distance is 0.1, the unit is the data set coordinate system unit::

    >>> regularize_result = regularize_building_footprint(polygon, 0.1, None, RegularizeMethod.ANYANGLE,
    >>> prj=dt.prj_coordsys)
    >>> assert regularize_result.type == GeometryType.GEOREGION
    True

    Regularize the data set::

    >>> regularize_dt = regularize_building_footprint(dt, 0.1,'meter', RegularizeMethod.RIGHTANGLES, min_area=10.0,
    >>> min_hole_area=2.0, is_attribute_retained=False)
    >>> assert regularize_dt.type = DatasetType.REGION
    True

    :param dataset_or_geo: the building area object or area dataset to be processed
    :type dataset_or_geo: GeoRegion or Rectangle or DatasetVector or str
    :param float offset_distance: The maximum distance that a regularized object can be offset from the boundary of its original object.
                                  With .py:attr:`.offset_distance_unit`, you can set the linear unit value based on the data coordinate system, and you can also set the distance unit value.
    :param offset_distance_unit: The unit of the regularized offset distance, the default is None, that is, the unit of the data used.
    :type offset_distance_unit: Unit or str
    :param regularize_method: regularize method
    :type regularize_method: RegularizeMethod or str
    :param float min_area: The minimum area of â€‹â€‹a regularized object. Objects smaller than this area will be deleted. It is valid when the value is greater than 0. When the spatial coordinate system or the coordinate system of the dataset is projection or latitude and longitude,
                          The area unit is square meter. When the coordinate system is None or the plane coordinate system, the area unit corresponds to the data unit.
    :param float min_hole_area: The minimum area of â€‹â€‹the hole in the regularized object. Holes smaller than this area will be deleted. It is valid when the value is greater than 0. When the spatial coordinate system or the coordinate system of the data set is projection or latitude and longitude, the area unit is square meters,
                                When the coordinate system is None or a plane coordinate system, the area unit corresponds to the data unit
    :param prj: The coordinate system of the building area object. It is valid only when the input is a geometric object.
    :type prj: PrjCoordSys or str
    :param bool is_attribute_retained: Whether to save the attribute field value of the original object. Only valid when the input is a data set.
    :param out_data: The data source to store the result data
    :type out_data: Datasource
    :param str out_dataset_name: result data set name
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: The result is the regularized area object or area dataset. If the input is a region object, the generated result will also be a region object. When the input is a polygon dataset, the generated result is also a polygon dataset, and a status field will be generated in the generated polygon dataset.
            When the status field value is 0, it means that the regularization fails, and the saved object is the original object. When the status field value is 1, it means that the regularization is successful, and the saved object is a regularized object.
    :rtype: DatasetVector or GeoRegion
""",
"iobjectspy._jsuperpy.analyst.sa.auto_compute_project_points" :"""
Automatically calculate the vertical foot from point to line.

    >>> ds = open_datasource('E:/data.udb')
    >>> auto_compute_project_points(ds['point'], ds['line'], 10.0)

    :param point_input: input point data set or record set
    :type point_input: DatasetVector or Recordset
    :param line_input: input line data set or record set
    :type line_input: DatasetVector or Recordset
    :param float max_distance: Maximum query distance, the unit of distance is the same as the unit of the dataset coordinate system. When the value is less than 0, it means that the search distance is not limited.
    :param out_data: The data source to store the result data
    :type out_data: Datasource
    :param str out_dataset_name: result data set name
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: Return the point to the vertical foot of the line.
    :rtype: DatasetVector or str
""",
"iobjectspy._jsuperpy.analyst.sa.compute_natural_breaks" :"""
Calculate the natural break point. Jenks Natural Breaks (Jenks Natural Breaks) is a statistical method of grading and classification according to the numerical statistical distribution law. It can maximize the difference between classes, that is, make the variance within the group as small as possible, and the variance between groups as much as possible Big,
    The features are divided into multiple levels or categories, and for these levels or categories, their boundaries will be set at locations where the data values â€‹â€‹differ relatively large.

    :param input_dataset_or_values: The data set or list of floating-point numbers to be analyzed. Supports raster datasets and vector datasets.
    :type input_dataset_or_values: DatasetGrid or DatasetVector or list[float]
    :param int number_zones: number of groups
    :param str value_field: The name of the field used for natural break point segmentation. When the input data set is a vector data set, a valid field name must be set.
    :return: an array of natural break points, the value of each break point is the maximum value of the group
    :rtype: list[float]
""",
"iobjectspy._jsuperpy.analyst.sa.tabulate_area":
    """
    Tabulate the area, count the area of each category in the area, and output the attribute table. It is convenient for users to view the area summary of each category in each area.
    In the resulting attribute table::
     -Each predicate in the regional data set has one record
     -Each unique value of the category data set for area statistics has a field
     -Each record will store the area of each category in each area

     .. image:: ../image/TabulateArea.png

    :param class_dataset: The category data set for area statistics to be performed. It supports raster, point, line, and area data sets. It is recommended to use a raster dataset first. If a point or line dataset is used, the area that intersects the feature will be output.
    :type class_dataset: DatasetGrid or DatasetVector or str
    :param zone_dataset: The zone dataset, which supports raster and point, line and area datasets. The area is defined as all areas with the same value in the input, and the areas do not need to be connected.
                         It is recommended to use a raster dataset first. If a vector dataset is used, it will be converted internally using "vector to raster".
    :type zone_dataset: DatasetGrid or DatasetVector or str
    :param str class_field: The category field of area statistics. When :py:attr:`.class_dataset` is DatasetVector, a valid category field must be specified.
    :param str zone_field: Zone refers to a field. When :py:attr:`zone_dataset` is DatasetVector, a valid zone value field must be specified.
    :param float resolution:
    :param out_data: The data source to store the result data
    :type out_data: Datasource
    :param str out_dataset_name: result data set name
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return:
    :rtype: DatasetVector
""",
"iobjectspy._jsuperpy.analyst.ss.GTWR":
    """
    Spatio-temporal geographic weighted regression.

    Spatio-temporal geographic weighted regression is an expanded and improved geographic weighted regression that can analyze spatial coordinate points with time attributes and solve the problem of the overall temporal and spatial non-stationarity of the model.
    Application scenarios::
     -Study the changing trends of urban housing in terms of time and space
     -Study the factors of provincial economic development and their temporal and spatial laws

    >>> result = GTWR(ds['data'],'FLOORSZ','PURCHASE','time_field', kernel_type='FIXED', kernel_function='GAUSSIAN',
    >>> band_width_type='CV', distance_tolerance=2000)

    Simultaneous prediction::

    >>> result = GTWR(ds['data'],'FLOORSZ','PURCHASE','time_field', kernel_type='FIXED', kernel_function='GAUSSIAN',
    >>> band_width_type='CV', distance_tolerance=2000, prediction_dataset=ds['predict'],
    >>> explanatory_fields_matching={'FLOORSZ':'FLOORSZ'}, prediction_time_field='time_field')


    :param source: The data set to be calculated. It can be a point, line, or area data set.
    :type source: DatasetVector or str
    :param explanatory_fields: a collection of explanatory field names
    :type explanatory_fields: list[str] or str
    :param str model_field: the name of the modeling field
    :param str time_field:
    :param time_distance_unit:
    :type time_distance_unit: TimeDistanceUnit or str
    :param kernel_function: kernel function type
    :type kernel_function: KernelFunction or str
    :param band_width_type: Bandwidth determination method
    :type band_width_type: BandWidthType or str
    :param float distance_tolerance: bandwidth range
    :param kernel_type: bandwidth type
    :type kernel_type: KernelType or str
    :param int neighbors: The number of neighbors. It is valid only when the bandwidth type is set to :py:attr:`.KernelType.ADAPTIVE` and the width determination method is set to :py:attr:`.BandWidthType.BANDWIDTH`.
    :param out_data: The data source used to store the result data set
    :type out_data: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param progress: progress information, please refer to :py:class:`.StepEvent`
    :type progress: function
    :param prediction_dataset: prediction data set
    :type prediction_dataset: DatasetVector or str
    :param str prediction_time_field: The name of the prediction data set time field. It is only valid when a valid forecast data set is set.
    :param dict[str,str] explanatory_fields_matching: prediction data set field mapping. Represents the corresponding relationship between the model's explanatory field name and the predicted data set field name.
                                                      Each interpretation field should have a corresponding field in the prediction data set. If no corresponding relationship is set,
                                                      Then all fields in the explanatory variable array must exist in the prediction data set.
    :param str out_predicted_name: The name of the prediction result data set. It is only valid when a valid forecast data set is set.
    :return: returns a three-element tuple, the first element of the tuple is :py:class:`.GWRSummary`, the second element is the geographically weighted regression result data set,
             The third element is the geographically weighted regression prediction result data set
    :rtype: tuple[GWRSummary, DatasetVector, DatasetVector]
    """,
"iobjectspy._jsuperpy.analyst.topo.integrate":
    """
    Data integration is performed on the data set, and the integration process includes node capture and insertion point operations. It has a similar function with py:func:`.preprocess`:, which can handle topological errors in the data,
    The difference from py:func:`.preprocess`: is that data integration will be iterated multiple times until there are no topological errors in the data (no node capture and interpolation are required).

    >>> ds = open_datasource('E:/data.udb')
    >>> integrate(ds['building'], 1.0e-6)
    True
    >>> integrate(ds['street'], 1.0,'meter')
    True

    :param source_dataset: the data set being processed
    :type source_dataset: DatasetVector or str
    :param float tolerance: node tolerance
    :param unit: node tolerance unit, when it is None, the data set coordinate system unit is used. If the data set coordinate system is a projected coordinate system, angle units are prohibited.
    :type unit: Unit or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: Return True if successful, otherwise False
    :rtype: bool
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalSchemaOrientation" :"""
    :var TopologicalSchemaOrientation.LEFTTORIGHT: The layout direction of the graph from left to right. The logic diagram will start from the root node on the left and end on the right.
    :var TopologicalSchemaOrientation.RIGHTTOLEFT: The layout direction of the graph from right to left. The logic diagram will start from the root node on the right and end on the left.
    :var TopologicalSchemaOrientation.TOPTOBOTTOM: The layout direction of the graph from top to bottom. The logic diagram will start from the root node on the top side and end at the bottom.
    :var TopologicalSchemaOrientation.BOTTOMTOTOP: The layout direction of the graph from bottom to top. The logic diagram will start from the root node at the bottom and end at the top.
""",
"iobjectspy._jsuperpy.analyst.schema.NetworkEdge" :"""
   The network edge object represents the network relationship. It is composed of the line object, the unique identifier of the line object, and the unique identifiers of the two nodes at the beginning and the end of the line object.
""",
"iobjectspy._jsuperpy.analyst.schema.NetworkEdge.__init__" :"""
    :param int edge_id: network edge line object ID
    :param int from_node_id: the starting point ID of the network edge segment line object
    :param int to_node_id: The end point ID of the network edge segment line object
    :param GeoLine edge: network edge line object
""",
"iobjectspy._jsuperpy.analyst.schema.NetworkEdge.edge" :"""GeoLine: In the network relationship, the edge geometry object""",
"iobjectspy._jsuperpy.analyst.schema.NetworkEdge.set_edge" :"""
Set the geometric object of the edge

        :param GeoLine value: edge geometry object
        :return: NetworkEdge
        :rtype: self
""",
"iobjectspy._jsuperpy.analyst.schema.NetworkEdge.edge_id" :"""int: The ID of the edge object in the network relationship""",
"iobjectspy._jsuperpy.analyst.schema.NetworkEdge.set_edge_id":
    """
    Set the ID of the edge object

        :param int value: edge object ID
        :return: self
        :rtype: NetworkEdgeID
    """,
"iobjectspy._jsuperpy.analyst.schema.NetworkEdge.from_node_id" :"""int: ID of the starting point of the arc in the network relationship""",
"iobjectspy._jsuperpy.analyst.schema.NetworkEdge.set_from_node_id":
    """
    Set the ID of the starting point of the edge

        :param int value: The starting point ID of the edge
        :return: self
        :rtype: NetworkEdgeID
    """,
"iobjectspy._jsuperpy.analyst.schema.NetworkEdge.to_node_id" :"""int: In the network relationship, the edge end point ID""",
"iobjectspy._jsuperpy.analyst.schema.NetworkEdge.set_to_node_id":
    """
    Set the ID of the end point of the edge

        :param int value: End point ID of edge
        :return: self
        :rtype: NetworkEdgeID
    """,
"iobjectspy._jsuperpy.analyst.schema.NetworkNode":
    """
    The node object in the network edge relationship is represented by the unique identifier of the node object and the node object in the network arc relationship.
    """,
"iobjectspy._jsuperpy.analyst.schema.NetworkNode.__init__" :"""
    :param int node_id: network node ID
    :param GeoPoint node: network node object
In the network relationship, the edge geometry object """,
"iobjectspy._jsuperpy.analyst.schema.NetworkNode.node" :"""GeoPoint: Network node object""",
"iobjectspy._jsuperpy.analyst.schema.NetworkNode.set_node":
    """
    Set the network node object

        :param value: network node object
        :type value: GeoPoint or Point2D
        :return: self
        :rtype: NetworkNode
    """,
"iobjectspy._jsuperpy.analyst.schema.NetworkNode.node_id" :"""int: network node ID""",
"iobjectspy._jsuperpy.analyst.schema.NetworkNode.set_node_id":
    """
Set the network node ID

        :param int value: network node ID
        :return: self
        :rtype: NetworkNode
""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema":
    """ Hierarchical topology logic diagram.

    The hierarchical diagram is applicable to networks with a clear source in a similar directed facility network. As shown in the figure below, there is only one source in the network, that is, in a subnet, there is only one entry, and the others are all exits. This kind of network can generate a hierarchical graph:

    .. image: ../image/SourceNetwork.png

    .. image: ../image/HierarchicalSchemaResult.png
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema.__init__":
    """
    :param float node_spacing: the distance of the topological logic graph node
        :param float rank_node_spacing: the distance between the topological logic graph levels
        :param int smooth: smoothness coefficient
        :param orientation: the layout direction of the topological logic diagram
        :type orientation: TopologicalSchemaOrientation or str
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema.node_spacing" :"""float: the distance of the topological logic diagram node. The default is 30.""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema.set_node_spacing":
    """
    Set the node distance of the topology logic diagram.

        As shown in the figure below, the node distance from node â‘  to node â‘¡ is dy

        .. image: ../image/HierarchicaPara.png

        :param float value: the distance of the topological logic diagram node
        :return: self
        :rtype: TopologicalHierarchicalSchema
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema.edge" :"""GeoLine: In the network relationship, the arc geometry object""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema.rank_node_spacing" :"""float: the distance between the topological logic diagram levels. The default is 50.""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema.set_rank_node_spacing":
    """
    Set the distance between the levels of the topology logic diagram.

        As shown in the figure below, there are two levels from node â‘  to node â‘¡, and dz is the distance between the levels

        .. image: ../image/HierarchicaPara.png

        :param float value: the distance between the topological logic diagram levels
        :return: self
        :rtype: TopologicalHierarchicalSchema
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema.smooth" :"""int: smoothness factor. The default is 1.""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema.set_smooth":
    """
    Set the smoothness factor. If you need to smooth the result, you can set a smoothing coefficient greater than 1. The default is not smoothing, that is, the value is 1.

        :param int value: smoothness coefficient
        :return: self
        :rtype: TopologicalHierarchicalSchema
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema.orientation" :"""TopologicalSchemaOrientation: Topological logic diagram layout trend""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalHierarchicalSchema.set_orientation":
    """
    Set the layout direction of the topology logic diagram. The default layout is from left to right.

        :param value: The layout trend of the topology logic diagram
        :type value: TopologicalSchemaOrientation or str
        :return: self
        :rtype: TopologicalHierarchicalSchema
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalTreeSchema":
    """
    Tree topology logic diagram.

    The tree diagram is the same as the hierarchical diagram. Both are applicable to networks with a clear source in a similar directed facility network.

    In a subnet, only single source or single sink is supported, that is, there can only be one source in a subnet, and sinks do not require it. It also supports only one sink point, and the source point does not require it.

    .. image: ../image/TreeSchemaResult.png
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalTreeSchema.__init__":
    """
        :param float node_spacing: the distance of the topological logic graph node
        :param float level_spacing: the distance between tree layer levels
        :param float break_radio: Get the break ratio of the broken line, the value range is [0,1]
        :param orientation: the layout direction of the topological logic diagram
        :type orientation: TopologicalSchemaOrientation or str
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalTreeSchema.node_spacing" :"""float: the distance of the topological logic graph node, the default value is 30.""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalTreeSchema.set_node_spacing":
    """
    Set the node distance of the topology logic diagram.
        As shown in the figure below, the node distance from node â‘  to node â‘¡ is dy

        .. image: ../image/TopologicalTreePara.png

        :param float value: the distance of the topological logic diagram node
        :return: self
        :rtype: TopologicalTreeSchema
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalTreeSchema.level_spacing" :"""float: distance between tree layer levels""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalTreeSchema.set_level_spacing":
    """
    Set the distance between tree layer levels.
        As shown in the figure below, there are two levels from node â‘  to node â‘¡, and dx is the distance between the levels

        .. image: ../image/TopologicalTreePara.png

        :param float value: the distance between the tree layer levels
        :return: self
        :rtype: TopologicalTreeSchema
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalTreeSchema.break_radio" :"""float: Broken line break ratio. The default is 0.5""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalTreeSchema.set_break_radio":
    """
    Set the percentage of broken lines.
        As shown in the figure below, the connecting polyline from node â‘  to node â‘¡ is the polyline to be broken. Set the breaking distance to 0.7 to get the effect as shown in the figure.

        .. image: ../image/TopologicalTreePara.png

        :param float value: Broken line ratio
        :return: self
        :rtype: TopologicalTreeSchema
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalTreeSchema.orientation" :"""TopologicalSchemaOrientation: Topological logic diagram layout direction""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalTreeSchema.set_orientation":
    """
    GeoLine: In the network relationship, the edge geometry object sets the layout trend of the topology logic diagram

        :param value: The layout trend of the topology logic diagram
        :type value: TopologicalSchemaOrientation or str
        :return: self
        :rtype: TopologicalTreeSchema
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalOrthogonalSchema":
    """
    Right-angle orthogonal topology logic diagram.

    The right-angle orthogonal graph requires less data, but requires that the data cannot have an edge segment that is self-circulating (that is, in a network edge segment, the start point is equal to the end point).

    .. image: ../image/OrthogonalSchemaResult.png
    """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalOrthogonalSchema.__init__" :""":param float node_spacing: Topological logic graph node distance """,
"iobjectspy._jsuperpy.analyst.schema.TopologicalOrthogonalSchema.node_spacing" :"""float: Topological logic diagram node distance""",
"iobjectspy._jsuperpy.analyst.schema.TopologicalOrthogonalSchema.set_node_spacing":
    """
    Set the distance between the nodes of the topology logic diagram. The default value is 10 units.

        :param float value: the distance of the topological logic diagram node
        :return: self
        :rtype: TopologicalOrthogonalSchema
    """,
"iobjectspy._jsuperpy.analyst.schema.build_topological_schema" :"""
    Build the topology logic diagram.

    The topological logic diagram is a schematic diagram that reflects its own logical structure based on the network data set. It expresses the complex network in an intuitive way and simplifies the form of the network. It can be applied to resource management in telecommunications, transportation, pipeline power and other industries.
    Viewing the network through the topology logic diagram can effectively evaluate the distribution of existing network resources, predict and plan the configuration of subsequent resources, etc.

    SuperMap supports the construction of a topological logic diagram based on the network relationship represented by the network edges and network nodes, which is convenient for checking network connectivity and obtaining a schematic diagram of network data.

    >>> network_dt = open_datasource('/home/iobjectspy/data/example_data.udbx')['network_schema']

    Build a hierarchy diagram:

    >>> hierarchical_schema_result = build_topological_schema(TopologicalHierarchicalSchema(smooth=3), network_dt)

    Build a tree diagram:

    >>> tree_schema_result = build_topological_schema(TopologicalTreeSchema(), network_dt)

    Construct a right-angled orthogonal graph:

    >>> orthogonal_schema_result = build_topological_schema(TopologicalOrthogonalSchema(), network_dt)

    Construct a topology diagram through network relationships:

    >>> network_edges = list()
    >>> network_edges.append(NetworkEdge(1, 1, 2))
    >>> network_edges.append(NetworkEdge(2, 1, 3))
    >>> network_edges.append(NetworkEdge(3, 2, 4))
    >>> network_edges.append(NetworkEdge(4, 2, 5))
    >>> network_edges.append(NetworkEdge(5, 3, 6))
    >>> network_edges.append(NetworkEdge(6, 3, 7))
    >>> out_ds = create_mem_datasource()
    >>> tree_schema_result_2 = build_topological_schema(TopologicalTreeSchema(), network_edges, out_data=out_ds)

    Construct a topology diagram through network edges and network nodes:

    >>> edges = []
    >>> nodes = []
    >>> edge_rd = network_dt.get_recordset()
    >>> while edge_rd.has_next():
    >>> edge_id = edge_rd.get_value('SmEdgeID')
    >>> f_node = edge_rd.get_value('SmFNode')
    >>> t_node = edge_rd.get_value('SmTNode')
    >>> edges.append(NetworkEdge(edge_id, f_node, t_node, edge_rd.get_geometry()))
    >>> edge_rd.move_next()
    >>> edge_rd.close()
    >>> node_rd = network_dt.child_dataset.get_recordset()
    >>> while node_rd.has_next():
    >>> node_id = node_rd.get_value('SmNodeID')
    >>> nodes.append(NetworkNode(node_id, node_rd.get_geometry()))
    >>> node_rd.move_next()
    >>> node_rd.close()
    >>>
    >>> tree_schema_result_2 = build_topological_schema(TopologicalTreeSchema(), edges, nodes, is_merge=True,
    >>> tolerance=1.0e-6, out_data=out_ds, out_dataset_name='SchemaRes')
    >>>

    :param schema_param: Topological logic diagram parameter class object
    :type schema_param: TopologicalHierarchicalSchema or TopologicalTreeSchema or TopologicalOrthogonalSchema
    :param network_dt_or_edges: two-dimensional network data set or virtual network edge
    :type network_dt_or_edges: DatasetVector or list[NetworkEdge]
    :param network_nodes: Virtual network node, when :py:attr:`network_dt_or_edges` is list[NetworkEdge], 
                          virtual network node objects can be set to express the complete network relationship.
                          When network_nodes is not set, you can use list[NetworkEdge] alone to express network relationships as well. 
                          And NetworkEdge may not need network edge space objects.
    :type network_nodes: list[NetworkNode]
    :param bool is_merge: Whether to set repeated network edges and network node objects in the merged spatial position. In the network relationship,if there are repeated edges and repeated nodes in the spatial position,
                          if this parameter is set to True, a common edge relationship will be extracted to construct a logical diagram, and the constructed topological logical diagram also contains spatial positions Repeating edges and nodes.
                           If this parameter is set to False, each correct network topology relationship will be processed normally when calculating the topology logic diagram.
                          Is_merge is valid only when a valid :py:attr:`network_nodes` is set.
    :param float tolerance: node tolerance, used for node object comparison in space calculation. Only valid if :py:attr:`is_merge` is True
    :param out_data: The data source to store the result data. When :py:attr:`network_dt_or_edges` is not a network data set, a valid result data source must be set.
    :type out_data: Datasource
    :param str out_dataset_name: result data set name
    :return: A two-dimensional network data set used to represent a topological logic diagram
    :rtype: DatasetVector
""",
}

_jsuperpy_mapping_locale = {
    "iobjectspy._jsuperpy.mapping": """""",

    "iobjectspy._jsuperpy.mapping.AlongLineCulture": """
    This class defines the type constants used to display the label text along the line.

    :var AlongLineCulture.ENGLISH: It is displayed in English habit. The direction of the text is always perpendicular to the direction of the line.
    :var AlongLineCulture.CHINESE: Display in Chinese habit. When the angle between the line and the horizontal direction is [], the text direction is parallel to the line direction, otherwise it is vertical.
    """,

    "iobjectspy._jsuperpy.mapping.AlongLineDirection": """
    This class defines the type constant of the label along the line.
    The acute angle between the route and the horizontal direction above 60 degrees indicates the up and down direction, and below 60 degrees indicates the left and right direction

    :var AlongLineDirection.ALONG_LINE_NORMAL: Place the label along the normal direction of the line.
    :var AlongLineDirection.LEFT_TOP_TO_RIGHT_BOTTOM: Place from top to bottom, left to right.
    :var AlongLineDirection.RIGHT_TOP_TO_LEFT_BOTTOM: Place from top to bottom, right to left.
    :var AlongLineDirection.LEFT_BOTTOM_TO_RIGHT_TOP: Place from bottom to top, left to right.
    :var AlongLineDirection.RIGHT_BOTTOM_TO_LEFT_TOP: Place from bottom to top, right to left.
    """,

    "iobjectspy._jsuperpy.mapping.AlongLineDrawingMode": """
    This class defines the constants of the tagging strategy type along the label.

    Starting from the version of SuperMap GIS 8C (2017), the drawing strategy of labels along the line has been adjusted. In order to be compatible with the previous version, a "compatible drawing" option is provided.

    In the new drawing strategy, users can choose whether to draw the label as a whole or separate the text and letters in the label according to actual application requirements. In general, the label along the line is drawn by splitting, and the label matches the trend of the marked lineï¼›
    if the line is drawn, the label will be taken as a whole. This setting is generally used for labeling along the line with background labels.

    .. image:: ../image/Labelchaifen.png

    :var AlongLineDrawingMode.COMPATIBLE: Compatible drawing
    :var AlongLineDrawingMode.WHOLEWORD: whole line drawing
    :var AlongLineDrawingMode.EACHWORD: Split drawing
    """,

    "iobjectspy._jsuperpy.mapping.AvoidMode": """
    This enumeration defines the type constants of the avoidance method of the label text in the label map.

    :var AvoidMode.TWO: Avoid text in both directions.
    :var AvoidMode.FOUR: Four directions text avoidance
    :var AvoidMode.EIGHT: Eight directions text avoidance.
    :var AvoidMode.FREE: Avoid surrounding text.
    """,

    "iobjectspy._jsuperpy.mapping.GraduatedMode": """
    This class defines the constants of thematic map classification mode. Mainly used in statistics thematic maps and graduated symbols thematic maps.

    The grading is mainly to reduce the difference between the data size when making thematic maps. If there is a large gap between the data, you can use the logarithmic or square root classification method to carry out, in this way, the absolute size difference
    Between the data is reduced, which makes the thematic map have better visual effect, and the comparison between different categories is also meaningful. There are three classification modes: constant, logarithm and square root. For fields with negative numbers, the logarithm and
    In the square root classification method, the absolute value of the negative value is taken as the value involved in the calculation.

    :var GraduatedMode.CONSTANT: Constant graduated mode. Perform hierarchical operations according to the linear ratio of the original values in the attribute table.
    :var GraduatedMode.SQUAREROOT: Square root grading mode. Perform hierarchical operations according to the linear ratio of the square root of the original value in the attribute table.
    :var GraduatedMode.LOGARITHM: Logarithmic grading mode. Perform a hierarchical operation according to the linear ratio of the natural logarithm of the original value in the attribute table.
    """,

    "iobjectspy._jsuperpy.mapping.GraphAxesTextDisplayMode": """
    The text display mode of the axis of the statistics map.

    :var GraphAxesTextDisplayMode.NONE: No display
    :var GraphAxesTextDisplayMode.YAXES: Display the text of Y axis
    :var GraphAxesTextDisplayMode.ALL: Display all text
    """,

    "iobjectspy._jsuperpy.mapping.LabelBackShape": """
    This class defines the shape type constants of the label background in the label map.

    The label background is a label display style supported by SuperMap iObjects. It uses various shapes with a certain color as the background of each label, which can highlight the label or make the label thematic map more beautiful.

    :var LabelBackShape.NONE: Empty background, do not use any shape as the background of the label.
    :var LabelBackShape.RECT: Rectangular background. The shape of the label background is rectangular
    :var LabelBackShape.ROUNDRECT: Rounded rectangle background. The shape of the label background is a rounded rectangle
    :var LabelBackShape.ELLIPSE: Oval background. The shape of the label background is an oval
    :var LabelBackShape.DIAMOND: Diamond background. The shape of the label background is a rhombus
    :var LabelBackShape.TRIANGLE: Triangular background. The shape of the label background is a triangle
    :var LabelBackShape.MARKER: Symbol background. The shape of the label background is a set symbol, which can be set by the method of :py:meth:`.ThemeLabel.set_back_style` respectively.
    """,

    "iobjectspy._jsuperpy.mapping.LabelMatrix": """
    Matrix label class.

    Through this class, complex labels can be made to annotate objects. This class can contain n*n matrix label elements. The type of matrix label elements can be pictures, symbols, label thematic maps, etc. The currently supported matrix tag elementï¼›
    types are: py:class:`LabelMatrixImageCell`, :py:class:`LabelMatrixSymbolCell`, :py:class:`ThemeLabel`, passing in another type
    Will throw an exception. Matrix label elements are not supported. Matrix label elements do not support expressions with special symbols, and do not support labeling along lines.

    The following code demonstrates how to use the LabelMatrix class to make complex labels to label objects::

    >>> label_matrix = LabelMatrix(2,2)
    >>> label_matrix.set(0, 0, LabelMatrixImageCell('path', 5, 5, is_size_fixed=False))
    >>> label_matrix.set(1, 0, ThemeLabel().set_label_expression('Country'))
    >>> label_matrix.set(0, 1, LabelMatrixSymbolCell('Symbol', GeoStyle.point_style(0, 0, (6,6),'red')))
    >>> label_matrix.set(1, 1, ThemeLabel().set_label_expression('Capital'))
    >>> theme_label = ThemeLabel()
    >>> theme_label.set_matrix_label(label_matrix)

    """,

    "iobjectspy._jsuperpy.mapping.LabelMatrix.__init__": """
        :param int cols: number of columns
        :param int rows: number of rows
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrix.cols": """int: number of columns""",

    "iobjectspy._jsuperpy.mapping.LabelMatrix.get": """
        Set the corresponding object at the specified row and column position.

        :param int col: the specified number of columns
        :param int row: the specified number of rows
        :return: the object corresponding to the specified row and column position
        :rtype: LabelMatrixImageCell or LabelMatrixSymbolCell or ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrix.rows": """int: number of rows""",

    "iobjectspy._jsuperpy.mapping.LabelMatrix.set": """
        Set the corresponding object at the specified row and column position.

        :param int col: The specified number of columns.
        :param int row: the specified number of rows
        :param value: the object corresponding to the specified row and column position
        :type value: LabelMatrixImageCell or LabelMatrixSymbolCell or ThemeLabel
        :return: self
        :rtype: LabelMatrix
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell": """
    The matrix label element class of the image type.

    This type of object can be used as a matrix label element in the matrix label object

    Specific reference: py:class:`LabelMatrix`.
    """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.__init__": """

        :param str path_field: Record the field name of the image path used by the image type matrix label element.
        :param float width: the width of the picture, in millimeters
        :param float height: The height of the picture in millimeters.
        :param float rotation: The rotation angle of the picture.
        :param bool is_size_fixed: Is the size of the picture fixed?
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.height": """float: Return the height of the image in millimeters""",

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.is_size_fixed": """bool: Is the size of the image fixed""",

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.path_field": """str: """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.rotation": """float: the rotation angle of the image""",

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.set_height": """
        Set the height of the picture in millimeters

        :param float value: the height of the picture
        :return: self
        :rtype: LabelMatrixImageCell
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.set_path_field": """

        :param str value:
        :return: self
        :rtype: LabelMatrixImageCell
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.set_rotation": """
        Set the rotation angle of the picture.

        :param float value: The rotation angle of the picture.
        :return: self
        :rtype: LabelMatrixImageCell
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.set_size_fixed": """
        Set whether the size of the picture is fixed

        :param bool value: Whether the size of the picture is fixed
        :return: self
        :rtype: LabelMatrixImageCell
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.set_width": """
        Set the width of the picture in millimeters

        :param float value: The width of the picture, in millimeters
        :return: self
        :rtype: LabelMatrixImageCell
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixImageCell.width": """float: Return the width of the image in millimeters""",

    "iobjectspy._jsuperpy.mapping.LabelMatrixSymbolCell": """
    The symbol type of the matrix label element class.

    This type of object can be used as a matrix label element in the matrix label object.

    Specific reference: py:class:`LabelMatrix`.
    """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixSymbolCell.__init__": """

        :param str symbol_id_field: Record the field name of the symbol ID used.
        :param GeoStyle style: the style of the symbol used
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixSymbolCell.set_style": """
        Set the style of symbols used

        :param GeoStyle value: the style of the symbol used
        :return: self
        :rtype: LabelMatrixSymbolCell
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixSymbolCell.set_symbol_id_field": """
        Set the field name of the symbol ID used in the record.

        :param str value: Record the field name of the symbol ID used.
        :return: self
        :rtype: LabelMatrixSymbolCell
        """,

    "iobjectspy._jsuperpy.mapping.LabelMatrixSymbolCell.style": """GeoStyle: Return the style of the symbol used""",

    "iobjectspy._jsuperpy.mapping.LabelMatrixSymbolCell.symbol_id_field": """str: Return the field name of the symbol ID used by the record.""",

    "iobjectspy._jsuperpy.mapping.Layer": """
    The layer class.

    This class provides a series of methods to facilitate map management such as layer display and control. When the dataset is loaded into the map window for display, a layer is formed, so the layer is a visualization display
    Of the dataset. A layer is a reference or reference to a dataset.
    The layers are divided into ordinary layers and thematic layers. All elements in the ordinary layers of the vector adopt the same rendering style, and the raster layer uses a color table to display its pixels; while The thematic layer uses the specified type of thematic map style to render the elements or pixels in it.
    The image data only corresponds to ordinary layers. The style of ordinary layers is passed: py:meth:`get_layer_setting`
     And :py:meth:`set_layer_setting` method to return or set.

    Instances of this class cannot be created. It can only be created by: py:class:`Map` class: py:meth:`Map.add_dataset` method
    """,

    "iobjectspy._jsuperpy.mapping.Layer.bounds": """Rectangle: the extent of the layer""",

    "iobjectspy._jsuperpy.mapping.Layer.caption": """str: Return the title of the layer. The title of the layer is the display name of the layer. For example, the name of the layer displayed in the legend or layout drawing is the map The title of the layer. Note the difference with the name of the layer. """,

    "iobjectspy._jsuperpy.mapping.Layer.dataset": """Dataset: Return the dataset object corresponding to this layer. A layer is a reference to a dataset, so a layer corresponds to a dataset. """,

    "iobjectspy._jsuperpy.mapping.Layer.from_xml": """
        Create a layer object based on the specified XML string. Any layer can be exported as an xml string, and the xml string of a layer can also be imported as a layer for display. The layer's
        xml string stores all the Settings for the layer's display and associated data. You can save the xml string of the layer as an xml file.

        :param str xml: The XML string used to create the layer
        :return: Return true if the creation is successful, otherwise Return false.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Layer.get_clip_region": """
        Return the clipping area of the layer.

        :return: Return the clipping area of the layer.
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.mapping.Layer.get_display_filter": """
        Return to the layer display filter condition. By setting the display filter conditions, some elements in the layer can be displayed while other elements are not displayed, so as to focus on analyzing the elements of interest and filter out other elements.

        Note: This method only supports attribute query, not spatial query

        :return: Layer display filter conditions.
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.mapping.Layer.get_layer_setting": """
        Return the style setting of the normal layer. The setting of common layer style is different for vector data layer, raster data layer and image data layer.
        :py:class:`LayerSettingVector`, :py:class:`LayerSettingGrid`, :py:class:`LayerSettingImage` classes are used to
        Set and modify according to the style of the layer, raster data layer and image data layer.

        :return: the style setting of the normal layer
        :rtype: LayerSetting
        """,

    "iobjectspy._jsuperpy.mapping.Layer.get_max_visible_scale": """
        Return the maximum visible scale of this layer. The maximum visible scale cannot be negative. When the current display scale of the map is greater than or equal to the maximum visible scale of the layer, the layer will not be displayed.

        :return: The maximum visible scale of the layer.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.Layer.get_min_visible_scale": """

        :return:
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.Layer.get_opaque_rate": """
        Return the opacity of the layer.

        :return: The opacity of the layer.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.Layer.get_theme": """
        Return the thematic map object of the thematic layer, for the thematic layer.

        :return: Thematic map object of the thematic layer
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.Layer.is_antialias": """
        Return whether the layer has anti-aliasing enabled.

        :return: Indicates whether anti-aliasing is turned on for the layer. true to enable anti-aliasing, false to disable.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Layer.is_clip_region_enabled": """
        Return whether the crop area is valid.

        :return: Specify whether the crop area is valid. true means valid, false means invalid.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Layer.is_symbol_scalable": """
        Return whether the symbol size of the layer is scaled with the image. The default is false. true means that when the layer is enlarged or reduced, the symbol will also be enlarged or reduced accordingly.

        :return: Whether the symbol size of the layer is scaled with the image.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Layer.is_visible": """
        Return whether this layer is visible. true means the layer is visible, false means the layer is not visible. When the layer is not visible, the settings of all other properties will be invalid

        :return: Whether the layer is visible.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Layer.is_visible_scale": """
        Return whether the specified scale is visible scale, that is, between the set minimum display scale and maximum display scale

        :param float scale: The specified display scale.
        :return: Return true, indicating that the specified scale is a visible scale; otherwise, it is false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_antialias": """
        Set whether to enable anti-aliasing for the layer.

        :param bool value: Indicates whether anti-aliasing is enabled for the layer. true to enable anti-aliasing, false to disable.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_caption": """
        Set the title of the layer. The title of the layer is the display name of the layer. For example, the name of the layer displayed in the legend or layout drawing is the title of the layer. Note the difference with the name of the layer.

        :param str value: Specify the title of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_clip_region": """
        Set the clipping area of the layer.

        :param region: The clipping region of the layer.
        :type region: GeoRegion or Rectangle
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_clip_region_enabled": """
        Set whether the crop area is valid.

        :param bool value: Whether the specified clipping area is valid, true means valid, false means invalid.

        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_dataset": """
        Set the dataset object corresponding to this layer. A layer is a reference to a dataset, therefore, a layer corresponds to a dataset

        :param Dataset dt: the dataset object corresponding to this layer
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_display_filter": """
        Set the layer display filter condition. By setting the display filter conditions, some elements in the layer can be displayed while other elements are not displayed, so as to focus on analyzing the elements of interest and filter out other elements. For example, the field of an external table is used as the expression field of the thematic map by joining (JoinItem). When the thematic map is generated and displayed, this method needs to be called, otherwise the creation of the thematic map will fail.

        Note: This method only supports attribute query, not spatial query

        :param QueryParameter parameter: Specify the layer display filter condition.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_layer_setting": """
        Set the style of ordinary layers

        :param LayerSetting setting: The style setting of common layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_max_visible_scale": """
        Set the maximum visible scale of this layer. The maximum visible scale cannot be negative. When the current display scale of the map is greater than or equal to the maximum visible scale of the layer, the layer will not be displayed.

        :param float value: Specify the maximum visible scale of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_min_visible_scale": """
        Return the minimum visible scale of this layer. The minimum visible scale cannot be negative. When the current display scale of the map is smaller than the minimum visible scale of the layer, this layer will not be displayed.

        :param float value: The minimum visible scale of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_opaque_rate": """
        Set the opacity of the layer.

        :param int value: The opacity of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_symbol_scalable": """
        Set whether the symbol size of the layer is scaled with the image. The default is false. true means that when the layer is enlarged or reduced, the symbol will also be enlarged or reduced accordingly.

        :param bool value: Specify whether the symbol size of the layer is scaled with the image.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.set_visible": """
        Set whether this layer is visible. true means the layer is visible, false means the layer is not visible. When the layer is not visible, the settings of all other properties will be invalid.

        :param bool value: Specify whether the layer is visible.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Layer.to_xml": """
        Return the description of this layer object in XML string form. Any layer can be exported as an xml string, and the xml string of a layer can also be imported as a layer for display. The layer's
        xml string stores all the Settings for the layer's display and associated data. You can save the xml string of the layer as an xml file.

        :return: Return the description of this layer object in XML string form.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation": """
    Grid aggregation graph
    """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.bounds": """Rectangle: the extent of the layer""",

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.caption": """str: Return the title of the layer. The title of the layer is the display name of the layer. For example, the name of the layer displayed in the legend or layout drawing is the map The title of the layer. Note the difference with the name of the layer. """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.dataset": """Dataset: Return the dataset object corresponding to this layer. A layer is a reference to a dataset, therefore, a layer corresponds to a dataset. """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.from_xml": """
        Create a layer object based on the specified XML string. Any layer can be exported as an xml string, and the xml string of a layer can also be imported as a layer for display. The layer's
        xml string stores all the Settings for the layer's display and associated data. You can save the xml string of the layer as an xml file.

        :param str xml: The XML string used to create the layer
        :return: Return true if the creation is successful, otherwise Return false.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_clip_region": """
        Return the clipping area of the layer.

        :return: Return the clipping area of the layer.
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_colorset": """
        Return the color corresponding to the maximum value of the grid cell statistics. The grid aggregation map will determine the color scheme of the gradient through MaxColor and MinColor, and then sort the grid cells based on the size of the grid cell statistics, and perform color rendering on the grid cells.

        :return: the color corresponding to the maximum value of the grid cell statistics
        :rtype: Colors
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_display_filter": """
        Return to the layer display filter condition. By setting the display filter conditions, some elements in the layer can be displayed while other elements are not displayed, so as to focus on analyzing the elements of interest and filter out other elements.

        Note: This method only supports attribute query, not spatial query

        :return: Layer display filter conditions.
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_grid_height": """
        Return the height of the rectangular grid. The unit is: screen coordinates.

        :return: the height of the rectangular grid
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_grid_type": """
        Return the grid type of the grid aggregation graph

        :return: grid type of grid aggregation graph
        :rtype: LayerGridAggregationType
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_grid_width": """
        Return the side length of a hexagonal grid, or the width of a rectangular grid. The unit is: screen coordinates.

        :return: the side length of a hexagonal grid, or the width of a rectangular grid
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_label_style": """
        Return the style of the statistical value label in the grid cell.

        :return: The style of the statistical value label in the grid cell.
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_layer_setting": """
        Return the style setting of the normal layer. The setting of common layer style is different for vector data layer, raster data layer and image data layer.
        :py:class:`LayerSettingVector`, :py:class:`LayerSettingGrid`, :py:class:`LayerSettingImage` classes are used to
        Set and modify according to the style of the layer, raster data layer and image data layer.

        :return: the style setting of the normal layer
        :rtype: LayerSetting
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_line_style": """
        Return the style of the rectangular border line of the grid cell.

        :return: the style of the rectangle border line of the grid cell
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_max_color": """
        Return the color corresponding to the maximum value of the grid cell statistics. The grid aggregation map will determine the color scheme of the gradient through MaxColor and MinColor , and then sort the grid cells based on the size of the grid cell statistics, and perform color rendering on the grid cells.

        :return: the color corresponding to the maximum value of the grid cell statistics
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_max_visible_scale": """
        Return the maximum visible scale of this layer. The maximum visible scale cannot be negative. When the current display scale of the map is greater than or equal to the maximum visible scale of the layer, the layer will not be displayed.

        :return: The maximum visible scale of the layer.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_min_color": """
        Return the color corresponding to the minimum value of the grid cell statistics. The grid aggregation graph will determine the color scheme of the gradient through MaxColor and MinColor, and then sort the grid cells based on the size of the grid cell statistics, and perform color rendering on the grid cells.

        :return: the color corresponding to the minimum value of the grid cell statistics
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_min_visible_scale": """

        :return:
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_opaque_rate": """
        Return the opacity of the layer.

        :return: The opacity of the layer.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_original_point_style": """
        Return the style of point data display. Magnify and browse the grid aggregation graph. When the scale is large, the aggregate grid effect will not be displayed, but the original point data content will be displayed.

        :return: The style of point data display.
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_theme": """
        Return the thematic map object of the thematic layer, for the thematic layer.

        :return: Thematic map object of the thematic layer
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.get_weight_field": """
        Return the weight field. The statistical value of each grid cell of the grid aggregation graph defaults to the number of point objects that fall in the cell. In addition, point weight information can be introduced, and the weighted value of the points in the grid cell is considered as the grid statistical value .

        :return: weight field
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.is_antialias": """
        Return whether the layer has anti-aliasing enabled.

        :return: Indicates whether anti-aliasing is turned on for the layer. true to enable anti-aliasing, false to disable.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.is_clip_region_enabled": """
        Return whether the crop area is valid.

        :return: Specify whether the crop area is valid. true means valid, false means invalid.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.is_show_label": """
        Whether to display grid cell labels

        :return: Whether to display the grid cell label, true means to display; false means not to display.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.is_symbol_scalable": """
        Return whether the symbol size of the layer is scaled with the image. The default is false. true means that when the layer is enlarged or reduced, the symbol will also be enlarged or reduced accordingly.

        :return: Whether the symbol size of the layer is scaled with the image.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.is_visible": """
        Return whether this layer is visible. true means the layer is visible, false means the layer is not visible. When the layer is not visible, the settings of all other properties will be invalid

        :return: Whether the layer is visible.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.is_visible_scale": """
        Return whether the specified scale is visible scale, that is, between the set minimum display scale and maximum display scale

        :param float scale: The specified display scale.
        :return: Return true, indicating that the specified scale is a visible scale; otherwise, it is false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_antialias": """
        Set whether to enable anti-aliasing for the layer.

        :param bool value: Indicates whether anti-aliasing is enabled for the layer. true to enable anti-aliasing, false to disable.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_caption": """
        Set the title of the layer. The title of the layer is the display name of the layer. For example, the name of the layer displayed in the legend or layout drawing is the title of the layer. Note the difference with the name of the layer.

        :param str value: Specify the title of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_clip_region": """
        Set the clipping area of the layer.

        :param region: The clipping region of the layer.
        :type region: GeoRegion or Rectangle
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_clip_region_enabled": """
        Set whether the crop area is valid.

        :param bool value: Whether the specified clipping area is valid, true means valid, false means invalid.

        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_colorset": """
        Set the color corresponding to the maximum value of the grid unit statistical value. The grid aggregation graph will determine the color scheme of the gradient through MaxColor and MinColor, and then sort the grid unit based on the size of the grid unit statistical value to perform color rendering on the grid unit.

        :param colors: the color corresponding to the maximum value of the grid cell statistics
        :type colors: Colors
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_dataset": """
        Set the dataset object corresponding to this layer. A layer is a reference to a dataset, therefore, a layer corresponds to a dataset

        :param Dataset dt: the dataset object corresponding to this layer
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_display_filter": """
        Set the layer display filter condition. By setting the display filter conditions, some elements in the layer can be displayed while other elements are not displayed, so as to focus on analyzing the elements of interest and filter out other elements. For example, the field of an external table is used as the expression field of the thematic map by joining (JoinItem). When the thematic map is generated and displayed, this method needs to be called, otherwise the creation of the thematic map will fail.

        Note: This method only supports attribute query, not spatial query

        :param QueryParameter parameter: Specify the layer display filter condition.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_grid_height": """
        Set the height of the rectangular grid. The unit is: screen coordinates.

        :param int value: the height of the rectangular grid
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_grid_type": """
        Set the grid type of the grid aggregation graph, which can be a rectangular grid or a hexagonal grid.

        :param value: Grid type of grid aggregation graph
        :type value: LayerGridAggregationType or str
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_grid_width": """
        Set the side length of the hexagonal grid or the width of the rectangular grid. The unit is: screen coordinates.

        :param int value: the side length of a hexagonal grid, or the width of a rectangular grid
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_label_style": """
        Set the style of the statistical value label in the grid cell.

        :param value: The style of the statistical value label in the grid cell.
        :type value: TextStyle
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_layer_setting": """
        Set the style of ordinary layers

        :param LayerSetting setting: The style setting of common layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_line_style": """
        Set the style of the rectangular border line of the grid cell.

        :param value: the style of the rectangle border line of the grid cell
        :type value: GeoStyle
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_max_color": """
        Set the color corresponding to the maximum value of the grid unit statistical value. The grid aggregation graph will determine the color scheme of the gradient through MaxColor and MinColor, and then sort the grid unit based on the size of the grid unit statistical value to perform color rendering on the grid unit.

        :param value: the color corresponding to the maximum value of the grid cell statistics
        :type value: Color or tuple[int,int,int]
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_max_visible_scale": """
        Set the maximum visible scale of this layer. The maximum visible scale cannot be negative. When the current display scale of the map is greater than or equal to the maximum visible scale of the layer, the layer will not be displayed.

        :param float value: Specify the maximum visible scale of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_min_color": """
        Set the color corresponding to the minimum value of the grid unit statistical value. The grid aggregation map will determine the gradient color scheme through MaxColor and MinColor, and then sort the grid unit based on the size of the grid unit statistical value to perform color rendering of the grid unit.

        :param value: the color corresponding to the minimum value of the grid cell statistics
        :type value: Color or tuple[int,int,int]
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_min_visible_scale": """
        Return the minimum visible scale of this layer. The minimum visible scale cannot be negative. When the current display scale of the map is smaller than the minimum visible scale of the layer, this layer will not be displayed.

        :param float value: The minimum visible scale of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_opaque_rate": """
        Set the opacity of the layer.

        :param int value: The opacity of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_original_point_style": """
        Set the style of point data display. Magnify and browse the grid aggregation graph. When the scale is large, the aggregate grid effect will not be displayed, but the original point data content will be displayed.

        :param value: point data display style
        :type value: GeoStyle
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_show_label": """
        Set whether to display grid cell labels.

        :param bool value: Indicates whether to display the grid cell label, true means to display; false means not to display.
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_symbol_scalable": """
        Set whether the symbol size of the layer is scaled with the image. The default is false. true means that when the layer is enlarged or reduced, the symbol will also be enlarged or reduced accordingly.

        :param bool value: Specify whether the symbol size of the layer is scaled with the image.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_visible": """
        Set whether this layer is visible. true means the layer is visible, false means the layer is not visible. When the layer is not visible, the settings of all other properties will be invalid.

        :param bool value: Specify whether the layer is visible.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.set_weight_field": """
        Set the weight field. The statistical value of each grid cell of the grid aggregation graph defaults to the number of point objects that fall in the cell. In addition, point weight information can be introduced, and the weighted value of the points in the grid cell is considered as the grid statistical value .

        :param str value: Weight field. The statistical value of each grid cell of the grid aggregation graph defaults to the number of point objects that fall in the cell. In addition, point weight information can be introduced, and the weighted value of the points in the grid cell is considered as the grid statistical value .
        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.to_xml": """
        Return the description of this layer object in XML string form. Any layer can be exported as an xml string, and the xml string of a layer can also be imported as a layer for display. The layer's
        xml string stores all the Settings for the layer's display and associated data. You can save the xml string of the layer as an xml file.

        :return: Return the description of this layer object in XML string form.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.LayerGridAggregation.update_data": """
        Automatically update the current grid aggregation graph according to data changes

        :return: self
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap": """
    Heat map layer class, which inherits from Layer class.

    Heat map is a map representation method that describes population distribution, density, and change trends through color distribution. Therefore, it can very intuitively present some data that is not easy to understand or express, such as density, frequency, temperature, etc.
    The heat map layer can not only reflect the relative density of point features, but also express the point density weighted according to attributes, so as to consider the contribution of the weight of the point itself to the density.
    The heat map layer will change as the map zooms in or out. It is a dynamic raster surface. For example, it draws a heat map of the visitor flow of tourist attractions across the country. When the map is zoomed in, the heat map can reflect a certain province. Or the distribution of visitor flow to tourist attractions in a local area.
    """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.bounds": """Rectangle: the extent of the layer""",

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.caption": """str: Return the title of the layer. The title of the layer is the display name of the layer, for example, the name of the layer displayed in the legend or layout drawing is the map The title of the layer. Note the difference with the name of the layer. """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.dataset": """Dataset: Return the dataset object corresponding to this layer. A layer is a reference to a dataset, so a layer corresponds to a dataset. """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.from_xml": """
        Create a layer object based on the specified XML string. Any layer can be exported as an xml string, and the xml string of a layer can also be imported as a layer for display. The layer's
        xml string stores all the Settings for the layer's display and associated data. You can save the xml string of the layer as an xml file.

        :param str xml: The XML string used to create the layer
        :return: Return true if the creation is successful, otherwise Return false.

        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_clip_region": """
        Return the clipping area of the layer.

        :return: Return the clipping area of the layer.
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_colorset": """
        Return the color set used to display the current heat map.

        :return: The color set used to display the current heat map
        :rtype: Colors
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_display_filter": """
        Return to the layer display filter condition. By setting the display filter conditions, some elements in the layer can be displayed while other elements are not displayed, so as to focus on analyzing the elements of interest and filter out other elements.

        Note: This method only supports attribute query, not spatial query

        :return: Layer display filter conditions.
        :rtype: QueryParameter
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_fuzzy_degree": """
        Return the blur degree of the color gradient in the heat map.

        :return: The blur degree of the color gradient in the heat map
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_intensity": """
        Return the high density color (MaxColor) and low density color (MinColor) in the heat map to determine the proportion of the high density color (MAXCOLOR) in the gradient color band. The greater the value,
        The greater the proportion of the high density color in the color band.

        :return: The high dot density color (MaxColor) and low dot density color (MinColor) in the heat map determine the proportion of the high dot density color (MaxColor) in the gradient color band
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_kernel_radius": """
        Return the core radius used to calculate the density. The unit is: screen coordinates.

        :return: core radius used to calculate density
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_layer_setting": """
        Return the style setting of the normal layer. The setting of common layer style is different for vector data layer, raster data layer and image data layer.
        :py:class:`LayerSettingVector`, :py:class:`LayerSettingGrid`, :py:class:`LayerSettingImage` classes are used to
        Set and modify according to the style of the layer, raster data layer and image data layer.

        :return: the style setting of the normal layer
        :rtype: LayerSetting
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_max_color": """
        Return the color of high dot density, the heat map layer will determine the color scheme of the gradient by the high dot density color (MaxColor) and the low dot density color (MinColor).

        :return: color with high dot density
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_max_value": """
        Return a maximum value. The grid between the maximum value (MaxValue) and the minimum value (MinValue) in the current heat map layer will be rendered using the color band determined by MaxColor and MinColor,
        Other grids larger than MaxValue will be rendered in MaxColor; and grids smaller than MinValue will be rendered in MinColor.

        :return: maximum
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_max_visible_scale": """
        Return the maximum visible scale of this layer. The maximum visible scale cannot be negative. When the current display scale of the map is greater than or equal to the maximum visible scale of the layer, the layer will not be displayed.

        :return: The maximum visible scale of the layer.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_min_color": """
        Return the color of low point density, the heat map layer will determine the color scheme of the gradient by the high point density color (MaxColor) and the low point density color (MinColor).

        :return: low-density color
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_min_value": """
        Return a minimum value. The grid between the maximum value (MaxValue) and the minimum value (MinValue) in the current heat map layer will be rendered using the color band determined by MaxColor and MinColor,
        Other grids larger than MaxValue will be rendered in MaxColor; and grids smaller than MinValue will be rendered in MinColor.

        :return: minimum value
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_min_visible_scale": """

        :return:
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_opaque_rate": """
        Return the opacity of the layer.

        :return: The opacity of the layer.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_theme": """
        Return the thematic map object of the thematic layer, for the thematic layer.

        :return: Thematic map object of the thematic layer
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.get_weight_field": """
        Return the weight field. The heat map layer can not only reflect the relative density of point features, but also express the point density weighted according to the weight field, so as to consider the contribution of the weight of the point itself to the density.

        :return: weight field
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.is_antialias": """
        Return whether the layer has anti-aliasing enabled.

        :return: Indicates whether anti-aliasing is turned on for the layer. true to enable anti-aliasing, false to disable.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.is_clip_region_enabled": """
        Return whether the crop area is valid.

        :return: Specify whether the crop area is valid. true means valid, false means invalid.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.is_symbol_scalable": """
        Return whether the symbol size of the layer is scaled with the image. The default is false. true means that when the layer is enlarged or reduced, the symbol will also be enlarged or reduced accordingly.

        :return: Whether the symbol size of the layer is scaled with the image.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.is_visible": """
        Return whether this layer is visible. true means the layer is visible, false means the layer is not visible. When the layer is not visible, the settings of all other properties will be invalid

        :return: Whether the layer is visible.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.is_visible_scale": """
        Return whether the specified scale is visible dimensions, i.e. the minimum and maximum setting display scale display scale between scale

        :param float scale: The specified display scale.
        :return: Return true, indicating that the specified scale is a visible scale; otherwise, it is false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_antialias": """
        Set whether to enable anti-aliasing for the layer.

        :param bool value: Indicates whether anti-aliasing is enabled for the layer. true to enable anti-aliasing, false to disable.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_caption": """
        Set the title of the layer. The title of the layer is the display name of the layer. For example, the name of the layer displayed in the legend or layout drawing is the title of the layer. Note the difference with the name of the layer.

        :param str value: Specify the title of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_clip_region": """
        Set the clipping area of the layer.

        :param region: The clipping region of the layer.
        :type region: GeoRegion or Rectangle
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_clip_region_enabled": """
        Set whether the crop area is valid.

        :param bool value: Whether the specified clipping area is valid, true means valid, false means invalid.

        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_colorset": """
        Set the color set used to display the current heat map.

        :param colors: The color set used to display the current heat map
        :type colors: Colors
        :return: self
        :rtype: LayerHeatmap
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_dataset": """
        Set the dataset object corresponding to this layer. A layer is a reference to a dataset, therefore, a layer corresponds to a dataset

        :param Dataset dt: the dataset object corresponding to this layer
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_display_filter": """
        Set the layer display filter condition. By setting the display filter conditions, some elements in the layer can be displayed while other elements are not displayed, so as to focus on analyzing the elements of interest and filter out other elements. For example, the field of an external table is used as the expression field of the thematic map by joining (JoinItem). When the thematic map is generated and displayed, this method needs to be called, otherwise the creation of the thematic map will fail.

        Note: This method only supports attribute query, not spatial query

        :param QueryParameter parameter: Specify the layer display filter condition.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_fuzzy_degree": """
        Set the blur degree of the color gradient in the heat map.

        :param float value: The blur degree of the color gradient in the heat map.
        :return: self
        :rtype: LayerHeatmap
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_intensity": """
        Set the high dot density color (MaxColor) and low dot density color (MinColor) in the heat map to determine the proportion of the high dot density color (MaxColor) in the gradient color band. The larger the value, the higher the density color in the color band. Bigger.

        :param float value: The high dot density color (MaxColor) and low dot density color (MinColor) in the heat map determine the proportion of the high dot density color (MaxColor) in the gradient color band
        :return: self
        :rtype: LayerHeatmap
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_kernel_radius": """
        Set the core radius used to calculate the density. The unit is: screen coordinates.
        The role of the core radius in the heat map is as follows:

        -The heat map will establish a buffer for each discrete point according to the set core radius value. The unit of the nuclear radius value is: screen coordinates;

        -After establishing a buffer for each discrete point, for each discrete point buffer, use a progressive gray band (the complete gray band is 0~255) from the inside out, from light to deep;

        -Because the gray value can be superimposed (the larger the value, the brighter the color is, and the whiter it appears in the gray band. In practice, any channel in the ARGB model can be selected as the superimposed gray value). The gray value can be superimposed on the area of, so the more the buffer crosses, the larger the gray value, the hotter the area;

        -Use the superimposed gray value as an index, map colors from a 256-color ribbon (for example, rainbow colors), and recolor the image to achieve a heat map.

        The larger the search radius, the smoother and more generalized the density raster is; the smaller the value, the more detailed the information displayed by the generated raster.

        :param int value: Calculate the core radius of the density
        :return: self
        :rtype: LayerHeatmap
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_layer_setting": """
        Set the style of ordinary layers

        :param LayerSetting setting: The style setting of common layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_max_color": """
        Set the color of high dot density, the heat map layer will determine the color scheme of the gradient through the high dot density color (MaxColor) and the low dot density color (MinColor).

        :param value: color of high dot density
        :type value: Color or tuple[int,int,int]
        :return: self
        :rtype: LayerHeatmap
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_max_value": """
        Set a maximum value. The grid between the maximum value (MaxValue) and the minimum value (MinValue) in the current heat map layer will be rendered using the color band determined by MaxColor and MinColor,
        Other grids larger than MaxValue will be rendered in MaxColor; and grids smaller than MinValue will be rendered in MinColor. If the maximum and minimum values are not specified, the system will automatically
        Calculate the maximum and minimum values in the current heat map layer.

        :param float value: maximum
        :return: self
        :rtype: LayerHeatmap
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_max_visible_scale": """
        Set the maximum visible scale of this layer. The maximum visible scale cannot be negative. When the current display scale of the map is greater than or equal to the maximum visible scale of the layer, the layer will not be displayed.

        :param float value: Specify the maximum visible scale of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_min_color": """
        Set the color of low dot density, the heat map layer will determine the color scheme of the gradient by the high dot density color (MaxColor) and the low dot density color (MinColor).

        :param value: low-density color
        :type value: Color or tuple[int,int,int]
        :return: self
        :rtype: LayerHeatmap
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_min_value": """
        Set a minimum value. The grid between the maximum value (MaxValue) and the minimum value (MinValue) in the current heat map layer will be rendered using the color band determined by MaxColor and MinColor,
        Other grids larger than MaxValue will be rendered in MaxColor; and grids smaller than MinValue will be rendered in MinColor.

        :param float value: minimum value
        :return: self
        :rtype: LayerHeatmap
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_min_visible_scale": """
        Return the minimum visible scale of this layer. The minimum visible scale cannot be negative. When the current display scale of the map is smaller than the minimum visible scale of the layer, this layer will not be displayed.

        :param float value: The minimum visible scale of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_opaque_rate": """
        Set the opacity of the layer.

        :param int value: The opacity of the layer.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_symbol_scalable": """
        Set whether the symbol size of the layer is scaled with the image. The default is false. true means that when the layer is enlarged or reduced, the symbol will also be enlarged or reduced accordingly.

        :param bool value: Specify whether the symbol size of the layer is scaled with the image.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_visible": """
        Set whether this layer is visible. true means the layer is visible, false means the layer is not visible. When the layer is not visible, the settings of all other properties will be invalid.

        :param bool value: Specify whether the layer is visible.
        :return: self
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.set_weight_field": """
        Set the weight field. The heat map layer can not only reflect the relative density of point features, but also express the point density weighted according to the weight field, so as to consider the contribution of the weight of the point itself to the density.
        According to the discrete point buffer determined by the kernel radius (KernelRadius), its superposition determines the heat distribution density, while the weight determines the influence of the point on the density, and the weight value of the point determines
        The influence of the point buffer on the density, that is, if the original influence coefficient of the point buffer is 1, and the weight value of the point is 10, after the weight is introduced, the influence coefficient of the point buffer is 1*10=10, so By analogy, the density influence coefficient of other discrete point buffers.

        Then, after the weight is introduced, a new superimposed gray value index will be obtained, and the specified color band is used to color it, so as to realize the heat map of the weight.


        :param str value: Weight field. The heat map layer can not only reflect the relative density of point features, but also express the point density weighted according to the weight field, so as to consider the contribution of the weight of the point itself to the density.
        :return: self
        :rtype: LayerHeatmap
        """,

    "iobjectspy._jsuperpy.mapping.LayerHeatmap.to_xml": """
        Return the description of this layer object in XML string form. Any layer can be exported as an xml string, and the xml string of a layer can also be imported as a layer for display. The layer's
        xml string stores all the Settings for the layer's display and associated data. You can save the xml string of the layer as an xml file.

        :return: Return the description of this layer object in XML string form.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.LayerSetting": """
    The base class for layer settings. This class is the base class for setting the display style of the layer.
    Use the methods provided in the LayerSettingVector, LayerSettingGrid and LayerSettingImage classes to set the layer styles of vector datasets, raster datasets and image datasets respectively.
    All elements in the vector layer use the same rendering style, the raster layer uses a color table to display its pixels, and the style setting of the image layer is the setting of the brightness, contrast, and transparency of the image.
    """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid": """
    Raster layer setting class.

    The raster layer settings are for ordinary layers. The raster layer uses a color table to display its pixels. The color table of SuperMap displays pixels according to the 8-bit RGB color coordinate system.
    You can set the display color value of the pixel according to its attribute value, thereby visually and intuitively representing the phenomenon reflected by the raster data.

    """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.get_brightness": """
        Return the brightness of the Grid layer. The value range is -100 to 100. Increasing brightness is positive, and decreasing brightness is negative.

        :return: The brightness of the Grid layer.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.get_color_dictionary": """
        Return the color comparison table of the layer.

        :return: The color comparison table of the layer.
        :rtype: dict[float, Color]
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.get_color_table": """
        Return to color table

        :return: color table
        :rtype: Colors
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.get_contrast": """
        Return the contrast of the Grid layer, the value range is -100 to 100, increasing the contrast is positive, reducing the contrast is negative.

        :return: The contrast of the Grid layer.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.get_image_interpolation_mode": """
        Return the interpolation algorithm used when displaying the image.

        :return: the interpolation algorithm used when displaying the image
        :rtype: ImageInterpolationMode
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.get_opaque_rate": """
        Return the opacity of the Grid layer display. The opacity is a number between 0-100. 0 means no display; 100 means completely opaque. It is only valid for raster layers, and it is also valid when the map is rotated.

        :return: Grid layer display opacity.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.get_special_value": """
        Return the special value of the layer. When adding a Grid layer, the return value of this method is equal to the NoValue property value of the dataset.

        :return:
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.get_special_value_color": """
        Return the color of the special value data of the raster dataset.

        :return: The color of the special value data of the raster dataset.
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.is_special_value_transparent": """
        Return whether the area of the layer's special value (SpecialValue) is transparent.

        :return: A boolean value, the area where the layer's special value (SpecialValue) is transparent Return true, otherwise it Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.set_brightness": """
        Set the brightness of the Grid layer, the value range is -100 to 100, increase the brightness to positive, and reduce the brightness to negative.

        :param int value:
        :return: self
        :rtype: LayerSettingGrid
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.set_color_dictionary": """
        Set the color comparison table of the layer

        :param colors: The color comparison table of the specified layer.
        :type colors: dict[float, Color]
        :return: self
        :rtype: LayerSettingGrid
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.set_color_table": """
        Set the color table.

        :param Colors value: color table
        :return: self
        :rtype: LayerSettingGrid
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.set_contrast": """
        Set the contrast of the Grid layer, the value range is -100 to 100, increase the contrast to be positive, and reduce the contrast to be negative.

        :param int value: The contrast of the Grid layer.
        :return: self
        :rtype: LayerSettingGrid
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.set_image_interpolation_mode": """
        Set the interpolation algorithm used when displaying the image.

        :param value: The specified interpolation algorithm.
        :type value: ImageInterpolationMode or str
        :return: self
        :rtype: LayerSettingGrid
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.set_opaque_rate": """
        Set the opacity of the Grid layer display. The opacity is a number between 0-100. 0 means no display; 100 means completely opaque. It is only valid for raster layers, and it is also valid when the map is rotated.

        :param int value: Grid layer display opacity.
        :return: self
        :rtype: LayerSettingGrid
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.set_special_value": """
        Set the special value of the layer.

        :param float value: the special value of the layer
        :return: self
        :rtype: LayerSettingGrid
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.set_special_value_color": """
        Set the color of the special value data of the raster dataset.

        :param value: The color of the special value data of the raster dataset.
        :type value: Color or tuple[int,int,int] or tuple[int,int,int,int]
        :return: self
        :rtype: LayerSettingGrid
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingGrid.set_special_value_transparent": """
        Set whether the area of the layer's special value (SpecialValue) is transparent.

        :param bool value: Whether the area where the special value of the layer is located is transparent.
        :return: self
        :rtype: LayerSettingGrid
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage": """
    Image layer setting class.
    """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_background_color": """
        Get the display color of the background value

        :return: the display color of the background value
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_background_value": """
        Get the value in the image that is regarded as the background

        :return: the value considered as background in the image
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_brightness": """
        Return the brightness of the image layer. The value range is -100 to 100, increasing the brightness is positive, and decreasing the brightness is negative. The brightness value can be saved to the workspace.

        :return: The brightness value of the image layer.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_contrast": """
        Return the contrast of the image layer. The value range is -100 to 100, increasing the contrast is positive, and decreasing the contrast is negative.

        :return: The contrast of the image layer.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_display_band_indexes": """
        Return the band index displayed by the current image layer. Assuming that the current image layer has several bands, when you need to set the display band according to the set color mode (such as RGB), specify the band index (such as 0, 2, 1 ) corresponding to the color (such as red, green, and blue in RGB) ).

        :return: The band index of the current image layer.
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_display_color_space": """
        Return the color display mode of the image layer. It will display the image layer in this color mode according to the current color format and displayed band of the image layer.

        :return: The color display mode of the image layer.
        :rtype: ColorSpaceType
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_display_mode": """
        Return to the image display mode.

        :return: Video display mode.
        :rtype: ImageDisplayMode
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_image_interpolation_mode": """
        Set the interpolation algorithm used when displaying the image.

        :return: the interpolation algorithm used when displaying the image
        :rtype: ImageInterpolationMode
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_opaque_rate": """
        Return the opacity of the image layer display. The opacity is a number between 0-100. 0 means no display; 100 means completely opaque. It is only valid for image layers, and it is also valid when the map is rotated.

        :return: The opacity of the image layer display.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_special_value": """
        Get the special value in the image. The special value can be specified by :py:meth:`set_special_value_color` to specify the display color.

        :return: special value in the image
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_special_value_color": """
        Get the display color of a special value

        :return: display color of special value
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_transparent_color": """
        Return the background transparent color

        :return: background transparent color
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.get_transparent_color_tolerance": """
        Return the background transparent color tolerance, the tolerance range is [0,255].

        :return: background transparent color tolerance
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.is_transparent": """
        Set whether to make the background of the image layer transparent

        :return: A boolean value specifies whether to make the background of the image layer transparent.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_background_color": """
        Set the display color of the specified background value.

        :param value: the display color of the specified background value
        :type value: Color or tuple[int,int,int] or tuple[int,int,int,int]
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_background_value": """
        Set the value of the image to be regarded as the background

        :param float value: The value in the image that is regarded as the background
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_brightness": """
        Set the brightness of the image layer. The value range is -100 to 100, increasing the brightness is positive, and decreasing the brightness is negative.

        :param int value: The brightness value of the image layer.
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_contrast": """
        Set the contrast of the image layer. The value range is -100 to 100, increasing the contrast is positive, and decreasing the contrast is negative.

        :param int value: The contrast of the image layer.
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_display_band_indexes": """
        Set the band index of the current image layer display. Assuming that the current image layer has several bands, when you need to set the display band according to the set color mode (such as RGB), specify the band index (such as 0, 2, 1) corresponding to the color (such as red, green, and blue in RGB) ).

        :param indexes: The band index of the current image layer display.
        :type indexes: list[int] or tuple[int]
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_display_color_space": """
        Set the color display mode of the image layer. It will display the image layer in this color mode according to the current color format and displayed band of the image layer.

        :param value: The color display mode of the image layer.
        :type value: ColorSpaceType
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_display_mode": """
        Set the image display mode.

        :param value: Image display mode, multi-band supports two display modes, single-band only supports stretch display mode.
        :type value: ImageDisplayMode
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_image_interpolation_mode": """
        Set the interpolation algorithm used when displaying the image

        :param value: the specified interpolation algorithm
        :type value: ImageInterpolationMode or str
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_opaque_rate": """
        Set the opacity of the image layer display. The opacity is a number between 0-100. 0 means no display; 100 means completely opaque. Only valid for image layers, also valid when the map is rotated

        :param int value: The opacity of the image layer display
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_special_value": """
        Set the special value in the image. The special value can be specified by :py:meth:`set_special_value_color` to specify the display color.

        :param float value: special value in the image
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_special_value_color": """
        Setting: the display color of the special value set by py:meth:`set_special_value`

        :param color: display color of special value
        :type color: Color or tuple[int,int,int] or tuple[int,int,int,int]
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_transparent": """
        Set whether to make the background of the image layer transparent

        :param bool value: A boolean value specifies whether to make the background of the image layer transparent
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_transparent_color": """
        Set the background transparent color.

        :param color: background transparent color
        :type color: Color or tuple[int,int,int] or tuple[int,int,int,int]
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingImage.set_transparent_color_tolerance": """
        Set the background transparent color tolerance, the tolerance range is [0,255].

        :param int value: background transparent color tolerance
        :return: self
        :rtype: LayerSettingImage
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingVector": """
    Vector layer setting class.

    This class is mainly used to set the display style of the vector layer. The vector layer draws all elements with a single symbol or style. When you just want to visually display your spatial data, and you only care about where the elements are
    In the spatial data, and you don't care about how the elements are different in quantity or nature, you can use ordinary layer to display element data.
    """,

    "iobjectspy._jsuperpy.mapping.LayerSettingVector.get_style": """
        Return the style of the vector layer.

        :return: The style of the vector layer.
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.LayerSettingVector.set_style": """
        Set the style of the vector layer.

        :param style: The style of the vector layer.
        :type style: GeoStyle
        :return: self
        :rtype: LayerSettingVector
        """,

    "iobjectspy._jsuperpy.mapping.Map": """
    The map category is responsible for the management of the map display environment.

    A map is a visualization of geographic data, usually composed of one or more layers. The map must be associated with a workspace in order to display the data in the workspace. In addition, the Settings
    For how the map is displayed will affect all layers within it. This class provides the return and setting of various map display modes, such as map display range, scale, coordinate system and default display mode of text and dot layers, etc.,
    And provide methods for related operations on the map, such as opening and closing the map, zooming, full-frame display, and map output.
    """,

    "iobjectspy._jsuperpy.mapping.Map.add_aggregation": """
        Make a grid aggregation map with default style according to the given point dataset.

        :param dataset: Participate in the production of grid aggregation data. The data must be a point vector dataset.
        :type dataset: DatasetVector
        :param min_color: The color corresponding to the minimum value of the grid cell statistics. The grid aggregation map will determine the color scheme of the gradient through maxColor and minColor, and then sort the grid cells based on the size of the grid cell statistics.
        :type min_color: Color or tuple[int,int,int]
        :param max_color: The color corresponding to the maximum value of the grid cell statistics. The grid aggregation map will determine the color scheme of the gradient through maxColor and minColor, and then sort the grid cells based on the size of the grid cell statistics to render the grid cells.
        :type max_color: Color or tuple[int,int,int]
        :return: Grid aggregate map layer object.
        :rtype: LayerGridAggregation
        """,

    "iobjectspy._jsuperpy.mapping.Map.add_dataset": """
        Add dataset to the map

        :param dataset: the dataset object to be added
        :type dataset: Dataset or DatasetVector or DatasetImage or DatasetGrid
        :param bool is_add_to_head: Whether to add to the top of the map
        :param layer_setting: map layer setting object or thematic map layer object
        :type layer_setting: LayerSetting or Theme
        :return: return the layer object if added successfully, otherwise it Return None
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Map.add_heatmap": """
        Make a heat map according to the given point dataset and parameter settings, that is, display the given point data in a heat map rendering mode.
        Heat map is a map representation method that describes population distribution, density, and change trends through color distribution. Therefore, it can very intuitively present some data that is not easy to understand or express, such as density, frequency, temperature, etc.
        The heat map layer can not only reflect the relative density of point features, but also express the point density weighted according to attributes, so as to consider the contribution of the weight of the point itself to the density.

        :param dataset: The data involved in making the heat map. The data must be a point vector dataset.
        :type dataset: DatasetVector
        :param int kernel_radius: The search radius used to calculate the density.
        :param max_color: Color with low dot density. The heat map layer will determine the color scheme of the gradient by the high dot density color (maxColor) and the low dot density color (minColor).
        :type max_color: Color or tuple[int,int,int]
        :param min_color: Color with high dot density. The heat map layer will determine the color scheme of the gradient by the high dot density color (maxColor) and the low dot density color (minColor).
        :type min_color: Color or tuple[int,int,int]
        :return: Heat map layer object
        :rtype: LayerHeatmap
        """,

    "iobjectspy._jsuperpy.mapping.Map.add_to_tracking_layer": """
        Add geometric objects to the tracking layer

        :param geos: geometric objects to be added
        :type geos: list[Geometry] or list[Feature] or list[Point2D] or list[Rectangle]
        :param GeoStyle style: the object style of the geometric object
        :param bool is_antialias: whether antialiasing
        :param bool is_symbol_scalable: Whether the symbol size of the tracking layer is scaled with the image
        :param float symbol_scale: The symbol scaling reference scale of this tracking layer
        :return: the tracking layer object of the current map object
        :rtype: TrackingLayer
        """,

    "iobjectspy._jsuperpy.mapping.Map.clear_layers": """
        Delete all layers in this layer collection object.

        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.close": """
        Close the current map.
        """,

    "iobjectspy._jsuperpy.mapping.Map.find_layer": """
        Return the layer object of the specified layer name.

        :param str layer_name: The specified layer name.
        :return: Return the layer object of the specified layer name.
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Map.from_xml": """
        Create a map object based on the specified XML string.
        Any map can be exported as an xml string, and the xml string of a map can also be imported as a map for display. The XML string of the map stores information about the display settings of the map
        And its layers, the associated data, and so on.

        :param str xml: The xml string used to create the map.
        :param workspace_version: The version of the workspace corresponding to the xml content. When using this parameter, please make sure that the specified version matches the xml content. If they do not match, the style of some layers may be lost.
        :type workspace_version: WorkspaceVersion or str
        :return: If the map object is created successfully, return true, otherwise return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_angle": """
        Return the rotation angle of the current map. The unit is degree, and the accuracy is 0.1 degree. The counterclockwise direction is positive. If the user enters a negative value, the map will rotate in a clockwise direction.

        :return: The rotation angle of the current map.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_bounds": """
        Return the spatial extent of the current map. The spatial range of the map is the smallest bounding rectangle of the range of each dataset displayed, that is, the smallest rectangle that contains the range of each dataset. When the dataset displayed on the map is added or deleted, its spatial extent will change accordingly.

        :return: The spatial extent of the current map.
        :rtype: Rectangle
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_center": """
        Return the center point of the display range of the current map.

        :return: The center point of the display range of the map.
        :rtype: Point2D
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_clip_region": """
        Return the cropped area on the map.
        The user can arbitrarily set a map display area, and the map content outside the area will not be displayed.

        :return: The map shows the cropped area.
        :rtype: GeoRegion
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_color_mode": """
        Return the color mode of the current map. The color modes of the map include color mode, black-and-white mode, gray-scale mode, and black-and-white reverse color mode. For details, please refer to the :py:class:`MapColorMode` class.

        :return: the color mode of the map
        :rtype: MapColorMode
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_description": """
        Return the description information of the current map.

        :return: The description of the current map.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_dpi": """
        Return the DPI of the map, representing how many pixels per inch

        :return: DPI of the map
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_dynamic_prj_trans_method": """
        Return the geographic coordinate system conversion algorithm used when the map is dynamically projected. The default value is: py:attr:`CoordSysTransMethod.MTH_GEOCENTRIC_TRANSLATION`

        :return: The projection algorithm used when the map is dynamically projected
        :rtype: CoordSysTransMethod
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_dynamic_prj_trans_parameter": """
        When setting the map dynamic projection, when the source projection and the target target projection are based on different geographic coordinate systems, you can use this method to set the conversion parameters.

        :return: The conversion parameters of the dynamic projection coordinate system.
        :rtype: CoordSysTransParameter
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_image_size": """
        Return the size of the picture when it is output, in pixels

        :return: return the width and height of the picture when the picture is output
        :rtype: tuple[int,int]
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_layer": """
        Return the layer object with the specified name in this layer collection.

        :param index_or_name: the name or index of the layer
        :type index_or_name: str or int
        :return: The layer object with the specified name in this layer collection.
        :rtype: Layer
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_layers": """
        Return all the layers contained in the current map.

        :return: All layer objects contained in the current map.
        :rtype: list[Layer]
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_layers_count": """
        Return the total number of layer objects in this layer collection.

        :return: the total number of layer objects in this layer collection
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_max_scale": """
        Return the maximum scale of the map.

        :return: The maximum scale of the map.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_min_scale": """
        Return the minimum scale of the map

        :return: The minimum scale of the map.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_name": """
        Return the name of the current map.

        :return: The name of the current map.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_prj": """
        Return the projected coordinate system of the map

        :return: The projected coordinate system of the map.
        :rtype: PrjCoordSys
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_scale": """
        Return the display scale of the current map.

        :return: The display scale of the current map.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.Map.get_view_bounds": """
        Return the visible range of the current map, also known as the display range. The visible range of the current map can be set by the :py:meth:`set_view_bounds` method, the visible range of the current map can also be set by setting the center point of the display range
        (:py:meth:`set_center`) and the display scale (:py:meth:`set_scale`).

        :return: The visible range of the current map.
        :rtype: Rectangle
        """,

    "iobjectspy._jsuperpy.mapping.Map.index_of_layer": """
        Return the index of the layer with the specified name in this layer collection.

        :param str layer_name: The name of the layer to be searched.
        :return: Return the layer index when the specified layer is found, otherwise -1.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.Map.is_clip_region_enabled": """
        Return whether the clipped area displayed on the map is valid, true means valid.

        :return: whether the map display clipping area is valid
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.is_contain_layer": """
        Determine whether this layer collection object contains the layer with the specified name.

        :param str layer_name: The name of the layer object that may be included in this layer set.
        :return: If this layer contains a layer with the specified name, it Return true, otherwise it Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.is_dynamic_projection": """
        Return whether the dynamic projection display of the map is allowed. The dynamic projection display of the map means that if the projection information of the map in the current map window is different from the projection information of the datasource, by using dynamic map projection display
        Can convert the current map projection information to the projection information of datasource.

        :return: Whether to allow dynamic projection display of the map.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.is_fill_marker_angle_fixed": """
        Return whether to fix the fill angle of the fill symbol.

        :return: Whether to fix the fill angle of the fill symbol.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.is_line_antialias": """
        Return whether the map line type is displayed in anti-aliasing.

        :return: Whether the map line type is displayed in anti-aliasing.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.is_map_thread_drawing_enabled": """
        Return whether to start the thread to draw the map element. True means to start the thread to draw the map element, which can improve the drawing performance of large data maps.

        :return: Indicates whether to start another thread to draw map elements, true means start another thread to draw map elements, which can improve the drawing performance of large data maps.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.is_marker_angle_fixed": """
        Return a Boolean value specifying whether the angle of the point symbol is fixed. For all point layers in the map.

        :return: Used to specify whether the angle of the point symbol is fixed.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.is_overlap_displayed": """
        Return whether to display objects when overlapping.

        :return: Whether to display objects when overlapping.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.is_use_system_dpi": """
        Whether to use system DPI

        :return: whether to use system DPI
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.move_layer_to": """
        Move the layer with the specified index in this layer collection to the specified target index.

        :param int src_index: the original index of the layer to be moved
        :param int tag_index: The target index to move the layer to.
        :return: Return true if the move is successful, otherwise false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.open": """
        Open the map with the specified name. The specified name is the name of a map in the map collection object in the workspace associated with the map, and it should be distinguished from the display name of the map.

        :param str name: The name of the map.
        :return:
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.output_to_file": """
        Among the files outputting the current map, BMP, PNG, JPG, GIF, PDF, TIFF files are supported. Do not save the tracking layer.

        :param str file_name: The path of the result file. The file extension must be included.
        :param image_size: Set the size of the image when outputting, in pixels. If not set, use the image_size of the current map, refer to: py:meth:`.get_image_size`
        :type image_size: tuple[int,int]
        :param Rectangle output_bounds: Map output bounds. If not set, the view range of the current map is used by default. For details, please refer to:py:meth:`.get_view_bounds`
        :param int dpi: DPI of the map, representing how many pixels per inch. If not set, the DPI of the current map will be used by default, please refer to:py:meth:`.get_dpi`
        :param bool is_back_transparent: Whether the background is transparent. This parameter is only valid when the type parameter is set to GIF and PNG.
        :param bool is_show_to_ipython: Whether to display in ipython. Note that it can only be displayed in the jupyter python environment, so ipython and
                                        jupyter environment. Only PNG, JPG and GIF are supported for display in jupyter.
        :return: Return True if the output is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.output_tracking_layer_to_png": """
        Output the tracking layer of the current map as a png file. Before calling this interface, the user can set the image size through set_image_size.

        :param str file_name: The path of the result file. The file extension must be included.
        :param Rectangle output_bounds: Map output bounds. If not set, the view range of the current map is used by default. For details, please refer to:py:meth:`.get_view_bounds`
        :param int dpi: DPI of the map, representing how many pixels per inch. If not set, the DPI of the current map will be used by default, please refer to:py:meth:`.get_dpi`
        :param bool is_back_transparent: Whether the background is transparent.
        :param bool is_show_to_ipython: Whether to display in ipython. Note that it can only be displayed in the jupyter python environment, so ipython and
                                        jupyter environment.
        :return: Return True if the output is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.refresh": """
        Redraw the current map.

        :param bool refresh_all: When refresh_all is TRUE, when the map is refreshed, the snapshot layer is refreshed at the same time. Snapshot layer, a special layer group,
                                 The layer contained in this layer group is used as a snapshot layer of the map. It adopts a special drawing method. The snapshot layer is drawn only when it is displayed for the first time.
                                 After that, if the map display range does not change, the snapshot layer will use this display, that is, the snapshot layer will not be redrawn with the map refresh;
                                 If the map display range changes, it will automatically trigger the refresh drawing of the snapshot layer. The snapshot layer is one of the means to improve the display performance of the map.
                                 If the display range of the map does not change, the snapshot layer will not be refreshed when the map is refreshed; if you need to force a refresh, you can use refresh_all
                                 To refresh the map and refresh the snapshot layer at the same time.

        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.refresh_tracking_layer": """
        Used to refresh the tracking layer in the map window.

        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.remove_layer": """
        Delete a layer with the specified name from this layer collection. Return true if the deletion is successful.

        :param index_or_name: The name or index of the layer to be deleted
        :type index_or_name: str or int
        :return: Return true if the deletion is successful, otherwise Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_angle": """
        Set the rotation angle of the current map. The unit is degree, and the accuracy is 0.1 degree. The counterclockwise direction is positive, if the user enters a negative value, the map will rotate clockwise

        :param float value: Specify the rotation angle of the current map.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_center": """
        Set the center point of the display range of the current map.

        :param Point2D center: The center point of the display range of the current map.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_clip_region": """
        Set the cropped area of the map display.
        The user can arbitrarily set a map display area, and the map content outside the area will not be displayed.

        :param region: The region where the map is cropped.
        :type region: GeoRegion or Rectangle
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_clip_region_enabled": """
        Set whether the map display clipping area is valid, true means valid.

        :param bool value: Display whether the cropping area is valid.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_color_mode": """
        Set the color mode of the current map

        :param value: Specify the color mode of the current map.
        :type value: str or MapColorMode
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_description": """
        Set the description information of the current map.

        :param str value: Specify the description information of the current map.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_dpi": """
        Set the DPI of the map, which represents how many pixels per inch, and the value range is (60, 180).

        :param float dpi: DPI of the picture
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_dynamic_prj_trans_method": """
        When setting the map dynamic projection, when the source projection and the target projection are based on different geographic coordinate systems, you need to set the conversion algorithm.

        :param value: Geographical coordinate system conversion algorithm
        :type value: CoordSysTransMethod or str
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_dynamic_prj_trans_parameter": """
        Set the conversion parameters of the dynamic projection coordinate system.

        :param CoordSysTransParameter parameter: The transformation parameter of the dynamic projection coordinate system.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_dynamic_projection": """
        Set whether to allow dynamic projection display of the map. The dynamic projection display of the map means that if the projection information of the map in the current map window is different from the projection information of the datasource, the projection information of the current map can be converted into the projection information of the datasource
        By using the map dynamic projection display.

        :param bool value: Whether to allow dynamic projection display of the map.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_fill_marker_angle_fixed": """
        Set whether to fix the fill angle of the fill symbol.

        :param bool value: Whether to fix the filling angle of the filling symbol.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_image_size": """
        Set the size of the picture when outputting, in pixels.

        :param int width: the width of the picture when outputting
        :param int height: the height of the picture when the picture is output
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_line_antialias": """
        Set whether the map line type is displayed in anti-aliasing.

        :param bool value: Whether the map line type is displayed in anti-aliasing.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_map_thread_drawing_enabled": """
        Set whether to start another thread to draw map elements, true means start another thread to draw map elements, which can improve the drawing performance of large data maps.

        :param bool value: A boolean value indicating whether to start a thread to draw map elements, true means to start a thread to draw map elements, which can improve the drawing performance of large data maps.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_mark_angle_fixed": """
        Set a Boolean value to specify whether the angle of the point symbol is fixed. For all point layers in the map.

        :param bool value: Specify whether the angle of the point symbol is fixed
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_max_scale": """
        Set the maximum scale of the map

        :param float scale: The maximum scale of the map.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_min_scale": """
        Set the minimum scale of the map.

        :param float scale: The minimum scale of the map.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_name": """
        Set the name of the current map.

        :param str name: The name of the current map.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_overlap_displayed": """
        Set whether to display objects when overlapping.

        :param bool value: Whether to display the object when overlapping
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_prj": """
        Set the projection coordinate system of the map

        :param prj: The projected coordinate system of the map.
        :type prj: PrjCoordSys
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_scale": """
        Set the display scale of the current map.

        :param float scale: Specify the display scale of the current map.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_use_system_dpi": """
        Set whether to use system DPI

        :param bool value: Whether to use system DPI. True means to use the DPI of the system, False means to use the map settings.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.set_view_bounds": """
        Set the visible range of the current map, also known as the display range. The visible range of the current map can be set by the :py:meth:`set_view_bounds` method, and can also be set by
        setting the center point of the display range (:py:meth:`set_center`) and display scale (:py:meth:`set_scale`).

        :param Rectangle bounds: Specify the visible range of the current map.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.show_to_ipython": """
        Display the current map in ipython. Note that it can only be displayed in the jupyter python environment, so ipython and jupyter environment are required

        :return: Return True if successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Map.to_xml": """
        Return the description of this map object in the form of an XML string.
        Any map can be exported as an xml string, and the xml string of a map can also be imported as a map for display. The xml string of the map stores information about the display 
        Settings of the map and its layers, the associated data, and so on. In addition, you can save the xml string of the map as an xml file.

        :return: description of the map in XML format
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.Map.tracking_layer": """TrackingLayer: Return the tracking layer object of the current map""",

    "iobjectspy._jsuperpy.mapping.Map.view_entire": """
        Show this map in full.

        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.Map.zoom": """
        Enlarge or reduce the map by the specified scale. The scale of the map after zooming=original scale*ratio, where the ratio must be a positive number. When the ratio is greater than 1, the map is enlarged;
        When the ratio is less than 1, the map is reduced.

        :param float ratio: zoom map ratio, this value cannot be negative.
        :return: self
        :rtype: Map
        """,

    "iobjectspy._jsuperpy.mapping.MixedTextStyle": """
    The text compound style class.

    This class is mainly used to style the text content of the label in the label map. Through this type of user, the label text can be displayed in different styles, such as the text "Himalayas". Through this type, the first three characters can be displayed in red, and the last two characters can be displayed in blue.

    Setting different styles for the same text is essentially segmenting the characters of the text, and the characters in the same segment have the same display style. There are two ways to segment characters, one is to segment the text with a separator; the other is to segment the text according to the segment index value.

     * Use separators to segment the text. For example, use "&" as a separator to divide the text "5&109" into two parts: "5" and "109". When displaying, use "5" and the separator "&" The same style, the string "109" uses the same style.

     * Using segment index value to segment the character index value of the text is an integer starting with 0, such as the text "Mount Everest", the index value of the first character ("bead") is 0, the second character (" Mu") has an index value of 1,
       And so on; when the segment index value is set to 1, 3, 4, 9, the corresponding character segment range is (-âˆž, 1), [1, 3), [3, 4), [4, 9 ), [9, +âˆž), you can see the character whose index number is 0 (ie "bead")
       In the first segment, the characters with index numbers 1, 2 (ie "Mu" and "lang") are in the second segment, and the characters with index number 3 ("çŽ›") are in the third segment. In the segment, the character with index number 4 ("peak") is in the fourth segment, and there are no characters in the remaining segments.

    """,

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.__init__": """
        :param TextStyle default_style: default style
        :param styles: A collection of text styles. The styles in the text style collection are used for characters in different segments
        :type styles: list[TextStyle] or tuple[TextStyle]
        :param str separator: The separator of the text, the style of the separator adopts the default style, and the separator can only be set to one character
        :param split_indexes: segment index value, segment index value is used to segment characters in the text
        :type split_indexes: list[int] or tuple[int]
        """,

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.default_style": """TextStyle: default style""",

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.get_separator": """
        Get text separator

        :return: The separator of the text.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.get_split_indexes": """
        Return the segment index value, which is used to segment characters in the text

        :return: return the segment index value
        :rtype: list[int]
        """,

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.is_separator_enabled": """bool: Is the text separator valid""",

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.set_default_style": """
        Set the default style

        :param TextStyle value: default style
        :return: self
        :rtype: MixedTextStyle
        """,

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.set_separator": """
        Set the text separator. The separator style adopts the default style, and the separator can only be set with one character.

        The text separator is a symbol that separates the text. For example, using "_" as a separator, it divides the text "5_109" into two parts, "5" and "109", assuming there are style arrays: style1, style2 and default text style
        'DefaultStyle'. When displayed, "5" is displayed using Style1, the separator "_" uses the default style (DefaultStyle), and the characters "1", "0", and "9" use the Style2 style.

        :param str value: Specify the separator of the text
        :return: self
        :rtype: MixedTextStyle
        """,

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.set_separator_enabled": """
        Set whether the separator of the text is valid.
        When the separator is valid, the text is segmented by the separator; when it is invalid, the text is segmented according to the position of the characters in the text. After segmentation, the characters in the same segment have the same display style.

        :param bool value: Whether the separator of the text is valid
        :return: self
        :rtype: MixedTextStyle
        """,

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.set_split_indexes": """
        Set the segment index value. The segment index value is used to segment the characters in the text.

        The index value of the characters in the text is an integer starting from 0, for example, in the text "Mount Everest", the index value of the first character ("bead") is 0, and the index value of the second character ("Mu") is 1. And so on; when set
        Segment index value is 1, 3, 4, 9, the corresponding character segment range is (-âˆž, 1), [1, 3), [3, 4), [4, 9), [9, + âˆž), it can be seen that the character with index number 0 ( "ç ") is in the first
        Segment, the characters with index numbers 1 and 2 (ie "ç©†" and "æœ—") are in the second segment, and the characters with index number 3 ("çŽ›") are in the third segment. The character number 4 ("å³°") is in the fourth segment,
        There are no characters in the remaining sections.

        :param value: Specify the segment index value
        :type value: list[int] or tuple[int]
        :return: self
        :rtype: MixedTextStyle
        """,

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.set_styles": """
        Set the text style collection. The styles in the text style collection are used for characters in different segments.

        :param value: text style collection
        :type value: list[TextStyle] or tuple[TextStyle]
        :return: self
        :rtype: MixedTextStyle
        """,

    "iobjectspy._jsuperpy.mapping.MixedTextStyle.styles": """list[TextStyle]: Collection of text styles """,

    "iobjectspy._jsuperpy.mapping.OverLengthLabelMode": """
    This class defines the constants of the processing mode of the over-long label in the label map.

    The label whose length exceeds the maximum length of the set label is called an overlength label. The maximum length of the label can be returned and set by the :py:meth:`.ThemeLabel.set_overlength_label` method
    SuperMap component products provide three processing methods for super long labels to control the display behavior of super long labels.


    :var OverLengthLabelMode.NONE: Do not process over-length labels.
    :var OverLengthLabelMode.OMIT: Omit the excess part. In this mode, the part of the super long label that exceeds the specified maximum label length (MaxLabelLength) is indicated by an ellipsis.
    :var OverLengthLabelMode.NEWLINE: New line display. This mode displays the part of the super long label that exceeds the maximum length of the specified label in a new line, that is, the super long label is displayed in multiple lines.
    """,

    "iobjectspy._jsuperpy.mapping.RangeMode": """

    This class defines the type constants of the range mode of the range map.

    In the range map, the value of the field or expression as thematic variable is divided into multiple range segments according to a certain segmentation method, and the element or record is assigned to one of the segments according to the corresponding field value or expression value. In the paragraph,
    Elements or records in the same range are displayed in the same style. Segmented thematic maps are generally used to show the number or degree characteristics of continuous distribution phenomena, such as the distribution of precipitation, the distribution of soil erosion intensity, etc.
    This reflects the differences in the concentration or development level of the phenomenon in each region.

    SuperMap component products provide a variety of classification methods, including equidistant segmentation method, square root segmentation method, standard difference segment method, logarithmic segmentation method, equal count segmentation method, and custom distance method. Obviously these segmentation methods
    are segmented according to according to a certain distance, so the thematic variable based on the range map must be numeric.

    :var RangeMode.EUQALINTERVAL: Equidistant segmentation. Equidistant segmentation is based on the maximum and minimum values of the fields or expressions as thematic variables, and according to the number of segments set by the user for equal spacing segment.
                                  In equidistant segments, each segment has the same length. The formula for calculating the distance interval of equidistant segments is:

                                  .. image:: ../image/EqualInterval_d_s.png

                                  Among them, d is the distance interval of the segment, Vmax is the maximum value of the thematic variable, Vmin is the minimum value of the thematic variable, and count is the number of segments specified by the user. Then the calculation formula for the segment point of each segment is:

                                  .. image:: ../image/EqualInterval_v_s.png

                                  Among them, Vi is the value of the segment point, and i is a positive integer from 0 to count-1, representing each segment. When i is equal to 0, Vi is Vmin; when i is equal to count-1, Vi is Vmax.

                                  For example, if you choose a field as thematic variable, its value is from 1 to 10, and you need to divide it into 4 segments using the equidistant segmentation method, which are 1-2.5, 2.5-5, 5-7.5 and 7.5-10 respectively. . note,
                                  "" and "" are used in the segment, so the value of the segment point is assigned to the next segment.

                                  Note: According to this segmentation method, it is very likely that there is no value in a segment, that is, there are 0 records or elements that fall into the segment.

    :var RangeMode.SQUAREROOT: Square root segmentation. The square root segmentation method is essentially the equidistant segmentation of the square root of the original data. First, it takes the square root of all data for equal-distance segmentation to obtain the segmented points of processed data,
                               And then square the values of these segmented points as the segmented points of the original data, so as to obtain the segmentation scheme of the original data. Therefore, according to
                               This segmenting mode, it is also very likely that there is no value in a segment, that is, there are 0 records or elements falling into that segment. This method is suitable for some specific data. For example, when there is a large difference between the minimum value and the maximum value,
                               The equidistance segmentation method may need to be divided into many segments to distinguish, the square root segmentation method can compress the difference between the data, and the segmentation can be performed more accurately
                               With less number of segments. The calculation formula of sectional interval distance of the square root of thematic variable is as follows:

                               .. image:: ../image/SquareRoot_d_s.png

                               Among them, d is the distance interval of the segment, Vmax is the maximum value of the thematic variable, Vmin is the minimum value of the thematic variable, and count is the number of segments specified by the user. Then the calculation formula for the segment points of thematic variables is:

                               .. image:: ../image/SquareRoot_v_s.png

                               Among them, Vi is the value of the segment point, i is a positive integer from 0 to count-1, representing each segment, when i is equal to 0, Vi is Vmin.
                               Note: If there are negative numbers in the data, this method is not suitable.

    :var RangeMode.STDDEVIATION: Standard differential segment. The standard difference segment method reflects the deviation of a certain attribute value of each element from its average value. The method first calculates the average and standard deviation of thematic variables,
                                 Perform segmentation on this basis. The length of each segment of the standard difference segment is a standard deviation, the middle segment is centered on the average, , the left segment point and the right segment point
                                 Differ by 0.5 standard deviations from the mean value respectively.Suppose the average value of thematic variable values is mean and the standard deviation is std, then the segmentation effect is shown in the figure:

                                 .. image:: ../image/rangemode_little.png

                                 For example, if the thematic variable is a value between 1-100, and the average value of the thematic variable is 50 and the standard deviation is 20, then the segments are 40-60, 20-40, 60-80, 0-20, 80-100 A total of 5 paragraphs.
                                 The elements that fall within the range of different segments are set to different display styles.

                                 Note: The number of segments of the standard deviation is determined by the calculation result and cannot be controlled by the user.

    :var RangeMode.LOGARITHM: Logarithmic range. Logarithmic segmentation method principle and the square root of the implementation of the segmentation method is basically the same, the difference is the square root method is to take the square root of the original data, the exponential and
                              Logarithmic segmentation method is for the original data, namely to 10 at the bottom of the original data of numerical equidistance section, the first of all, the log of all the values of the original data of equidistance segmentation,
                              Segmentation points after processing data, and then to 10 at the bottom, the subsection point value as the index of the power to get the original data of each section point, and segmentation scheme is obtained.
                              It is applicable to the situation where the difference between the maximum value and the minimum value is great and the equidistant segmentation is not ideal. The logarithmic segmentation method has higher compression ratio than the square root segmentation method, which makes the difference scale between the data
                              Smaller and optimizes the segmentation results.The formula for calculating the distance interval of the equidistant segment of the logarithm of the thematic variable is:

                              .. image:: ../image/Logarithm_d_s.png

                              Among them, d is the distance interval of the segment, Vmax is the maximum value of the thematic variable , Vmin is the minimum value of the thematic variable, and count is the number of segments specified by the user. Therefore, the formula for calculating the segment points of thematic variables is:

                              .. image:: ../image/Logarithm_v_s.png

                              Among them, Vi is the value of the segment point, and i is a positive integer from 0 to count-1, representing each segment. When i is equal to 0, Vi is Vmin; when i is equal to count-1, Vi is Vmax.
                              Note: If there are negative numbers in the data, this method is not suitable.

    :var RangeMode.QUANTILE: equal count segmentation. In the equal count segmentation, try to ensure that the number of objects in each section is as equal as possible. The equal number is determined by the number of segments specified by the user and
                             The actual number of elements. In the case of equal partition, the number of objects in each segment should be the same, but when the object data of each segment is equal, there will be one more object in the last
                             Segments of the segmented result. For example, if there are 9 objects, divided into 9 segments, each segment has one object; if divided into 8 segments, the first 7 segments are 1 object, and the 8th segment is 2 objects; if it is divided into 7 segments,
                             The first 5 paragraphs are 1 object, and the 6th and 7th paragraphs are 2 objects. This segmentation method is suitable for linearly distributed data. The formula for calculating the number of elements in each segment of the equal counting segment is:

                             .. image:: ../image/Quantile_n_s.png

                             Among them, n is the number of elements in each segment, N is the total number of elements to be segmented, and count is the number of segments specified by the user. When the calculation result of n is not an integer, the rounding method is used.

    :var RangeMode.CUSTOMINTERVAL: Custom segmentation. In custom segmentation, the length of each segment is specified by the user, that is, the interval distance is used for segmentation. The number of segments is calculated by SuperMap based on
                                   The specified interval distance and the maximum and minimum values of the topic variables. The calculation formula for each segment point is:

                                   .. image:: ../image/custominterval_s.png

                                   Among them, Vi is the value of each segment point, Vmin is the minimum value of the thematic variable, d is the distance specified by the user,count is the number of segments calculated, i is the positive integer from 0 to
                                   Count-1, denoted each segment, when i is equal to 0, Vi is Vmin; when i is equal to count-1, Vi is Vmax.
    :var RangeMode.NONE: Null Range Mode
    """,

    "iobjectspy._jsuperpy.mapping.Theme": """
    Thematic map class, which is the base class of all thematic maps. All thematic map classes, such as unique values thematic maps, label thematic maps, and range thematic maps, are inherited from this class.
    """,

    "iobjectspy._jsuperpy.mapping.Theme.from_xml": """
        Import thematic map information from XML string.
        In SuperMap, the style settings of various thematic maps can be exported into XML format strings. This XML format string records all the settings related to this thematic map, such as
        The XML format string for a label thematic map will record the thematic map type, visible scale, tag style Settings, whether it flows, whether it automatically avoids, etc. All the style Settings for the tag topic map
        And the fields or expressions used to make the tag topic map. This XML format string can be used to import and set thematic maps

        It should be noted that the information recorded in xml must correspond to the type of the current object. For example, if the label map information recorded in xml, the current object must be a ThemeLabel object.
        If you don't know the type of thematic map recorded in xml, you can use :py:meth:`.Theme.make_from_xml` to construct a new thematic map object from xml.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: Return True if the import is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.Theme.make_from_xml": """
        Import the thematic map information and construct a new thematic map object.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: thematic map object
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.Theme.to_xml": """
        Export thematic map information as XML string.

        :return: XML string of thematic map information
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.Theme.type": """ThemeType: Thematic map type""",

    "iobjectspy._jsuperpy.mapping.ThemeCustom": """
    Custom thematic map class, which can dynamically set the display style through field expressions.
    """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.from_xml": """
        Import thematic map information from XML string.
        In SuperMap, the style settings of various thematic maps can be exported into XML format strings. This XML format string records all the settings related to this thematic map, such as
        The XML format string for a label thematic map will record the thematic map type, visible scale, tag style Settings, whether it flows, whether it automatically avoids, etc. All the style Settings for the tag topic map
        And the fields or expressions used to make the tag topic map. This XML format string can be used to import and set thematic maps

        It should be noted that the information recorded in xml must correspond to the type of the current object. For example, if the label map information recorded in xml, the current object must be a ThemeLabel object.
        If you don't know the type of thematic map recorded in xml, you can use :py:meth:`.Theme.make_from_xml` to construct a new thematic map object from xml.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: Return True if the import is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_fill_back_color_expression": """
        Return the field expression representing the background color of the fill.

        :return: Represents the field expression to fill the background color.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_fill_fore_color_expression": """
        Return the field expression representing the fill color.

        :return: field expression representing the fill color
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_fill_gradient_angle_expression": """
        Return the field expression representing the filling angle

        :return: field expression representing the filling angle
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_fill_gradient_mode_expression": """
        Return the field expression representing the fill gradient type.

        :return: Represents the field expression of the fill gradient type.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_fill_gradient_offset_ratio_x_expression": """
        Return the field expression representing the offset of the filling center point in the X direction

        :return: A field expression representing the offset of the center point in the X direction
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_fill_gradient_offset_ratio_y_expression": """
        Return the field expression representing the offset of the center point of the filling in the Y direction

        :return: A field expression representing the offset of the center point in the Y direction
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_fill_opaque_rate_expression": """
        Return a field expression representing the opacity of the fill

        :return: Field expression representing the opacity of the fill
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_fill_symbol_id_expression": """
        Return the field expression representing the style of the fill symbol.

        :return: Represents the field expression of the fill symbol style.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_line_color_expression": """

        :return:
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_line_symbol_id_expression": """
        Get the field expression representing the color of the line symbol or point symbol

        :return: field expression representing the color of line symbol or dot symbol
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_line_width_expression": """
        Get the field expression representing the line width of the line symbol

        :return: field expression representing the line width of the line symbol
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_marker_angle_expression": """
        Return the field expression representing the rotation angle of the point symbol. The direction of rotation is counterclockwise and the unit is degree

        :return: field expression representing the rotation angle of the point symbol
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_marker_size_expression": """
        Return the field expression representing the size of the point symbol. Unit is mm

        :return: Field expression representing the size of the point symbol.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.get_marker_symbol_id_expression": """
        Return the field expression representing the dot notation style.

        :return: Represents a field expression in dot notation style.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.is_argb_color_mode": """
        Return whether the color in the color expression indicates whether the rule is RGB mode. The default value is False.

        When the return value is true, it means that the value of the color expression uses RRGGBB to express the color. (RRGGBB is a hexadecimal color converted to a decimal value, generally obtained by converting the hexadecimal value
        Under the desktop color panel to a decimal value.)

        When the attribute value is false, it means that the value of the color expression adopts BBGGRR to express the color. (BBGGRR is a hexadecimal color conversion to a decimal value, generally through the desktop color panel, firstly,
        Exchange the R and B values of the target color, and then convert the obtained hexadecimal value into a decimal value, which is the BBGGRR decimal value of the target color. )

        :return: The color in the color expression indicates whether the rule is RGB mode
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.make_from_xml": """
        Import the thematic map information and construct a new thematic map object.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: thematic map object
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_argb_color_mode": """
        Set whether the color expression rule in the color expression is RGB mode. The default value is False.

        When the return value is true, it means that the value of the color expression uses RRGGBB to express the color. (RRGGBB is a hexadecimal color converted to a decimal value, generally obtained by converting the hexadecimal value 
        Under the desktop color panel to a decimal value.)

        When the attribute value is false, it means that the value of the color expression adopts BBGGRR to express the color. (BBGGRR is a hexadecimal color conversion to a decimal value, generally through the desktop color panel, firstly,
        Exchange the R and B values of the target color, and then convert the obtained hexadecimal value into a decimal value, which is the BBGGRR decimal value of the target color. )

        :param bool value: Whether the color expression rule in the color expression is RGB mode
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_fill_back_color_expression": """
        Set the field expression that represents the fill background color

        :param str value: Represents the field expression to fill the background color.
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_fill_fore_color_expression": """
        Set the field expression that represents the fill color

        :param str value: field expression representing the fill color
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_fill_gradient_angle_expression": """
        Set the field expression representing the filling angle

        :param str value: field expression representing the filling angle
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_fill_gradient_mode_expression": """
        Set the field expression representing the fill gradient type.

        :param str value: Represents the field expression of the fill gradient type.
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_fill_gradient_offset_ratio_x_expression": """
        Set the field expression that represents the offset of the center point in the X direction

        :param str value: A field expression representing the offset of the center point in the X direction
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_fill_gradient_offset_ratio_y_expression": """
        Set the field expression that represents the offset of the center point of the filling in the Y direction

        :param str value: A field expression representing the offset of the filling center point in the Y direction
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_fill_opaque_rate_expression": """
        Set the field expression representing the opacity of the fill

        :param str value: field expression representing the opacity of the fill
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_fill_symbol_id_expression": """
        Set the field expression representing the style of the fill symbol.

        :param str value: Field expression that represents the filling symbol style.
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_line_color_expression": """
        Set the field expression representing the color of line symbol or dot symbol

        :param str value: field expression representing the color of line symbol or dot symbol
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_line_symbol_id_expression": """
        Set the field expression representing the style of the line symbol

        :param str value: field expression representing the style of line symbol
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_line_width_expression": """
        Set the field expression representing the line width of the line symbol.

        :param str value: field expression representing the line width of the line symbol
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_marker_angle_expression": """
        Set the field expression representing the rotation angle of the point symbol. The direction of rotation is counterclockwise and the unit is degree

        :param str value: The field expression representing the rotation angle of the point symbol.
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_marker_size_expression": """
        Set the field expression representing the size of the point symbol. The unit is mm.

        :param str value: Field expression representing the size of the point symbol. The unit is mm.
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.set_marker_symbol_id_expression": """
        Set the field expression representing the dot notation style.

        :param str value: Represents a field expression in dot notation style.
        :return: self
        :rtype: ThemeCustom
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.to_xml": """
        Export thematic map information as XML string.

        :return: XML string of thematic map information
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeCustom.type": """ThemeType: Thematic map type""",

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity": """
    Point density thematic map class.

    The dot density thematic map of SuperMap iObjects uses dots of a certain size and the same shape to represent the distribution range, quantitative characteristics and distribution density of the phenomenon. The number of points and the meaning they represent are determined by the content of the map.

    The following code demonstrates how to make a dot density thematic map::

    >>> ds = open_datasource('/home/data/data.udb')
    >>> dt = ds['world']
    >>> mmap = Map()
    >>> theme = ThemeDotDensity('Pop_1994', 10000000.0)
    >>> mmap.add_dataset(dt, True, theme)
    >>> mmap.set_image_size(2000, 2000)
    >>> mmap.view_entire()
    >>> mmap.output_to_file('/home/data/mapping/dotdensity_theme.png')
    """,

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.__init__": """
        :param str expression: The field or field expression used to create the dot density map.
        :param float value: The value represented by each point in the thematic map. The determination of the point value is related to the map scale and the size of the point. The larger the map scale, the larger the corresponding drawing area, and the more the corresponding points
                            The smaller the point value can be at this time. The larger the dot shape, the smaller the dot value should be set accordingly. Too big or too small a point value is inappropriate.
        :param GeoStyle style: the style of the points in the point density map
        """,

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.expression": """str: The field or field expression used to create the dot density thematic map.""",

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.from_xml": """
        Import thematic map information from XML string.
        In SuperMap, the style settings of various thematic maps can be exported into XML format strings. This XML format string records all the settings related to this thematic map, such as
        The XML format string for a tag topic map will record the topic map type, visible scale, tag style Settings, whether it flows, whether it automatically avoids, etc. All the style Settings for the tag topic map
        And the fields or expressions used to make the tag topic map. This XML format string can be used to import and set thematic maps

        It should be noted that the information recorded in xml must correspond to the type of the current object. For example, if the label map information recorded in xml, the current object must be a ThemeLabel object.
        If you don't know the type of thematic map recorded in xml, you can use :py:meth:`.Theme.make_from_xml` to construct a new thematic map object from xml.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: Return True if the import is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.make_from_xml": """
        Import the thematic map information and construct a new thematic map object.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: thematic map object
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.set_expression": """
        Set the field or field expression used to create the dot density thematic map.

        :param str expression: field or field expression used to create the dot density map
        :return: self
        :rtype: ThemeDotDensity
        """,

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.set_style": """
        Set the point style in the point density map.

        :param GeoStyle style: the style of the points in the point density map
        :return: self
        :rtype: ThemeDotDensity
        """,

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.set_value": """
        Set the value represented by each point in the thematic map.

        The determination of the point value is related to the map scale and the size of the point. The larger the map scale, the larger the corresponding drawing area, and the more points can correspond. At this time, the point value can be set relatively small. The larger the point shape,
        The point value should be set smaller accordingly. Too big or too small a point value is inappropriate.

        :param float value: The value represented by each point in the thematic map.
        :return: self
        :rtype: ThemeDotDensity
        """,

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.style": """GeoStyle: Point style in the thematic map of point density""",

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.to_xml": """
        Export thematic map information as XML string.

        :return: XML string of thematic map information
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.type": """ThemeType: Thematic map type""",

    "iobjectspy._jsuperpy.mapping.ThemeDotDensity.value": """float: the value represented by each point in the thematic map""",

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol": """
    The class of graduated symbols thematic map.

    SuperMap iObjects' hierarchical symbol thematic map uses symbols of different shapes, colors and sizes to represent the quantity and quality characteristics of each object that are independent and displayed as a whole concept.
    The shape, color, and size of the symbol are usually used to reflect the specific attributes of the object; the shape and color of the symbol indicate quality characteristics, and the size of the symbol indicates quantitative characteristics.

    For example, you can create graduated symbols thematic map objects in the following ways::

    >>> theme = ThemeGraduatedSymbol.make_default(dataset,'SmID')

    or::

    >>> theme = ThemeGraduatedSymbol()
    >>> theme.set_expression('SmID').set_graduated_mode(GraduatedMode.CONSTANT).set_base_value(120).set_flow_enabled(True)

    """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.__init__": """

        :param str expression: The field or field expression used to create the graduated symbol map. The field or field expression used to make the graduated symbol thematic map should be a numeric field
        :param float base_value: The base value of the graduated symbol map, the unit is the same as the unit of the thematic variable
        :param GeoStyle positive_style: positive grade symbol style
        :param graduated_mode: graduated symbol map classification mode
        :type graduated_mode: GraduatedMode or str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.base_value": """float: the base value of the graduated symbol thematic map, the unit is the same as the unit of the theme variable.""",

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.expression": """str: The field or field expression used to create the graduated symbol thematic map.""",

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.from_xml": """
        Import thematic map information from XML string.
        In SuperMap, the style settings of various thematic maps can be exported into XML format strings. This XML format string records all the settings related to this thematic map, such as
        The XML format string for a tag topic map will record the topic map type, visible scale, tag style Settings, whether it flows, whether it automatically avoids, etc. All the style Settings for the tag topic map
        And the fields or expressions used to make the tag topic map. This XML format string can be used to import and set thematic maps

        It should be noted that the information recorded in xml must correspond to the type of the current object. For example, if the label map information recorded in xml, the current object must be a ThemeLabel object.
        If you don't know the type of thematic map recorded in xml, you can use :py:meth:`.Theme.make_from_xml` to construct a new thematic map object from xml.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: Return True if the import is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.get_leader_line_style": """
        Return the style of the leader line between the grade symbol and its corresponding object.

        :return: The style of the leader line between the grade symbol and its corresponding object
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.get_negative_style": """
        Return the grade symbol style of a negative value.

        :return: negative grade symbol style
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.get_offset_x": """
        Get the X coordinate direction (lateral) offset of the grade symbol

        :return: X coordinate direction (lateral) offset of grade symbol
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.get_offset_y": """
        Get the Y coordinate direction (vertical) offset of the grade symbol

        :return: Y coordinate direction (vertical) offset of grade symbol
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.get_positive_style": """
        Return the positive grade symbol style.

        :return: Positive grade symbol style.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.get_zero_style": """
        Return the grade symbol style with a value of 0.

        :return: 0 value grade symbol style
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.graduated_mode": """GraduatedMode: Return to the graduated symbol map grading mode""",

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.is_flow_enabled": """
        Return whether the grade symbol is displayed in flow

        :return: Whether the grade symbol is displayed in flow
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.is_leader_line_displayed": """
        Return whether to display the leader line between the grade symbol and its corresponding object.

        :return: Whether to display the leader line between the grade symbol and its corresponding object
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.is_negative_displayed": """
        Return whether to display the negative grade symbol style, true means display

        :return: Whether to display the negative grade symbol style
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.is_offset_prj_coordinate_unit": """
        Get whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system

        :return: Whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system. If it is True, it is the geographic coordinate unit, otherwise the device unit is used.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.is_zero_displayed": """
        Return whether to display the grade symbol style of 0 value, True means display

        :return: Whether to display the grade symbol style of 0 value
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.make_default": """
        Generate the default graduated symbol thematic map.

        :param dataset: Vector dataset.
        :type dataset: DataetVector or str
        :param str expression: field expression
        :param graduated_mode: Type of thematic map classification mode.
        :type graduated_mode: GraduatedMode or str
        :return: thematic map of graduated symbols
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.make_from_xml": """
        Import the thematic map information and construct a new thematic map object.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: thematic map object
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_base_value": """
        Set the base value of the graduated symbol thematic map, the unit is the same as the unit of thematic variable.

        The display size of each symbol is equal to
        :py:meth:`.get_positive_style` (or :py:meth:`.get_zero_style` or :py:meth:`.get_negative_style`) :py:meth:`.GeoStyle.marker_size` *value/base_value,
        Among them, value refers to the thematic value after grading calculation, that is, the value obtained by calculating the thematic value according to the grading mode selected by the user (:py:attr:`.graduated_mode`).

        :param float value: Base value of the graduated symbol map
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_expression": """
        Set the field or field expression used to create the graduated symbol map. The field or field expression used to make the graduated symbol map should be a numeric field.

        :param str value: The field or field expression used to create the graduated symbol map.
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_flow_enabled": """
        Set whether the grade symbol is displayed in a fluid manner.

        :param bool value: Whether the grade symbols are displayed in a fluid manner.
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_graduated_mode": """
        Set the grading mode of graduated symbols thematic map.

        * Grading is mainly to reduce the difference between the data sizes in the production of thematic maps of grade symbols. If there is a large gap between the data , you can use the logarithmic or square root classification method to carry out, which reduces the absolute size differences between the data,
          and makes the visual effect of the grade symbol better, and the comparison between different categories is also meaningful;

        * There are three classification modes: constant, logarithm and square root. For fields with negative values, logarithm and square root classification methods cannot be used;

        * Different grading modes are used to determine the value of the symbol size. The constant is based on the original data of the field, the logarithm is the natural logarithm of the thematic value corresponding to each record, and the square root is the square of it.
          Using the final result to determine the size of its grade symbol.

        :param value: Grading mode of graduated symbol map
        :type value: GraduatedMode or str
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_leader_line": """
        Set to display the leader line between the grade symbol and its corresponding object

        :param bool is_displayed: Whether to display the style of the leader line between the grade symbol and its corresponding object
        :param GeoStyle style:
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_negative_displayed": """
        Set whether to display the grade symbol style of negative value, true means display.

        :param bool is_displayed: Whether to display the grade symbol style of negative values
        :param GeoStyle style: negative grade symbol style
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_offset_prj_coordinate_unit": """
        Set whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system. If it is True, it is the geographic coordinate unit, otherwise the device unit is used. For details, check the :py:meth:`set_offset_x` and :py:meth:`set_offset_y` interfaces.

        :param bool value: Whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_offset_x": """
        Set the X coordinate direction (lateral) offset of the grade symbol

        :param str value: X coordinate direction (horizontal) offset of grade symbol
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_offset_y": """
        Set the Y coordinate direction (vertical) offset of the grade symbol

        :param str value: Y coordinate direction (vertical) offset of grade symbol
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_positive_style": """
        Set the positive grade symbol style.

        :param GeoStyle value: The style of the graduated symbol with a positive value.
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.set_zero_displayed": """
        Set whether to display the grade symbol style of 0 value.

        :param bool is_displayed: Whether to display the 0-value grade symbol style
        :param GeoStyle style: 0 value of the grade symbol style
        :return: self
        :rtype: ThemeGraduatedSymbol
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.to_xml": """
        Export thematic map information as XML string.

        :return: XML string of thematic map information
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraduatedSymbol.type": """ThemeType: Thematic map type""",

    "iobjectspy._jsuperpy.mapping.ThemeGraph": """
    Statistics thematic map class.
    The statistical thematic map reflects the size of the corresponding thematic value by drawing a statistical map for each element or record. Statistical thematic maps can be based on multiple variables and reflect multiple attributes, that is, the values of multiple thematic variables can be plotted on a statistical map.

    """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.__init__": """
        :param graph_type: The statistical graph type of the statistical map. According to the actual data and usage, different types of statistical graphs can be selected.
        :type graph_type: ThemeGraphType or str
        :param graduated_mode: thematic map classification mode
        :type graduated_mode: GraduatedMode or str
        :param items: list of subitems of thematic map
        :type items: list[ThemeGraphItem] or tuple[ThemeGraphItem]
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.add": """
        Add sub item of thematic map

        :param ThemeGraphItem item: Statistical thematic map item
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.clear": """
        Delete all sub-items in the statistics map.

        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.exchange_item": """
        The two sub-items of the specified sequence number are exchanged.

        :param int index1: The sequence number of the first subitem of the specified exchange.
        :param int index2: The number of the second subitem of the specified exchange.
        :return: The exchange is successful, return True, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.extend": """
        Add sub-items of statistical thematic map in batch

        :param items: list of subitems of thematic map
        :type items: list[ThemeGraphItem] or tuple[ThemeGraphItem]
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.from_xml": """
        Import thematic map information from XML string.
        In SuperMap, the style settings of various thematic maps can be exported into XML format strings. This XML format string records all the settings related to this thematic map, such as
        The XML format string for a tag topic map will record the topic map type, visible scale, tag style Settings, whether it flows, whether it automatically avoids, etc. All the style Settings for the tag topic map
        And the fields or expressions used to make the tag topic map. This XML format string can be used to import and set thematic maps

        It should be noted that the information recorded in xml must correspond to the type of the current object. For example, if the label map information recorded in xml, the current object must be a ThemeLabel object.
        If you don't know the type of thematic map recorded in xml, you can use :py:meth:`.Theme.make_from_xml` to construct a new thematic map object from xml.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: Return True if the import is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_axes_color": """
        Return the axis color.

        :return: The color of the axis.
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_axes_text_display_mode": """
        When displaying axis text, the displayed text mode

        :return: The text mode displayed when the axis text is displayed
        :rtype: GraphAxesTextDisplayMode
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_axes_text_style": """
        Return the style of the axis text of the chart

        :return: the style of the axis text of the chart
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_bar_space_ratio": """
        Return the interval of the columns in the column map, the return value is a coefficient value, the value range is 0 to 10, and the default value is 1

        :return: the interval of the columns in the column map
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_bar_width_ratio": """
        Return the width of each column in the histogram, the return value is a coefficient value, the value range is 0 to 10, and the default value is 1. The column width of the histogram is equal to the original column width multiplied by the coefficient value.

        :return: The width of each column in the column map. Is a coefficient value, the value range is 0 to 10
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_count": """
        Return the number of sub-items of the statistics map

        :return: count the number of thematic map items
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_custom_graph_size_expression": """
        Return a field expression, which is used to control the size of the statistical map element corresponding to the object. The field in the field expression must be a numeric field. The field expression can specify a field also
        Can specify a field expression; you can also specify a value, and all thematic map items will be displayed uniformly at the size specified by the value.

        :return: field expression used to control the size of the statistical map element corresponding to the object
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_graph_text_format": """
        Return the text display format of the statistical map

        :return: The text display format of the statistics map
        :rtype: ThemeGraphTextFormat
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_graph_text_style": """
        Return the text label style on the chart. The text alignment of the coordinate axis on the statistics thematic map adopts the alignment at the bottom right corner to prevent the coordinate axis from overwriting the text

        :return: The text label style on the chart.
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_item": """
        Replace the thematic map item on the specified serial number with the specified statistical thematic map item.

        :param int index: The specified serial number.
        :return: Statistics thematic map item
        :rtype: ThemeGraphItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_leader_line_style": """
        Return the style of the leader line between the statistical graph and the object it represents.

        :return: The style of the leader line between the statistical graph and the object it represents.
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_max_graph_size": """
        Return the maximum value displayed by the statistical symbols in the statistical map. The display size of the statistical symbols in the statistical chart gradually changes between the maximum and minimum values. The maximum and minimum values of the statistical graph are a value related to the number of statistical objects and the size of the layer.

        :return: The maximum value displayed by the statistical symbol in the statistics map
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_min_graph_size": """
        Return the minimum value displayed by the statistical symbol in the statistical map.

        :return: The minimum value displayed by the statistical symbol in the statistical map.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_offset_x": """
        Return the horizontal offset of the statistical graph

        :return: horizontal offset
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_offset_y": """
        Return the vertical offset of the chart

        :return: vertical offset
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_rose_angle": """
        Return the angle of the rose chart or 3D rose chart slices in the statistical graph. The unit is degree, accurate to 0.1 degree

        :return: The angle of the rose chart or 3D rose chart slices in the statistical graph
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.get_start_angle": """
        Return the starting angle of the pie chart. By default, the horizontal direction is the positive direction. The unit is degree, accurate to 0.1 degree.

        :return:
        The starting angle of the pie chart
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.graduated_mode": """GraduatedMode: Thematic map grading mode""",

    "iobjectspy._jsuperpy.mapping.ThemeGraph.graph_type": """ThemeGraphType: Statistical graph type of statistical thematic graph""",

    "iobjectspy._jsuperpy.mapping.ThemeGraph.index_of": """
        Return the serial number of the object of the specified statistical field expression in the current statistical map.

        :param str expression: The specified statistical field expression.
        :return: The serial number of the sub-item of the statistics map in the sequence.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.insert": """
        Insert the given statistical thematic map item into the position of the specified sequence number.

        :param int index: The serial number of the specified sub-item of the statistical map.
        :param ThemeGraphItem item: The item of the statistical map to be inserted.
        :return: Return True if the insertion is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_all_directions_overlapped_avoided": """
        Return whether to allow omni-directional statistical thematic map avoidance

        :return: Whether to allow omni-directional statistics thematic map avoidance
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_axes_displayed": """
        Return whether to display the axis

        :return: Whether to display the coordinate axis
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_axes_grid_displayed": """
        Get whether to display the grid on the graph axis

        :return: whether to display the grid on the graph axis
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_axes_text_displayed": """
        Return whether to display the text label of the axis.

        :return: Whether to display the text label of the axis
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_display_graph_text": """
        Return whether to display the text label on the statistical graph

        :return: Whether to display the text label on the chart
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_flow_enabled": """
        Return whether the statistics thematic map is displayed in flow.

        :return: Whether the statistics thematic map is displayed in flow
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_global_max_value_enabled": """
        Return whether to use the global maximum value to make the statistical map. True, indicates that the global maximum value is used as the maximum value of the statistical graph elements to ensure that the statistical graph elements in the same thematic layer have the same scale.

        :return: Whether to use the global maximum value to make the statistical map
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_graph_size_fixed": """
        Return whether the statistical graph is fixed in size when zooming in or out

        :return: Whether the size of the statistical graph is fixed when zooming in or out.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_leader_line_displayed": """
        Return whether to display the leader line between the statistical graph and the object it represents. If the rendering symbol is offset from the object, the drawing line can be used to connect the graph and the object.

        :return: Whether to display the leader line between the statistical graph and the object it represents
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_negative_displayed": """
        Return whether the data with negative attributes is displayed in the thematic map.

        :return: Whether to display data with negative attributes in the thematic map
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_offset_prj_coordinate_unit": """
        Get whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system

        :return: Whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system. If it is True, it is the geographic coordinate unit, otherwise the device unit is used.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.is_overlap_avoided": """
        Return whether the statistical graph is displayed in avoidance mode. Use avoidance method to display return true, otherwise return false

        :return: Whether to use avoidance method to display
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.make_from_xml": """
        Import the thematic map information and construct a new thematic map object.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: thematic map object
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.remove": """
        Delete the specified serial number of the statistical thematic map sub-item from the sub-item sequence of the statistical map.

        :param int index: the number of the specified item to be deleted
        :return: If the deletion is successful, it Return True; otherwise, it Return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_all_directions_overlapped_avoided": """
        Set whether to allow the thematic map avoidance in all directions. All directions refer to the 12 directions formed by the outer border and reference line of the statistical map. Four directions refer to the directions of the four corners of the rectangular frame outside the statistical map.

        Generally, the avoidance of statistical thematic maps is performed in all directions. Although the avoidance is reasonable, it will affect the display efficiency; if you improve the display efficiency, please set it to False.

        :param bool value: Whether to avoid the thematic map in all directions
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_axes": """
        Set whether the coordinate axis, and the coordinate axis text label related content.

        :param bool is_displayed: Whether to display the coordinate axis.
        :param color: axis color
        :type color: Color or str
        :param bool is_text_displayed: Whether to display the text label of the axis
        :param text_display_mode: The text mode displayed when the axis text is displayed
        :type text_display_mode: GraphAxesTextDisplayMode or str
        :param TextStyle text_style: The style of the axis text of the chart
        :param bool is_grid_displayed: Whether to display the grid on the graph axis
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_bar_space_ratio": """
        Set the interval of the bars in the bar thematic map. The set value is a coefficient value, the value range is 0 to 10, and the default value is 1. The bar interval of the histogram is equal to the original interval multiplied by the coefficient value.

        :param float value: the interval of the columns in the column map
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_bar_width_ratio": """
        Set the width of each column in the column map. The set value is a coefficient value. The value range is from 0 to 10. The default value is 1. The column width of the histogram is equal to the original column width multiplied by the coefficient value.

        :param float value: The width of each column in the column map, the value is a coefficient value, and the value range is 0-10.
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_custom_graph_size_expression": """
        Set a field expression, which is used to control the size of the statistical map element corresponding to the object. The field in the field expression must be a numeric field. The field expression can specify a field also
        You can specify a field expression; you can also specify a value, and all thematic map items will be displayed uniformly at the size specified by the value.

        :param str value: The field expression used to control the size of the statistical map element corresponding to the object
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_display_graph_text": """
        Set whether to display the text labels on the statistical graph

        :param bool value: Specify whether to display the text label on the statistical graph
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_flow_enabled": """
        Set whether the statistics thematic map is displayed in flow.

        :param bool value: Whether the statistics thematic map is displayed in a fluid manner.
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_global_max_value_enabled": """
        Set whether to use the global maximum value to make the statistical map. True, indicates that the global maximum value is used as the maximum value of the statistical graph elements to ensure that the statistical graph elements in the same thematic layer have the same scale.

        :param bool value: Whether to use the global maximum value to make the statistical map
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_graduated_mode": """
        Set the thematic map classification mode

        :param value: Set the thematic map classification mode
        :type value: GraduatedMode or str
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_graph_size_fixed": """
        Set whether the size of the statistical graph is fixed when zooming in or out of the map.

        :param bool value: Whether the size of the statistical graph is fixed when zooming in or out.
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_graph_text_format": """
        Set the text display format of the statistical map.

        :param value: The text display format of the statistics map
        :type value: ThemeGraphTextFormat or str
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_graph_text_style": """
        Set the text label style on the chart. The text alignment of the coordinate axis on the statistics thematic map adopts the alignment at the bottom right corner to prevent the coordinate axis from overwriting the text

        :param TextStyle value: text label style on the chart
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_graph_type": """
        Set the graph type of the graph thematic map. According to the actual data and usage, different types of statistical graphs can be selected.

        :param value: Statistical graph type of thematic graph
        :type value: ThemeGraphType or str
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_leader_line": """
        Set to display the leader line between the statistical graph and the object it represents

        :param bool is_displayed: Whether to display the leader line between the statistical graph and the object it represents
        :param GeoStyle style: The style of the leader line between the graph and its representation.
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_max_graph_size": """
        Set the maximum value of the statistical symbols displayed in the statistical map. The display size of the statistical symbols in the statistical chart gradually changes between the maximum and minimum values. The maximum and minimum values of the statistical graph are a value related to the number of statistical objects and the size of the layer.

        When :py:meth:`is_graph_size_fixed` is True, the unit is 0.01mm, and :py:meth:`is_graph_size_fixed` is False, the map unit is used.

        :param float value: The maximum value displayed by the statistical symbol in the statistical map
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_min_graph_size": """
        Set the minimum value displayed by the statistical symbols in the statistical map. The display size of the statistical symbols in the statistical chart gradually changes between the maximum and minimum values. The maximum and minimum values of the statistical graph are a value related to the number of statistical objects and the size of the layer.

        When :py:meth:`is_graph_size_fixed` is True, the unit is 0.01mm, and :py:meth:`is_graph_size_fixed` is False, the map unit is used.

        :param float value: The minimum value displayed by the statistical symbols in the statistical map.
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_negative_displayed": """
        Set whether to display data with negative attributes in the thematic map.

        This method is invalid for area charts, ladder charts, line charts, dot charts, histograms, and three-dimensional histograms, because negative data will always be displayed when drawing;

        For pie chart, 3D pie chart, rose chart, 3D rose chart, pyramid thematic map-bar, pyramid thematic map-surface, if the user sets the method parameter to True, then take the absolute value of the negative value and treat it as a positive value,
        If set to False, it will not be drawn (positive and negative data are not drawn)

        :param bool value: Whether to display data with negative attributes in the thematic map
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_offset_prj_coordinate_unit": """
        Set whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system. If it is True, it is the geographic coordinate unit, otherwise the device unit is used. For details, check the :py:meth:`set_offset_x` and :py:meth:`set_offset_y` interfaces.

        :param bool value: Whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_offset_x": """
        Set the horizontal offset of the statistical graph

        :param str value: horizontal offset
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_offset_y": """
        Set the vertical offset of the chart

        :param str value: vertical offset
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_overlap_avoided": """
        Set whether the statistical graph is displayed in avoidance mode.

        * Make statistical thematic maps for dataset. When the statistical maps are displayed in the avoidance mode, if the :py:meth:`.Map.is_overlap_displayed` method is set to True, then in the case of large overlap of the statistical maps,
          There will be a phenomenon that the statistical graphs cannot be completely avoided; when the :py:meth:`.Map.is_overlap_displayed` method is set to False, some statistical graphs will be filtered out to ensure that all statistical graphs do not overlap.

        * Create statistical thematic maps and label thematic maps at the same time for the dataset
          -When the statistic graph does not display the sub-item text, even if the label of the label map overlaps the statistic graph, both can be displayed normally;
          -When the statistical graph displays the sub-item text, if the sub-item text in the statistical graph and the label in the label map do not overlap, both are displayed normally; if they overlap, the sub-item text of the statistical graph will be filtered out. Show label.

        :param bool value: Whether to use avoidance method to display
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_rose_angle": """
        Set the angle of the rose chart or 3D rose chart slices in the statistical chart. The unit is degree, accurate to 0.1 degree.

        :param float value: The angle of the rose chart or 3D rose chart slices in the statistical graph.
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.set_start_angle": """
        Set the starting angle of the pie chart. By default, the horizontal direction is the positive direction. The unit is degree, accurate to 0.1 degree.
        It is valid only when the selected statistical graph type is a pie chart (pie chart, 3D pie chart, rose chart, 3D rose chart).

        :param float value:
        :return: self
        :rtype: ThemeGraph
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.to_xml": """
        Export thematic map information as XML string.

        :return: XML string of thematic map information
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraph.type": """ThemeType: the type of thematic map""",

    "iobjectspy._jsuperpy.mapping.ThemeGraphItem": """
    The sub-item class of statistics thematic map.

    The statistical thematic map reflects the size of the corresponding thematic value by drawing a statistical map for each element or record. Statistical thematic maps can be based on multiple variables and reflect multiple attributes, that is, the values of multiple thematic variables can be plotted on
    A statistical graph. The statistical map corresponding to each thematic variable is a thematic map item. This class is used to set the name, thematic variable, display style and segment style of the sub-items of the statistical map.
    """,

    "iobjectspy._jsuperpy.mapping.ThemeGraphItem.__init__": """
        :param str expression: Thematic variables of the statistical map. Thematic variable can be a field or field expression
        :param str caption: the name of the thematic map item
        :param GeoStyle style: The display style of the sub-items of the statistics map
        :param ThemeRange range_setting: the segmentation style of the sub-items of the statistical thematic map
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraphItem.caption": """str: the name of the thematic map item """,

    "iobjectspy._jsuperpy.mapping.ThemeGraphItem.expression": """str: Thematic variable of the statistical map """,

    "iobjectspy._jsuperpy.mapping.ThemeGraphItem.range_setting": """ThemeRange: Return the segmentation style of the sub-item of the statistical thematic map""",

    "iobjectspy._jsuperpy.mapping.ThemeGraphItem.set_caption": """
        Set the name of the thematic map item.

        :param str value: the name of the thematic map item
        :return: self
        :rtype: ThemeGraphItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraphItem.set_expression": """
        Set the thematic variables of the statistical map. Thematic variable can be a field or field expression.

        :param str value: Thematic variable of the statistical map
        :return: self
        :rtype: ThemeGraphItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraphItem.set_range_setting": """
        Set the sub-item style of the statistics map

        :param value: the sub-item style of the statistics map
        :type value: ThemeRange
        :return: self
        :rtype: ThemeGraphItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraphItem.set_style": """
        Set the display style of the sub-items of the statistics map

        :param value:
        :type value: GeoStyle
        :return: self
        :rtype: ThemeGraphItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGraphItem.style": """GeoStyle: Return the sub-item style of the statistic map.""",

    "iobjectspy._jsuperpy.mapping.ThemeGraphTextFormat": """
    This class defines the constants of the text display format of the statistical map.

    :var ThemeGraphTextFormat.PERCENT: Percentage. Mark the percentage of each sub-item.

                                       .. image:: ../image/percent.png


    :var ThemeGraphTextFormat.VALUE: The real value. Label with the actual value of each sub-item.

                                      .. image:: ../image/value.png


    :var ThemeGraphTextFormat.CAPTION: Title. Label with the title of each sub-item.

                                       .. image:: ../image/caption.png


    :var ThemeGraphTextFormat.CAPTION_PERCENT: Title + percentage. Label with the title and percentage of each sub-item.

                                               .. image:: ../image/captionpercent.png


    :var ThemeGraphTextFormat.CAPTION_VALUE: Title + real value. Label with the title and actual value of each sub-item.

                                             .. image:: ../image/captionvalue.png


    """,

    "iobjectspy._jsuperpy.mapping.ThemeGraphType": """
    This class defines the constants of the statistical graph types of statistical thematic maps.

    :var ThemeGraphType.AREA: Area graph. When the area chart is displayed, multiple ThemeGraphItems are combined into one surface, and the surface style is rendered in the style of the first ThemeGraphItem.

                              .. image:: ../image/Area.png


    :var ThemeGraphType.STEP: Step graph.

                              .. image:: ../image/Step.png


    :var ThemeGraphType.LINE: Line graph.

                              .. image:: ../image/Line.png


    :var ThemeGraphType.POINT: Point graph.

                               .. image:: ../image/Point.png


    :var ThemeGraphType.BAR: histogram

                             .. image:: ../image/Bar.png


    :var ThemeGraphType.BAR3D: three-dimensional histogram

                               .. image:: ../image/Bar3D.png


    :var ThemeGraphType.PIE: Pie chart

                              .. image:: ../image/Pie.png


    :var ThemeGraphType.PIE3D: Three-dimensional pie chart. The size of the annotation label of the 3D pie chart will be adjusted according to the size of the statistical symbol to avoid the problem of small statistical symbols and large annotations when there are many statistical symbols.

                               .. image:: ../image/Pie3D.png


    :var ThemeGraphType.ROSE: Rose graph

                              .. image:: ../image/Rose.png


    :var ThemeGraphType.ROSE3D: Three-dimensional rose graph

                                .. image:: ../image/Rose3D.png


    :var ThemeGraphType.STACK_BAR: Stacked bar graph

                                    .. image:: ../image/StackedBar.png


    :var ThemeGraphType.STACK_BAR3D: 3D stacked bar graph

                                     .. image:: ../image/StackedBar3D.png


    :var ThemeGraphType.RING: ring graph

                              .. image:: ../image/Ring.png

    """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange": """
    The grid range thematic map class.

    The grid range thematic map divides the values of all cells into multiple ranges according to a certain range method, and the cells with values in the same range are displayed in the same color. Thematic maps of raster segments are generally used to
    Reflect the quantity or degree of continuous distribution phenomena. For example, in the national precipitation distribution map of a certain year, the grid data generated after the interpolation of the observed values of each meteorological station is displayed in segments. This class is similar to the segmented thematic map class,
    The difference is that the segmented thematic map operates on vector data, while the raster segmented thematic map operates on raster data.

    For example, you can create raster thematic map objects in the following ways:

    >>>theme = ThemeGridRange.make_default(dataset,'EUQALINTERVAL', 6,'RAINBOW')

    or::

    >>> theme = ThemeGridRange()
    >>> theme.add(ThemeGridRangeItem(-999, 3,'rosybrown', '1'))
    >>> theme.add(ThemeGridRangeItem(3, 6,'darkred', '2'))
    >>> theme.add(ThemeGridRangeItem(6, 9,'cyan', '3'))
    >>> theme.add(ThemeGridRangeItem(9, 20,'blueviolet', '4'))
    >>> theme.add(ThemeGridRangeItem(20, 52,'darkkhaki', '5'))

    """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.__init__": """
        :param items: grid range thematic map sub-item list
        :type items: list[ThemeGridRangeItem] or tuple[ThemeGridRangeItem]
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.add": """
        Add sub item list of grid range map

        :param ThemeGridRangeItem item: Grid range thematic map item list
        :param bool is_normalize: Indicates whether to normalize, when normalize is true, if the item value is illegal, then normalize, and when normalize is fasle, if the item value is illegal, an exception will be thrown
        :param bool is_add_to_head: Whether to add to the head of the segment list, if it is True, add to the head, otherwise add to the tail.
        :return: self
        :rtype: ThemeGridRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.clear": """
        Delete a range value of the grid range map. After executing this method, all the sub-items of the grid range thematic map are released and are no longer available.

        :return: self
        :rtype: ThemeGridRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.extend": """
        Add the sub-item list of grid range thematic map in batches. Added to the end by default.

        :param items: grid range thematic map sub-item list
        :type items: list[ThemeGridRangeItem] or tuple[ThemeGridRangeItem]
        :param bool is_normalize: Indicates whether to normalize, when normalize is true, if the item value is illegal, then normalize, and when normalize is fasle, if the item value is illegal, an exception will be thrown
        :return: self
        :rtype: ThemeGridRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.from_xml": """
        Import thematic map information from XML string.
        In SuperMap, the style settings of various thematic maps can be exported into XML format strings. This XML format string records all the settings related to this thematic map, such as
        The XML format string for a tag topic map will record the topic map type, visible scale, tag style Settings, whether it flows, whether it automatically avoids, etc. All the style Settings for the tag topic map
        And the fields or expressions used to make the tag topic map. This XML format string can be used to import and set thematic maps

        It should be noted that the information recorded in xml must correspond to the type of the current object. For example, if the label map information recorded in xml, the current object must be a ThemeLabel object.
        If you don't know the type of thematic map recorded in xml, you can use :py:meth:`.Theme.make_from_xml` to construct a new thematic map object from xml.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: Return True if the import is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.get_count": """
        Return the number of ranges in the grid ranges map

        :return: the number of ranges in the grid range map
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.get_item": """
        Return the range thematic map item of the grid range map with the specified serial number

        :param int index: The specified sub-item number of the grid range map.
        :return: The range map sub-item of the grid range map with the specified serial number.
        :rtype: ThemeGridRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.get_special_value": """
        Return the special value of the grid segment thematic layer.

        :return: The special value of the grid segment thematic layer.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.get_special_value_color": """
        Return the color of the special value of the grid segment thematic layer

        :return: the color of the special value of the raster segment thematic layer
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.index_of": """
        Return the serial number of the specified range field value in the current range sequence in the grid ranges map.

        :param str value:
        :return: The sequence number of the segment field value in the segment sequence. If the value of the given segment field does not have a corresponding sequence number, -1 is returned.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.is_special_value_transparent": """
        Whether the area where the special value of the raster segment thematic layer is located is transparent.

        :return: Whether the area where the special value of the raster segment thematic layer is located is transparent; True means transparent; False means opaque.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.make_default": """
        According to the given raster dataset, segmentation mode and corresponding segmentation parameters, a default raster segmentation thematic map is generated.

        :param dataset: raster dataset.
        :type dataset: DatasetGrid or str
        :param range_mode: segment mode. Only supports equidistant segmentation method, square root segmentation method, logarithmic segmentation method, and custom distance method.
        :type range_mode: RangeMode or str
        :param float range_parameter: segment parameter. When the segmentation mode is equidistant segmentation method, square root segmentation method, or logarithmic segmentation method, this parameter is the number of segments; when the segmentation mode is custom distance, this parameter represents custom distance .
        :param color_gradient_type: Color gradient mode.
        :type color_gradient_type: ColorGradientType or str
        :return: The new grid range thematic map object.
        :rtype: ThemeGridRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.make_from_xml": """
        Import the thematic map information and construct a new thematic map object.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: thematic map object
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.range_mode": """RangeMode: The segmentation mode of the current thematic map""",

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.reverse_color": """
        Display the styles of the ranges in the range map in reverse order.

        :return: self
        :rtype: ThemeGridRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.set_special_value": """
        Set the special value of the grid segment thematic layer.

        :param float value: The special value of the grid segment thematic layer.
        :param color: The color of the special value of the grid segment thematic layer.
        :type color: Color or str
        :param bool is_transparent: Whether the area where the special value of the grid segmentation thematic layer is located is transparent. True means transparent; False means opaque.
        :return: self
        :rtype: ThemeRangeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.to_xml": """
        Export thematic map information as XML string.

        :return: XML string of thematic map information
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRange.type": """ThemeType: Thematic map type""",

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem": """
    The sub-item class of the grid range map.

    In the grid range map, the expression value of the range field is divided into multiple ranges according to a certain range mode. This class is used to set the start value, end value, name and color of each range segment.
    The range represented by each segment is [Start, End).
    """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.__init__": """
        :param float start: the starting value of the sub item of the grid range map
        :param float end: the end value of the grid range map item
        :param Color color: The corresponding color of each range map item in the grid ranges map.
        :param str caption: The name of the item in the grid range map
        :param bool visible: Whether the sub items in the grid range map are visible
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.caption": """str: The name of the item in the grid range map """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.color": """Color: The corresponding color of each range thematic map item in the grid range map.""",

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.end": """float: the end value of the grid range thematic map item""",

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.set_caption": """
        Set the name of the item in the grid range map.

        :param str value: The name of the item in the grid range map.
        :return: self
        :rtype: ThemeGridRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.set_color": """
        Set the corresponding color of each range map item in the grid ranges map.

        :param value: The corresponding color of each range map item in the grid ranges map.
        :type value: Color or str
        :return: self
        :rtype: ThemeGridRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.set_end": """
        Set the end value of the grid range map item.
        Note: If the sub-item is the last sub-item in the segment, then the end value is the maximum value of the segment; if it is not the last item, the end value must be the same as the start value of the next sub-item, otherwise the system will throw An exception occurred.

        :param float value: The end value of the grid range map item.
        :return: self
        :rtype: ThemeGridRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.set_start": """
        Set the starting value of the grid range map item.
        Note: If the sub-item is the first sub-item in the segment, then the starting value is the minimum value of the segment; if the sequence number of the sub-item is greater than or equal to 1, the starting value must be the same as that of the previous sub-item The end value is the same, otherwise
        The system will throw an exception.

        :param float value: The starting value of the grid range map item.
        :return: self
        :rtype: ThemeGridRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.set_visible": """
        Set whether the sub items in the grid range map are visible

        :param bool value: Whether the sub items in the grid range map are visible
        :return: self
        :rtype: ThemeGridRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.start": """float: the starting value of the grid range thematic map item""",

    "iobjectspy._jsuperpy.mapping.ThemeGridRangeItem.visible": """bool: Whether the subitem in the grid range map is visible""",

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique": """
    The grid unique values map class.

    The grid unique values map is to classify cells with the same value into one category, and set a color for each category to distinguish different categories. Raster single-valued thematic map is applicable to discrete raster data and part of continuous raster data.
    For those continuous raster data with different cell values, it is not meaningful to use raster single-valued thematic map.

    For example, you can create raster thematic map objects in the following ways:

    >>> theme = ThemeGridUnique.make_default(dataset,'RAINBOW')

    or::

    >>> theme = ThemeGridUnique()
    >>> theme.add(ThemeGridUniqueItem(1, Color.rosybrown(), '1'))
    >>> theme.add(ThemeGridUniqueItem(2, Color.coral(), '2'))
    >>> theme.add(ThemeGridUniqueItem(3, Color.darkred(), '3'))
    >>> theme.add(ThemeGridUniqueItem(4, Color.blueviolet(), '4'))
    >>> theme.add(ThemeGridUniqueItem(5, Color.greenyellow(), '5'))
    >>> theme.set_default_color(Color.white())
    """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.__init__": """
        :param items: grid unique values map sub-item list
        :type items: list[ThemeGridUniqueItem] or tuple[ThemeGridUniqueItem]
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.add": """
        Add sub item of grid unique values map

        :param ThemeGridUniqueItem item: grid unique values map item
        :return: self
        :rtype: ThemeGridUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.clear": """
        Delete all grid unique values map sub-items.

        :return: self
        :rtype: ThemeGridUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.extend": """
        Add sub-items of grid unique values map in batch

        :param items: grid unique values map sub-item list
        :type items: list[ThemeGridUniqueItem] or tuple[ThemeGridUniqueItem]
        :return: self
        :rtype: ThemeGridUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.from_xml": """
        Import thematic map information from XML string.
        In SuperMap, the style settings of various thematic maps can be exported into XML format strings. This XML format string records all the settings related to this thematic map, such as
        The XML format string for a tag topic map will record the topic map type, visible scale, tag style Settings, whether it flows, whether it automatically avoids, etc. All the style Settings for the tag topic map
        And the fields or expressions used to make the tag topic map. This XML format string can be used to import and set thematic maps

        It should be noted that the information recorded in xml must correspond to the type of the current object. For example, if the label map information recorded in xml, the current object must be a ThemeLabel object.
        If you don't know the type of thematic map recorded in xml, you can use :py:meth:`.Theme.make_from_xml` to construct a new thematic map object from xml.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: Return True if the import is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.get_count": """
        Return the number of grid unique values map items

        :return: the number of sub-items of the grid unique values map
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.get_default_color": """
        Return the default color of the grid unique values map. Those objects that are not listed in the grid unique values map are displayed in this color. If not set, the default color of the layer will be used for display.

        :return: The default color of grid unique values map.
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.get_item": """
        Return the grid unique values map item of the specified serial number

        :param int index: The number of the specified grid unique values map item
        :return: Grid unique values map subitem with specified serial number
        :rtype: ThemeGridUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.get_special_value": """
        Return the special value of the grid unique value thematic layer. When adding a new raster layer, the return value of this method is equal to the NoValue property value of the dataset.

        :return: The special value of the grid unique value thematic layer.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.get_special_value_color": """
        Return the color of the special value of the grid unique value thematic layer

        :return: The color of the special value of the grid unique value thematic layer.
        :rtype: Color
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.index_of": """
        Return the serial number of the specified sub-item unique value in the grid unique values map in the current series.

        :param int unique_value: the unique value of the given grid unique values map item
        :return: The serial number value of the grid thematic map item in the sequence. If the value does not exist, -1 is returned.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.insert": """
        Insert the given grid unique values map item to the position of the specified sequence number.

        :param int index: The serial number of the specified grid unique values map sub-item sequence.
        :param ThemeGridUniqueItem item: the inserted grid unique values map item.
        :return: self
        :rtype: ThemeGridUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.is_special_value_transparent": """
        Whether the area of the special value of the grid unique value thematic layer is transparent.

        :return: Whether the area of the special value of the grid unique value thematic layer is transparent; True means transparent; False means opaque.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.make_default": """
        Generate the default grid unique values map based on the given raster dataset and color gradient mode.
        Only supports making unique values maps for raster datasets whose raster values are integers, and cannot make raster unique values maps for raster datasets with floating-point raster values.

        :param dataset: raster dataset
        :type dataset: DatasetGrid or str
        :param color_gradient_type: color gradient mode
        :type color_gradient_type: ColorGradientType or str
        :return: object instance of the new grid unique values map class
        :rtype: ThemeGridUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.make_from_xml": """
        Import the thematic map information and construct a new thematic map object.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: thematic map object
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.remove": """
        Delete a sub-item of the grid unique values map with a specified serial number.

        :param int index: The specified sequence number of the sub-item of the grid unique values map to be deleted.
        :return: If the deletion is successful, it Return True; otherwise, it Return False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.reverse_color": """
        Display the colors of the sub-items in the grid unique values map in reverse order.

        :return: self
        :rtype: ThemeGridUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.set_default_color": """
        Set the default color of the grid unique values map, and use this color to display the objects that are not listed in the grid unique values map sub-items. If not set, the default color of the layer will be used for display.

        :param color: the default color of grid unique values map
        :type color: Color or str
        :return: self
        :rtype: ThemeGridUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.set_special_value": """
        Set the special value of the grid unique value thematic layer.

        :param float value: The special value of the grid unique value thematic layer.
        :param color: The color of the special value of the grid unique value thematic layer.
        :type color: Color or str
        :param bool is_transparent: Whether the area where the special value of the grid unique value thematic layer is located is transparent. True means transparent; False means opaque.
        :return: self
        :rtype: ThemeGridUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.to_xml": """
        Export thematic map information as XML string.

        :return: XML string of thematic map information
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUnique.type": """ThemeType: Thematic map type""",

    "iobjectspy._jsuperpy.mapping.ThemeGridUniqueItem": """
    The sub-item class of grid unique values map.
    """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUniqueItem.__init__": """
        :param str unique_value: the unique value of the sub-item of the grid unique values map
        :param Color color: The display color of the grid unique values map item
        :param str caption: The name of the sub-item of the grid unique values map
        :param bool visible: Whether the grid unique values map item is visible
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUniqueItem.caption": """str: the name of the sub-item of the grid unique values map """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUniqueItem.color": """Color: the display color of the grid unique values map item""",

    "iobjectspy._jsuperpy.mapping.ThemeGridUniqueItem.set_caption": """
        Set the name of each grid unique values map item

        :param str value: The name of each grid unique values map item
        :return: self
        :rtype: ThemeGridUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUniqueItem.set_color": """
        Set the display color of each grid unique values map item.

        :param value: The display color of the grid unique values map item.
        :type value: Color or str
        :return: self
        :rtype: ThemeGridUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUniqueItem.set_unique_value": """
        Set the unique value of grid unique values map item

        :param str value: the single value of the subitem of the grid unique values map
        :return: self
        :rtype: ThemeGridUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUniqueItem.set_visible": """
        Set whether the grid unique values map item is visible

        :param bool value: Whether the grid unique values map item is visible
        :return: self
        :rtype: ThemeGridUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeGridUniqueItem.unique_value": """str: the unique value of the sub-item of the grid unique values map""",

    "iobjectspy._jsuperpy.mapping.ThemeGridUniqueItem.visible": """bool: Whether the grid unique values map item is visible""",

    "iobjectspy._jsuperpy.mapping.ThemeLabel": """
    Label thematic map class.

    The label of the label thematic map can be numbers, letters, and text, such as geographic names of rivers, lakes, oceans, mountains, towns, villages, etc., elevation, contour values, river flow velocity, highway section mileage, navigation line mileage, etc.

    In the label thematic map, you can set or control the display style and position of the labels. You can set a unified display style and position option for all labels to display; you can also use the unique value label thematic map, based on
    The value of the specified field expression, the labels of objects with the same value are displayed in the same style as one class, and the labels of different classes are displayed in different styles. It can also be segmented based on the value of
    The specified field expression through the section label thematic map. Object labels in the same section are displayed in the same style, and labels in different sections are displayed in different styles.

    There are many types of label thematic maps: unified label thematic map, single value label thematic map, composite style label thematic map, range label thematic map, and custom label thematic map. ThemeLabel class can be used to achieve
    All the above style label thematic map Settings, it is recommended that users do not set two or more styles at the same time. If multiple styles are set at the same time, the display of the label thematic map will be displayed according to the priority of the following table:

    .. image:: ../image/themelabelmore.png

    Note: Legends, title, scale, etc. will usually appear on the map. These are all cartographic elements and do not belong to the category of label thematic icon annotations

    Note: If you have established a connection with an external table by means of Join or Link, when the thematic variables of the thematic map are used in the fields of the external table, when displaying the thematic map,
    You need call :py:meth:`.Layer.set_display_filter` method, otherwise the thematic map will fail to output.

    Build a unified style label thematic map::

    >>> text_style = TextStyle().set_fore_color(Color.rosybrown()).set_font_name('Microsoft Yahei')
    >>> theme = ThemeLabel().set_label_expression('zone').set_uniform_style(text_style)

    Build the default unique value label thematic map::

    >>> theme = ThemeLabel.make_default_unique(dataset,'zone','color_field', ColorGradientType.CYANGREEN)

    Build the default segment label thematic map::

    >>> theme = ThemeLabel.make_default_range(dataset,'zone','color_field', RangeMode.EUQALINTERVAL, 6)

    Build a composite style label thematic map::

    >>> mixed_style = MixedTextStyle()
    >>> mixed_style.set_default_style(TextStyle().set_fore_color('rosybrown'))
    >>> mined_style.set_separator_enabled(True).set_separator("_")
    >>> theme = ThemeLabel().set_label_expression('zone').set_uniform_mixed_style(mixed_style)
    """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.from_xml": """
        Import thematic map information from XML string.
        In SuperMap, the style settings of various thematic maps can be exported into XML format strings. This XML format string records all the settings related to this thematic map, such as
        The XML format string for a tag topic map will record the topic map type, visible scale, tag style Settings, whether it flows, whether it automatically avoids, etc. All the style Settings for the tag topic map
        And the fields or expressions used to make the tag topic map. This XML format string can be used to import and set thematic maps

        It should be noted that the information recorded in xml must correspond to the type of the current object. For example, if the label map information recorded in xml, the current object must be a ThemeLabel object.
        If it is unclear thematic maps xml recorded can be made by: py: meth: `.Theme.make_from_xml` construct a new object from the xml thematic FIG.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: Return True if the import is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_along_line_culture": """
        Return the language and cultural habits of the labels along the line. The default value is related to the non-Unicode language of the current system. If it is a Chinese environment, it is CHINESE, otherwise it is ENGLISH.

        :return: the language and cultural habits used in the label along the line
        :rtype: AlongLineCulture
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_along_line_direction": """
        Return the labeling direction along the line. Default value: py:attr:`AlongLineDirection.ALONG_LINE_NORMAL`.

        :return: Label the direction along the line.
        :rtype: AlongLineDirection
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_along_line_drawing_mode": """
        Return the strategy used for label drawing in the label along the line. The default is: py:attr:`AlongLineDrawingMode.COMPATIBLE`

        :return: The strategy used for label drawing
        :rtype: AlongLineDrawingMode
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_along_line_space_ratio": """
        Return the ratio of text spacing along the line. The value is a multiple of the word height.

        note:
         * If the value is greater than 1, the line center shall prevail, and the two sides shall be marked at the specified interval;
         * If the value is between 0 and 1 (including 1), a single text will be marked at the line center according to the angle along the line.
         * If the value is less than or equal to 0, the default labeling mode along the line will be used.

        :return: the ratio of text spacing along the line
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_along_line_word_angle_range": """
        Return the tolerance value of the relative angle between words or letters in the label along the line, in degrees.
        In the labeling along the line, in order to adapt to the trend of the curved line, the Chinese label and the English label will rotate the text or letter, but the single word or letter is always perpendicular to the tangent direction of the current labeling point.
        Therefore, the effect as shown in the figure below will appear. Adjacent words or letters form a certain included Angle. When the bending degree of the line is large, the included Angle will also increase, resulting in the overall unattractive effect of the label.
        Therefore, the interface limits the maximum Angle between adjacent words or letters through a given volume limit, so as to ensure the aesthetics of markings along the line.

        The smaller the included angle tolerance limit, the more compact the label, but the place with large curvature may not be able to label; the larger the included angle tolerance limit, the large curvature can also display the label, but the aesthetics of the label along the line is reduced.

        .. image:: ../image/LabelWordAngle10.png

        .. image:: ../image/LabelWordAngle20.png

        .. image:: ../image/LabelWordAngle40.png

        What is the relative angle between words and letters or letters and letters in the label along the line? As shown below:

        .. image:: ../image/LabelWordAngle.png

        :return: Mark the tolerance value of the relative angle between Chinese characters or letters and letters along the line, the unit is: degree
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_back_shape": """
        Return the shape type of the label background in the label map

        :return: The shape type of the label background in the label map
        :rtype: LabelBackShape
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_back_style": """
        Set the label background style in the label map.

        :return: label background style
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_label_angle_expression": """
        Return a field, the field is a numeric field, the field value controls the rotation angle of the text

        :return: a field, the field is a numeric field, the field value controls the rotation angle of the text
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_label_color_expression": """
        Return a field, the field is a numeric field, control the text color

        :return: A field, which is a numeric field, which controls the text color.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_label_font_type_expression": """
        Return a field name, the field value is the font name, such as: Microsoft Yahei, Times New Roman, controls the font style of the label text in the label map.

        :return: a field name that controls the font style of the label text in the label map.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_label_repeat_interval": """
        Return the interval of circular labeling when labeling along the line. The set interval size represents the paper distance of the adjacent mark interval after printing, and the unit is 0.1 mm. For example: the cycle labeling interval is set to 500, after the map is printed,
        Measure the distance between adjacent labels on paper to be 5 cm.

        :return: the interval of circular labeling when labeling along the line
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_label_size_expression": """
        Return a field, the field is a numeric field, the field value controls the height of the text, and the numeric unit is millimeters.

        :return: A field that controls the height of the text.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_leader_line_style": """
        Return the style of the leader line between the label and the label object.

        :return: The style of the leader line between the label and its label.
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_matrix_label": """
        Return the matrix label in the label map. In the matrix label, the labels are arranged together in a matrix.

        :return: matrix label in label map
        :rtype: LabelMatrix
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_max_label_length": """
        Return the maximum length of the label displayed in each line. The default value is 256

        If the input character exceeds the set maximum length, it can be processed in two ways. One is to display in a line break mode. This method automatically adjusts the word spacing to make the number of characters in each line as close as possible.
        So, the number of characters displayed in each line is less than or equal to the maximum length set; the other is displayed in ellipsis mode. When the input characters are greater than the maximum length set, the extra characters will be displayed in ellipsis mode.

        :return: The maximum length of each line displayed.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_max_text_height": """
        Return the maximum height of the text in the label. This method is effective when the size of the label is not fixed. When the height of the enlarged text exceeds the maximum height, it will not be enlarged. The unit of height is 0.1 mm.

        :return: The maximum height of the text in the label.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_min_text_height": """
        Return the minimum height of the text in the label.

        :return: The minimum height of the text in the label.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_numeric_precision": """
        Return the precision of the number in the label. For example, the number corresponding to the label is 8071.64529347, when the return value is 0, it displays 8071, when it is 1, it displays 8071.6; when it is 3, it is 8071.645

        :return: The precision of the number in the label.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_offset_x": """
        Return the horizontal offset of the label text in the label map relative to the point in the element

        :return: The horizontal offset of the label text in the label map relative to the point in the element.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_offset_y": """
        Return the vertical offset of the label text in the label map relative to the point within the element

        :return: The vertical offset of the label text in the label map relative to the point within the element
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_overlap_avoided_mode": """
        Get text automatic avoidance method

        :return: automatic text avoidance method
        :rtype: AvoidMode
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_overlength_mode": """
        Return the processing method of overlength tags. There is no need to deal with the over-long label, the excess part can be omitted, or it can be displayed in a new line.

        :return: How to handle super long tags
        :rtype: OverLengthLabelMode
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_range_expression": """
        Return the segment field expression. The value in the segment expression must be numeric.
        The user compares each segment value from the beginning to the end according to the return value of the method to determine what style to use to display the label text corresponding to a given label field expression.

        :return: segment field expression
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_range_items": """
        Return the sub-item collection of the range label map. Based on the range result of the field expression value, a range corresponds to a sub-item of the range label map. Add the sub-items of the range label thematic map through this object.

        :return: sub-item collection of the range label thematic map
        :rtype: ThemeLabelRangeItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_range_mode": """
        Return the current segmentation mode.

        :return: segmented mode
        :rtype: RangeMode
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_split_separator": """
        Get the line break used to wrap the label text, which can be: "/", ";", space, etc.

        If you set overlength_mode to: py:attr:`.OverLengthLabelMode.NEWLINE` through the :py:meth:`set_overlength_label` interface, it means line break
        At the same time, the line break is set through split_separator, then the label text will be displayed in a line break at the position specified by the special character.

        When the label thematic map uses line wrapping for ultra-long text processing, you can control the wrapping position of the text by specifying special characters. This requires you to prepare data in advance. In the field for labeling,
        Add the newline character you set in the position where the field value needs to be wrapped, such as "/", ";", and space. When using special characters to wrap, it will wrap at the specified special characters, and the specified special characters will not display.

        :return: newline character used to wrap label text
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_text_extent_inflation": """
        Return the buffer range of the text in the label in the positive X and Y directions. The size of the space occupied by the text in the map can be modified by setting this value, and it must be non-negative.

        :return: The buffer range of the text in the label in the positive X and Y directions.
        :rtype: tuple[int,int]
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_uniform_mixed_style": """
        Return the unified text compound style of the label map

        :return: unified text composite style of label map
        :rtype: MixedTextStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_uniform_style": """
        Return to unified text style

        :return: unified text style
        :rtype: TextStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_unique_expression": """
        Return a single-valued field expression. The expression can be a field or an expression composed of multiple fields. The value of the expression controls the style of the object label. Object labels with the same expression value are displayed in the same style. .

        :return: single value field expression
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.get_unique_items": """
        Return the sub-item collection of the unique value label map. Object labels with the same value based on the expression of a single value field are classified as one type, and a single value corresponds to a sub item of the unique value label map.

        :return: The sub-item collection of the unique value label map.
        :rtype: ThemeLabelUniqueItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_along_line": """
        Return whether to display text along the line. True means that the text is displayed along the line, and False means that the text is displayed normally. The label attributes along the line are only applicable to the thematic map of the line dataset. The default value is True

        :return: Whether to display text along the line.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_angle_fixed": """
        Whether to fix the text angle when displaying text along the line. True means to display the text at a fixed angle of the text, False means to display the text at an angle along the line. The default value is False.

        :return: When displaying text along the line, whether to fix the angle of the text.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_flow_enabled": """
        Return whether to display labels in a fluid manner. The default is True.

        :return: Whether to display the label in the flow
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_leader_line_displayed": """
        Return whether to display the leader line between the label and the object it labels. The default value is False, which means no display.

        :return: Whether to display the leader line between the label and the object it marked.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_offset_prj_coordinate_unit": """
        Get whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system

        :return: Whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system. If it is True, it is the geographic coordinate unit, otherwise the device unit is used.
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_on_top": """
        Return whether the label map layer is displayed on the top layer. The top layer here refers to the upper layer of all non-label thematic map layers.

        :return: Whether the label map layer is displayed on the top layer
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_overlap_avoided": """
        Return whether to allow text to be displayed in a text avoidance mode. Only for the text data in the label thematic layer.

        :return: Whether to automatically avoid text overlapping.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_repeat_interval_fixed": """
        Return whether the cycle label interval is fixed. True means a fixed cycle labeling interval, which does not change with the zoom of the map; False means a cycle labeling interval changes with the zoom of the map.

        :return: return True if the cycle label interval is fixed; otherwise, return False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_repeated_label_avoided": """
        Return whether to avoid repeated labeling on the map.

        For the line data representing Beijing Metro Line 4, if it consists of 4 sub-line segments, when the name field (field value: Metro Line 4) is used as the thematic variable to make a label thematic map and set the label along the line,
        If you do not choose to avoid repeating the map, the display will look like the figure on the left. If you choose to avoid repeated labeling on the map, the system will regard the four sub-lines of this polyline as a line for labeling, and the display effect is shown in the figure below.

        .. image:: ../image/IsRepeatedLabelAvoided.png

        :return:
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_small_geometry_labeled": """
        When the length of the label is greater than the length of the labeled object itself, return whether to display the label.

        When the length of the label is greater than the length of the line or area object itself, if you choose to continue labeling, the label text will be displayed superimposed. In order to display the label clearly and completely, you can use the line break mode to display the label.
        But you must ensure that the length of each line is less than the length of the object itself.

        :return: Whether to display labels whose length is greater than the length of the labeled object itself
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_support_text_expression": """
        Return whether the text expression is supported, that is, the subscript and subscript function. The default value is False, text expressions are not supported

        :return: Whether to support text expressions, namely subscripts and subscripts
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.is_vertical": """
        Whether to use vertical labels

        :return: whether to use vertical label
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.label_expression": """str: label field expression """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.make_default_range": """
        Generate the default range label thematic map.

        :param dataset: The vector dataset used to make the thematic map of segment labels.
        :type dataset: DataestVector or str
        :param str label_expression: label field expression
        :param str range_expression: Range field expression.
        :param range_mode: segment mode
        :type range_mode: RangeMode or str
        :param float range_parameter: segment parameter. When the segment mode is equal distance segment method or square root segment method, this parameter is the segment value; when the segment mode is standard difference segment method, this parameter does not work; when the segment mode is When custom distance, this parameter means custom distance.
        :param color_gradient_type: Color gradient mode.
        :type color_gradient_type: ColorGradientType or str
        :param join_items: external table join items
        :type join_items: list[JoinItem] or tuple[JoinItem]
        :return: Segment label thematic map object
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.make_default_unique": """
        Generate the default unique value label thematic map.

        :param dataset: A vector dataset used to make unique value label thematic maps.
        :type dataset: DatasetVector or str
        :param str label_expression: label field expression
        :param str unique_expression: Specify a field or an expression composed of multiple fields. The value of the expression is used to classify the object labels. Object labels with the same value are displayed in the same style for one category, and labels of different categories are displayed in different styles.
        :param color_gradient_type: color gradient mode
        :type color_gradient_type: ColorGradientType or str
        :param join_items: external table join items
        :type join_items: list[JoinItem] or tuple[JoinItem]
        :return: unique value label map object
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.make_from_xml": """
        Import the thematic map information and construct a new thematic map object.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: thematic map object
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_along_line": """
        Set the display text along the line, only applicable to line data and label thematic map.

        :param bool is_along_line: Whether to display text along the line
        :param bool is_angle_fixed: Whether to fix the angle of the text
        :param culture: The language and cultural habits used along the line. The default is related to the non-Unicode language of the current system. If it is a Chinese environment, it is CHINESE, otherwise it is ENGLISH.
        :type culture: AlongLineCulture or str
        :param direction: the direction of the label along the line
        :type direction: AlongLineDirection or str
        :param drawing_mode: The strategy used for label drawing
        :type drawing_mode: AlongLineDrawingMode or str
        :param float space_ratio: The space ratio of the text along the line, which is a multiple of the character height.
                                  note:

                                   * If the value is greater than 1, the line center shall prevail, and mark on both sides according to the specified interval

                                   * If the value is between 0 and 1 (including 1), a single text will be marked at the line center according to the angle along the line

                                   * The value is less than or equal to 0, using the default labeling mode along the line

        :param int word_angle_range: the tolerance value of the relative angle between word and word or letter and letter, unit: degree
        :param float repeat_interval: The interval of repeated labeling when labeling along the line. The set interval size represents the paper distance of the adjacent mark interval after printing, the unit is 0.1 mm
        :param bool is_repeat_interval_fixed: Whether the cycle label interval is fixed
        :param bool is_repeated_label_avoided: Whether to avoid repeated labeling on the map
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_back_shape": """
        Set the shape type of the label background in the label map, no background is displayed by default

        :param value: The shape type of the label background in the label map
        :type value: LabelBackShape or str
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_back_style": """
        Return the label background style in the label map.

        :param GeoStyle value: The label background style in the label map.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_flow_enabled": """
        Set whether to display labels in a fluid manner. Flow display is only suitable for labeling of line and area features

        :param bool value: Whether to display the label in a fluid manner.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_label_angle_expression": """
        Set a field, the field is a numeric field, the field value controls the rotation angle of the text. After specifying the field, the text rotation angle of the label will be read from the field value in the corresponding record.

        :param str value: A field, the field is a numeric field, the field value controls the rotation angle of the text.
                          The value unit is degrees. The angle rotation takes the counterclockwise direction as the positive direction, and the corresponding value is the positive value; the angle value supports the negative value, which means rotating in the clockwise direction.
                          Regarding the label rotation angle and offset, if both are set at the same time, the label is rotated first, and then offset.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_label_color_expression": """
        Set a field, which is a numeric field, and control the text color. After specifying the field, the text color of the label will be read from the field value in the corresponding record.

        :param str value: A field, which is a numeric field, which controls the text color.
                          The color value supports hexadecimal expression as 0xRRGGBB, which is arranged according to RGB.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_label_expression": """
        Set label field expression

        :param str value: label field expression
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_label_font_type_expression": """
        Set a field, the field value is the font name, such as: Microsoft Yahei, Song Ti, to control the font style of the label text in the label map. After specifying the field, the font style of the label will be read from the field value in the corresponding record.

        :param str value: A field that controls the font style of the label text in the label map. If the font specified by the field value does not exist in the current system, or the field value has no value, it will be displayed
                          According to the specific font set by the current TAB thematic map, such as the font in the text style set by the :py:meth:`set_uniform_style` method.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_label_size_expression": """
        Set a field, the field is a numeric field, the field value controls the height of the text, and the numeric unit is millimeters. After specifying the field, the text size of the label will be read from the field value in the corresponding record.

        :param str value: A field that controls the height of the text. If the field value is no value, it will be displayed according to the specific value of the font size set in the current label map
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_leader_line": """
        Set whether to display the leader line between the label and the label object, and the style of the leader line, etc.

        :param bool is_displayed: Whether to display the leader line between the label and the object it marks.
        :param GeoStyle leader_line_style: The style of the leader line between the label and its label.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_matrix_label": """
        Set the matrix label in the label map. In the matrix label, the labels are arranged together in a matrix.

        :param LabelMatrix value: the matrix label in the label map
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_max_text_height": """
        Set the maximum height of the text in the label. This method is effective when the size of the label is not fixed. When the height of the enlarged text exceeds the maximum height, it will not be enlarged. The unit of height is 0.1 mm.

        :param int value: The maximum height of the text in the label.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_min_text_height": """
        Set the minimum height of the text in the label.

        :param int value: The maximum width of the text in the label.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_numeric_precision": """
        Set the precision of the numbers in the label. For example, the number corresponding to the label is 8071.64529347, when the return value is 0, it displays 8071, when it is 1, it displays 8071.6; when it is 3, it is 8071.645.

        :param int value: The precision of the number in the label.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_offset_prj_coordinate_unit": """
        Set whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system. If it is True, it is the geographic coordinate unit, otherwise the device unit is used. For details, check the :py:meth:`set_offset_x` and :py:meth:`set_offset_y` interfaces.

        :param bool value: Whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_offset_x": """
        Set the horizontal offset of the label text in the label map relative to the point in the feature.
        The value of the offset is a constant value or the value represented by the field expression, that is, if the field expression is SmID, where SmID=2, then the value of the offset is 2.

        The unit of the offset is determined by: py:meth:`.set_offset_prj_coordinate_unit`, True means the geographic coordinate unit is used, otherwise the device unit is used

        :param str value:
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_offset_y": """
        Set the vertical offset of the label text in the label map relative to the point in the element.

        The value of the offset is a constant value or the value represented by the field expression, that is, if the field expression is SmID, where SmID=2, then the value of the offset is 2.

        :param str value: The vertical offset of the label text in the label map relative to the point in the element.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_on_top": """
        Set whether the label map layer is displayed on the top layer. The top layer here refers to the upper layer of all non-label thematic map layers.

        In general mapping, the label thematic map layer in the map will be placed in front of all non-label thematic map layers, but when layer grouping is used, the label thematic layer in the group may be covered by other normal layers in the upper layer group.
        In order to maintain the layer group state and make the label not be covered, you can use the set_on_top method to pass true value. The label thematic map will appear first regardless of its current position on the map.
        If there are multiple label thematic map layers that pass in the true value through the set_on_top method, the display order between them is determined by the layer order of the map where they are located.

        :param bool value: Whether the label map layer is displayed on the top layer
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_overlap_avoided": """
        Set whether to allow text to be displayed in a text avoidance mode. Only for the text data in the label thematic layer.

        Note: In the case of large label overlap, even if the automatic avoidance function is used, it may not be possible to completely avoid label overlap. When two overlapping labels are set with text avoidance at the same time,
        The preceding ID tag text has precedence in drawing.

        :param bool value: whether to automatically avoid text overlap
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_overlap_avoided_mode": """
        Set automatic text avoidance method

        :param value: text automatic avoidance method
        :type value: AvoidMode or str
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_overlength_label": """
        Set to handle very long text.

        :param overlength_mode: The processing mode of overlength tags. There is no need to deal with the over-long label, the excess part can be omitted, or it can be displayed in a new line.
        :type overlength_mode: OverLengthLabelMode or str
        :param int max_label_length: The maximum length of the label displayed in each line. If it exceeds this length, it can be handled in two ways, one is to display in a newline mode, and the other is to display in an ellipsis mode.
        :param str split_separator: The line break used to wrap the label text, which can be: "/", ";", space, etc. When the ultra-long label processing mode is NEWLINE, it will wrap according to the specified character.
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_range_label": """
        Set the range label thematic map.

        :param str range_expression: Range field expression. The value in the segment expression must be numeric.
        :param range_mode: segment mode
        :type range_mode: RangeMode or str
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_small_geometry_labeled": """
        When the length of the label is greater than the length of the labeled object itself, set whether to display the label.

        When the length of the label is greater than the length of the line or area object itself, if you choose to continue labeling, the label text will be displayed superimposed. In order to display the label clearly and completely, you can use the line feed mode to display the label.
        But you must ensure that the length of each line is less than the length of the object itself.

        :param bool value: Whether to display labels whose length is greater than the length of the labeled object itself
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_support_text_expression": """
        Set whether to support text expressions, that is, subscripts and subscripts.
        When the selected field is a text type, the text contains superscripts and subscripts, and is based on specific standards (for text expressions, please refer to the following description), you need to set this property to display the text correctly (as shown in the right picture below).
        The following figure shows the effect comparison when setting this property to False and True:

        .. image:: ../image/isTextExpression.png

        note:

         * When this property is set to true, the alignment of labels with subscripts and subscripts can only be displayed as the "top left corner" effect, and the alignment of labels for text without subscripts and subscripts is the same as the alignment set in the text style.
         * Text labels with a rotation angle are not supported, that is, when the rotation angle of the text label is not 0, the setting of this attribute is invalid.
         * Text labels displayed in vertical and new lines are not supported.
         * Text tags containing strikethrough, underline, and separator are not supported.
         * Text labels marked along the lines of the label thematic map of the line dataset are not supported.
         * When the map has a rotation angle, the text label set to support the text expression will not rotate with the rotation of the map.
         * The text label of the label thematic map with special symbols is not supported.
         * In a text expression containing subscripts and subscripts, #+ means superscript; #- means subscript, #= means to split a string into two superscript and subscript parts.
         * If the text label that supports text expressions starts with "#+", "#-", "#=", the entire string is output as it is.

        The following figure shows the effect comparison when setting this attribute to false and true:

        .. image:: ../image/isTextExpression_1.png

        * When #+ or #- is encountered, the string immediately behind will be regarded as the subscript content, and the new string rule will be adopted when #+ or #- is encountered for the third time. The following figure shows the effect comparison when setting this attribute to flse and true respectively.

          .. image:: ../image/isTextExpression_2.png

        * In a text expression containing subscripts and subscripts, two consecutive "#+" have the same effect as "#-", and two consecutive "#-" have the same effect as "#+". The following figure shows the effect comparison when setting this attribute to false and true:

          .. image:: ../image/isTextExpression_3.png

        * Currently the types of label thematic maps that support this function are unified style label thematic maps, segment style label thematic maps and label matrix thematic maps.

        :param bool value: Whether to support text expressions
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_text_extent_inflation": """
        Set the buffer range of the text in the label in the positive X and Y directions. The size of the space occupied by the text in the map can be modified by setting this value, and it must be non-negative.

        :param int width: size in X direction
        :param int height: Y direction size
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_uniform_mixed_style": """
        Set the unified text compound style of the label map.
        When the text composite style (:py:meth:`.get_uniform_mixed_style`) and the text style (:py:meth:`.get_uniform_style`) are set at the same time,
        Drawing style priority, text compound style is greater than text style.

        :param MixedTextStyle value: The text compound style of the label map
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_uniform_style": """
        Set uniform text style

        :param TextStyle value: unified text style
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_unique_label": """
        Set the unique value label label thematic map.

        :param str unique_expression: single value field expression
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.set_vertical": """
        Set whether to use vertical labels.

         * Matrix label and label along the line are not supported.
         * Text labels with a rotation angle are not supported, that is, when the rotation angle of the text label is greater than 0, the setting of this attribute is invalid.

        :param bool value: whether to use vertical label
        :return: self
        :rtype: ThemeLabel
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.to_xml": """
        Export thematic map information as XML string.

        :return: XML string of thematic map information
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabel.type": """ThemeType: Thematic map type""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem": """
    The sub-item of the range label thematic map.

    The segment label map refers to the segmentation of object labels based on the value of the specified field expression. Object labels in the same section are displayed in the same style, and labels in different sections are displayed in different styles. Among them, a piecewise
    Corresponds to a segmented label project items.
    """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.__init__": """
        :param float start: The starting value of the corresponding segment of the sub-item.
        :param float end: The end value of the corresponding sub-item.
        :param str caption: The name of the subkey.
        :param TextStyle style: The text style of the child item.
        :param bool visible: Whether the sub item of the range label map is visible
        :param float offset_x: The offset of the label in the child item in the X direction.
        :param float offset_y: The offset of the label in the child item in the Y direction.
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.caption": """str: The name of the sub-item.""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.end": """float: the end value of the sub-item corresponding to the segment.""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.offset_x": """float: The offset of the label in the child item in the X direction.""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.offset_y": """float: The offset of the label in the child item in the Y direction.""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.set_caption": """
        Set the name of the child.

        :param str value: The name of the sub-item.
        :return: self
        :rtype: ThemeLabelRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.set_end": """
        Set the end value of the corresponding sub-item.

        :param float value:
        :return: self
        :rtype: ThemeLabelRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.set_offset_x": """
        Set the offset of the label in the child item in the X direction

        :param float value: The offset of the label in the child item in the X direction
        :return: self
        :rtype: ThemeLabelRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.set_offset_y": """
        Set the offset of the label in the child item in the Y direction.

        :param float value: The offset of the label in the child item in the Y direction.
        :return: self
        :rtype: ThemeLabelRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.set_start": """
        Set the starting value of the corresponding sub-item.

        :param float value: The starting value of the corresponding segment of the sub-item.
        :return: self
        :rtype: ThemeLabelRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.set_style": """
        Set the text style of the child

        :param TextStyle value: the text style of the child
        :return: self
        :rtype: ThemeLabelRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.set_visible": """
        Set whether the sub-items of the range label thematic map are visible

        :param bool value: Whether the sub item of the range label map is visible
        :return: self
        :rtype: ThemeLabelRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.start": """float: the starting value of the sub-item corresponding to the segment.""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.style": """TextStyle: the text style of the child""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItem.visible": """bool: Whether the sub-items of the segment label thematic map are visible""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItems": """
    The sub-item collection of the range label map.

    The segment label map refers to the segmentation of object labels based on the value of the specified field expression. Object labels in the same section are displayed in the same style, and labels in different sections are displayed in different styles. Among them, a piecewise
    Corresponds to a segmented label project items.
    """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItems.add": """
        Add sub-item of thematic map of range label

        :param ThemeLabelRangeItem item: sub-item of thematic map of segment labels
        :param bool is_normalize: Whether to correct the illegal sub-item, True to correct it, False to not correct it and throw an exception to change the sub-item to an illegal value.
        :param bool is_add_to_head: Whether to add to the head of the list. If it is True, it will be added to the head of the list. If it is False, it will be added to the end.
        :return: self
        :rtype: ThemeLabelRangeItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItems.clear": """
        Delete the sub-items of the range label map. After executing this method, all the label thematic map items are released and are no longer available.

        :return: self
        :rtype: ThemeLabelRangeItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItems.extend": """
        Add sub-items of the range label thematic map in batches. By default, they are added to the end of the sub-item list in order.

        :param items: the sub-item list of the segment label map
        :type items: list[ThemeLabelRangeItem] or tuple[ThemeLabelRangeItem]
        :param bool is_normalize: Whether to correct the illegal sub-item, True to correct it, False to not correct it and throw an exception to change the sub-item to an illegal value.
        :return: self
        :rtype: ThemeLabelRangeItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItems.get_count": """
        Return the number of sub-items in the sub-item set of the range label map.

        :return: the number of sub-items in the sub-item set of the range label map
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItems.get_item": """
        Return the sub-item in the sub-item set of the range label thematic map with the specified serial number.

        :param int index: The number of the specified sub-item of the range label map.
        :return: The sub-item in the sub-item set of the range label map with the specified serial number.
        :rtype: ThemeLabelRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItems.index_of": """
        Return the serial number of the specified range field value in the current range sequence in the label map.

        :param str value: The value of the given segment field.
        :return: The sequence number of the segment field value in the segment sequence. If the value does not exist, -1 is returned.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelRangeItems.reverse_style": """
        Display the styles of the ranges in the range label map in reverse order.

        :return: self
        :rtype: ThemeLabelRangeItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem": """
    The sub-item of the unique value label map.

    The unique value label map refers to the classification of object labels based on the value of the specified field expression. Object labels with the same value are displayed in the same style for one category, and labels of different categories are displayed in different styles; among them, a single value
    Corresponds to a single value label thematic map subitem.
    """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.__init__": """

        :param str unique_value: single value.
        :param str caption: The name of the item of the unique value label map.
        :param TextStyle style: text style corresponding to single value
        :param bool visible: Whether the items of the unique value label map are visible
        :param float offset_x: The offset of the label in the child item in the X direction
        :param float offset_y: The offset of the label in the child item in the Y direction
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.caption": """str: The name of the unique value label thematic map item """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.offset_x": """float: the offset of the label in the child item in the X direction""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.offset_y": """float: the offset of the label in the child item in the Y direction""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.set_caption": """
        Set the name of the sub-item of the unique value label map

        :param str value:
        :return: self
        :rtype: ThemeLabelUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.set_offset_x": """
        Set the offset of the label in the child item in the X direction.

        :param float value: The offset of the label in the child item in the X direction
        :return: self
        :rtype: ThemeLabelUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.set_offset_y": """
        Set the offset of the label in the child item in the Y direction.

        :param float value: The offset of the label in the child item in the Y direction
        :return: self
        :rtype: ThemeLabelUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.set_style": """

        :param TextStyle value:
        :return: self
        :rtype: ThemeLabelUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.set_unique_value": """
        Set the single value corresponding to the sub item of the unique value label map.

        :param str value: The single value corresponding to the sub item of the unique value label map.
        :return: self
        :rtype: ThemeLabelUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.set_visible": """
        Set whether the child items of the unique value label map are visible. True means visible, False means invisible.

        :param bool value: Whether the items of the unique value label map are visible
        :return: self
        :rtype: ThemeLabelUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.style": """TextStyle: """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.unique_value": """str: Return the single value corresponding to the item of the unique value label map. """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItem.visible": """bool: Return whether the unique value label thematic map item is visible.""",

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems": """
    The sub-item collection of the unique value label map.

    The unique value label map refers to the classification of object labels based on the value of the specified field expression. Object labels with the same value are displayed in the same style for one category, and labels of different categories are displayed in different styles; among them, a single value
    Corresponds to a single value label thematic map subitem.

    """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.add": """
        Add a sub-item to the sub-item set of the unique value label map.

        :param ThemeLabelUniqueItem item: the unique value label thematic map item to be added to the collection
        :return: self
        :rtype: ThemeLabelUniqueItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.clear": """
        Delete the item in the item set of the unique value label map. After executing this method, all the sub-items of the unique value label map are released and are no longer available.

        :return: self
        :rtype: ThemeLabelUniqueItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.extend": """
        Batch add sub-items of unique value label thematic map

        :param items: unique value label thematic map sub-item collection
        :type items: list[ThemeLabelUniqueItem] or tuple[ThemeLabelUniqueItem]
        :return: self
        :rtype: ThemeLabelUniqueItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.get_count": """
        Return the number of items in the unique value label map item set.

        :return: the number of items in the item set of the unique value label map
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.get_default_offset_x": """
        Return the offset in the X direction of the label in the default sub-item of the unique value label map

        :return: The offset of the label in the X direction in the default sub-item of the unique value label map
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.get_default_offset_y": """
        Return the offset of the label in the default sub-item of the unique value label map in the Y direction

        :return: The offset of the label in the default sub-item of the unique value label map in the Y direction
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.get_default_style": """
        Return the text style of the default item of the unique value label map

        :return: The text style of the default sub-item of the unique value label map
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.get_item": """
        Return the item in the set of unique value label thematic map items with the specified serial number

        :param int index: specify the serial number
        :return: unique value label thematic map item
        :rtype: ThemeLabelUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.insert": """
        Insert a sub-item into the sub-item set of the unique value label map.

        :param int index: Specify the number position of the subitem insertion.
        :param ThemeLabelUniqueItem item: The specified unique value label thematic map item to be added to the collection.
        :return: Return True if the insert is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.remove": """
        Remove the unique value label thematic map item at the specified sequence number in the collection.

        :param int index: the serial number of the unique value label map item to be removed
        :return: Return True if the removal is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.reverse_style": """
        Display the unique value style in the unique value label map in reverse order.

        :return: self
        :rtype: ThemeLabelUniqueItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.set_default_offset_x": """
        Set the X-direction offset of the label in the default sub-item of the unique value label map

        :param float value: The offset of the label in the default sub-item of the unique value label map in the X direction
        :return: self
        :rtype: ThemeLabelUniqueItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.set_default_offset_y": """
        Set the Y-direction offset of the label in the default sub-item of the unique value label map

        :param float value: The offset of the label in the default sub-item of the unique value label map in the Y direction
        :return: self
        :rtype: ThemeLabelUniqueItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeLabelUniqueItems.set_default_style": """
        Set the text style of the default sub-item of the unique value label map. The default style is used for the sub-item that does not specify the corresponding single value.

        :param GeoStyle style: The text style of the default sub-item of the unique value label map
        :return: self
        :rtype: ThemeLabelUniqueItems
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange": """
    Range thematic map class.
    The attribute value of the field is segmented according to the provided segmentation method, and the display style of the corresponding object is given according to the segment range where each attribute value is located.

    note:
    To make a range thematic map, if there is no style set for the beginning and end intervals, and no default style is set, then whether it is added to the beginning or the end, the beginning and end intervals default to the style of the first section added by the user, for example:
    There are 5 sections in total. The :py:meth:`.add` method adds three sections [0, 1), [1, 2), [2, 4) in sequence, then the first interval (negative infinity, 0), the end interval [ 4. Positive infinity), using the style of [0,1).

    The following code demonstrates the creation of a default range thematic map through a dataset::

    >>> ds = open_datasource('/home/data/data.udb')
    >>> dt = ds['zones']
    >>> mmap = Map()
    >>> theme = ThemeRange.make_default(dt,'SmID', RangeMode.EUQALINTERVAL, 6, ColorGradientType.RAINBOW)
    >>> mmap.add_dataset(dt, True, theme)
    >>> mmap.set_image_size(2000, 2000)
    >>> mmap.view_entire()
    >>> mmap.output_to_file('/home/data/mapping/range_theme.png')

    You can also create unique values map in the following ways:

    >>> ds = open_datasource('/home/data/data.udb')
    >>> dt = ds['zones']
    >>>
    >>> theme = ThemeRange('SmID')
    >>> theme.add(ThemeRangeItem(1, 20, GeoStyle().set_fill_fore_color('gold'), '1'), is_add_to_head=True)
    >>> theme.add(ThemeRangeItem(20, 50, GeoStyle().set_fill_fore_color('rosybrown'), '2'), is_add_to_head=False)
    >>> theme.add(ThemeRangeItem(50, 90, GeoStyle().set_fill_fore_color('coral'), '3'), is_add_to_head=False)
    >>> theme.add(ThemeRangeItem(90, 160, GeoStyle().set_fill_fore_color('crimson'), '4'), is_add_to_head=False)
    >>> mmap.add_dataset(dt, True, theme)
    >>> mmap.set_image_size(2000, 2000)
    >>> mmap.view_entire()
    >>> mmap.output_to_file('/home/data/mapping/range_theme.png')

    """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.__init__": """
        :param str expression: segment field expression.
        :param items: List of sub-items of range thematic map
        :type items: list[ThemeRangeItem] or tuple[ThemeRangeItem]
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.add": """
        Add a range thematic map item

        :param item: sub-item of range thematic map
        :type item: ThemeRangeItem
        :param bool is_normalize: Indicates whether to normalize. When is_normalize is True, if the item value is illegal, then normalize is performed. When is_normalize is Fasle, if the item value is illegal, an exception will be thrown.
        :param bool is_add_to_head: Whether to add to the beginning of the segment list. If it is False, it is added to the end of the segment list.
        :return: self
        :rtype: ThemeRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.clear": """
        Delete all the sub-items of the range map. After executing this method, all the sub-items of the range map are released and are no longer available.

        :return: self
        :rtype: ThemeRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.expression": """str: segment field expression """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.extend": """
        Add sub-items of range thematic map in batch

        :param items: List of sub-items of range thematic map
        :type items: list[ThemeRangeItem] or tuple[ThemeRangeItem]
        :return: self
        :rtype: ThemeRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.from_xml": """
        Import thematic map information from XML string.
        In SuperMap, the style settings of various thematic maps can be exported into XML format strings. This XML format string records all the settings related to this thematic map, such as
        The XML format string for a tag topic map will record the topic map type, visible scale, tag style Settings, whether it flows, whether it automatically avoids, etc. All the style Settings for the tag topic map
        And the fields or expressions used to make the tag topic map. This XML format string can be used to import and set thematic maps

        It should be noted that the information recorded in xml must correspond to the type of the current object. For example, if the label map information recorded in xml, the current object must be a ThemeLabel object.
        If you don't know the type of thematic map recorded in xml, you can use :py:meth:`.Theme.make_from_xml` to construct a new thematic map object from xml.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: Return True if the import is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.get_count": """
        Return the number of ranges in the ranges map

        :return: the number of ranges in the range map
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.get_custom_interval": """
        Get custom segment length

        :return: self-positioning segment length
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.get_item": """
        Return the range thematic map item of the specified serial number

        :param int index: the serial number of the specified range map
        :return: range thematic map item
        :rtype: ThemeRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.get_offset_x": """
        Get the horizontal offset

        :return: horizontal offset
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.get_offset_y": """
        Get the vertical offset

        :return: vertical offset
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.get_precision": """
        Get the rounding precision of the range range map.

        :return: rounding precision
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.index_of": """
        Return the serial number of the specified range field value in the current range sequence in the ranges map.

        :param str value: The value of the given segment field.
        :return: The sequence number of the segment field value in the segment sequence. If the value does not exist, -1 is returned.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.is_offset_prj_coordinate_unit": """
        Get whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system

        :return: Whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system. If it is True, it is the geographic coordinate unit, otherwise the device unit is used.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.make_default": """
        According to the given vector dataset, segment field expression, segment mode, corresponding segment parameters, color gradient filling mode, external connection entries and rounding precision, generate the default segment thematic map.

        Note: When making thematic maps by connecting external tables, for UDB datasources, the connection type does not support inner joins, that is, the :py:attr:`.JoinType.INNERJOIN` connection type is not supported.

        :param dataset: Vector dataset.
        :type dataset: DatasetVector or str
        :param str expression: segment field expression
        :param range_mode: segment mode
        :type range_mode: str or RangeMode
        :param float range_parameter: segment parameter. When the segmentation mode is one of equidistant segmentation method, square root segmentation, logarithmic segmentation method, and equal counting segmentation method, this parameter is the number of segments;
                                      When the segment mode is the standard difference segment method, this parameter does not work; when the segment mode is a custom distance, this parameter represents a custom distance.
        :param color_gradient_type: color gradient mode
        :type color_gradient_type: ColorGradientType or str
        :param float range_precision: The precision of the segment value. For example, the calculated segment value is 13.02145, and the segment accuracy is 0.001, the segment value is 13.021
        :param join_items: External table join items. If you want to add the created thematic map to the map as a layer in the map, you need to make the following settings for the thematic map layer,
                           Through the :py:meth:`.Layer.set_display_filter` method of the Layer object corresponding to the thematic map Layer, The parameter in this method is the :py:class:`.QueryParameter` object.
                           :py:meth:`.QueryParameter.set_join_items` method through QueryParameter object is needed here, connect the project external table items (i.e., the current method of join_items parameters) assigned to the project tutu Layer corresponding object Layer,
                           So do project shown in the figure on the map is right.
        :type join_items: list[JoinItem] or tuple[JoinItem]
        :return: result range thematic map object
        :rtype: ThemeRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.make_from_xml": """
        Import the thematic map information and construct a new thematic map object.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: thematic map object
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.range_mode": """RangeMode: Segmentation Mode""",

    "iobjectspy._jsuperpy.mapping.ThemeRange.reverse_style": """
        Display the styles of the ranges in the range map in reverse order. For example, the thematic map has three segments, namely item1, item2, and item3. After calling the reverse order display, the style of item3 and item1 will be exchanged, and the display style of item2 remains unchanged.

        :return: self
        :rtype: ThemeRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.set_expression": """
        Set the segment field expression.
        By comparing the value of a certain element segment field expression with the segment value of each segment range (determined according to a certain segment mode), the range segment of the element is determined, and the elements falling in different segments Set to different styles.

        :param str value: Specify the segment field expression.
        :return: self
        :rtype: ThemeRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.set_offset_prj_coordinate_unit": """
        Set whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system. If it is True, it is the geographic coordinate unit, otherwise the device unit is used. For details, check the :py:meth:`set_offset_x` and :py:meth:`set_offset_y` interfaces.

        :param bool value: Whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system
        :return: self
        :rtype: ThemeRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.set_offset_x": """
        Set the horizontal offset.

        The unit of the offset is determined by: py:meth:`.set_offset_prj_coordinate_unit`, True means the geographic coordinate unit is used, otherwise the device unit is used

        :param str value: The offset in the horizontal direction.
        :return: self
        :rtype: ThemeRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.set_offset_y": """
        Set the vertical offset.

        The unit of the offset is determined by: py:meth:`.set_offset_prj_coordinate_unit`, True means the geographic coordinate unit is used, otherwise the device unit is used

        :param str value:
        :return: self
        :rtype: ThemeRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.set_precision": """
        Set the rounding precision of the range thematic map.

        For example, if the calculated segment value is 13.02145 and the segment accuracy is 0.001, the segment value will be 13.021.

        :param float value: rounding precision
        :return: self
        :rtype: ThemeRange
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.to_xml": """
        Export thematic map information as XML string.

        :return: XML string of thematic map information
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRange.type": """ThemeType: Thematic map type""",

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem": """
    The sub-item class of the range map.
    In the range map, the value of the range field expression is divided into multiple range segments according to a certain range mode. Each segment has its start value, end value, name and style, etc. The range represented by each segment is [Start, End).
    """,

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.__init__": """
        :param float start: The starting value of the range map item.
        :param float end: The end value of the range map item.
        :param str caption: The name of the sub-item of the range map.
        :param GeoStyle style: The display style of the sub-items of the range map.
        :param bool visible: Whether the sub item in the range map is visible.
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.caption": """str: The name of the item in the range map.""",

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.end": """float: the end value of the range thematic map item""",

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.set_caption": """
        Set the name of the item in the range map.

        :param str value: The name of the item in the range map.
        :return: self
        :rtype: ThemeRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.set_end": """
        Set the end value of the range map item.

        :param float value: the end value of the range map item
        :return: self
        :rtype: ThemeRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.set_start": """
        Set the starting value of the range map item.

        If the sub-item is the first sub-item in the segment, then the starting value is the minimum value of the segment; if the sequence number of the sub-item is greater than or equal to 1, the starting value must be the same as the ending value of the previous sub-item Same, otherwise the system will throw an exception.

        :param float value: the starting value of the range map item
        :return: self
        :rtype: ThemeRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.set_style": """
        Set the corresponding style of each item in the ranges map.

        :param GeoStyle value: The corresponding style of each range map item in the ranges map.
        :return: self
        :rtype: ThemeRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.set_visible": """
        Set whether the sub items in the ranges map are visible.

        :param bool value: Specify whether the sub item in the range map is visible.
        :return: self
        :rtype: ThemeRangeItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.start": """float: the starting value of the range thematic map item""",

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.style": """GeoStyle: Return the corresponding style of each range map item in the range map. """,

    "iobjectspy._jsuperpy.mapping.ThemeRangeItem.visible": """bool: Return whether the child item in the range map is visible. """,

    "iobjectspy._jsuperpy.mapping.ThemeType": """
    The thematic map type constant.

    Both vector data and raster data can be used to make thematic maps. The difference is that vector data thematic maps are based on the attribute information in the attribute table, while raster data is based on pixel values. SuperMap provides thematic maps for vector data
    (points, lines, planes, and composite datasets),including single value thematic map, the scope of piecewise thematic map, point density thematic map, statistic thematic map and thematic map level symbols, labels projects and custom chart,
    Also provide suitable for raster data (grid dataset) of thematic map function, including grid section thematic map and thematic map grid single values.

    :var ThemeType.UNIQUE: Unique value thematic map. In the unique values map, elements with the same value of thematic variables are grouped into one category, and a rendering style is set for each category, such as color or symbol, etc.,
                           While elements with the same value of fields or expressions of thematic variables adopt the same rendering style, so as to distinguish different categories.

    :var ThemeType.RANGE: Range thematic map. In the range map, the values of thematic variables are divided into multiple range segments, and elements or records in the same range segment are displayed with the same color or symbol style.
                          The available segmentation methods are equidistant segmentation method, square root segmentation method, standard difference segment method, logarithmic segmentation method, and equal counting segmentation method. The thematic variables on which
                          The subsection thematic map is based must be of numerical type.

    :var ThemeType.GRAPH: Statistical thematic map. Statistical thematic map draws a statistical map for each element or record to reflect the value of its corresponding thematic variable. Statistical thematic maps can be based on multiple variables, reflecting multiple
                          Properties, that is, the values of multiple variables can be plotted on a statistical graph. The types of statistical graphs currently provided are: area graphs, ladder graphs, line graphs, dot graphs, histograms, and three-dimensional column graphs,
                          Pie charts, 3D pie charts, rose charts, 3D rose charts, stacked column charts and 3D stacked column charts.

                           .. image:: ../image/graphy.png

    :var ThemeType.GRADUATEDSYMBOL: Thematic map of graduated symbols. The graduated symbol map uses the size of the symbol to express the value of the field or expression (thematic variable) corresponding to the element or record.
                                    When using gradient symbols to draw features, elements or records in a range segment are drawn with symbols of the same size.
                                    The thematic variables on which the graduated symbols map is based must be numeric.

                                     .. image:: ../image/graduatedSymbol.png

    :var ThemeType.DOTDENSITY: Dot density thematic map. The dot density thematic map uses the number or density of points to reflect the value of the thematic data corresponding to a region or range, one of the points
                               Represents a certain number, then the number of points in a region multiplied by the number of points represents the value of the thematic variable corresponding to this region. The more the number of points is,
                               The denser the density or concentration of the thing or phenomenon reflected by the data is in this region. The thematic variables on which the point density thematic map is based must be numerical.

                                .. image:: ../image/dotDensity.png

    :var ThemeType.LABEL: Label thematic map. The label thematic map is to display the data in the attribute table directly on the layer in the form of text, which is essentially the labeling of the layer

                           .. image:: ../image/labelM.png

    :var ThemeType.CUSTOM: Custom thematic map. By customizing the thematic map, users can set a specific style for each element or record, and store these settings in one or more fields, and then
                           Based on this or the field to map project. In SuperMap, various symbols, line styles or filling styles have corresponding ID values, and the color value, symbol size, line width, etc.
                           Both can be set with numerical data. Using custom thematic maps, users are very free to express various elements and data.

    :var ThemeType.GRIDRANGE: grid range thematic map. In the grid range thematic map, all the cell values of the grid are divided into multiple range segments, pixels within the same range segment are displayed with the same color.
                              The available segmentation methods are equidistant segmentation method, square root segmentation method, and logarithmic segmentation method.

                               .. image:: ../image/gridRanges.png

    :var ThemeType.GRIDUNIQUE: Grid unique values map. In the grid unique values map, the pixels with the same pixel value in the grid are grouped into one category, and a color is set for each category to distinguish different categories.
                               For example, in a land use classification map, pixels with the same land use type have the same value and will be rendered with the same color to distinguish different land use types.

                                .. image:: ../image/gridUnique.png

    """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique": """
    Unique value thematic map class.

    Elements with the same value in a field or expression are displayed in the same style, so as to distinguish different categories. For example, in the surface data representing land, the fields representing land use type include grassland, woodland, residential land, arable land equivalent,
    When the unique value map is used for rendering, each type of land use type is given a color or filling style, so that the distribution area and scope of each type of land use can be seen. Can be used for geological maps,
    Landform maps, vegetation maps, land use maps, political and administrative division maps, natural division maps, economic division maps, etc. The unique value thematic map emphasizes the difference of the qualitative phenomena, and generally does not indicate the characteristics of the quantity. Especially if there is crossover or overlap
    It is not recommended to use this type when it is like, for example: ethnic distribution area.

    Note: If you have established a connection with an external table by means of Join or Link, when the thematic variables of the thematic map are used in the fields of the external table, you need to adjust when displaying the thematic map.
    Use :py:meth:`.Layer.set_display_filter` method, otherwise the thematic map will fail to output.

    The following code demonstrates the creation of a default unique values map through a dataset::

    >>> ds = open_datasource('/home/data/data.udb')
    >>> dt = ds['zones']
    >>> mmap = Map()
    >>> theme = ThemeUnique.make_default(dt,'zone', ColorGradientType.CYANGREEN)
    >>> mmap.add_dataset(dt, True, theme)
    >>> mmap.set_image_size(2000, 2000)
    >>> mmap.view_entire()
    >>> mmap.output_to_file('/home/data/mapping/unique_theme.png')

    You can also create unique values map in the following ways:

    >>> ds = open_datasource('/home/data/data.udb')
    >>> dt = ds['zones']
    >>> mmap = Map()
    >>> default_style = GeoStyle().set_fill_fore_color('yellow').set_fill_back_color('green').set_fill_gradient_mode('RADIAL')
    >>> theme = ThemeUnique('zone', default_style)
    >>> mmap.add_dataset(dt, True, theme)
    >>> mmap.set_image_size(2000, 2000)
    >>> mmap.view_entire()
    >>> mmap.output_to_file('/home/data/mapping/unique_theme.png')

    Or specify custom items::

    >>> ds = open_datasource('/home/data/data.udb')
    >>> dt = ds['zones']
    >>>
    >>> theme = ThemeUnique()
    >>> theme.set_expression('zone')
    >>> color = [Color.gold(), Color.blueviolet(), Color.rosybrown(), Color.coral()]
    >>> zone_values = dt.get_field_values(['zone'])['zone']
    >>> for index, value in enumerate(zone_values):
    >>> theme.add(ThemeUniqueItem(value, GeoStyle().set_fill_fore_color(colors[index% 4]), str(index)))
    >>>
    >>> mmap.add_dataset(dt, True, theme)
    >>> mmap.set_image_size(2000, 2000)
    >>> mmap.view_entire()
    >>> mmap.output_to_file('/home/data/mapping/unique_theme.png')

    """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.__init__": """

        :param str expression: Unique values map field expression. The field or field expression used to make unique values map. This field can be a certain attribute of the feature (such as the age or composition in the geological map),
                               The data type of its value can be numeric or character.
        :param GeoStyle default_style: The default style of unique values map. Use this style to display the objects that are not listed in the sub-items of the unique values map. If not set, the default style of the layer will be used for display.
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.add": """
        Add sub-items of unique values map.

        :param item: unique values map item
        :type item: ThemeUniqueItem
        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.clear": """
        Delete all the sub-items of the unique values map. After executing this method, all the sub-items of the unique values map are released and are no longer available.

        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.expression": """str: unique values map field expression. The field or field expression used to make unique values map. This field can be an attribute of the element (such as Age or composition in the geological map), the data type of its value can be
                It is either numeric or character type. """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.extend": """
        Add sub-items of unique values map in batches.

        :param items: list of unique values map items
        :type items: list[ThemeUniqueItem] or tuple[ThemeUniqueItem]
        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.from_xml": """
        Import thematic map information from XML string.
        In SuperMap, the style settings of various thematic maps can be exported into XML format strings. This XML format string records all the settings related to this thematic map, such as
        The XML format string for a tag topic map will record the topic map type, visible scale, tag style Settings, whether it flows, whether it automatically avoids, etc. All the style Settings for the tag topic map
        And the fields or expressions used to make the tag topic map. This XML format string can be used to import and set thematic maps

        It should be noted that the information recorded in xml must correspond to the type of the current object. For example, if the label map information recorded in xml, the current object must be a ThemeLabel object.
        If you don't know the type of thematic map recorded in xml, you can use :py:meth:`.Theme.make_from_xml` to construct a new thematic map object from xml.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: Return True if the import is successful, otherwise False.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.get_count": """

        :return:
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.get_custom_marker_angle_expression": """
        Return a field expression, which is used to control the rotation angle of the dot symbol in the point single-value question map corresponding to the object. The field in the field expression must be a numeric field. You can specify
        A field or a field expression through this interface; you can also specify a value, and all thematic map items will be rotated uniformly at the angle specified by the value.

        :return: field expression
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.get_custom_marker_size_expression": """
        Return a field expression, which is used to control the size of the dot symbol in the point single-value question map corresponding to the object. The field in the field expression must be a numeric field. You can specify a field
        Or a field expression through this interface; you can also specify a value, and all thematic map items will be displayed uniformly in the size specified by the value.

        This setting is only valid for point unique values map.

        :return: field expression
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.get_default_style": """
        Return the default style of unique values map

        :return: The default style of unique values map.
        :rtype: GeoStyle
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.get_item": """
        Return the unique values map item of the specified serial number.

        :param int index: The serial number of the specified unique values map item.
        :return: unique values map item
        :rtype: ThemeUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.get_offset_x": """
        Return the horizontal offset of the object in the unique values map made by the point, line, and area layer relative to the original position.

        :return: The horizontal offset of the object in the unique values map created by the point, line, and area layer relative to the original position.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.get_offset_y": """
        Return the vertical offset of the object in the unique values map made by the point, line, and area layer relative to the original position.

        :return: The vertical offset of the object in the unique values map created by the point, line, and area layer relative to the original position.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.index_of": """
        Return the serial number of the specified sub-item single value in the unique values map in the current sequence.

        :param str value: The given unique value map item single value.
        :return:
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.insert": """
        Insert the given unique values map item into the position of the specified sequence number.

        :param int index: The serial number of the specified unique values map sub-item sequence.
        :param ThemeUniqueItem item: The unique values map item to be inserted.
        :return: Return True if the insert is successful, otherwise False
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.is_default_style_visible": """
        Whether the default style of unique values map is visible

        :return: Whether the default style of unique values map is visible.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.is_offset_prj_coordinate_unit": """
        Get whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system

        :return: Whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system. If it is True, it is the geographic coordinate unit, otherwise the device unit is used.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.make_default": """
        Generate the default unique values map based on the given vector dataset and unique values map field expression.

        :param dataset: vector dataset
        :type dataset: DatasetVector or str
        :param str expression: Unique values map field expression.
        :param color_gradient_type: color gradient mode
        :type color_gradient_type: str or ColorGradientType
        :param join_items: External table join items. If you want to add the created thematic map to the map as a layer in the map, you need to make the following settings for the thematic map layer,
                           Through the :py:meth:`.Layer.set_display_filter` method of the Layer object corresponding to the thematic map Layer, The parameter in this method is the :py:class:`.QueryParameter` object.
                           :py:meth:`.QueryParameter.set_join_items` method through QueryParameter object is needed here, connect the project external table items (i.e., the current method of join_items parameters) assigned to the project tutu Layer corresponding object Layer,
                           So do project shown in the figure on the map is right.
        :type join_items: list[JoinItem] or tuple[JoinItem]
        :return: new unique values map
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.make_default_four_colors": """
        Generate a default four-color unique value thematic map based on the specified surface dataset, color field name, and color. The four-color unique value thematic map refers to a map, only four colors can make the surface objects with common edges not
        The same color.

        Note: In the case of low complexity of the polygon dataset, four colors can be used to generate a four-color single-value thematic map; if the complexity of the polygon dataset is high, the coloring result may be five colors.

        :param dataset: The specified face dataset. Since this constructor will modify the attribute information of the polygon dataset, it is necessary to ensure that the dataset is not read-only.
        :type dataset: DatasetVector or str
        :param str color_field: The name of the color field. The coloring field must be an integer field. It can be an existing attribute field in the polygon dataset or other self-defined fields. If it is an existing attribute field,
                                The type of the field should be guaranteed to be an integer type. The system will modify the attribute value of the field and assign it to 1, 2, 3 and 4 respectively. If it is a custom field and the field name is valid,
                                The system will first create the field in the surface dataset and assign the values as 1, 2, 3, and 4. Thus, the coloring fields have been assigned values of 1, 2, 3, and 4,
                                Representing four different colors, and the four-color thematic map can be generated according to the values of this field.
        :param Colors colors: The colors passed by the user to make thematic maps. The system does not specify the number of incoming colors. For example, if the user only passes in one color, when the thematic map is generated, the system
                              Will automatically fill in the colors needed for the drawing.
        :return: Four-color unique value thematic map
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.make_from_xml": """
        Import the thematic map information and construct a new thematic map object.

        :param xml: XML string or file path containing thematic map information
        :type xml: str
        :return: thematic map object
        :rtype: Theme
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.remove": """
        Delete a sub-item of the unique values map with a specified serial number.

        :param int index: The serial number of the specified unique values map sub-item sequence to be deleted.
        :return:
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.reverse_style": """
        Display the styles of items in the unique values map in reverse order.

        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.set_custom_marker_angle_expression": """
        Set a field expression, which is used to control the rotation angle of the dot symbol in the point single-value question map corresponding to the object. The field in the field expression must be a numeric field. You can specify a field
        Or a field expression through this interface; you can also specify a value, and all thematic map items will be rotated uniformly at the angle specified by the value.

        This setting is only valid for point unique values map.

        :param str value: field expression
        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.set_custom_marker_size_expression": """
        Set a field expression, which is used to control the size of the dot symbol in the point single-value question map corresponding to the object. The field in the field expression must be a numeric field. You can specify a field
        Or a field expression through this interface; you can also specify a value, and all thematic map items will be displayed uniformly in the size specified by the value.

        This setting is only valid for point unique values map.

        :param str value: field expression
        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.set_default_style": """
        Set the default style of the unique values map. Use this style to display the objects that are not listed in the sub-items of the unique values map. If not set, the default style of the layer will be used for display.

        :param GeoStyle style:
        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.set_default_style_visible": """
        Set whether the default style of the unique values map is visible.

        :param bool value: Whether the default style of unique values map is visible
        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.set_expression": """
        Set the field expression of the unique values map. The field or field expression used to make unique values map. The field can be a certain attribute of the feature (such as the age or composition in a geological map), and the data type of its value can be numeric or character.

        :param str value: Specify the unique value map field expression
        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.set_offset_prj_coordinate_unit": """
        Set whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system. If it is True, it is the geographic coordinate unit, otherwise the device unit is used. For details, check the :py:meth:`set_offset_x` and :py:meth:`set_offset_y` interfaces.

        :param bool value: Whether the unit of the horizontal or vertical offset is the unit of the geographic coordinate system
        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.set_offset_x": """
        Set the horizontal offset of the object in the unique values map made by point, line, and area layer relative to the original position.

        The unit of the offset is determined by: py:meth:`.set_offset_prj_coordinate_unit`, True means the geographic coordinate unit is used, otherwise the device unit is used

        :param str value: The horizontal offset of the object in the unique values map made by point, line, and area layer relative to the original position.
        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.set_offset_y": """
        Set the vertical offset of the objects in the unique values map made by point, line, and area layers relative to the original position.

        The unit of the offset is determined by: py:meth:`.set_offset_prj_coordinate_unit`, True means the geographic coordinate unit is used, otherwise the device unit is used

        :param str value: The vertical offset of the object in the unique values map made by point, line, and area layer relative to the original position.
        :return: self
        :rtype: ThemeUnique
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.to_xml": """
        Export thematic map information as XML string.

        :return: XML string of thematic map information
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUnique.type": """ThemeType: Thematic map type""",

    "iobjectspy._jsuperpy.mapping.ThemeUniqueItem": """
    The sub-item class of unique values map.

    Unique values map is to classify elements with the same thematic value into one category, and set a rendering style for each category, and each category is a thematic map item. For example, use the unique value thematic map to make an administrative division map, , the Name field
    Represents the name of the province/municipality directly under the Central Government, which is used as the thematic variable. If the field value of this field has 5 different values in total, then the administrative district map has 5 thematic map subitems,
    In which the element Name field value in each subitem is the same.
    """,

    "iobjectspy._jsuperpy.mapping.ThemeUniqueItem.__init__": """

        :param str value: the single value of the unique values map item
        :param GeoStyle style: The display style of each unique values map item
        :param str caption: The name of the unique values map item
        :param bool visible: Whether the unique values map item is visible
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUniqueItem.caption": """str: the name of each unique value map item """,

    "iobjectspy._jsuperpy.mapping.ThemeUniqueItem.set_caption": """
        Set the name of each unique values map item

        :param str value: The name of each unique values map item
        :return: self
        :rtype: ThemeUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUniqueItem.set_style": """
        Set the display style of each unique values map item

        :param value: The display style of each unique values map item
        :type value: GeoStyle
        :return: self
        :rtype: ThemeUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUniqueItem.set_value": """
        Set the unique value of the unique values map item

        :param str value: the single value of the unique values map item
        :return: self
        :rtype: ThemeUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUniqueItem.set_visible": """
        Set whether the unique values map item is visible

        :param bool value: Whether the unique values map item is visible
        :return: self
        :rtype: ThemeUniqueItem
        """,

    "iobjectspy._jsuperpy.mapping.ThemeUniqueItem.style": """GeoStyle: the display style of each unique value map item""",

    "iobjectspy._jsuperpy.mapping.ThemeUniqueItem.value": """str: the unique value of the unique value map item """,

    "iobjectspy._jsuperpy.mapping.ThemeUniqueItem.visible": """bool: Whether the unique values map item is visible""",

    "iobjectspy._jsuperpy.mapping.TrackingLayer": """
    Tracking layer class.

    In SuperMap, each map window has a trace layer, or to be precise, each map is displayed with a trace layer. The trace layer is a blank,
    Transparent layer that is always on top of each layer of the map. It is used to temporarily store graphics objects, text, etc., during a process or analysis. The trace layer will exist as long as the map is displayed.
    You cannot remove the trace layer or change its position.

    The main functions of tracking layers in SuperMap are as follows:

    -When you do not want to add a geometric object to the record set, but you need this geometric object, you can temporarily add the geometric object to the tracking layer, and clear the trace layer when you are done with the geometry object.
     For example, when you need to measure the distance, you need to pull a line on the map, but this line does not exist on the map, you can use the tracking layer to achieve this.

    -When the target needs to be dynamically tracked, if the target is placed in the record set, the entire layer must be constantly refreshed to achieve dynamic tracking, which will greatly affect the efficiency.
     If the target to be tracked is placed on the tracking layer, then only the tracking layer needs to be refreshed to realize the dynamic tracking.

    -When you need to batch add geometric objects to the record set, you can temporarily place these objects on the tracking layer, and then batch add geometry objects from the trace layer to the recordset after you determine
     That you need to add them.

    Please be careful to avoid using the trace layer as a container to store a large number of temporary geometry objects. If there is a large number of temporary data, it is recommended to create a temporary datasource in the local computer temporary directory (e.g. c:	emp)
    And create the corresponding temporary dataset in the temporary datasource to store the temporary data.

    You can control the trace layer, including whether the trace layer is displayed and whether the symbol scales with the image. Unlike a normal layer, objects in a trace layer are not saved, but are temporarily stored in memory
    While the map is displayed. When the map is closed, the objects in the trace layer will still exist, and the corresponding memory will not disappear until the map is opened again.
    When the map is opened again, the trace layer will appear as a blank and transparent layer.

    This class provides management methods for adding, deleting, and so on geometry objects on trace layers. You can also classify the geometry objects on the trace layer by setting labels.
    You can think of labels as descriptions of the geometry objects. Geometry objects with the same purpose can have the same label.
    """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.add": """
        Add a geometric object to the current tracking layer and give its label information.

        :param geo: The geometric object to be added.
        :type geo: Rectangle or Geometry or Point2D or Feature
        :param str tag: The tag of the geometric object to be added.
        :return: The index of the geometric object added to the tracking layer.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.clear": """
        Clear all geometric objects in this tracking layer.

        :return: self
        :rtype: TrackingLayer
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.finish_edit_bulk": """
        Complete batch update

        :return: self
        :rtype: TrackingLayer
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.flush_bulk_edit": """
        During batch update, it is forced to refresh and save the data of this batch editing.

        :return: Force refresh to return true, otherwise return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.get": """
        Return the geometric object with the specified index in this tracking layer.

        :param int index:
        :return: The geometric object of the specified index.
        :rtype: Geometry
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.get_symbol_scale": """
        Return the symbol zoom reference scale of this tracking layer.

        :return: The symbol zoom reference scale of the tracking layer.
        :rtype: float
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.get_tag": """
        Return the label of the geometric object with the specified index in this tracking layer.

        :param int index: The index of the geometric object whose label is to be returned.
        :return: The label of the geometric object with the specified index in this tracking layer.
        :rtype: str
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.index_of": """
        Return the index value of the first geometric object with the same label as the specified label.

        :param str tag: The tag that needs index check.
        :return: Return the index value of the first geometric object with the same label as the specified label.
        :rtype: int
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.is_antialias": """
        Return a Boolean value specifying whether to anti-alias the tracking layer. After the text and line type are set to anti-aliasing, some display jagged can be removed to make the display more beautiful. The picture shows the line type and text respectively
        Comparison of the effect before and after anti-aliasing

        :return: The anti-aliasing tracking layer Return true; otherwise, it Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.is_symbol_scalable": """
        Return whether the symbol size of the tracking layer scales with the image. true means that when the map zooms in and zooms in, the symbol will also be zoomed in as the map zooms in.

        :return: A Boolean value indicating whether the symbol size of the tracking layer is scaled with the image.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.is_visible": """
        Return whether this tracking layer is visible. true means this tracking layer is visible, false means this tracking layer is invisible. When this tracking layer is not visible, other settings will be invalid.

        :return: Indicates whether this layer is visible.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.remove": """
        Delete the geometric object with the specified index in the current tracking layer.

        :param int index: The index of the geometric object to be deleted.
        :return: Return true if the deletion is successful; otherwise, Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.set": """
        Replace the geometric object at the specified index in the tracking layer with the specified geometric object. If there are other geometric objects at this index, they will be deleted.

        :param int index: The index of the geometric object to be replaced.
        :param geo: The new Geometry object to replace.
        :type geo: Geometry or Point2D or Rectangle or Feature
        :return: Return true if the replacement is successful; otherwise, Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.set_antialias": """
        Set a Boolean value to specify whether to anti-alias the tracking layer.

        :param bool value: Specify whether to anti-alias the tracking layer.
        :return: self
        :rtype: TrackingLayer
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.set_symbol_scalable": """
        Set whether the symbol size of the tracking layer is scaled with the image. true means that when the map zooms in and zooms in, the symbol will also be zoomed in as the map zooms in.

        :param bool value: A Boolean value indicating whether the symbol size of the tracking layer is scaled with the image.
        :return: self
        :rtype: TrackingLayer
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.set_symbol_scale": """
        Set the symbol zoom reference scale of this tracking layer.

        :param float value: The symbol zoom reference scale of this tracking layer.
        :return: self
        :rtype: TrackingLayer
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.set_tag": """
        Set the label of the geometric object with the specified index in this tracking layer

        :param int index: The index of the geometric object whose label is to be set.
        :param str tag: The new tag of the geometric object.
        :return: Return true if the setting is successful; otherwise, Return false.
        :rtype: bool
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.set_visible": """
        Set whether this tracking layer is visible. true means this tracking layer is visible, false means this tracking layer is invisible. When this tracking layer is not visible, other settings will be invalid.

        :param bool value: Indicates whether this layer is visible.
        :return: self
        :rtype: TrackingLayer
        """,

    "iobjectspy._jsuperpy.mapping.TrackingLayer.start_edit_bulk": """
        Start batch update

        :return: self
        :rtype: TrackingLayer
        """,

}

_jsuperpy_enums_locale = {
    "iobjectspy._jsuperpy.enums": """""",

    "iobjectspy._jsuperpy.enums.AggregationMethod": """
    The aggregation method constant used to create a dataset for analysis by event points

    :var AggregationMethod.NETWORKPOLYGONS: Calculate the appropriate mesh size, create a mesh surface dataset, the generated grid surface dataset with the point count of the surface grid cell
                                            Will be used as the analysis field to perform hot spot analysis. The grid will overlay the input event point, and calculate the
                                            Number of points. If the boundary surface data of the area where the incident occurred is not provided (see: py:func:`optimized_hot_spot_analyst` bounding_polygons parameter),
                                            It will use the input event point dataset range to divide the grid, and will delete the surface grid cells without points, and only analyze the remaining
                                            Surface grid elements; if boundary surface data is provided, only the surface grid elements within the boundary surface dataset will be retained and analyzed.

    :var AggregationMethod.AGGREGATIONPOLYGONS: Need to provide a polygon dataset that aggregates event points to obtain event counts (see: py:func:`optimized_hot_spot_analyst`'s aggregate_polygons parameter),
                                                The number of point events in each area object will be calculated, and then the hot spot analysis will be performed on the area dataset with the number of point events as the analysis field.

    :var AggregationMethod.SNAPNEARBYPOINTS: Calculate the capture distance for the input event point dataset and use the distance to aggregate nearby event points, providing a point count for each
                                             Aggregation point, which represents the number of event points aggregated together, and then perform a hot spot analysis on the number of point events aggregated together as an analysis field for
                                             The generated aggregation point dataset
    """,

    "iobjectspy._jsuperpy.enums.AggregationType": """
    Defines the type constant of the calculation method of the result raster during the aggregation operation

    :var AggregationType.SUM: The sum of all the raster values contained in an aggregated raster
    :var AggregationType.MIN: the smallest value among all the raster values contained in an aggregated raster
    :var AggregationType.MAX: The maximum value of all the raster values contained in an aggregated raster
    :var AggregationType.AVERRAGE: The average value of all the raster values contained in an aggregated raster
    :var AggregationType.MEDIAN: The median of all the raster values contained in an aggregated raster
    """,

    "iobjectspy._jsuperpy.enums.ArcAndVertexFilterMode": """
    This class defines the constants of the arc intersection filtering mode.

    The arc intersection is used to break the line object at the intersection, and is usually the first step when establishing a topological relationship for the line data.

    :var ArcAndVertexFilterMode.NONE: No filtering, that is, the line object is broken at all intersections. In this mode, the filter line expression or filter point dataset is invalid.
                                      As shown in the figure below, the line objects A, B, C, and D are interrupted at their intersections, that is, A and B are interrupted at their intersections, and C is interrupted at the intersections with A and D.

                                      .. image:: ../image/FilterMode_None.png

    :var ArcAndVertexFilterMode.ARC: Only filter by the filter line expression, that is, the line object queried by the filter line expression will not be interrupted. In this mode, the filter point record set is invalid.
                                     As shown in the figure below, the line object C is an object that satisfies the filter line expression, and the entire line of the line object C will not be interrupted at any position.

                                     .. image:: ../image/FilterMode_Arc.png

    :var ArcAndVertexFilterMode.VERTEX: Only filtered by the filter point record set, that is, the line object is not interrupted at the location of the filter point (or the distance from the filter point is within the tolerance range). The filter line expression set in this mode is invalid.
                                         As shown in the figure below, if a filter point is located at the intersection of line objects A and C, then C will not be interrupted at that point, and will still be interrupted at other intersections.

                                         .. image:: ../image/FilterMode_Vertex.png

    :var ArcAndVertexFilterMode.ARC_AND_VERTEX: The filter line expression and the filter point record set jointly determine which positions are not interrupted. The relationship between the two is and, that is, only the line object queried by the filter line expression is at the filter point position (or two Within the tolerance) without interruption.
                                                As shown in the figure below, the line object C is an object that satisfies the filter line expression. There is a filter point at the intersection of A and B, and the intersection of C and D. According to the pattern rules, the location of the filter point on the filter line will not be affected. Interrupt, that is, C does not interrupt at the intersection with D.

                                                .. image:: ../image/FilterMode_ArcAndVertex.png

    :var ArcAndVertexFilterMode.ARC_OR_VERTEX: The line object queried by the filter line expression and the line object at the position of the filter point (or the distance from the filter point is within the tolerance range) are not interrupted, and the two are in a union relationship.
                                               As shown in the figure below, the line object C is an object that satisfies the filter line expression. There is a filter point at the intersection of A and B, and the intersection of C and D. According to the pattern rule, the result is as shown in the figure on the right. If interrupted, the intersection of A and B will not interrupt.

                                               .. image:: ../image/FilterMode_ArcOrVertex.png

    """,

    "iobjectspy._jsuperpy.enums.AreaUnit": """Area unit type:

    :var AreaUnit.SQUAREMILLIMETER: Metric unit, square millimeter.
    :var AreaUnit.SQUARECENTIMETER: Metric unit, square centimeter.
    :var AreaUnit.SQUAREDECIMETER: Metric unit, square decimetre.
    :var AreaUnit.SQUAREMETER: Metric unit, square meter.
    :var AreaUnit.SQUAREKILOMETER: Metric unit, square kilometers.
    :var AreaUnit.HECTARE: Metric unit, hectares.
    :var AreaUnit.ARE: Metric unit, ares.
    :var AreaUnit.QING: City system unit, ha.
    :var AreaUnit.MU: Municipal unit, mu.
    :var AreaUnit.SQUAREINCH: Imperial units, square inches.
    :var AreaUnit.SQUAREFOOT: English units, square feet.
    :var AreaUnit.SQUAREYARD: Imperial unit, square yard.
    :var AreaUnit.SQUAREMILE: Imperial units, square miles.
    :var AreaUnit.ACRE: English units, acres.
    """,

    "iobjectspy._jsuperpy.enums.AttributeStatisticsMode": """
    A mode for performing attribute statistics when connecting points to form lines and when updating vector dataset attributes.

    :var AttributeStatisticsMode.MAX: The maximum value of statistics, which can perform statistics on numeric, text, and time fields.
    :var AttributeStatisticsMode.MIN: Statistic minimum value, which can perform statistics on numeric, text and time fields.
    :var AttributeStatisticsMode.SUM: Count the sum of a set of numbers, only valid for numeric fields
    :var AttributeStatisticsMode.MEAN: Count the average value of a group of numbers, only valid for numeric fields
    :var AttributeStatisticsMode.STDEV: Statistic the standard deviation of a group of numbers, only valid for numeric fields
    :var AttributeStatisticsMode.VAR: Count the variance of a group of numbers, only valid for numeric fields
    :var AttributeStatisticsMode.MODALVALUE: take the mode, the mode is the value with the highest frequency, which can be any type of field
    :var AttributeStatisticsMode.RECORDCOUNT: Count the number of records in a group. The number of statistical records is not for a specific field, only for a group.
    :var AttributeStatisticsMode.MAXINTERSECTAREA: Take the largest intersection area. If the area object intersects multiple area objects that provide attributes, the attribute value of the object with the largest intersection area with the original area object is used for update. It is valid for any type of field.
                                                   Only valid for vector dataset attribute update (:py:func:`update_attributes`)
    """,

    "iobjectspy._jsuperpy.enums.BandWidthType": """
    Geographically weighted regression analysis bandwidth determination method is constant.

    :var BandWidthType.AICC: Use "Akaike Information Criteria (AICc)" to determine the bandwidth range.
    :var BandWidthType.CV: Use "cross-validation" to determine the bandwidth range.
    :var BandWidthType.BANDWIDTH: Determine the bandwidth range according to a given fixed distance or fixed adjacent number.
    """,

    "iobjectspy._jsuperpy.enums.BlockSizeOption": """
    This enumeration defines the type constants of pixel blocks. For raster datasets or image data:

    :var BlockSizeOption.BS_64: Represents a block of 64 pixels * 64 pixels
    :var BlockSizeOption.BS_128: Represents a block of 128 pixels * 128 pixels
    :var BlockSizeOption.BS_256: Represents a block of 256 pixels * 256 pixels
    :var BlockSizeOption.BS_512: Represents a block of 512 pixels * 512 pixels.
    :var BlockSizeOption.BS_1024: Represents a block of 1024 pixels * 1024 pixels.

    """,

    "iobjectspy._jsuperpy.enums.BoundaryCleanSortType": """
    Sorting method of boundary cleaning. That is, specify the sorting type to be used in the smoothing process. This will determine the priority of pixels that can be extended to neighboring pixels

    :var BoundaryCleanSortType.NOSORT: Do not sort by size. Areas with larger values have higher priority and can be extended to several areas with smaller values.
    :var BoundaryCleanSortType.DESCEND: Sort the regions in descending order of size. Areas with a larger total area have higher priority and can be extended to several areas with
                                        A small total area..
    :var BoundaryCleanSortType.ASCEND: Sort areas in ascending order of size. Areas with a smaller total area have higher priority and can be extended to several areas with
                                       a large total area..
    """,

    "iobjectspy._jsuperpy.enums.Buffer3DJoinType": """
    The constant of the chamfering style of lofting
    :var Buffer3DJoinType.SQUARE: sharp corner joint style
    :var Buffer3DJoinType.ROUND: rounded corner connection style
    :var Buffer3DJoinType.MITER: Bevel connection style
    """,

    "iobjectspy._jsuperpy.enums.BufferEndType": """
    This class defines the constants of the buffer endpoint type.

    It is used to distinguish whether the endpoint of the line object buffer analysis is round or flat.

    :var BufferEndType.ROUND: Round head buffer. The round head buffer is a semi-circular arc treatment at the end of the line segment when the buffer is generated
    :var BufferEndType.FLAT: Flat head buffer. The flat buffer is the vertical line of the arc at the end of the line segment when the buffer is generated.
    """,

    "iobjectspy._jsuperpy.enums.BufferRadiusUnit": """
    This enumeration defines the constants of the buffer analysis radius unit type

    :var BufferRadiusUnit.MILIMETER: mm
    :var BufferRadiusUnit.CENTIMETER: cm
    :var BufferRadiusUnit.DECIMETER: Decimeter
    :var BufferRadiusUnit.METER: Meter
    :var BufferRadiusUnit.KILOMETER: kilometers
    :var BufferRadiusUnit.INCH: inches
    :var BufferRadiusUnit.FOOT: feet
    :var BufferRadiusUnit.YARD: code
    :var BufferRadiusUnit.MILE: Miles
    """,

    "iobjectspy._jsuperpy.enums.CADVersion": """
    This class defines the AutoCAD version type constants. Provides different version types and descriptions of AutoCAD.

    :var CADVersion.CAD12: OdDb::vAC12 R11-12
    :var CADVersion.CAD13: OdDb::vAC13 R13
    :var CADVersion.CAD14: OdDb::vAC14 R14
    :var CADVersion.CAD2000: OdDb::vAC15 2000-2002
    :var CADVersion.CAD2004: OdDb::vAC18 2004-2006
    :var CADVersion.CAD2007: OdDb::vAC21 2007
    """,

    "iobjectspy._jsuperpy.enums.ChamferStyle": """
    The constant of the chamfering style of lofting
    :var ChamferStyle.SOBC_CIRCLE_ARC: the second order bezier curve arc
    :var ChamferStyle.SOBC_ELLIPSE_ARC: the second order bezier curve elliptic arc
    """,

    "iobjectspy._jsuperpy.enums.Charset": """
    This class defines the character set type constants of the vector dataset.

    :var Charset.ANSI: ASCII character set
    :var Charset.DEFAULT: The extended ASCII character set.
    :var Charset.SYMBOL: Symbol character set.
    :var Charset.MAC: Characters used by Macintosh
    :var Charset.SHIFTJIS: Japanese character set
    :var Charset.HANGEUL: Other common spellings in the Korean character set
    :var Charset.JOHAB: Korean character set
    :var Charset.GB18030: Chinese character set used in Mainland China
    :var Charset.CHINESEBIG5: The most commonly used Chinese character set in Hong Kong Special Administrative Region of China and Taiwan
    :var Charset.GREEK: Greek character set
    :var Charset.TURKISH: Turkish character set
    :var Charset.VIETNAMESE: Vietnamese character set
    :var Charset.HEBREW: Hebrew character set
    :var Charset.ARABIC: Arabic character set
    :var Charset.BALTIC: Baltic character set
    :var Charset.RUSSIAN: Russian character set
    :var Charset.THAI: Thai character set
    :var Charset.EASTEUROPE: Eastern European character set
    :var Charset.OEM: extended ASCII character set
    :var Charset.UTF8: UTF-8 (8-bit Universal Character Set/Unicode Transformation Format) is a variable-length character encoding for Unicode. It can be used to represent any character in the Unicode standard, and the first byte of its encoding is still compatible with ASCII, so that the original software that handles ASCII characters can continue to be used without or with minor modifications.
    :var Charset.UTF7: UTF-7 (Unicode Transformation Format (Unicode Transformation Format, abbreviated as UTF)) is a variable-length character encoding method used to present Unicode characters as ASCII-encoded strings .
    :var Charset.WINDOWS1252: Commonly used encoding in English. Windows1252 (Window 9x standard for Western European languages).
    :var Charset.KOREAN: Korean character set
    :var Charset.UNICODE: In the field of computer science, Unicode (Unicode, Universal Code, Single Code, Standard Universal Code) is a standard in the industry.
    :var Charset.CYRILLIC: Cyrillic (Windows)
    :var Charset.XIA5: IA5
    :var Charset.XIA5GERMAN: IA5 (German)
    :var Charset.XIA5SWEDISH: IA5 (Swedish)
    :var Charset.XIA5NORWEGIAN: IA5 (Norwegian)

    """,

    "iobjectspy._jsuperpy.enums.ColorGradientType": """
    This class defines constants for the color gradient type.

    The color gradient is the gradual mixing of multiple colors, which can be a gradient of two colors from the start color to the end color, or a gradient with multiple intermediate colors between the start color and the end color. This color gradient type can be used in the color scheme settings of thematic map objects, such as unique values map, range thematic map, statistical map, label map, grid range map and grid unique values map.

    :var ColorGradientType.BLACKWHITE: black and white gradient
    :var ColorGradientType.REDWHITE: Red and white gradient
    :var ColorGradientType.GREENWHITE: Green and white gradient
    :var ColorGradientType.BLUEWHITE: blue and white gradient
    :var ColorGradientType.YELLOWWHITE: Yellow-white gradient
    :var ColorGradientType.PINKWHITE: pink white gradient
    :var ColorGradientType.CYANWHITE: Cyan white gradient
    :var ColorGradientType.REDBLACK: Red and black gradient
    :var ColorGradientType.GREENBLACK: Green and black gradient
    :var ColorGradientType.BLUEBLACK: blue-black gradient
    :var ColorGradientType.YELLOWBLACK: Yellow-black gradient
    :var ColorGradientType.PINKBLACK: pink black gradient
    :var ColorGradientType.CYANBLACK: Cyan-black gradient
    :var ColorGradientType.YELLOWRED: Yellow-red gradient
    :var ColorGradientType.YELLOWGREEN: Yellow-green gradient
    :var ColorGradientType.YELLOWBLUE: Yellow-blue gradient
    :var ColorGradientType.GREENBLUE: Green-blue gradient
    :var ColorGradientType.GREENRED: Green-red gradient
    :var ColorGradientType.BLUERED: blue-red gradient
    :var ColorGradientType.PINKRED: pink red gradient
    :var ColorGradientType.PINKBLUE: pink blue gradient
    :var ColorGradientType.CYANBLUE: Cyan blue gradient
    :var ColorGradientType.CYANGREEN: cyan gradient
    :var ColorGradientType.RAINBOW: Rainbow color
    :var ColorGradientType.GREENORANGEVIOLET: Green orange purple gradient
    :var ColorGradientType.TERRAIN: Terrain gradient
    :var ColorGradientType.SPECTRUM: spectral gradient

    """,

    "iobjectspy._jsuperpy.enums.ColorSpaceType": """
    This class defines the color space type constants.

    Due to the different color forming principles, the difference in the way of color generation is determined between color devices such as displays and projectors that directly synthesize colors by color light and printing devices that use pigments such as printers and printers. For the above-mentioned different color forming methods, SuperMap provides 7 color spaces, namely RGB, CMYK, RGBA, CMY, YIQ, YUV, and YCC, which can be applied to different systems.

    :var ColorSpaceType.RGB: This type is mainly used in display systems. RGB is an abbreviation for red, green, and blue . The RGB color mode uses the RGB model to assign an intensity value in the range of 0~255 to the RGB component of each pixel in the image
    :var ColorSpaceType.CMYK: This type is mainly used in printing systems. CMYK is cyan, magenta, yellow, and black. It mixes pigments of various colors by adjusting the density of the three basic colors of cyan, magenta and yellow, and uses black to adjust brightness and purity.
    :var ColorSpaceType.RGBA: This type is mainly used in display systems. RGB is the abbreviation for red, green, and blue, and A is used to control transparency.
    :var ColorSpaceType.CMY: This type is mainly used in printing systems. CMY (Cyan, Magenta, Yellow) are cyan, magenta, and yellow respectively. This type mixes pigments of various colors by adjusting the density of the three basic colors of cyan, magenta and yellow.
    :var ColorSpaceType.YIQ: This type is mainly used in North American Television System (NTSC).
    :var ColorSpaceType.YUV: This type is mainly used in the European Television System (PAL).
    :var ColorSpaceType.YCC: This type is mainly used for JPEG image format.
    :var ColorSpaceType.UNKNOW: unknown
    """,

    "iobjectspy._jsuperpy.enums.ComputeType": """
    This class defines the calculation method type constant for the shortest path analysis of the distance raster

    :var ComputeType.CELL: Cell path, each grid unit corresponding to the target object generates a shortest path. As shown in the figure below, the red point is the source and the black polygon is the target. The method is used to
                           Analyze the shortest path of raster, and the shortest path represented by blue cell is obtained.

                           .. image:: ../image/ComputeType_CELL.png

    :var ComputeType.ZONE: Zone path, only one shortest path is generated for the grid area corresponding to each target object. As shown in the figure below, the red point is the source and the black polygon is the target.
                           The method is used to analyze the shortest path of raster, and the shortest path represented by blue cell is obtained.

                           .. image:: ../image/ComputeType_ZONE.png

    :var ComputeType.ALL: Single path, all cells corresponding to the target object generate only one shortest path, that is, the shortest path among all paths for the entire target area dataset. As shown below,
                          The red point is the source, and the black polygon is the target. This method is used to analyze the shortest path of the grid to obtain the shortest path represented by the blue cell.

                          .. image:: ../image/ComputeType_ALL.png
    """,

    "iobjectspy._jsuperpy.enums.ConceptualizationModel": """
    Spatial relationship conceptualization model constant

    :var ConceptualizationModel.INVERSEDISTANCE: Inverse distance model. Any element will affect the target element, but as the distance increases, the impact will be smaller. The weight between the features is one part of the distance.
    :var ConceptualizationModel.INVERSEDISTANCESQUARED: Inverse distance square model. Similar to the "inverse distance model", as the distance increases, the impact decreases faster. The weight between features is one square of the distance.
    :var ConceptualizationModel.FIXEDDISTANCEBAND: Fixed distance model. The elements within the specified fixed distance range have equal weight (weight 1), and the elements outside the specified fixed distance range will not affect the calculation (weight 0).
    :var ConceptualizationModel.ZONEOFINDIFFERENCE: Indifferent zone model. This model is a combination of "inverse distance model" and "fixed distance model". The elements within the specified fixed distance range have the same weight (weight is 1); the elements outside the specified fixed distance range have less influence as the distance increases.
    :var ConceptualizationModel.CONTIGUITYEDGESONLY: Surface adjacency model. Only areas with shared boundaries, overlaps, inclusions, and inclusions will affect the target element (weight 1), otherwise, they will be excluded from the calculation of the target element (weight 0).
    :var ConceptualizationModel.CONTIGUITYEDGESNODE: Surface adjacency model. Only when the surface has contact will affect the target element (weight is 1), otherwise, it will be excluded from the calculation of the target element (weight is 0).
    :var ConceptualizationModel.KNEARESTNEIGHBORS: K nearest neighbor model. The K elements closest to the target element are included in the calculation of the target element (weight is 1), and the remaining elements will be excluded from the calculation of the target element (weight is 0).
    :var ConceptualizationModel.SPATIALWEIGHTMATRIXFILE: Provides spatial weight matrix file.
    """,

    "iobjectspy._jsuperpy.enums.CoordSysTransMethod": """
    This class defines constants for the projection conversion method type.

    In the projection conversion, if the geographic coordinate system of the source projection and the target projection are different, a reference system conversion is required.

    There are two types of reference system conversion, grid-based conversion and formula-based conversion. The conversion methods provided by this class are all based on formula conversion. According to different conversion parameters, it can be divided into three-parameter method and seven-parameter method. Currently
    The most widely used method is the seven-parameter method. For parameter information, see: py:class:`CoordSysTransParameter`; if the geographic coordinate system of the source projection and the target projection are the same, the user does not need to perform the conversion of the reference system, that is, it is not necessary
    To set :py:class:`CoordSysTransParameter` parameter information. GeocentricTranslation, Molodensky, and MolodenskyAbridged in this version are based on the three-parameter conversion of the center of the earth
    Method; PositionVector, CoordinateFrame, BursaWolf are all seven-parameter methods.

    :var CoordSysTransMethod.MTH_GEOCENTRIC_TRANSLATION: Three-parameter transformation method based on the center of the earth
    :var CoordSysTransMethod.MTH_MOLODENSKY: Molodensky conversion method
    :var CoordSysTransMethod.MTH_MOLODENSKY_ABRIDGED: Simplified Morodinsky transformation method
    :var CoordSysTransMethod.MTH_POSITION_VECTOR: position vector method
    :var CoordSysTransMethod.MTH_COORDINATE_FRAME: Seven-parameter conversion method based on the center of the earth
    :var CoordSysTransMethod.MTH_BURSA_WOLF: Bursa-Wolf method
    :var CoordSysTransMethod.MolodenskyBadekas: Molodensky-Badekas projection transformation method, a ten-parameter space coordinate transformation model.
    """,

    "iobjectspy._jsuperpy.enums.CursorType": """
    Cursor type:

    :var CursorType.DYNAMIC: Dynamic cursor type. Support various editing operations, slow speed. Dynamic cursor meaning: you can see the additions, changes and deletions made by other users. Allows to move back and forth in the record set, (but not
      The bookmark operation that the data provider does not support, the bookmark operation is mainly for ADO). This type of cursor is very powerful, but it is also the cursor that consumes the most system resources. Dynamic cursor can know
      All changes to the Recordset. Users who use dynamic cursors can see the editing, adding, and deleting operations that other users have done to the dataset. If the data provider allows this type of cursor, then it
      Dynamically refreshes the query's recordset by fetching data from the datasource at regular intervals. There is no doubt that this will require a lot of resources.

    :var CursorType.STATIC: Static cursor type. Meaning of a static cursor: a static copy of a collection of records that can be used to find data or generate reports. In addition, additions, changes, or deletions made by other users are not visible. Static cursor only
      Is a snapshot of the data. In other words, it cannot see the editing operations made by other users on the Recordset since it was created.
      With this type of cursor you can backtrack forward and backward. Because of its simple function, the resource consumption is smaller than that of the dynamic cursor (DYNAMIC)! )
    """,

    "iobjectspy._jsuperpy.enums.DatasetType": """
    This class defines the dataset type constants. dataset are generally a collection of related data stored together; according to the different types of data, they are divided into vector dataset, raster dataset and image dataset, , and are designed to handle specific problems such as topology dataset,
    Network dataset, etc.. According to the different spatial characteristics of the elements, vector dataset are divided into point dataset, line dataset, area dataset, composite dataset, text dataset, pure attribute dataset, etc.

    :var DatasetType.UNKNOWN: Unknown type dataset
    :var DatasetType.TABULAR: Pure attribute dataset. It is used to store and manage pure attribute data. The pure attribute data is used to describe information such as the features and shapes of terrain and features, such as the length and width of a river. The data
                              The set has no spatial graphics data. That is, a pure attribute dataset cannot be added to the map window as a layer for display.
    :var DatasetType.POINT: Point dataset. The dataset class used to store point objects, such as the distribution of discrete points.
    :var DatasetType.LINE: Line dataset. A dataset used to store line objects, such as the distribution of rivers, roads, and national borders.
    :var DatasetType.REGION: Polygon dataset. A dataset used to store surface objects, such as the distribution of houses and administrative areas.
    :var DatasetType.TEXT: Text dataset. A dataset used to store text objects, then only text objects can be stored in the text dataset, not other geometric objects. For example, a text object representing annotation.
    :var DatasetType.CAD: Composite dataset. Refers to a dataset that can store a variety of geometric objects, that is, a collection of different types of objects such as points, lines, surfaces, and texts. Each object in the CAD dataset can
                          Have different styles, and the CAD dataset stores styles for each object.
    :var DatasetType.LINKTABLE: Database table. That is, the external attribute table does not contain system fields (fields starting with SM). Use the same as a general attribute dataset, but this dataset only has a read-only function.
    :var DatasetType.NETWORK: Network dataset. Network datasets are used to store datasets with network topology relationships . Such as road traffic network, etc. The network dataset is different from the point dataset and the line dataset.
                              It contains not only network line objects, but also network node objects, as well as the spatial topological relationship between the two objects. Based on the network dataset, path analysis,
                              Various network analyses such as service area analysis, nearest facility search, location selection, bus transfer, and neighboring point and access point analysis.
    :var DatasetType.NETWORK3D: Three-dimensional network dataset, a dataset used to store three-dimensional network objects.
    :var DatasetType.LINEM: Route dataset. It is composed of a series of line objects with scale value Measure in the spatial information. Usually can be applied to linear reference models or as the result data of network analysis.
    :var DatasetType.PARAMETRICLINE: Composite parametric line dataset, used to store the dataset of composite parametric line geometric objects.
    :var DatasetType.PARAMETRICREGION: Composite parameterized surface dataset, used to store the dataset of composite parameterized surface geometry objects.
    :var DatasetType.GRIDCOLLECTION: The dataset storing the raster dataset collection objects. For a detailed description of raster dataset collection objects, please refer to: py:class:`DatasetGridCollection`.
    :var DatasetType.IMAGECOLLECTION: The dataset storing the object of the image dataset collection. For a detailed description of the image dataset collection objects, please refer to: py:class:`DatasetImageCollection`.
    :var DatasetType.MODEL: Model dataset.
    :var DatasetType.TEXTURE: Texture dataset, a sub-dataset of the model dataset.
    :var DatasetType.IMAGE: Image dataset. Does not have attribute information, such as image maps, multi-band images, and physical maps. Each raster stores a color value or color index value (RGB value).
    :var DatasetType.WMS: WMS dataset, a type of DatasetImage. WMS (Web Map Service), that is, Web Map Service. WMS uses data with geospatial location information
                          To make maps. The web map service Return a layer-level map image. The map is defined as the visual representation of geographic data.
    :var DatasetType.WCS: WCS dataset, which is a type of DatasetImage. WCS (Web Coverage Service), that is, Web Coverage Service, for spatial image data,
                          It exchanges geospatial data containing geographic location values as "Coverage" on the Internet.
    :var DatasetType.GRID: Raster dataset. For example, elevation dataset and land use maps. Each raster stores the attribute value (such as elevation value) representing the features.
    :var DatasetType.VOLUME: Grid volume data collection, which expresses three-dimensional volume data in a slice sampling method, such as the signal strength of a mobile phone in a specified spatial range, smog pollution index, etc.
    :var DatasetType.TOPOLOGY: Topological dataset. The topology dataset is actually a container that provides comprehensive management capabilities for topology errors. It covers topology related dataset, topology rules, topology preprocessing,
                               Topological error generation, location modification, automatic maintenance of dirty areas and other key elements of topology error checking provide a complete solution for topology error checking. Dirty area
                               Is an area that has not been topologically checked, and it has already been topologically checked. If the user partially edits the data locally, a new dirty area will be generated in this local area.
    :var DatasetType.POINT3D: 3D point dataset, used to store 3D point object dataset.
    :var DatasetType.LINE3D: 3D line dataset, used to store 3D line object dataset.
    :var DatasetType.REGION3D: Three-dimensional surface dataset, used to store three-dimensional surface object dataset.
    :var DatasetType.POINTEPS: Tsinghua Mountain Dimension Point dataset, used to store Tsinghua Mountain Dimension Point Object dataset.
    :var DatasetType.LINEEPS: Tsinghua Mountain dimension line dataset, used to store the dataset of Tsinghua Mountain dimension line objects.
    :var DatasetType.REGIONEPS: Tsinghua Mountain dimension dataset, used to store the dataset of Tsinghua Mountain dimension object.
    :var DatasetType.TEXTEPS: Tsinghua Sundimensional text dataset, a dataset used to store Tsinghua Sundimensional text objects.
    :var DatasetType.VECTORCOLLECTION: Vector dataset collection, used to store multiple vector datasets, only supports PostgreSQL engine.
    :var DatasetType.MOSAIC: mosaic dataset
    """,

    "iobjectspy._jsuperpy.enums.DissolveType": """
    Fusion type constant

    :var DissolveType.ONLYMULTIPART: combination. Combine objects with the same fusion field value into a complex object.
    :var DissolveType.SINGLE: Dissolve. Combine objects with the same fusion field value and topologically adjacent objects into a simple object.
    :var DissolveType.MULTIPART: Combination after fusion. Combine objects with the same fusion field value and topologically adjacent objects into a simple object, and then combine non-adjacent objects with the same fusion field value into a complex object.
    """,

    "iobjectspy._jsuperpy.enums.DistanceMethod": """
    Distance calculation method constant

    :var DistanceMethod.EUCLIDEAN: Euclidean distance. Calculate the straight-line distance between two points.

                                   DistanceMethod_EUCLIDEAN.png

    :var DistanceMethod.MANHATTAN: Manhattan distance. Calculate the sum of the absolute value of the difference between the x and y coordinates of two points. This type is temporarily unavailable, only as a test, the result of use is unknown.

                                   DistanceMethod_MANHATTAN.png
    """,

    "iobjectspy._jsuperpy.enums.EdgeMatchMode": """
    This enumeration defines the constants of the way the frame is joined.

    :var EdgeMatchMode.THEOTHEREDGE: Join the edge to one side. The edge connection point is the end point of the record associated with the edge in the edge target dataset, and the end point of the record associated with the edge in the source dataset will be moved to this connection point.
    :var EdgeMatchMode.THEMIDPOINT: Connect edges at the midpoint. The edge connection point is the midpoint between the edge connection target dataset and the end point of the edge connection record in the source dataset, and the end point of the record where the edge connection occurs in the source and target dataset will move to this connection point.
    :var EdgeMatchMode.THEINTERSECTION: Connect edges at the intersection. The edge connection point is the intersection of the connection line and the edge line of the edge connection record in the target dataset and the source dataset. The end point of the record where the connection connection occurs in the source and target dataset will move to this connection point.
    """,

    "iobjectspy._jsuperpy.enums.EllipseSize": """
    Output ellipse size constant

    :var EllipseSize.SINGLE: One standard deviation. The semi-major axis and semi-minor axis of the output ellipse are twice the corresponding standard deviation. When geometric objects have spatial normal distribution, that is, these
                             Geometric objects are concentrated in the center and less toward the periphery, the generated ellipse will contain about 68% of the geometric objects.

                             .. image:: ../image/EllipseSize_SINGLE.png


    :var EllipseSize.TWICE: Two standard deviations. The semi-major axis and semi-minor axis of the output ellipse are twice the corresponding standard deviation. When geometric objects have spatial normal distribution, that is, these
                            Geometric objects are concentrated at the center and less toward the periphery, the generated ellipse will contain approximately 95% of the geometric objects.

                            .. image:: ../image/EllipseSize_TWICE.png

    :var EllipseSize.TRIPLE: Three standard deviations. The semi-major axis and semi-minor axis of the output ellipse are three times the corresponding standard deviation. When geometric objects have spatial normal distribution, that is, these
                             Geometric objects are concentrated at the center and less toward the periphery, the generated ellipse will contain approximately 99% of the geometric objects.

                             .. image:: ../image/EllipseSize_TRIPLE.png
    """,

    "iobjectspy._jsuperpy.enums.EncodeType": """
    This class defines the type constants of the compression encoding method when the dataset is stored.

    For vector dataset, four compression encoding methods are supported, namely single-byte, double-byte, three-byte and four-byte encoding methods. These four compression encoding methods use the same compression encoding mechanism, but the compression ratios are different.
    All of them are lossy compression. It should be noted that point dataset, pure attribute dataset and CAD dataset are not compressible. For raster data, four compression coding methods can be used, namely DCT, SGL, LZW and
    COMPOUND. Among them, DCT and COMPOUND are lossy compression coding methods, and SGL and LZW are lossless compression coding methods.

    For image and raster datasets, choosing an appropriate compression encoding method according to its pixel format (PixelFormat) is very beneficial to improve the efficiency of system operation and save storage space. The following table lists reasonable encoding methods for different
    Pixel formats of image and raster datasets:

    .. image:: ../image/EncodeTypeRec.png

    :var EncodeType.NONE: Do not use encoding
    :var EncodeType.BYTE: Single-byte encoding method. Use 1 byte to store a coordinate value. (Only applicable to line and area datasets)
    :var EncodeType.INT16: Double-byte encoding method. Use 2 bytes to store a coordinate value. (Only applicable to line and area datasets)
    :var EncodeType.INT24: Three-byte encoding method. Use 3 bytes to store a coordinate value. (Only applicable to line and area datasets)
    :var EncodeType.INT32: Four-byte encoding method. Use 4 bytes to store a coordinate value. (Only applicable to line and area datasets)
    :var EncodeType.DCT: DCT (Discrete Cosine Transform), discrete cosine encoding. It is a transform coding method widely used in image compression. This transform method
                         Provides a good balance between information compression capacity, reconstructed image quality, adaptation range and algorithm complexity, and has become the most widely used image compression technology. The principle is
                         To reduce the strong correlation existing in the original spatial domain representation of the image by transformation, so that the signal can be expressed more compact. This method has high compression rate and performance, but the encoding is distorted.
                         Since image dataset are generally not used for accurate analysis, the DCT encoding method is a compression encoding method for image dataset storage. (Applicable to image dataset)
    :var EncodeType.SGL: SGL (SuperMap Grid LZW), a compressed storage format customized by SuperMap. Its essence is an improved LZW encoding method. SGL improves on LZW
                         And is a more efficient way of compressed storage. At present, the compression and storage of Grid dataset and DEM dataset in SuperMap is the SGL compression encoding method.
                         This is a lossless compression. (Applicable to raster datasets)
    :var EncodeType.LZW: LZW is a widely used dictionary compression method, which was first used in the compression of text data. The principle of LZW encoding is to replace a string with a code name.
                         Subsequent strings of the same name use the same code name, so this encoding method can not only compress repeated data, but also compress non-repetitive data. It is suitable for the compression of
                         Indexed color image, which is a lossless compression coding method. (Applicable to raster and image datasets)
    :var EncodeType.PNG: PNG compression encoding method supports images with multiple bit depths and is a lossless compression method. (Applicable to image dataset)
    :var EncodeType.COMPOUND: The dataset composite encoding method, the compression ratio is close to the DCT encoding method, mainly for the problem of boundary image block distortion caused by DCT compression. (Applicable to image dataset in RGB format)

    """,

    "iobjectspy._jsuperpy.enums.EngineType": """
    This class defines constants for the spatial database engine type.
    The spatial database engine is on top of the conventional database management system. In addition to the functions necessary for the conventional database management system, it also provides specific storage and management capabilities for spatial data.
    SuperMap SDX+ is the spatial database technology of supermap and an important part of the data model of SuperMap GIS software. Various spatial geometric objects and image data can be passed through SDX+
    Engine, stored in a relational database to form a spatial database integrating spatial data and attribute data

    :var EngineType.IMAGEPLUGINS: Image read-only engine type, the corresponding enumeration value is 5. For common image formats such as BMP, JPG, TIFF and SuperMap custom image format SIT, two-dimensional map cache configuration file format SCI, etc. When loading the 2D map cache, the user needs to set this engine type, and also need to use the :py:meth:`DatasourceConnectionInfo.set_server` method to set the parameter to the 2D map cache configuration file (SCI). For MrSID and ECW, the read-only opening is for the quick principle, and it is opened in the synthetic band mode. The non-grayscale data will be displayed in RGB or RGBA by default , and the grayscale data will be displayed in the original way.
    :var EngineType.ORACLEPLUS: Oracle engine type
    :var EngineType.SQLPLUS: SQL Server engine type, only supported in Windows platform version
    :var EngineType.DB2: DB2 engine type
    :var EngineType.KINGBASE: Kingbase engine type, for Kingbase datasource, does not support multi-band data
    :var EngineType.MEMORY: Memory datasource.
    :var EngineType.OGC: OGC engine type, for web datasources, the corresponding enumeration value is 23. Currently supported types are WMS, WFS, WCS and WMTS. The default BoundingBox and TopLeftCorner label reading method in WMTS service is (longitude, latitude). The coordinate format provided by some service providers is (latitude, longitude). When you encounter this situation, in order to ensure the correctness of the coordinate data read, please check the SuperMap.xml file (the file is located in the Bin directory). Correctly modify the content. Usually, the performance of this situation is that the local vector data and the published WMTS service data cannot be superimposed together.
    :var EngineType.MYSQL: MYSQL engine type, support MySQL version 5.6.16 and above
    :var EngineType.MONGODB: MongoDB engine type, currently supported authentication method is Mongodb-cr
    :var EngineType.BEYONDB: BeyonDB engine type
    :var EngineType.GBASE: GBase engine type
    :var EngineType.HIGHGODB: HighGoDB engine type
    :var EngineType.UDB: UDB engine type
    :var EngineType.POSTGRESQL: PostgreSQL engine type
    :var EngineType.GOOGLEMAPS: GoogleMaps engine type. The engine is read-only and cannot be created. This constant is only supported in the Windows 32-bit platform version, not in the Linux version
    :var EngineType.SUPERMAPCLOUD: Supermap cloud service engine type. This engine is a read-only engine and cannot be created. This constant is only supported in the Windows 32-bit platform version, not in the Linux version.
    :var EngineType.ISERVERREST: REST map service engine type. This engine is read-only and cannot be created. For map services published based on the REST protocol. This constant is only supported in the Windows 32-bit platform version, not in the Linux version.
    :var EngineType.BAIDUMAPS: Baidu map service engine type
    :var EngineType.BINGMAPS: Bing map service engine type
    :var EngineType.GAODEMAPS: GaoDe map service engine type
    :var EngineType.OPENSTREETMAPS: OpenStreetMap engine type. This constant is only supported in the Windows 32-bit platform version, not in the Linux version
    :var EngineType.SCV: Vector cache engine type
    :var EngineType.DM: The third-generation DM engine type
    :var EngineType.ORACLESPATIAL: Oracle Spatial engine type
    :var EngineType.SDE: ArcSDE engine type:

                         -Support ArcSDE 9.2.0 and above
                         -Supports reading of 5 data types of point, line, area, text and raster datasets of ArcSDE 9.2.0 and above, and does not support writing.
                         -The style of reading ArcSDE text is not supported. The default field "TEXTSTRING" of ArcSDE storing text cannot be deleted, otherwise we cannot read the text.
                         - does not support raster 2bit ArcSDE read bit depth, the bit depth of the other support, and stretchable display.
                         -Does not support multi-threading.
                         -To use the SDE engine, you need ArcInfo's permission, and copy the three dlls sde.dll, sg.dll and pe.dll in the ArcSDE installation directory bin to the Bin directory under the SuperMap product (ie SuSDECI.dll and SuEngineSDE.sdx) Same level directory)
                         -Support platform: Windows 32 bit, Windows 64 bit.

    :var EngineType.ALTIBASE: Altibase engine type
    :var EngineType.KDB: KDB engine type
    :var EngineType.SRDB: The engine type of the relational database
    :var EngineType.MYSQLPlus: MySQLPlus database engine type, essentially MySQL+Mongo
    :var EngineType.VECTORFILE: Vector file engine type. For general vector formats such as shp, tab, Acad, etc., it supports editing and saving of vector files. If it is a type supported by FME, the corresponding FME license is required. Currently, there is no FME license that does not support FileGDBVector format.
    :var EngineType.PGGIS: PostgreSQL's spatial data extension PostGIS engine type
    :var EngineType.ES: Elasticsearch engine type
    :var EngineType.SQLSPATIAL: SQLSpatial engine type
    :var EngineType.UDBX: UDBX engine type
    :var EngineType.TIBERO: Tibero engine type
    :var EngineType.SHENTONG: engine type
    :var EngineType.HWPOSTGRESQL: HUAWEI PostgreSQL engine type
    :var EngineType.GANOS: Ali PolarDB PostgreSQL engine type
    :var EngineType.XUGU:  XUGU engine type
    :var EngineType.ATLASDB: AtlasDB engine type
    """,

    "iobjectspy._jsuperpy.enums.Exponent": """
    This class defines the type constant of the order of the trend surface equation in the sample point data during Universal Kriging interpolation. A certain trend inherent between the sample points in the sample dataset can be presented by function or polynomial fitting.

    :var SearchMode.EXP1: The order is 1, indicating that the central trend surface of the sample data shows a first-order trend.
    :var SearchMode.EXP2: The order is 2, indicating that the central trend surface of the sample data shows a second-order trend.

    """,

    "iobjectspy._jsuperpy.enums.FieldSign": """
    Field identifier constant

    :var FieldSign.ID: ID field
    :var FieldSign.GEOMETRY: Geometry field
    :var FieldSign.NODEID: NodeID field
    :var FieldSign.FNODE: FNode field
    :var FieldSign.TNODE: TNode field
    :var FieldSign.EDGEID: EdgeID field
    """,

    "iobjectspy._jsuperpy.enums.FieldType": """
    This class defines field type constants. Define a series of constants to represent fields that store different types of values.

    :var FieldType.BOOLEAN: Boolean type
    :var FieldType.BYTE: byte type field
    :var FieldType.INT16: 16-bit integer field
    :var FieldType.INT32: 32-bit integer field
    :var FieldType.INT64: 64-bit integer field
    :var FieldType.SINGLE: 32-bit precision floating point field
    :var FieldType.DOUBLE: 64-bit precision floating point field
    :var FieldType.DATETIME: Date field
    :var FieldType.LONGBINARY: Binary field
    :var FieldType.TEXT: variable length text field
    :var FieldType.CHAR: Long text type field, for example, the length of the specified string is 10, then the input string has only 3 characters, and the others are all occupied by 0
    :var FieldType.WTEXT: wide character type field
    :var FieldType.JSONB: JSONB type field (PostgreSQL unique field)
    """,

    "iobjectspy._jsuperpy.enums.FillGradientMode": """
    The gradient mode that defines the gradient fill mode. All gradient modes are gradients between two colors, that is, the gradient from the start color of the gradient to the end color of the gradient.

    For different gradient mode styles, you can rotate the angle in :py:class:`GeoStyle`, the start color (foreground color) and end color (background color) of the gradient, and the position of the center point of the gradient fill (for linear gradients) Invalid) and so on. By default, the gradient rotation angle is 0, and the gradient fill center point is the center point of the filled area. The following descriptions of various gradient modes use the default gradient rotation angle and center point.
    For more information about gradient fill rotation, please refer to the :py:meth:`set_fill_gradient_angle` method in the :py:class:`GeoStyle` class;
    For the setting of the gradient fill center point, please refer to the :py:meth:`set_fill_gradient_offset_ratio_x` and :py:meth:`set_fill_gradient_offset_ratio_y` methods in the :py:class:`GeoStyle` class.
    The calculation of the gradient style is based on the bounding rectangle of the filled area, that is, the smallest enclosing rectangle, so the range of the filled area mentioned below is the smallest enclosing rectangle of the filled area.

    :var FillGradientMode.NONE: No gradient. When using the normal fill mode, set the gradient mode to no gradient
    :var FillGradientMode.LINEAR: Linear gradient. The gradient from the start point to the end point of the horizontal line segment. As shown in the figure, from the start point to the end point of the horizontal line segment, its color gradually changes from the start color to the end color. The color on the straight line perpendicular to the line segment is the same, and no gradient occurs.

                                 .. image:: ../image/Gra_Linear.png

    :var FillGradientMode.RADIAL: Radiation gradient. A circular gradient with the center point of the filled area as the starting point of the gradient filling, and the boundary point farthest from the center point as the ending point. Note that the color does not change on the same circle, and the color changes between different circles.
                                  As shown in the figure, from the start point to the end point of the gradient fill, the color of each circle with the start point as the center gradually changes from the start color to the end color as the radius of the circle increases.

                                  .. image:: ../image/Gra_Radial.png

    :var FillGradientMode.CONICAL: Conical gradient. From the start bus to the end bus, the gradual change occurs in both counterclockwise and clockwise directions, both from the start color to the end color. Note that the center point of the filled area is the vertex of the cone, and the color does not change on the generatrix of the cone.
                                   As shown in the figure, the starting generatrix of the gradient is on the right side of the center point of the filled area and passing through the horizontal line. The color of the upper cone gradually changes counterclockwise, and the color of the lower half cone changes clockwise, in two directions. The start bus and the end bus of the gradation are the same. In the process from the start bus to the end bus in the counterclockwise and clockwise directions, the gradation is uniformly gradual from the start color to the end color

                                  .. image:: ../image/Gra_Conical.png

    :var FillGradientMode.SQUARE: Four-corner gradient. A square gradient with the center point of the filled area as the starting point of the gradient filling, and the midpoint of the shorter side of the smallest bounding rectangle of the filled area as the ending point. Note that the color on each square does not change, and the color changes between different squares.
                                  As shown in the figure, from the start point to the end point of the gradient filling, the color of the square with the start point as the center gradually changes from the start color to the end color as the side length increases.

                                  .. image:: ../image/Gra_Square2.png

    """,

    "iobjectspy._jsuperpy.enums.FunctionType": """
    Transformation function type constant

    :var FunctionType.NONE: Do not use transformation functions.
    :var FunctionType.LOG: The transformation function is log, and the original value is required to be greater than 0.
    :var FunctionType.ARCSIN: The transformation function is arcsin, and the original value is required to be in the range [-1,1].
    """,

    "iobjectspy._jsuperpy.enums.GeoCoordSysType": """An enumeration.""",

    "iobjectspy._jsuperpy.enums.GeoDatumType": """An enumeration.""",

    "iobjectspy._jsuperpy.enums.GeoPrimeMeridianType": """
    This class defines constants of the central meridian type.

    :var GeoPrimeMeridianType.PRIMEMERIDIAN_USER_DEFINED: user-defined
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_GREENWICH: Greenwich prime meridian, that is, 0Â° longitude
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_LISBON: 9Â°07'54".862 W
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_PARIS: 2Â°20'14".025 E
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_BOGOTA: 74Â°04'51".3 W
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_MADRID: 3Â°41'16".58 W
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_ROME: 12Â°27'08".4 E
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_BERN: 7Â°26'22".5 E
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_JAKARTA: 106Â°48'27".79 E
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_FERRO: 17Â°40'00" W
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_BRUSSELS: 4Â°22'04".71 E
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_STOCKHOLM: 18Â°03'29".8 E
    :var GeoPrimeMeridianType.PRIMEMERIDIAN_ATHENS: 23Â°42'58".815 E
    """,

    "iobjectspy._jsuperpy.enums.GeoSpatialRefType": """
    This class defines the constants of the spatial coordinate system type.

    The type of space coordinate system is used to distinguish plane coordinate system, geographic coordinate system, and projected coordinate system. The geographic coordinate system is also called the latitude and longitude coordinate system.

    :var GeoSpatialRefType.SPATIALREF_NONEARTH: Plane coordinate system. When the coordinate system is a plane coordinate system, projection conversion cannot be performed.
    :var GeoSpatialRefType.SPATIALREF_EARTH_LONGITUDE_LATITUDE: geographic coordinate system. The geographic coordinate system consists of a geodetic reference system, a central meridian, and coordinate units. In the geographic coordinate system, the unit can be degrees, minutes, and seconds. The east-west direction (horizontal direction) ranges from -180 degrees to 180 degrees. The north-south direction (vertical direction) ranges from -90 degrees to 90 degrees.
    :var GeoSpatialRefType.SPATIALREF_EARTH_PROJECTION: Projected coordinate system. The projection coordinate system is composed of map projection method, projection parameters, coordinate unit and geographic coordinate system. SuperMap Objects Java provides many predefined projection systems that users can use directly. In addition, users can also customize their own projection systems.
    """,

    "iobjectspy._jsuperpy.enums.GeoSpheroidType": """An enumeration.""",

    "iobjectspy._jsuperpy.enums.GeometryType": """
    This class defines a series of type constants of geometric objects.

    :var GeometryType.GEOPOINT: point geometry object
    :var GeometryType.GEOLINE: Line geometry object.
    :var GeometryType.GEOREGION: Geometry object
    :var GeometryType.GEOTEXT: text geometry object
    :var GeometryType.GEOLINEM: A route object is a set of linear feature objects composed of points with X, Y coordinates and linear measurement values.
    :var GeometryType.GEOCOMPOUND: Compound geometry object. A composite geometric object is composed of multiple sub-objects, and each sub-object can be any type of geometric object.
    :var GeometryType.GEOPARAMETRICLINECOMPOUND: Compound parametric line geometry object.
    :var GeometryType.GEOPARAMETRICREGIONCOMPOUND: Compound parametric area geometry object.
    :var GeometryType.GEOPARAMETRICLINE: Parametric line geometry object.
    :var GeometryType.GEOPARAMETRICREGION: Parametric area geometry object.
    :var GeometryType.GEOMULTIPOINT: Multipoint object, parameterized geometric object type.
    :var GeometryType.GEOROUNDRECTANGLE: rounded rectangle geometry object, the parameterized geometry object type.
    :var GeometryType.GEOCIRCLE: Circle geometry object, the parameterized geometry object type.
    :var GeometryType.GEOELLIPSE: Ellipse geometry object, the parameterized geometry object type.
    :var GeometryType.GEOPIE: Sector geometry object, the parameterized geometry object type.
    :var GeometryType.GEOARC: circular arc geometry object, the parameterized geometry object type.
    :var GeometryType.GEOELLIPTICARC: elliptic arc geometric object, the parameterized geometric object type.
    :var GeometryType.GEOCARDINAL: Two-dimensional Cardinal spline geometry object, a parameterized geometry object type.
    :var GeometryType.GEOCURVE: A two-dimensional curve geometry object, a parameterized geometry object type.
    :var GeometryType.GEOBSPLINE: A two-dimensional B-spline curve geometry object, a parameterized geometry object type.
    :var GeometryType.GEOPOINT3D: Three-dimensional point geometry object.
    :var GeometryType.GEOLINE3D: 3D line geometry object.
    :var GeometryType.GEOREGION3D: Three-dimensional surface geometry object.
    :var GeometryType.GEOCHORD: Arch geometry object, the parameterized geometry object type.
    :var GeometryType.GEOCYLINDER: Round table geometry object.
    :var GeometryType.GEOPYRAMID: Pyramid geometry object.
    :var GeometryType.GEORECTANGLE: Rectangular geometry object, parameterized geometry object type.
    :var GeometryType.GEOBOX: Cuboid geometry object.
    :var GeometryType.GEOPICTURE: Two-dimensional picture geometry object.
    :var GeometryType.GEOCONE: Cone geometry object.
    :var GeometryType.GEOPLACEMARK: Three-dimensional landmark geometry object.
    :var GeometryType.GEOCIRCLE3D: 3D circular geometry object.
    :var GeometryType.GEOSPHERE: sphere geometry object
    :var GeometryType.GEOHEMISPHERE: Hemisphere geometry object.
    :var GeometryType.GEOPIECYLINDER: Geometry object of pie table.
    :var GeometryType.GEOPIE3D: Three-dimensional fan geometry object.
    :var GeometryType.GEOELLIPSOID: ellipsoid geometry object.
    :var GeometryType.GEOPARTICLE: 3D particle geometry object.
    :var GeometryType.GEOTEXT3D: 3D text geometry object.
    :var GeometryType.GEOMODEL: 3D model geometry object.
    :var GeometryType.GEOMAP: Map geometry object, used to add a map to the layout.
    :var GeometryType.GEOMAPSCALE: The geometric object of the map scale.
    :var GeometryType.GEONORTHARROW: North arrow geometry object.
    :var GeometryType.GEOMAPBORDER: The border of the map geometry object.
    :var GeometryType.GEOPICTURE3D: Three-dimensional picture geometry object.
    :var GeometryType.GEOLEGEND: Legend object.
    :var GeometryType.GEOUSERDEFINED: User-defined geometric object.
    :var GeometryType.GEOPOINTEPS: EPS point geometry object
    :var GeometryType.GEOLINEEPS: EPS line geometry object
    :var GeometryType.GEOREGIONEPS: EPS surface geometry object
    :var GeometryType.GEOTEXTEPS: EPS text geometry object
    """,

    "iobjectspy._jsuperpy.enums.GridStatisticsMode": """
    Raster statistics type constant

    :var GridStatisticsMode.MIN: minimum value
    :var GridStatisticsMode.MAX: Maximum
    :var GridStatisticsMode.MEAN: Average
    :var GridStatisticsMode.STDEV: standard deviation
    :var GridStatisticsMode.SUM: Sum
    :var GridStatisticsMode.VARIETY: Type
    :var GridStatisticsMode.RANGE: Value range, that is, the difference between the maximum value and the minimum value
    :var GridStatisticsMode.MAJORITY: Mode (the grid value with the highest frequency)
    :var GridStatisticsMode.MINORITY: the least number (the grid value with the lowest frequency)
    :var GridStatisticsMode.MEDIAN: median (arrange the values of all grids from small to large, and take the grid value at the middle position)
    """,

    "iobjectspy._jsuperpy.enums.GriddingLevel": """
    For the query of the geometric area object (GeometriesRelation), by setting the grid of the area object, the judgment speed can be speeded up, such as the judgment that the area contains points. Grid of a single area object
    The higher the level, the more memory is required, which is generally applicable to situations where there are few area objects but a single area object is relatively large.

    :var GriddingLevel.NONE: No grid
    :var GriddingLevel.LOWER: Low-level gridding, using 32*32 grids for each surface
    :var GriddingLevel.MIDDLE: Intermediate level gridding, using 64*64 grids for each face
    :var GriddingLevel.NORMAL: general level gridding, using 128*128 grids for each face
    :var GriddingLevel.HIGHER: High-level gridding, using 256*256 grids for each face
    """,

    "iobjectspy._jsuperpy.enums.IgnoreMode": """
    This class defines type constants that ignore the color value mode.

    :var IgnoreMode.IGNORENONE: Do not ignore the color value.
    :var IgnoreMode.IGNORESIGNAL: Ignore by value, ignore one or several color values.
    :var IgnoreMode.IGNOREBORDER: Ignore the color value according to the scan line.
    """,

    "iobjectspy._jsuperpy.enums.ImageDisplayMode": """
    Image display mode, currently supports combination mode and stretch mode.

    :var ImageDisplayMode.COMPOSITE: Combination mode. The combination mode is for multi-band images. The images are combined into RGB display according to the set band index sequence. Currently, only RGB and RGBA color spaces are supported.
    :var ImageDisplayMode.STRETCHED: Stretch mode. Stretch mode supports all images (including single band and multi-band). For multi-band images, when this display mode is set, the first band of the set band index will be displayed.

    """,

    "iobjectspy._jsuperpy.enums.ImageInterpolationMode": """
    This class defines constants for the image interpolation mode.

    :var ImageInterpolationMode.NEARESTNEIGHBOR: The nearest neighbor interpolation mode.
    :var ImageInterpolationMode.LOW: Low-quality interpolation mode.
    :var ImageInterpolationMode.HIGH: High-quality interpolation mode.
    :var ImageInterpolationMode.DEFAULT: The default interpolation mode.
    :var ImageInterpolationMode.HIGHQUALITYBICUBIC: High-quality bilinear interpolation mode.
    :var ImageInterpolationMode.HIGHQUALITYBILINEAR: The highest quality bicubic interpolation mode.
    """,

    "iobjectspy._jsuperpy.enums.ImageType": """
    This class defines the image type constants for map output

    :var ImageType.BMP: BMP is a standard format used by Windows for storing device-independent and application-independent images. The bit-per-pixel value (1, 4, 8, 15, 24, 32, or 64) of a given BMP file is specified in the file header. BMP files with 24 bits per pixel are universal. BMP files are usually uncompressed, so they are not suitable for transmission over the Internet.
    :var ImageType.GIF: GIF is a general format used to display images on web pages. GIF files are suitable for drawing lines, pictures with solid color blocks, and pictures with clear boundaries between colors. GIF files are compressed, but no information is lost during the compression process; the decompressed image is exactly the same as the original image. A color in a GIF file can be designated as transparent, so that the image will have the background color of any web page on which it is displayed. Storing a series of GIF images in a single file can form an animated GIF. GIF files can store up to 8 bits per pixel, so they are limited to 256 colors.
    :var ImageType.JPG: JPEG is a compression scheme adapted to natural landscapes (such as scanned photos). Some information will be lost in the compression process, but the loss is imperceptible to the human eye. JPEG files store 24 bits per pixel, so they can display more than 16,000,000 colors. JPEG files do not support transparency or animation. JPEG is not a file format. "JPEG File Interchange Format (JFIF)" is a file format commonly used to store and transmit images that have been compressed according to the JPEG scheme. The JFIF file displayed by the web browser has a .jpg extension.
    :var ImageType.PDF: PDF (Portable Document Format) file format is an electronic file format developed by Adobe. This file format has nothing to do with the operating system platform, that is to say, the PDF file is universal whether it is in Windows, Unix or Apple's Macos operating system
    :var ImageType.PNG: PNG type. The PNG format not only retains many of the advantages of the GIF format, but also provides functions beyond GIF. Like GIF files, PNG files do not lose information when compressed. PNG files can store colors at 8, 24, or 48 bits per pixel and grayscale at 1, 2, 4, 8, or 16 bits per pixel. In contrast, GIF files can only use 1, 2, 4, or 8 bits per pixel. PNG files can also store an alpha value for each pixel, which specifies the degree to which the color of the pixel blends with the background color. The advantage of PNG over GIF is that it can display an image progressively (that is, the displayed image will become more and more complete as the image is transmitted through the network connection). PNG files can contain grayscale correction and color correction information so that the image can be accurately presented on a variety of display devices.
    :var ImageType.TIFF: TIFF is a flexible and extensible format, which is supported by various platforms and image processing applications. TIFF files can store images in any bit per pixel and can use various compression algorithms. A single multi-page TIFF file can store several images. You can store information related to the image (scanner manufacturer, host, compression type, printing direction and sampling per pixel, etc.) in a file and use tags to arrange the information. The TIFF format can be extended by approving and adding new tags as needed.
    """,

    "iobjectspy._jsuperpy.enums.ImportMode": """
    This class defines constants for import mode types. It is used to control the operation mode when the target object (dataset, etc.) name of the setting that appears during data import already exists, that is, the setting name has a name conflict.

    :var ImportMode.NONE: If there is a name conflict, automatically modify the name of the target object before importing.
    :var ImportMode.OVERWRITE: If there is a name conflict, perform a forced overwrite.
    :var ImportMode.APPEND: If there is a name conflict, the dataset will be added.
    """,

    "iobjectspy._jsuperpy.enums.InterpolationAlgorithmType": """
    This class defines the type constants of the algorithms supported by interpolation analysis.

    For a region, if only part of the discrete point data is known, if you want to create or simulate a surface or field, you need to estimate the value of the unknown point, usually using the method of interpolating the surface. Provided in SuperMap
    Three interpolation methods, using to simulate or create a surface, namely: inverse distance weighting method (IDW), Kriging interpolation method (Kriging), and radial basis function interpolation method (RBF). The method you choose to interpolate
    Usually depends on the distribution of the sample data and the type of surface to create.

    :var InterpolationAlgorithmType.IDW: Inverse Distance Weighted interpolation method. The method by calculating the average area discrete point group to estimate
                                         The value of the cell, and generates the raster dataset. This is a simple and effective data interpolation method, and the calculation speed is relatively fast. The closer the point to the discrete center, the more affected its estimated value.
    :var InterpolationAlgorithmType.SIMPLEKRIGING: Simple Kriging (Simple Kriging) interpolation method. Simple Kriging is one of the commonly used Kriging interpolation methods, this method assumes
                                                   That the expectation (mean) of the field values used for interpolation is known for some constant.
    :var InterpolationAlgorithmType.KRIGING: Common Kriging interpolation method. One of the most commonly used Kriging interpolation methods. This method assumes that the expectation
                                             (mean) of the field values used for interpolation is unknown and constant. It uses a certain mathematical function to estimate the value of a cell by fitting a given space point.
                                             Generate grid dataset. It can not only generate a surface, but also give a measure of the accuracy or certainty of the prediction result. Therefore, the calculation accuracy
                                             Of this method is high, and it is often used in social sciences and geology.
    :var InterpolationAlgorithmType.UNIVERSALKRIGING: Universal Kriging (Universal Kriging) interpolation method. Universal Kriging is also one of the commonly used Kriging interpolation methods.
                                                      The method assumes that the expected (mean) variable of the field value used for interpolation is unknown. The existence of a dominant trend in the data sample, and the trend can be fitted by a certain
                                                      Function or polynomial in the case of pan-Clutkin interpolation method.
    :var InterpolationAlgorithmType.RBF: Radial Basis Function (Radial Basis Function) interpolation method. This method assumes that the change is smooth, and it has two characteristics:

                                         -The surface must pass through the data points accurately;
                                         -The surface must have a minimum curvature.

                                         This interpolation has advantages in creating visually demanding curves and contours.
    :var InterpolationAlgorithmType.DENSITY: Point density (Density) interpolation method

    """,

    "iobjectspy._jsuperpy.enums.JEnum": """Enumeration value type, providing an interface for constructing enumeration items based on names and enumeration values.""",

    "iobjectspy._jsuperpy.enums.JoinType": """
    This class defines constants that define the connection type between two tables.

    This class is used to query between the two connected tables, which determines the records obtained in the query results

    :var JoinType.INNERJOIN: Full inner join, only if there are related records in two tables will it be added to the query result set.
    :var JoinType.LEFTJOIN: Left join, all related records in the left table enter the query result set, and if there is no related record in the right table, the corresponding field value is displayed as empty.
    """,

    "iobjectspy._jsuperpy.enums.KernelFunction": """
    Geographically weighted regression analysis kernel function type constant.

    :var KernelFunction.GAUSSIAN: Gaussian kernel function.

                                  Gaussian kernel function calculation formula:

                                  W_ij=e^(-((d_ij/b)^2)/2).

                                  Where W_ij is the weight between point i and point j, d_ij is the distance between point i and point j, and b is the bandwidth range.

    :var KernelFunction.BISQUARE: Quadratic kernel function.
                                  Quadratic kernel function calculation formula:

                                  If d_ijâ‰¤b, W_ij=(1-(d_ij/b)^2))^2; otherwise, W_ij=0.

                                  Where W_ij is the weight between point i and point j, d_ij is the distance between point i and point j, and b is the bandwidth range.

    :var KernelFunction.BOXCAR: Box-shaped kernel function.

                                Box kernel function calculation formula:

                                If d_ijâ‰¤b, W_ij=1; otherwise, W_ij=0.

                                Where W_ij is the weight between point i and point j, d_ij is the distance between point i and point j, and b is the bandwidth range.

    :var KernelFunction.TRICUBE: Cube kernel function.

                                 Cube kernel function calculation formula:

                                 If d_ijâ‰¤b, W_ij=(1-(d_ij/b)^3))^3; otherwise, W_ij=0.

                                 Where W_ij is the weight between point i and point j, d_ij is the distance between point i and point j, and b is the bandwidth range.
    """,

    "iobjectspy._jsuperpy.enums.KernelType": """
    Geographically weighted regression analysis bandwidth type constant

    :var KernelType.FIXED: Fixed type bandwidth. For each regression analysis point, a fixed value is used as the bandwidth range.
    :var KernelType.ADAPTIVE: Variable type bandwidth. For each regression analysis point, the distance between the regression point and the Kth nearest neighbor point is used as the bandwidth range. Among them, K is the number of neighbors.
    """,

    "iobjectspy._jsuperpy.enums.LayerGridAggregationType": """
    The grid type of the grid aggregation graph.

    :var LayerGridAggregationType.QUADRANGLE: rectangular grid
    :var LayerGridAggregationType.HEXAGON: Hexagonal grid
    """,

    "iobjectspy._jsuperpy.enums.LineToPointMode": """
    Line to point

    :var LineToPointMode.VERTEX: node mode, each node of the line object is converted into a point object
    :var LineToPointMode.INNER_POINT: Inner point mode, convert the inner point of the line object into a point object
    :var LineToPointMode.SUB_INNER_POINT: Sub-object inner point mode, which converts the inner point of each sub-object of the line object into a point object. If the number of sub-objects of the line is 1, it will be the same as the result of INNER_POINT.
    :var LineToPointMode.START_NODE: Starting point mode, which converts the first node of the line object, the starting point, to a point object
    :var LineToPointMode.END_NODE: End point mode, which converts the last node of the line object, the end point, to a point object
    :var LineToPointMode.START_END_NODE: start and end point mode, convert the start and end points of the line object into a point object respectively
    :var LineToPointMode.SEGMENT_INNER_POINT: Line segment inner point mode, which converts the inner point of each line segment of the line object into a point object. The line segment refers to the line formed by two adjacent nodes.
    :var LineToPointMode.SUB_START_NODE: Sub-object starting point mode, which converts the first point of each sub-object of the line object into a point object respectively
    :var LineToPointMode.SUB_END_NODE: Sub-object end point mode, which converts the next point of each sub-object of the line object into a point object respectively
    :var LineToPointMode.SUB_START_END_NODE: Sub-object start and end point mode, which converts the first point and the last point of each sub-object of the line object into a point object.

    """,

    "iobjectspy._jsuperpy.enums.MajorityDefinition": """
    Before replacing, specify the number of adjacent (spatially connected) cells that must have the same value, that is, when the same value of adjacent cells is continuous, the replacement is performed.

    :var MajorityDefinition.HALF: Indicates that half of the pixels must have the same value and are adjacent, that is, the connected pixels greater than or equal to two-quarters or four-eights must have the same value.
                                  A smoother effect can be obtained.
    :var MajorityDefinition.MAJORITY: Indicates that most pixels must have the same value and be adjacent, that is, connected pixels greater than or equal to three-quarters or five-eighths must have the same value.
    """,

    "iobjectspy._jsuperpy.enums.MapColorMode": """
    This class defines the constants of the map color mode type.

    This color mode is only for map display, and only works for vector elements. When each color mode is converted, the thematic style of the map will not change, and the conversion of various color modes is based on
    The thematic style color of the map comes. SuperMap component products provide 5 color modes when setting the map style.

    :var MapColorMode.DEFAULT: Default color mode, corresponding to 32-bit enhanced true color mode. 32 bits are used to store colors, of which red, green, blue and alpha are represented by 8 bits each.
    :var MapColorMode.BLACK_WHITE: Black and white mode. According to the thematic style of the map (default color mode), map elements are displayed in two colors: black and white. The elements whose thematic style color is white are still displayed in white, and the other colors are displayed in black.
    :var MapColorMode.GRAY: Grayscale mode. According to the thematic style of the map (default color mode), set different weights for the red, green, and blue components and display them in grayscale.
    :var MapColorMode.BLACK_WHITE_REVERSE: Black and white reverse color mode. According to the thematic style of the map (default color mode), elements whose thematic style color is black are converted to white, and the remaining colors are displayed in black
    :var MapColorMode.ONLY_BLACK_WHITE_REVERSE: Reverse black and white, other colors remain unchanged. According to the thematic style of the map (default color mode), the elements whose thematic style color is black are converted to white, and the elements whose thematic style color is white are converted to black, and the other colors remain unchanged.

    """,

    "iobjectspy._jsuperpy.enums.MultiBandImportMode": """
    This class defines the constants of the multi-band import mode type, and provides the mode used to import the multi-band data.

    :var MultiBandImportMode.SINGLEBAND: Import multi-band data into multiple single-band dataset
    :var MultiBandImportMode.MULTIBAND: Import multi-band data as a multi-band dataset
    :var MultiBandImportMode.COMPOSITE: Import multi-band data as a single-band dataset. Currently, this mode is suitable for the following two situations:

                                        -Three-band 8-bit data is imported into a RGB single-band 24-bit dataset;
                                        -Four-band 8-bit data is imported as a RGBA single-band 32-bit dataset.
    """,

    "iobjectspy._jsuperpy.enums.NeighbourNumber": """
    Number of neighborhood pixels for spatial connectivity

    :var NeighbourNumber.FOUR: 4 pixels up, down, left and right are regarded as neighboring pixels. Only if the pixels with the same value are directly connected to each of the four nearest pixels,
                               The connectivity between these pixels will be defined. Orthogonal pixels retain the corners of the rectangular area.

                               .. image:: ../image/four.png

    :var NeighbourNumber.EIGHT: 8 adjacent pixels are regarded as neighboring pixels. Only when the pixels with the same value are located in the 8 nearest neighbors to each other, the connection between these pixels will be defined.
                                Eight adjacent pixels make the rectangle smooth.

                                 .. image:: ../image/eight.png

    """,

    "iobjectspy._jsuperpy.enums.NeighbourShapeType": """
    :var NeighbourShapeType.RECTANGLE: Rectangular neighborhood. The size of the rectangle is determined by the specified width and height . The cells within the rectangle participate in the calculation of neighborhood statistics. The default width and height of the rectangular neighborhood
                                       Are both 0 (the unit is geographic unit or grid unit).

                                       .. image:: ../image/Rectangle.png

    :var NeighbourShapeType.CIRCLE: Circular neighborhood. The size of the circular neighborhood is determined according to the specified radius. All cells within the circle area participate in the neighborhood processing, as long as the cell is partially contained within the circular range
                                    Will participate in neighborhood statistics. The default radius of a circular neighborhood is 0 (units are geographic units or grid units).

                                    .. image:: ../image/Circle.png

    :var NeighbourShapeType.ANNULUS: Ring neighborhood. The size of the circular neighborhood is determined according to the specified outer radius and inner radius, and the cells in the circular area participate in the neighborhood processing. The default radius of the outer circle and the inner circle in the ring neighborhood
                                    Are both 0 (in geographic or grid units)

                                    .. image:: ../image/Annulus.png

    :var NeighbourShapeType.WEDGE: Fan-shaped neighborhood. The size of the fan-shaped neighborhood is determined according to the specified circle radius, starting angle and ending angle. All cells in the fan-shaped area participate in neighborhood processing.
                                   The default radius of the fan-shaped neighborhood is 0 (the unit is geographic unit or grid unit), and the default value of the start angle and end angle are both 0 degrees.

                                   .. image:: ../image/Wedge.png

    """,

    "iobjectspy._jsuperpy.enums.NeighbourUnitType": """
    This class defines unit type constants for neighborhood analysis.

    :var NeighbourUnitType.CELL: grid coordinates, that is, the number of grids is used as the neighborhood unit.
    :var NeighbourUnitType.MAP: Geographical coordinates, that is, use the length unit of the map as the neighborhood unit.
    """,

    "iobjectspy._jsuperpy.enums.OverlayAnalystOutputType": """
    Overlay analysis Return the result geometric object type. Only valid for the face-to-face intersection operator.

    :var OverlayAnalystOutputType.INPUT: The result object type is consistent with the input source data type
    :var OverlayAnalystOutputType.POINT: The result object type is a point object
    """,

    "iobjectspy._jsuperpy.enums.OverlayMode": """
    Overlay analysis mode type

    * Clipping (CLIP)

        It is used to perform overlay analysis on the dataset by erasing method, and cut and delete the objects contained in the second dataset in the first dataset.

        * The type of the cropped dataset (the second dataset) must be a surface, and the dataset to be cropped (the first dataset) can be a point, a line, or a surface.
        * In the cropped dataset, only objects that fall within the polygons of the cropped dataset will be output to the result dataset.
        * The geographic coordinate system of the cropped dataset, the cropped dataset, and the result dataset must be consistent.
        * Clip and intersect are the same in spatial processing. The difference lies in the processing of the attributes of the result record set. Clip analysis is only used for clipping. The result record set has the same structure as the attribute table of the first record set. The analysis parameters are superimposed here. Object setting is invalid. The results of intersect intersection analysis can retain the fields of the two record sets according to the field settings.
        * All the results of overlay analysis do not consider the system fields of the dataset.

        .. image:: ../image/OverlayClip.png

    * Erase (ERASE)

        It is used to perform superposition analysis on the dataset in the same way, and the result dataset retains all the objects of the same operation dataset and the objects that are intersected by the same operation dataset and the dataset used for the same operation.

        * The type of the erased dataset (the second dataset) must be a surface, and the erased dataset (the first dataset) can be a point, line, or surface dataset.
        * The polygon set in the erasing dataset defines the erasing area. All the features in the erasing dataset that fall within these polygon areas will be removed, and the feature elements that fall outside the polygon area will be output to the result dataset , The opposite of clip operation.
        * The geographic coordinate system of the erased dataset, the erased dataset, and the result dataset must be consistent.

        .. image:: ../image/OverlayErase.png

    * Same (IDENTITY)

        It is used to perform superposition analysis on the dataset in the same way, and the result dataset retains all the objects of the same operation dataset and the objects that are intersected by the same operation dataset and the dataset used for the same operation.

        * The same operation is an operation in which the first dataset and the second dataset intersect first, and then the result of the intersection is merged with the first dataset. Among them, the type of the second dataset must be a polygon, and the type of the first dataset can be a point, line, or polygon dataset. If the first dataset is a point set, the newly generated dataset retains all the objects of the first dataset; if the first dataset is a line dataset, the newly generated dataset retains the data of the first dataset All objects, but the objects that intersect with the second dataset are interrupted at the intersection; if the first dataset is a polygon dataset, the result dataset retains all the polygons within the control boundary with the first dataset , And divide the object that intersects with the second dataset into multiple objects at the intersection .
        * The identiy operation is similar to the union operation. The difference is that the union operation retains all the parts of the two dataset, while the identity operation keeps the disjoint parts of the first dataset and the second dataset . The result attribute table of the identity operation comes from the attribute tables of the two dataset.
        * The geographic coordinate system of the dataset used for the same operation, the same operation dataset and the result dataset must be consistent.

        .. image:: ../image/OverlayIdentity.png

    * Intersect (INTERSECT)

        Perform the overlap analysis of the intersection method, and cut and delete the objects in the dataset that are not included in the dataset used for the intersection overlay analysis. That is, the overlapping part of the two dataset will be output to the result dataset, and the rest will be excluded.

        * The dataset to be analyzed by intersection and overlay can be point type, line type and area type, and the dataset used for intersection and overlay analysis must be of surface type. The feature objects (points, lines, and areas) of the first dataset are split at the intersection with the polygons in the second dataset (except point objects), and the split result is output to the result dataset.
        * The spatial geometric information of the result dataset obtained by the intersection operation and the clipping operation is the same, but the clipping operation does not do any processing on the attribute table, and the intersection operation allows the user to select the attribute fields that need to be retained.
        * The geographic coordinate system of the dataset used for the intersection and overlay analysis, the dataset to be intersected and overlay analysis, and the result dataset must be consistent.

        .. image:: ../image/OverlayIntersect.png

    * Symmetrical difference (XOR)

        Perform the symmetric difference analysis operation on the two face dataset. That is, the intersection is inverted.

        * The geographic coordinate system of the dataset used for symmetric difference analysis, the dataset to be analyzed by symmetric difference, and the result dataset must be consistent.
        * Symmetric difference operation is the exclusive OR operation of two dataset. The result of the operation is that for each area object, the part that it intersects with the geometric object in another dataset is removed, and the remaining part is retained. The attribute table of the output result of the symmetric difference operation contains the non-system attribute fields of the two input dataset.

        .. image:: ../image/OverlayXOR.png

    * UNION

        It is used to perform a merged overlay analysis on two surface dataset, and the result dataset saves the merged overlay analysis dataset and all the objects in the merged overlay analysis dataset, and performs intersection and division operations on the intersecting part. note:

        * Merging is the operation of merging two datasets. The merged layer retains all the layer features of the two datasets, and is limited to the two area datasets.
        * After the union operation, the two face datasets are divided into polygons at the intersection, and the geometry and attribute information of the two datasets are output to the result dataset.
        * The geographic coordinate system of the dataset used for the merged overlay analysis, the merged overlay analysis dataset, and the result dataset must be consistent.

        .. image:: ../image/OverlayUnion.png

    * Update (UPDATE)

        It is used for the overlay analysis of the update method of two face dataset. The update operation is to replace the overlapping part of the updated dataset with the updated dataset, which is a process of erasing and pasting.

        * The geographic coordinate system of the dataset used to update the overlay analysis, the dataset to be updated, and the result dataset must be consistent.
        * The type of the first dataset and the second dataset must be a face dataset. The result dataset retains the geometric shape and attribute information of the updated dataset.

        .. image:: ../image/OverlayUpdate.png

    :var OverlayMode.CLIP: Clipping
    :var OverlayMode.ERASE: Erase
    :var OverlayMode.IDENTITY: same
    :var OverlayMode.INTERSECT: Intersect
    :var OverlayMode.XOR: Symmetrical difference
    :var OverlayMode.UNION: merge
    :var OverlayMode.UPDATE: Update
    """,

    "iobjectspy._jsuperpy.enums.PixelFormat": """
    This class defines the pixel format type constants for raster and image data storage.

    The raster data structure is actually an array of pixels, and the pixel (or pixel) is the most basic information storage unit of raster data. There are two types of raster data in SuperMap: Raster Dataset (DatasetGrid)
    And image datasets (DatasetImage), raster datasets are mostly used for raster analysis, so their pixel values are attribute values of features, such as elevation, precipitation, etc.; image datasets are generally used for display or as a base
    Graph, so its pixel value is the color value or color index value.

    :var PixelFormat.UNKONOWN: Unknown pixel format
    :var PixelFormat.UBIT1: Each pixel is represented by 1 bit. For raster datasets, it can represent two values of 0 and 1. For image datasets, it can represent two colors of black and white, corresponding to monochrome image data.
    :var PixelFormat.UBIT4: Each pixel is represented by 4 bits. For a raster dataset, it can represent a total of 16 integer values from 0 to 15; for an image dataset, it can represent 16 colors. These 16 colors are indexed colors, which are defined in its color table, corresponding to 16 colors Image data.
    :var PixelFormat.UBIT8: Each pixel is represented by 8 bits, that is, 1 byte. For a raster dataset, it can represent a total of 256 integer values from 0 to 255; for an image dataset, it can represent 256 gradual colors. These 256 colors are indexed colors, which are defined in the color table and correspond to Image data of 256 colors.
    :var PixelFormat.BIT8: Each pixel is represented by 8 bits, that is, 1 byte. For a raster dataset, it can represent 256 integer values from -128 to 127. Each pixel is represented by 8 bits, that is, 1 byte. For a raster dataset, it can represent 256 integer values from -128 to 127.
    :var PixelFormat.BIT16: Each pixel is represented by 16 bits, that is, 2 bytes. For raster datasets, it can represent 65536 integer values from -32768 to 32767; for image datasets, among the 16 bits, red, green, and blue are each represented by 5 bits, and the remaining 1 bit is unused. Corresponds to color image data.
    :var PixelFormat.UBIT16: Each pixel is represented by 16 bits, that is, 2 bytes. For raster datasets, it can represent 65536 integer values from 0 to 65535
    :var PixelFormat.RGB: Each pixel is represented by 24 bits, ie 3 bytes. It is only available for image dataset. Among the 24 bits, red, green, and blue are each represented by 8 bits, corresponding to true color image data.
    :var PixelFormat.RGBA: Each pixel is represented by 32 bits, that is, 4 bytes. It is only available for image dataset. Among the 32 bits, red, green, blue and alpha are represented by 8 bits each, corresponding to the image data with enhanced true color.
    :var PixelFormat.BIT32: Each pixel is represented by 32 bits, that is, 4 bytes. For raster datasets, it can represent 4294967296 integer values from -231 to (231-1); for image datasets, among the 32 bits, red, green, blue and alpha are represented by 8 bits each, corresponding to Enhance true color image data. This format supports DatasetGrid, DatasetImage (only supports multi-band).
    :var PixelFormat.UBIT32: Each pixel is represented by 32 bits, that is, 4 bytes, which can represent 4294967296 integer values from 0 to 4294967295.
    :var PixelFormat.BIT64: Each pixel is represented by 64 bits, that is, 8 bytes. It can represent a total of 18446744073709551616 integer values from -263 to (263-1). .
    :var PixelFormat.SINGLE: Each pixel is represented by 4 bytes. It can represent single-precision floating-point numbers in the range of -3.402823E+38 to 3.402823E+38.
    :var PixelFormat.DOUBLE: Each pixel is represented by 8 bytes. It can represent a double-precision floating-point number in the range of -1.7976313486232E+308 to 1.79769313486232E+308.

    """,

    "iobjectspy._jsuperpy.enums.PlaneType": """
    Plane type constant
    :var PlaneType.PLANEXY: A plane formed by the X and Y coordinate directions, that is, the XY plane
    :var PlaneType.PLANEYZ: The plane formed by the X and Z coordinate directions, that is, the YZ plane
    :var PlaneType.PLANEXZ: A plane formed by the Y and Z coordinate directions, that is, the XZ plane
    """,

    "iobjectspy._jsuperpy.enums.PrjCoordSysType": """An enumeration.""",

    "iobjectspy._jsuperpy.enums.ProjectionType": """An enumeration.""",

    "iobjectspy._jsuperpy.enums.PyramidResampleType": """
    The resampling method used when building the image pyramid.

    :var PyramidResampleType.NONE: no resampling
    :var PyramidResampleType.NEAREST: The nearest neighbor method, a simple sampling method
    :var PyramidResampleType.AVERAGE: Average method, calculate the average of all effective values for resampling calculation.
    :var PyramidResampleType.GAUSS: Use Gaussian kernel calculation method for resampling, which is better for images with high contrast and obvious pattern boundaries.
    :var PyramidResampleType.AVERAGE_MAGPHASE: Average joint data method, averaging joint data in a magphase space, used for resampling of images in complex data space.
    """,

    "iobjectspy._jsuperpy.enums.RasterJoinPixelFormat": """
    Defines the pixel format type constant of the mosaic result.

    :var RasterJoinPixelFormat.RJPMONO: PixelFormat.UBIT1.
    :var RasterJoinPixelFormat.RJPFBIT: ie PixelFormat.UBIT4
    :var RasterJoinPixelFormat.RJPBYTE: ie PixelFormat.UBIT8
    :var RasterJoinPixelFormat.RJPTBYTE: ie PixelFormat.BIT16
    :var RasterJoinPixelFormat.RJPRGB: ie PixelFormat.RGB
    :var RasterJoinPixelFormat.RJPRGBAFBIT: ie PixelFormat.RGBA
    :var RasterJoinPixelFormat.RJPLONGLONG: ie PixelFormat.BIT64
    :var RasterJoinPixelFormat.RJPLONG: ie PixelFormat.BIT32
    :var RasterJoinPixelFormat.RJPFLOAT: ie PixelFormat.SINGLE
    :var RasterJoinPixelFormat.RJPDOUBLE: ie PixelFormat.DOUBLE
    :var RasterJoinPixelFormat.RJPFIRST: The pixel format of the first raster dataset participating in mosaicking.
    :var RasterJoinPixelFormat.RJPLAST: The pixel format of the last raster dataset participating in mosaicking.
    :var RasterJoinPixelFormat.RJPMAX: The largest pixel format in the raster dataset participating in mosaicking.
    :var RasterJoinPixelFormat.RJPMIN: The smallest pixel format in the raster dataset participating in mosaicking.
    :var RasterJoinPixelFormat.RJPMAJORITY: The pixel format with the highest frequency in the raster dataset participating in mosaicking. If the pixel format appears with the same frequency, the smallest index value is used.

    """,

    "iobjectspy._jsuperpy.enums.RasterJoinType": """
    Defines the statistical type constant of the mosaic result raster value.

    :var RasterJoinType.RJMFIRST: Take the value in the first raster dataset after mosaicking the overlapping area of the raster.
    :var RasterJoinType.RJMLAST: Take the value in the last raster dataset after mosaicking the overlapping area of the raster.
    :var RasterJoinType.RJMMAX: Take the maximum value of the corresponding position in all raster datasets after mosaicking the overlapping area of the raster.
    :var RasterJoinType.RJMMIN: Take the minimum value of the corresponding position in all raster datasets after mosaicing the overlapping area of raster.
    :var RasterJoinType.RJMMean: Take the average value of the corresponding positions in all raster datasets after mosaicking the overlapping raster regions.
    """,

    "iobjectspy._jsuperpy.enums.RasterResampleMode": """
    The type constant of the raster resampling calculation method

    :var RasterResampleMode.NEAREST: The nearest neighbor method. The nearest neighbor method assigns the nearest grid value to a new grid. The advantage of this method is that the original grid value will not be changed, it is simple and the processing speed is fast, but the maximum displacement of this method is half the grid size. It is suitable for discrete data representing classification or a certain topic, such as land use, vegetation type, etc.
    :var RasterResampleMode.BILINEAR: Bilinear interpolation method. Bilinear interpolation uses the weighted average of the interpolation points in the 4 neighborhoods of the input grid to calculate the new grid value, and the weight is determined according to the distance between the center of each grid in the 4 neighborhoods and the interpolation point. The resampling result of this method will be smoother than that of the nearest neighbor method, but it will change the original grid value. It is suitable for continuous data representing the distribution of a certain phenomenon and topographic surface, such as DEM, temperature, rainfall distribution, slope, etc. These data are originally continuous surfaces obtained by interpolation of sampling points.
    :var RasterResampleMode.CUBIC: cubic convolution interpolation method. The cubic convolution interpolation method is more complicated, similar to bilinear interpolation, it also changes the grid value, the difference is that it uses 16 neighborhoods to weight the calculation, which will make the calculation result get some sharpening effect. This method will also change the original raster value, and may exceed the value range of the input raster, and is computationally intensive. Suitable for resampling of aerial photos and remote sensing images.

    """,

    "iobjectspy._jsuperpy.enums.ReclassPixelFormat": """
    This class defines the storage type constants of the cell values of the raster dataset

    :var ReclassPixelFormat.BIT32: Integer
    :var ReclassPixelFormat.BIT64: Long integer
    :var ReclassPixelFormat.SINGLE: Single precision
    :var ReclassPixelFormat.DOUBLE: double precision

    """,

    "iobjectspy._jsuperpy.enums.ReclassSegmentType": """
    This class defines constants for the reclassification interval type.

    :var ReclassSegmentType.OPENCLOSE: Open left and close right, such as (number1, number2].
    :var ReclassSegmentType.CLOSEOPEN: Close left and open right, such as [number1, number2).

    """,

    "iobjectspy._jsuperpy.enums.ReclassType": """
    This class defines constants for the grid reclassification type

    :var ReclassType.UNIQUE: Single value reclassification, that is, re-assign certain single values.
    :var ReclassType.RANGE: Range reclassification, that is, re-assign a value in an interval to a value.

    """,

    "iobjectspy._jsuperpy.enums.RegionToPointMode": """
    Face to point

    :var RegionToPointMode.VERTEX: node mode, each node of the region object is converted into a point object
    :var RegionToPointMode.INNER_POINT: Inner point mode, which converts the inner point of a region object into a point object
    :var RegionToPointMode.SUB_INNER_POINT: Sub-object interior point mode, which converts the interior points of each sub-object of the region into a point object
    :var RegionToPointMode.TOPO_INNER_POINT: Topological interior point mode. The interior points of multiple region objects obtained after protective decomposition of complex region objects are converted into a sub-object.
    """,

    "iobjectspy._jsuperpy.enums.ResamplingMethod": """
    This class defines constants for creating pyramid types.

    :var ResamplingMethod.AVERAGE: Average
    :var ResamplingMethod.NEAR: neighbor value
    """,

    "iobjectspy._jsuperpy.enums.SearchMode": """
    This class defines the type constants of the sample point search method used in interpolation.

    For the same interpolation method, the selection method of sample points is different, and the interpolation results obtained will also be different. SuperMap provides four interpolation search methods, namely no search, block (QUADTREE) search, fixed length search (KDTREE_FIXED_RADIUS) and variable length search (KDTREE_FIXED_COUNT).

    :var SearchMode.NONE: Do not search, use all input points for interpolation analysis.
    :var SearchMode.QUADTREE: Block search mode, that is, the dataset is divided into blocks according to the maximum number of points in each block, and the points in the block are used for interpolation.
                              Note: Currently it only works for Kriging and RBF interpolation methods, but not for IDW interpolation methods.
    :var SearchMode.KDTREE_FIXED_RADIUS: Fixed-length search mode, that is, all sampling points within the specified radius are involved in the interpolation operation of the grid unit. This method consists of search radius (search_radius) and
                                         It is expected that the minimum number of samples involved in the operation (expected_count) are two parameters to finally determine the sampling points involved in the operation.
                                         When calculating the unknown value of a certain position, the position will be taken as the center of the circle, and the set fixed length value (that is, the search radius) will be used as the radius.
                                         and all sampling points falling within this range will participate in the operation; but if the minimum number of points expected to participate in the calculation is set, if the number of points within the search radius does not reach this value, it will automatically
                                         Expand the search radius until the specified number of sampling points are found.
    :var SearchMode.KDTREE_FIXED_COUNT: Variable length search mode, that is, the specified number of sampling points closest to the grid unit participate in the interpolation operation. This method consists of the most diverse number of points
                                        (EXPECTED_COUNT) that are expected to participate in the calculation and search radius (search_radius) are two parameters to finally determine the sampling points involved in the calculation. When calculating a certain
                                        When the unknown value of a location, it will search for N sampling points near the location, and the N value is the set fixed number of points (that is, the most sample points expected to participate in the calculation
                                        Number), then these N sampling points will participate in the calculation; but if the search radius is set, if the number of points in the radius is less than the set fixed number of points, then
                                        The sampling points outside the range are discarded and do not participate in the calculation.
    """,

    "iobjectspy._jsuperpy.enums.ShadowMode": """
    This class defines the type constants of the shaded image rendering mode.

    :var ShadowMode.IllUMINATION_AND_SHADOW: Rendering and shadowing. At the same time consider the local illumination angle and the role of shadows.
    :var ShadowMode.SHADOW: Shadow. Only consider whether the area is in shadow.
    :var ShadowMode.IllUMINATION: Rendering. Only the local light angle is considered.
    """,

    "iobjectspy._jsuperpy.enums.SlopeType": """
    This class defines the unit type constant of the slope.

    :var SlopeType.DEGREE: Express the slope in angles.
    :var SlopeType.RADIAN: Express the slope in radians.
    :var SlopeType.PERCENT: Express the slope as a percentage. The percentage is the ratio of the vertical height to the horizontal distance multiplied by 100, that is, the height per unit horizontal distance multiplied by 100, or the tangent of the slope multiplied by 100.
    """,

    "iobjectspy._jsuperpy.enums.SmoothMethod": """
    This class defines the smooth method type constants. It is used to smooth the boundary line of the isoline or isosurface when generating isoline or isosurface from Grid or DEM data.

    The isoline is generated by interpolating the original raster data, and then connecting the equivalent points, so the result is a sharp polyline, and the isosurface is generated by interpolating the original raster data, then connecting the contour points
    To get the contour lines, which are closed by adjacent contour lines, so the result is a polygonal surface with sharp edges and corners. Both of these need to be smoothed. SuperMap provides two smoothing methods.
    B-spline method and angle grinding method.

    :var SmoothMethod.NONE: No smoothing.
    :var SmoothMethod.BSPLINE: B-spline method. The B-spline method uses a B-spline curve that passes through some nodes in the polyline instead of the original polyline to achieve smoothness. The B-spline curve is a extension of Bezier curve.
                               As shown in the figure below, the B-spline curve does not have to pass through all the nodes of the original line object. Except for some points on the original polyline that passed, other points on the curve pass
                               The B-spline function is fitted.

                               .. image:: ../image/BSpline.png

                               After using the B-spline method on a non-closed line object, the relative positions of its two end points remain unchanged.
    :var SmoothMethod.POLISH: Angle grinding method. The angle grinding method is a smooth method with relatively simple calculation and faster processing speed, but the effect is relatively limited. Its main process is to combine two adjacent line segments
                              On a polyline, add nodes at one-third of the length of the line segment from the vertex of the included angle, and connect the two newly added nodes on both sides of the included angle to smooth out the nodes of the original line segment, so it is called
                              Angle grinding method. The figure below is a schematic diagram of the process of one-step angle grinding.

                              .. image:: ../image/Polish.png

                              The angle can be sharpened multiple times to get a nearly smooth line. After using the angle grinding method on the non-closed line object, the relative position of its two end points remains unchanged.
    """,

    "iobjectspy._jsuperpy.enums.SpatialIndexType": """
    This class defines the spatial index type constants.

    Spatial index is used to improve the data structure of data space query efficiency. R-tree index, quad-tree index, map frame index and multi-level grid index are provided in SuperMap. The above indexes are only applicable to vector datasets.

    At the same time, a dataset can only use one index at a time, but the index can be switched, that is, after creating an index on the dataset, the old index must be deleted to create a new one. When the dataset is in the editing state,
    The system automatically maintains the current index. In particular, when the data is edited multiple times, the efficiency of the index will be affected to varying degrees. Through the judgment of the system, we know whether to re-establish the spatial index:

    -The current version of UDB and PostgreSQL datasources only support R-tree indexes (RTree), and DB2 datasources only support multi-level grid indexes (Multi_Level_Grid);
    -None of the point datasets in the database supports quad-tree (QTree) index and R-tree index (RTree);
    -The network dataset does not support any type of spatial index;
    -The composite dataset does not support multi-level grid index;
    -The routing dataset does not support tile index (TILE);
    -The attribute dataset does not support any type of spatial index;
    -For database-type datasources, indexes can be created only when the database records are greater than 1000.

    :var SpatialIndexType.NONE: No spatial index means no spatial index, suitable for very small data volume
    :var SpatialIndexType.RTREE: R-tree index is a disk-based index structure. It is a natural expansion of B-tree (one-dimensional) in high-dimensional space. It is easy to integrate with existing database systems and can support various types of
                                 Spatial query processing operation of, has been widely used in practice and is currently one of the most popular spatial index methods. The R-tree spatial index method is to design some
                                 Rectangle of the spatial object contains some target objects with similar spatial positions in this rectangle, and uses these rectangles as the spatial index. It contains pointers to the contained
                                 Space object.
                                 note:

                                 -This index is suitable for static data (when browsing and querying data).
                                 -This index supports concurrent operations of data.

    :var SpatialIndexType.QTREE: Quadtree is an important hierarchical dataset structure, mainly used to express the spatial hierarchical relationship under two-dimensional coordinates. In fact, it is an expansion of one-dimensional binary tree in two-dimensional space.
                                 Then, the quadtree index is to divide a map into four equal parts, and then divide it into four equal parts in each grid, and subdivide it layer by layer until it can no longer be divided. Now in SuperMap
                                 The middle quadtree allows up to 13 levels. Based on the sorting rules of Hilbert coding, From the quadtree we can determine the minimum range to which the indexed attribute value of each object
                                 Instance in the indexed class belongs.
    :var SpatialIndexType.TILE: The map frame index. In SuperMap, spatial objects are classified according to a certain attribute field of the dataset or according to a given range, The spatial objects are classified, and the classified spatial objects are managed by index,
                                 So as to improve the query retrieval speed.
    :var SpatialIndexType.MULTI_LEVEL_GRID: Multilevel grid index, also known as dynamic index. Multilevel grid index combines the advantages of R tree index and quadtree index, provides very good concurrent editing support,
                                            And has good universality. If it is not clear which spatial index is suitable for the data, a multi-level grid index can be established for it. Multilayer grid 
                                            Is used to organize and manage data. The basic method of grid index is to divide the dataset into equal or unequal grids according to certain rules and record
                                            The grid position occupied by each geographic object. Regular grids are commonly used in GIS. When the user makes a spatial query, the grid of the user's query object is first calculated,
                                            And the query operation can be optimized by quickly querying the selected geographic object through the grid.

                                            In the current version, the index to define the grid is level 1, level 2, and level 3. Each level has its own division rules, the first level has the smallest grid, and the second level
                                            The grid corresponding to the third level should be larger than the previous one. When establishing a multi-level grid index, according to the specific data and its distribution, the size of the grid and
                                            The number of grid index levels is automatically given by the system and does not need to be set by the user.
    :var SpatialIndexType.PRIMARY: Native index, which creates a spatial index. In PostgreSQL spatial data extension PostGIS, it is GIST index, which means general search tree. In the SQL Server spatial data extension SQLSpatial is a multi-level grid index:

                                   -PostGIS's GIST index is a balanced, tree-like access method, mainly using B-tree, R-tree, and RD-tree index algorithms. Advantages: Applicable to multidimensional data types and collection data types, as well as other data types. The GIST multi-field index will use index scans for any subset of indexed fields in the query conditions. Disadvantages: GIST index creation takes a long time and takes up a lot of space.
                                   -SQLSpatial's multi-level grid index can be set up to four levels, and each level is performed in sequence in a uniform grid manner. When creating an index, you can choose high, medium, and low grid densities, corresponding to (4*4), (8*8) and (16*16) respectively. The current default medium grid density.
    """,

    "iobjectspy._jsuperpy.enums.SpatialQueryMode": """
    This class defines the constants of the spatial query operation mode type.
    Spatial query is a query method that constructs filter conditions through the spatial position relationship between geometric objects. For example: through spatial query, you can find spatial objects contained in the surface, separated or adjacent spatial objects, etc.

    :var SpatialQueryMode.NONE: No spatial query
    :var SpatialQueryMode.IDENTITY: Coincident spatial query mode. Return the objects in the searched layer that completely overlap with the searched objects. Note: The types of the searched object and the searched object must be the same; and the intersection of the two objects is not empty, the boundary and interior of the searched object and the external intersection of the searched object are empty.
                                    The object type that this relationship is suitable for:

                                    -Search object: point, line, area;
                                    -Searched object: point, line, area.

                                    As shown:

                                     .. image:: ../image/SQIdentical.png

    :var SpatialQueryMode.DISJOINT: separate spatial query mode. Return the objects that are separated from the search object in the searched layer. Note: The search object is separated from the searched object, that is, there is no intersection.
                                    The object type that this relationship is suitable for:

                                    -Search object: point, line, area;
                                    -Searched object: point, line, area.

                                     As shown:

                                      .. image:: ../image/SQDsjoint.png

    :var SpatialQueryMode.INTERSECT: Intersecting spatial query mode. Return all objects that intersect the search object. Note: If the search object is a face, all or part of the objects contained in the search object and all or part of the objects contained in the search object will be returned; if the search object is not a face, all or part of the objects contained in the search object will be returned.
                                     The object type that this relationship is suitable for:

                                     -Search object: point, line, area;
                                     -Searched object: point, line, area.

                                     As shown:

                                      .. image:: ../image/SQIntersect.png

    :var SpatialQueryMode.TOUCH: Adjacent spatial query mode. Back in the boundary layer to be searched and a search for the object touching the object boundary. Note: The internal intersection of the searched object and the searched object is empty.
                                 The object types for which this relationship is not suitable are:

                                 -Point to query the spatial relationship of points.

                                 As shown:

                                  .. image:: ../image/SQTouch.png

    :var SpatialQueryMode.OVERLAP: Overlay spatial query mode. Return the object that partially overlaps the search object in the searched layer.
                                   The suitable object types for this relationship are:

                                   -Line/line, surface/surface. Among them, the dimensions of the two geometric objects must be the same, and the dimension of their intersection should also be the same as the dimension of the geometric object

                                   Note: There is no partial overlap between the point and any geometric object

                                   As shown:

                                    .. image:: ../image/SQOverlap.png

    :var SpatialQueryMode.CROSS: Cross spatial query mode. Return all objects (lines or areas) that intersect the search object (line) in the searched layer. Note: The internal intersection of the search object and the searched object cannot be empty; one of the two objects involved in the cross relation operation must be a line object.
                                 The object type that this relationship is suitable for:

                                 -Search object: line;
                                 -The searched object: line, surface.

                                 As shown:

                                  .. image:: ../image/SQCross.png

    :var SpatialQueryMode.WITHIN: Included spatial query mode. Return the objects in the searched layer that completely contain the search objects. If the returned object is a surface, it must contain all (including edge contact) the search object; if the returned object is a line, it must completely contain the search object; if the returned object is a point, it must coincide with the search object. This type is the opposite of the Contain query mode.
                                  The object type that this relationship is suitable for:

                                  -Search object: point, line, area;
                                  -Searched object: point, line, area.

                                  As shown:

                                   .. image:: ../image/SQWithin.png

    :var SpatialQueryMode.CONTAIN: Contains the spatial query mode. Return the objects in the searched layer that are completely contained by the searched objects. Note: The boundary intersection of the searched object and the searched object may not be empty; point-check line/point-check surface/line-check surface, there is no inclusion.
                                   The object type that this relationship is suitable for:

                                   -Search object: point, line, area;
                                   -Searched object: point, line, area.

                                   As shown:

                                    .. image:: ../image/SQContain.png

    :var SpatialQueryMode.INNERINTERSECT: Internal intersection query mode, Return all objects that intersect but not only touch the search object. That is, the results of all contact operators are excluded from the results of the intersection operator.

    """,

    "iobjectspy._jsuperpy.enums.SpatialStatisticsType": """
    The field statistical type constant after spatial measurement of the dataset

    :var SpatialStatisticsType.MAX: The maximum value of the statistical field. Only valid for numeric fields.
    :var SpatialStatisticsType.MIN: The minimum value of the statistical field. Only valid for numeric fields.
    :var SpatialStatisticsType.SUM: The sum of statistical fields. Only valid for numeric fields.
    :var SpatialStatisticsType.MEAN: The average value of the statistical field. Only valid for numeric fields.
    :var SpatialStatisticsType.FIRST: Keep the field value of the first object. It is valid for numeric, Boolean, time and text fields.
    :var SpatialStatisticsType.LAST: Keep the field value of the last object. It is valid for numeric, Boolean, time and text fields.
    :var SpatialStatisticsType.MEDIAN: The median of the statistical field. Only valid for numeric fields.
    """,

    "iobjectspy._jsuperpy.enums.StatisticMode": """
    This class defines the constants of the field statistics method type. Provide common statistical functions for a single field. There are 6 statistical functions provided by SuperMap, including the maximum, minimum, average, sum, standard deviation and variance of statistical fields.

    :var StatisticMode.MAX: Count the maximum value of the selected field.
    :var StatisticMode.MIN: Count the minimum value of the selected field.
    :var StatisticMode.AVERAGE: Calculate the average value of the selected field.
    :var StatisticMode.SUM: Count the sum of the selected fields.
    :var StatisticMode.STDDEVIATION: Calculate the standard deviation of the selected field.
    :var StatisticMode.VARIANCE: Calculate the variance of the selected field.
    """,

    "iobjectspy._jsuperpy.enums.StatisticsCompareType": """
    Comparison type constant

    :var StatisticsCompareType.LESS: Less than.
    :var StatisticsCompareType.LESS_OR_EQUAL: Less than or equal to.
    :var StatisticsCompareType.EQUAL: equal to.
    :var StatisticsCompareType.GREATER: Greater than.
    :var StatisticsCompareType.GREATER_OR_EQUAL: Greater than or equal to.
    """,

    "iobjectspy._jsuperpy.enums.StatisticsFieldType": """
    Point thinning statistics type, the statistics are the value of the original point set of thinning points

    :var StatisticsFieldType.AVERAGE: Statistical average
    :var StatisticsFieldType.SUM: Statistics and
    :var StatisticsFieldType.MAXVALUE: Maximum value
    :var StatisticsFieldType.MINVALUE: minimum value
    :var StatisticsFieldType.VARIANCE: Variance
    :var StatisticsFieldType.SAMPLEVARIANCE: sample variance
    :var StatisticsFieldType.STDDEVIATION: standard deviation
    :var StatisticsFieldType.SAMPLESTDDEV: sample standard deviation
    """,

    "iobjectspy._jsuperpy.enums.StatisticsType": """
    Field statistics type constant

    :var StatisticsType.MAX: The maximum value of the statistical field
    :var StatisticsType.MIN: The minimum value of the statistical field
    :var StatisticsType.SUM: the sum of statistical fields
    :var StatisticsType.MEAN: The average value of the statistical field
    :var StatisticsType.FIRST: Keep the field value of the first object
    :var StatisticsType.LAST: Keep the field value of the last object.
    """,

    "iobjectspy._jsuperpy.enums.StreamOrderType": """
    The method type constant of the basin water system number (ie river classification)

    :var StreamOrderType.STRAHLER: Strahler river classification. The Strahler river classification method was proposed by Strahler in 1957. Its rules are defined as follows: the river
                                   Directly originating from the source of a river is a class 1 river; The level of the river formed by the confluence of two rivers of the same level is increased by 1 level.
                                   The grade of a river formed by the confluence of two rivers of different grades is equal to that of the middle grade and higher of the original river.

                                   .. image:: ../image/Strahler.png

    :var StreamOrderType.SHREVE: Shreve river classification. Shreve river classification method was proposed by Shreve in 1966. Its rules are defined as follows: the level of a river directly originating
                                 From a river source is level 1, and the level of a river formed by the confluence of two rivers is the sum of the levels of two rivers. For example, two class 1 rivers meet to form a class 2 river,
                                 And a class 2 river and a class 3 river meet to form a class 5 river.

                                 .. image:: ../image/Shreve.png
    """,

    "iobjectspy._jsuperpy.enums.StringAlignment": """
    This class defines the type constants of multi-line text typesetting

    :var StringAlignment.LEFT: Left alignment
    :var StringAlignment.CENTER: Center alignment
    :var StringAlignment.RIGHT: Right alignment
    :var StringAlignment.DISTRIBUTED: Distributed alignment (justified at both ends)
    """,

    "iobjectspy._jsuperpy.enums.TerrainInterpolateType": """
    Terrain interpolation type constant

    :var TerrainInterpolateType.IDW: Inverse distance weight interpolation method. Reference: py:attr:`.InterpolationAlgorithmType.IDW`
    :var TerrainInterpolateType.KRIGING: Kriging interpolation. Reference: py:attr:`.InterpolationAlgorithmType.KRIGING`
    :var TerrainInterpolateType.TIN: Irregular TIN. First generate a TIN model from the given line dataset, and then generate a DEM model based on the given extreme point information and lake information.
    """,

    "iobjectspy._jsuperpy.enums.TerrainStatisticType": """
    Topographic statistics type constant

    :var TerrainStatisticType.UNIQUE: To repeat statistics.
    :var TerrainStatisticType.MEAN: Mean statistics.
    :var TerrainStatisticType.MIN: Minimum statistics.
    :var TerrainStatisticType.MAX: Maximum statistics.
    :var TerrainStatisticType.MAJORITY: The mode refers to the grid value with the highest frequency. Currently only used for grid zoning statistics.
    :var TerrainStatisticType.MEDIAN: The median refers to the grid value in the middle, arranged in descending order of grid values. Currently only used for grid zoning statistics.
    """,

    "iobjectspy._jsuperpy.enums.TextAlignment": """
    This class defines constants for text alignment types.

    Specify the alignment of each sub-object in the text. The position of each child object of the text object is determined by the anchor point of the text and the alignment of the text. When the anchor point of the text sub-object is fixed, the alignment determines the relative position of the text sub-object and the anchor point, thereby determining the position of the text sub-object.

    :var TextAlignment.TOPLEFT: Align the upper left corner. When the alignment of the text is the upper left corner alignment, the upper left corner of the smallest enclosing rectangle of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.TOPCENTER: Top center alignment. When the alignment of the text is the top center alignment, the midpoint of the upper line of the smallest enclosing rectangle of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.TOPRIGHT: Align the upper right corner. When the alignment of the text is the upper right corner alignment, the upper right corner of the smallest enclosing rectangle of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.BASELINELEFT: Align the baseline to the left. When the alignment of the text is the baseline left alignment, the left end of the baseline of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.BASELINECENTER: The baseline is aligned in the center. When the alignment of the text is the baseline alignment, the midpoint of the baseline of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.BASELINERIGHT: Align the baseline to the right. When the alignment of the text is the baseline right alignment, the right end of the baseline of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.BOTTOMLEFT: Align the bottom left corner. When the alignment of the text is the lower left corner alignment, the lower left corner of the smallest enclosing rectangle of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.BOTTOMCENTER: Align the bottom to the center. When the alignment of the text is bottom line centered, the midpoint of the bottom line of the smallest enclosing rectangle of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.BOTTOMRIGHT: Align the bottom right corner. When the alignment of the text is the lower right corner alignment, the lower right corner of the smallest enclosing rectangle of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.MIDDLELEFT: Align left center. When the alignment of the text is left-center alignment, the midpoint of the left line of the smallest enclosing rectangle of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.MIDDLECENTER: Center alignment. When the alignment of the text is center alignment, the center point of the smallest enclosing rectangle of the text sub-object is at the anchor point of the text sub-object
    :var TextAlignment.MIDDLERIGHT: Right center alignment. When the alignment of the text is right-center alignment, the midpoint of the right line of the smallest enclosing rectangle of the text sub-object is at the anchor point of the text sub-object

    """,

    "iobjectspy._jsuperpy.enums.TopologyRule": """
    This class defines constants of topology rule types.

    This class is mainly used for topological inspection of point, line and area data, and is a parameter of topological inspection. According to the corresponding topology rules, return objects that do not meet the rules.

    :var TopologyRule.REGION_NO_OVERLAP: There is no overlap in the surface, it is used to check the topology of the surface data. Check a polygon dataset (or a polygon record set) that has overlapping polygon objects. This rule
                                         Is mostly used when an area cannot belong to two objects at the same time. Such as administrative divisions, the requirements between adjacent divisions must not have any overlap, On the data of administrative division,
                                         There must be a clear regional definition for each region. Such data also include: land use plots, ZIP code coverage zoning, referendum district zoning, etc. 
                                         The overlap is generated as an error in the result dataset. Error dataset type: surface. Note: Only check a dataset or the record set itself.
    :var TopologyRule.REGION_NO_GAPS: There is no gap in the surface, which is used to check the topology of the surface data. Return a region object with gaps between adjacent regions in a region dataset (or region record set). This rule
                                      Is mostly used to check a single area or gaps between adjacent areas in a surface data. Generally, for data such as land use pattern,
                                      It is required that there should not be patches with undefined land use type, and this rule can be used for inspection.

                                      note:

                                      -Only check a dataset or record set itself.
                                      -If there is a self-intersecting area object in the area dataset (or record set) being inspected, the inspection may fail or the result may be wrong. It is suggested to
                                      Check the REGION_NO_SELF_INTERSECTION rule first, or modify the self-intersecting plane by yourself, and then check the no-gap rule in the plane after
                                      It is confirmed that there is no self-intersecting object.

    :var TopologyRule.REGION_NO_OVERLAP_WITH: There is no overlap between the surface and the surface, which is used to check the topology of the surface data. Check all objects that overlap in the two face dataset. This rule checks the data in the
                                              First face, all objects that overlap with the second surface data. If the water area data is superimposed with the dry land data, this rule can be used to check. Overlap as
                                              The error is generated in the result dataset, the type of the error dataset: surface
    :var TopologyRule.REGION_COVERED_BY_REGION_CLASS: The polygon is covered by multiple polygons, which is used to check the topology of the polygon data. Checks for objects in the first facet dataset (or facet record set)
                                                      That are not overwritten by the second facet dataset (or facet record set). For example, each province in county boundary AREA1
                                                      Must be completely covered by the province's face in county boundary AREA2. The uncovered part will be generated as an error in the result dataset. Type of error dataset: surface

    :var TopologyRule.REGION_COVERED_BY_REGION: The surface is contained by the surface and is used to check the topology of the surface data.
                                                Check that the first polygon dataset (or polygon record set) does not contain any objects in the second polygon dataset (or polygon record set). That is, the area of surface data 1 must be completely contained by a certain area of surface data 2.
                                                The area objects that are not included will be generated as an error in the result dataset. The type of the error dataset: area.
    :var TopologyRule.REGION_BOUNDARY_COVERED_BY_LINE: The surface boundary is covered by multiple lines, which is used to check the topology of the surface data.
                                                       Check that the boundary of the object in the polygon dataset (or polygon record set) is not covered by the lines in the line dataset (or line record set).
                                                       It is usually used to check the boundaries of administrative districts or land parcels and the line data stored with boundary line attributes. Some boundary line attributes cannot be stored in the surface data,
                                                       At this time, special boundary line data is needed to store different attributes of the area boundary, and the boundary line and the area boundary line are required to completely overlap.
                                                       The uncovered boundary will be generated as an error in the result dataset. Error dataset type: line.
    :var TopologyRule.REGION_BOUNDARY_COVERED_BY_REGION_BOUNDARY: The boundary of the surface is covered by the boundary, which is used to check the topology of the surface data.
                                                                  Check that the boundary of the polygon dataset (or polygon record set) is not covered by the boundary of the object (there can be multiple) in the other polygon dataset (or polygon record set).
                                                                  The uncovered boundary will be generated as an error in the result dataset. Error dataset type: line.
    :var TopologyRule.REGION_CONTAIN_POINT: The polygon contains points, which are used to check the topology of the polygon data.
                                            Check that the polygon dataset (or polygon record set) does not contain any point objects in the point dataset (or point record set). For example, provincial data and provincial capital data are checked. Each province must have a provincial capital city. Area objects that do not contain any point data will be checked.
                                            Area objects that do not contain points will be generated as errors in the result dataset. The type of error dataset: area.
    :var TopologyRule.LINE_NO_INTERSECTION: There is no intersection within the line, which is used to check the topology of the line data.
                                            Check a line dataset (or line record set) that has intersecting line objects (not including end and internal contact and end and end contact). The intersection point will be generated as an error in the result dataset. Error dataset type: point.
                                            Note: Only check a dataset or the record set itself.
    :var TopologyRule.LINE_NO_OVERLAP: There is no overlap in the line, which is used to check the topology of the line data. Check for overlapping line objects in a line dataset (or line record set). The overlapping parts between objects will be generated as errors in the result dataset. Error dataset type: line.
                                       Note: Only check a dataset or the record set itself.
    :var TopologyRule.LINE_NO_DANGLES: There are no dangling lines in the line, which is used to check the topology of the line data. Check the objects defined as overhangs in a line dataset (or line record set), including excessive lines and long overhangs. Dangling points will be generated as errors in the result dataset. Error dataset type: point.
                                       Note: Only check a dataset or the record set itself.
    :var TopologyRule.LINE_NO_PSEUDO_NODES: There are no false nodes in the line, which is used to check the topology of the line data. Return a line object containing false nodes in a line dataset (or line record set). The false node will be generated as an error in the result dataset, the type of the error dataset: point.
                                            Note: Only check a dataset or the record set itself.
    : var TopologyRule.LINE_NO_OVERLAP_WITH: no overlap line and line, the data line topology for inspection check. Check all objects in the first line dataset (or line record set) that overlap with the objects in the second line dataset (or line record set). For example, roads and railways in traffic routes cannot overlap.
                                            The overlapping part is generated as an error in the result dataset, the type of error dataset: line.
    :var TopologyRule.LINE_NO_INTERSECT_OR_INTERIOR_TOUCH: There is no intersection or internal contact in the line, used to check the topology of the line data. Return the line objects that intersect with other line objects in a line dataset (or line record set), that is, all intersected or internally contacted line objects except for the contact between the endpoints.
                                                           The intersection point is generated as an error in the result dataset, the type of the error dataset: point.
                                                           Note: All intersection points in the line dataset (or line record set) must be the end points of the line, that is, the intersecting arc must be interrupted, otherwise this rule is violated (self-intersection is not checked).
    :var TopologyRule.LINE_NO_SELF_OVERLAP: There is no self-overlapping in the line, which is used to check the topology of the line data. Check a line dataset (or line record set) for line objects that overlap each other (the intersection is a line). The self-overlapping part (line) will be generated as an error in the result dataset. Error dataset type: line.
                                            Note: Only check a dataset or the record set itself.
    :var TopologyRule.LINE_NO_SELF_INTERSECT: There is no self-intersection within the line, which is used to check the topology of the line data. Check the self-intersecting line objects in a line dataset (or line record set) (including self-overlapping).
                                              The intersection point will be generated as an error in the result dataset. Error dataset type: point.
                                              Note: Only check a dataset or the record set itself.
    :var TopologyRule.LINE_BE_COVERED_BY_LINE_CLASS: The line is completely covered by multiple lines, which is used to check the topology of the line data.
                                                     Check that there are no objects in the first line dataset (or line record set) that overlap with the objects in the second line dataset (or line record set).
                                                     The uncovered part will be generated as an error in the result dataset. Error dataset type: line.
                                                     Note: Each object in a line dataset (or line record set) must be covered by one or more line objects in another line dataset (or line record set). For example, a certain bus route in Line1 must be covered by a series of connected streets in Line2.
    :var TopologyRule.LINE_COVERED_BY_REGION_BOUNDARY: The line is covered by the polygon boundary, which is used to check the topology of the line data. Check that there is no object in the line dataset (or line record set) that coincides with the boundary of an object in the area dataset (or area record set). (Can be covered by the boundary of multiple faces).
                                                       The part that is not covered by the boundary will be generated as an error in the result dataset, the type of the error dataset: line.
    :var TopologyRule.LINE_END_POINT_COVERED_BY_POINT: The end of the line must be covered by a point for topological inspection of the line data.
                                                       Check that the endpoints in the line dataset (or line record set) do not coincide with any point in the point dataset (or point record set).
                                                       Endpoints that are not covered will be generated as errors in the result dataset. Error dataset type: point.
    : var TopologyRule.POINT_COVERED_BY_LINE: point must be on-line, the dot data for topology detection check.
                                             Return the objects in the point dataset (or point record set) that are not covered by an object in the line dataset (or line record set). Such as a toll station on a highway.
                                             Points that are not covered will be generated as errors in the result dataset. Error dataset type: point.
    :var TopologyRule.POINT_COVERED_BY_REGION_BOUNDARY: The point must be on the boundary of the surface, which is used to check the topology of the point data.
                                                        Check that there is no object on the boundary of an object in the area dataset (or area record set) in the point dataset (or point record set).
                                                        Points not on the boundary of the surface will be generated as errors in the result dataset. Error dataset type: point.
    :var TopologyRule.POINT_CONTAINED_BY_REGION: The point is completely contained by the surface, which is used to check the topology of the point data.
                                                 Checkpoint dataset (or point record set) does not contain any point object contained in the area dataset (or area record set).
                                                 Points not in the surface will be generated as errors in the result dataset. Error dataset type: point.
    :var TopologyRule.POINT_BECOVERED_BY_LINE_END_POINT: The point must be covered by the line end point, which is used to check the topology of the point data.
                                                         Return the objects in the point dataset (or point record set) that are not covered by the endpoints of any object in the line dataset (or line record set).
    :var TopologyRule.NO_MULTIPART: No complex objects. Check a dataset or a complex object that contains sub-objects in a dataset or record set. It is suitable for areas and lines.
                                    Complex objects will be generated as errors in the result dataset, the type of error dataset: line or area.
    :var TopologyRule.POINT_NO_IDENTICAL: No duplicate points, used for topological inspection of point data. Check the duplicate point objects in the point dataset. All overlapping objects in the point dataset will be generated as topological errors.
                                          All duplicate points will be generated as errors in the result dataset, the type of error dataset: point.
                                          Note: Only check a dataset or the record set itself.
    :var TopologyRule.POINT_NO_CONTAINED_BY_REGION: The point is not contained by the polygon. Checkpoint dataset (or point record set) is a point object contained within a certain object in the area dataset (or area record set).
                                                    The points contained by the surface will be generated as errors in the result dataset. Error dataset type: point.
                                                    Note: If the point is located on the surface boundary, this rule is not violated.
    :var TopologyRule.LINE_NO_INTERSECTION_WITH_REGION: The line cannot intersect the surface or be included. Check the line objects in the line dataset (or line record set) that intersect with the area objects in the area dataset (or area record set) or are contained by the area objects.
                                                        The intersection of line and surface will be generated as an error in the result dataset. The type of error dataset: line.
    :var TopologyRule.REGION_NO_OVERLAP_ON_BOUNDARY: There is no overlap on the surface boundary, which is used to check the topology of the surface data.
                                                     Check that the boundary of the surface object in the polygon dataset or record set overlaps with the boundary of the object in the other surface dataset or record set.
                                                     The overlapping part of the boundary will be generated as an error in the result dataset. Error dataset type: line.
    :var TopologyRule.REGION_NO_SELF_INTERSECTION: There is no self-intersection in the surface, which is used to check the topology of the surface data.
                                                   Check whether there are self-intersecting objects in the polygon data.
                                                   The intersection point of the area object's self-intersection will be generated as an error in the result dataset, the type of the error dataset: point.
    :var TopologyRule.LINE_NO_INTERSECTION_WITH: The line does not intersect with the line, that is, the line object and the line object cannot intersect.
                                                 Check that there are no objects in the first line dataset (or line record set) that intersect with objects in the second line dataset (or line record set).
                                                 The intersection point will be generated as an error in the result dataset. Error dataset type: point.
    :var TopologyRule.VERTEX_DISTANCE_GREATER_THAN_TOLERANCE: The node distance must be greater than the tolerance. Check whether the node distance between the two dataset of point, line, and surface type or between the two dataset is less than the tolerance.
                                                              Nodes that are not larger than the tolerance will be generated as errors in the result dataset. Error dataset type: point.
                                                              Note: If the two nodes overlap, that is, the distance is 0, it is not regarded as a topology error.
    :var TopologyRule.LINE_EXIST_INTERSECT_VERTEX: There must be an intersection at the intersection of the line segments. A node must exist at the intersection of a line segment and a line segment in a dataset of line or area type or between two dataset, and this node must exist in at least one of the two intersecting line segments.
                                                   If it is not satisfied, calculate the intersection point as an error and generate it into the result dataset. Error dataset type: point.
                                                   Note: The fact that the endpoints of two line segments meet does not violate the rules.
    :var TopologyRule.VERTEX_MATCH_WITH_EACH_OTHER: The nodes must match each other, that is, there are vertical foot points on the line segment within the tolerance range.
                                                    Check the line and area type dataset inside or between two dataset, point dataset and line dataset, point dataset and area data, within the tolerance range of current node P, there should be a node on line segment L Q is matched, that is, Q is within the tolerance range of P. If it is not satisfied, then calculate the "vertical foot" point A from P to L (that is, A matches P) and generate it as an error in the result dataset. Error dataset type: point.
    :var TopologyRule.NO_REDUNDANT_VERTEX: There are no redundant nodes on the line or surface boundary. Check whether there are objects with redundant nodes in the line dataset or polygon dataset. If there are other collinear nodes between two nodes on the boundary of a line object or a region object, these collinear nodes are redundant nodes.
                                           Redundant nodes will be generated as errors in the result dataset, error data type: point
    :var TopologyRule.LINE_NO_SHARP_ANGLE: No discount in the line. Check whether there is a discount on the line object in the line dataset (or record set). If the two included angles formed by four consecutive nodes on a line are less than the given sharp angle tolerance , the line segment is considered to be discounted here.
                                           The first turning point that produces a sharp corner is generated as an error in the result dataset, the error data type: point.
                                           Note: When using the :py:meth:`topology_validate` method to check the rule, the tolerance parameter of the method is used to set the sharp angle
    :var TopologyRule.LINE_NO_SMALL_DANGLES: There is no short dangling line in the line, which is used to check the topology of the line data. Check whether the line object in the line dataset (or record set) is a short hanging line. A line object whose length is less than the suspension tolerance is a short suspension
                                             The end point of the short suspension line is generated as an error in the result dataset, and the error data type: point.
                                             Note: When using the :py:meth:`topology_validate` method to check this rule, the tolerance parameter of this method is used to set the short suspension tolerance.
    :var TopologyRule.LINE_NO_EXTENDED_DANGLES: There is no long hanging wire in the line, which is used to check the topology of the line data. Check whether the line object in the line dataset (or record set) is a long hanging line. If a suspension line extends a specified length (suspension line tolerance) according to its traveling direction and then has an intersection with a certain arc, the line object is a long suspension line.
                                                The long suspension line needs to extend the end point of one end as an error generated in the result dataset, the error data type: point.
                                                Note: When using the :py:meth:`topology_validate` method to check this rule, the tolerance parameter of this method is used to set the long suspension tolerance.
    :var TopologyRule.REGION_NO_ACUTE_ANGLE: There are no acute angles in the surface, which is used to check the topology of the surface data. Check whether there are sharp angles in the surface object in the surface dataset (or record set). If the included angle formed by three consecutive nodes on the surface boundary line is less than the given acute angle tolerance, the included angle is considered to be an acute angle.
                                             The second node that produces the acute angle is generated as an error in the result dataset, and the error data type: point.
                                             Note: When using the :py:meth:`topology_validate` method to check this rule, the tolerance parameter of this method is used to set the acute angle tolerance.
    """,

    "iobjectspy._jsuperpy.enums.Unit": """
    This class defines type constants that represent units.

    :var Unit.MILIMETER: mm
    :var Unit.CENTIMETER: cm
    :var Unit.DECIMETER: Decimeter
    :var Unit.METER: Meter
    :var Unit.KILOMETER: kilometers
    :var Unit.INCH: inch
    :var Unit.FOOT: Feet
    :var Unit.YARD: Code
    :var Unit.MILE: Miles
    :var Unit.SECOND: second, angle unit
    :var Unit.MINUTE: minute, angle unit
    :var Unit.DEGREE: degree, angle unit
    :var Unit.RADIAN: radians, radians unit

    """,

    "iobjectspy._jsuperpy.enums.VCTVersion": """
    VCT version

    :var VCTVersion.CNSDTF_VCT: National Natural Standard 1.0
    :var VCTVersion.LANDUSE_VCT: National Land Use 2.0
    :var VCTVersion.LANDUSE_VCT30: National Land Use 3.0
    """,

    "iobjectspy._jsuperpy.enums.VariogramMode": """
    This class defines the semi-variable function type constants for Kriging interpolation. Define the type of semivariable function for Kriging interpolation. Including exponential, spherical and Gaussian. The type of semi-variable function
    Selected by the user can affect the prediction of the unknown point,especially the different shape of the curve at the origin is of great significance. The steeper the curve at the origin, the greater the influence of the closer area on the predicted value. Therefore, the output surface will be less smooth.
    Each type has its own application.

    :var VariogramMode.EXPONENTIAL: Exponential function (Exponential Variogram Mode). This type is suitable for situations where the spatial autocorrelation relationship decreases exponentially with increasing distance.
                                    The figure below shows that the spatial autocorrelation relationship completely disappears at infinity. Exponential functions are more commonly used.

                                    .. image:: ../image/VariogramMode_Exponential.png

    :var VariogramMode.GAUSSIAN: Gaussian function (Gaussian Variogram Mode).

                                .. image:: ../image/variogrammode_Gaussian.png

    :var VariogramMode.SPHERICAL: Spherical Variogram Mode. This type shows that the spatial autocorrelation relationship gradually decreases (that is, the value of the semivariable function increases
                                  Gradually), until a certain distance is exceeded, the spatial autocorrelation is 0. Spherical functions are more commonly used.

                                  .. image:: ../image/VariogramMode_Spherical.png


    """,

    "iobjectspy._jsuperpy.enums.VectorResampleType": """
    Vector dataset resampling method type constant

    :var VectorResampleType.RTBEND: Resample using the haphazard sampling algorithm
    :var VectorResampleType.RTGENERAL: use Douglas algorithm for resampling
    """,

    "iobjectspy._jsuperpy.enums.ViewShedType": """
    This class defines the type constant of the visual field when the visual field is analyzed for multiple observation points (observed points).
    :var ViewShedType.VIEWSHEDINTERSECT: Common visual field, taking the intersection of the visual field range of multiple observation points.
    :var ViewShedType.VIEWSHEDUNION: Non-common viewing area, taking the union of multiple viewing points.
    """,

    "iobjectspy._jsuperpy.enums.WorkspaceType": """
    This class defines constants of workspace type.

    SuperMap supports four types of file workspaces, SSXWU format and SMWU format; SuperMap supports two types of database workspaces: Oracle workspace and SQL Server workspace.

    :var WorkspaceType.DEFAULT: The default value, which indicates the type of workspace when the workspace is not saved.
    :var WorkspaceType.ORACLE: Oracle workspace. The workspace is saved in the Oracle database.
    :var WorkspaceType.SQL: SQL Server workspace. The workspace is saved in the SQL Server database. This constant is only supported in the Windows platform version, not in the Linux version.
    :var WorkspaceType.DM: DM workspace. The workspace is stored in the DM database.
    :var WorkspaceType.MYSQL: MYSQL workspace. The workspace is saved in the MySQL database.
    :var WorkspaceType.PGSQL: PostgreSQL workspace. The workspace is saved in the PostgreSQL database.
    :var WorkspaceType.MONGO: MongoDB workspace. The workspace is stored in the MongoDB database.
    :var WorkspaceType.SXWU: SXWU workspace. Only the 6R version of the workspace can be saved as a workspace file of type SXWU. When saving as 6R version workspace, file-type workspace can only be saved as SXWU or SMWU.
    :var WorkspaceType.SMWU: SMWU workspace. Only the 6R version of the workspace can be saved as a workspace file of type SMWU. When saving as 6R version workspace, file-type workspace can only be saved as SXWU or SMWU. This constant is only supported in the Windows platform version, not in the Linux version.

    """,

    "iobjectspy._jsuperpy.enums.WorkspaceVersion": """
    This class defines the workspace version type constants.

    :var WorkspaceVersion.UGC60: SuperMap UGC 6.0 workspace
    :var WorkspaceVersion.UGC70: SuperMap UGC 7.0 workspace

    """,
"iobjectspy._jsuperpy.enums.DividePolygonOrientation" :
    """  
    When cutting surface polygons, the starting cutting direction is the position of a cutting surface in the resulting surface object after cutting. Specific reference :py:fun:`.divide_polygon`

    :var DividePolygonOrientation.WEST: The cutting surface position is west
    :var DividePolygonOrientation.NORTH: The cutting surface position is north
    :var DividePolygonOrientation.EAST: The cutting surface position is east
    :var DividePolygonOrientation.SOUTH: The cutting surface position is south
    """,
"iobjectspy._jsuperpy.enums.DividePolygonType" :
    """  
    The type of the cutting surface object. Specific reference :py:fun:`.divide_polygon`

    :var DividePolygonType.AREA: Cut polygons by area
    :var DividePolygonType.PART: Cut polygons
    """,

    "iobjectspy._jsuperpy.enums.RegularizeMethod":
        """  
        Defines the regularization processing method of the building. Users can choose the appropriate regularization method according to the shape of the building.
    
        :var RegularizeMethod.RIGHTANGLES: Used for buildings mainly defined by right angles
        :var RegularizeMethod.RIGHTANGLESANDDIAGONALS:Used for buildings composed of right angles and diagonal edges
        :var RegularizeMethod.ANYANGLE: Used for irregular buildings
        :var RegularizeMethod.CIRCLE: Used in buildings with round features, such as granaries and water towers.
        """,

"iobjectspy._jsuperpy.enums.OverlayOutputAttributeType" :
    """  
    Multi-layer overlay analysis field attribute return type

    :var OverlayOutputAttributeType.ALL: All non-system fields and object IDs are returned, and SmUserID is not returned either.
    :var OverlayOutputAttributeType.ONLYID: Return only the ID of the object
    :var OverlayOutputAttributeType.ONLYATTRIBUTES: Only non-system fields of the object are returned, and the SmUserID field is not returned
    """,
"iobjectspy._jsuperpy.enums.TimeDistanceUnit" :
    """  
    Time distance unit

    :var TimeDistanceUnit.SECONDS: second
    :var TimeDistanceUnit.MINUTES: minute
    :var TimeDistanceUnit.HOURS: hour
    :var TimeDistanceUnit.DAYS: day
    :var TimeDistanceUnit.WEEKS: week
    :var TimeDistanceUnit.MONTHS: month
    :var TimeDistanceUnit.YEARS: year
    """,
"iobjectspy._jsuperpy.enums.GJBLayerType" :
    """  
    :var GJBLayerType.GJB_A: Measurement control point
     :var GJBLayerType.GJB_B: Industrial and agricultural social and cultural facilities
     :var GJBLayerType.GJB_C: Residential area and ancillary settings
     :var GJBLayerType.GJB_D: Land transportation
     :var GJBLayerType.GJB_E: pipeline
     :var GJBLayerType.GJB_F: water, land
     :var GJBLayerType.GJB_G: Submarine landform and bottom quality
     :var GJBLayerType.GJB_H: reef, shipwreck, obstacle
     :var GJBLayerType.GJB_I: Hydrology
     :var GJBLayerType.GJB_J: Landform and soil quality
     :var GJBLayerType.GJB_K: Realm and political area
     :var GJBLayerType.GJB_L: vegetation
     :var GJBLayerType.GJB_M: Geomagnetic elements
     :var GJBLayerType.GJB_N: Navigation aids and navigation channels
     :var GJBLayerType.GJB_O: maritime area boundary
     :var GJBLayerType.GJB_P: aviation elements
     :var GJBLayerType.GJB_Q: military area
     :var GJBLayerType.GJB_R: Note
     :var GJBLayerType.GJB_S: Metadata
    """,
}

_jsuperpy_conversions_locale = {
    "iobjectspy._jsuperpy.conversion": """
The conversion module provides basic data import and export functions. By using the conversion module, you can quickly import third-party files into SuperMap datasources, you can also
Export data from the SuperMap datasource as a third-party file.

In the conversion module, in all interfaces for importing data, the output parameter inputs the datasource information of the result dataset, which can be a Datasource object or a DatasourceConnectionInfo object.
At the same time, it also supports the alias of the datasource in the current workspace, and also supports the UDB file path, DCF file path, etc.


>>> ds = Datasource.create(':memory:')
>>> alias = ds.alias
>>> shape_file ='E:/Point.shp'
>>> result1 = import_shape(shape_file, ds)
>>> result2 = import_shape(shape_file, alias)
>>> result3 = import_shape(shape_file,'E:/Point_Out.udb')
>>> result4 = import_shape(shape_file,'E:/Point_Out_conn.dcf')


The result of importing data Return a list object of Dataset or str. When the imported data generates only one dataset, the number of lists is 1. When the imported data generates multiple dataset, the number of lists may be greater than 1.
Whether the Dataset or str is returned in the list is determined by the input output parameter. When the input output parameter can directly obtain the datasource object in the current workspace, the Dataset list will be returned.
If the input output parameter cannot directly obtain the datasource object in the current workspace, the program will automatically try to open the datasource or create a new datasource (only new UDB datasources are supported), at this point, the result returned 
Will be the dataset name of the result dataset, and the result datasource will also be closed after the data import is completed. Therefore, if the user needs to continue to operate based on the imported result dataset, he needs to develop the datasource again to obtain the dataset according to the result dataset name and datasource information.


For all interfaces for exporting datasets, the data parameter is the exported dataset information, and the data parameter accepts the input of a dataset object (Dataset) or a combination of a datasource alias and a dataset name (for example,'alias/dataset_name','alias\ \\dataset_name'),
Also supports the combination of datasource connection information and dataset name (for example, 'E:/data.udb/dataset_name'). It is worth noting that when the datasource information is entered, the program will automatically open the datasource, but Will not automatically close the datasource, that is, the opened datasource
Will exist in the current workspace

>>> export_to_shape('E:/data.udb/Point','E:/Point.shp', is_over_write=True)
>>> ds = Datasource.open('E:/data.udb')
>>> export_to_shape(ds['Point'],'E:/Point.shp', is_over_write=True)
>>> export_to_shape(ds.alias +'|Point','E:/Point.shp', is_over_write=True)
>>> ds.close()

""",

    "iobjectspy._jsuperpy.conversion.export_to_bmp": """
    Export dataset to BMP file

    :param data: The exported dataset
    :type data: DatasetImage or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str world_file_path: The coordinate file path of the exported image data
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_csv": """
    Export dataset to csv file

    :param data: The exported dataset
    :type data: DatasetVector or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param bool is_export_field_names: Whether to write out the field names.
    :param bool is_export_point_as_wkt: Whether to write the point in WKT mode.
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_dbf": """
    Export dataset to dbf file

    :param data: The exported dataset, only supports exporting attribute table dataset
    :type data: DatasetVector or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_dwg": """
    Export dataset to DWG file. Linux platform does not support export dataset as DWG file.

    :param data: The exported dataset
    :type data: DatasetVector or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param cad_version: The version of the exported DWG file.
    :type cad_version: CADVersion or str
    :param bool is_export_border: Whether to export borders when exporting CAD faces like or rectangular objects.
    :param bool is_export_xrecord: Whether to export user-defined fields and attribute fields as extended records
    :param bool is_export_external_data: whether to export extended fields
    :param str style_map_file: The path of the style comparison table
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_dxf": """
    Export dataset to DXF file, Linux platform does not support exporting dataset as DXF file

    :param data: The exported dataset
    :type data: DatasetVector or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param cad_version: The version of the exported DWG file.
    :type cad_version: CADVersion or str
    :param bool is_export_border: Whether to export borders when exporting CAD faces like or rectangular objects.
    :param bool is_export_xrecord: Whether to export user-defined fields and attribute fields as extended records
    :param bool is_export_external_data: whether to export extended fields
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_e00": """
    Export dataset to E00 file

    :param data: The exported dataset
    :type data: DatasetVector or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param bool double_precision: Whether to export E00 in double precision, the default is False.
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_geojson": """
    Export dataset to GeoJson file

    :param data: The exported dataset collection
    :type data: DatasetVector or str or list[DatasetVector] or list[str]
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_gif": """
    Export dataset to GIF file

    :param data: The exported dataset
    :type data: DatasetImage or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str world_file_path: The coordinate file path of the exported image data
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_grd": """
    Export dataset to GRD file

    :param data: The exported dataset
    :type data: DatasetGrid or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_img": """
    Export dataset to IMG file

    :param data: The exported dataset
    :type data: DatasetImage or DatasetGrid or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_jpg": """
    Export dataset to JPG file

    :param data: The exported dataset
    :type data: DatasetImage or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str world_file_path: The coordinate file path of the exported image data
    :param int compression: compression rate of the image file, unit: percentage
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_kml": """
    Export dataset to KML file

    :param data: The exported dataset collection
    :type data: DatasetVector or str or list[DatasetVector] or list[str]
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_kmz": """
    Export dataset to KMZ file

    :param data: The exported dataset collection
    :type data: DatasetVector or str or list[DatasetVector] or list[str]
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_mif": """
    Export dataset to MIF file

    :param data: The exported dataset
    :type data: DatasetVector or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_png": """
    Export dataset to PNG file

    :param data: The exported dataset
    :type data: DatasetImage or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str world_file_path: The coordinate file path of the exported image data
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_shape": """
    Export dataset to Shape file

    :param data: The exported dataset
    :type data: DatasetVector or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_simplejson": """
    Export dataset to SimpleJson file

    :param data: The exported dataset
    :type data: DatasetVector or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_sit": """
    Export dataset to SIT file

    :param data: The exported dataset
    :type data: DatasetImage or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str password: password
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_tab": """
    Export dataset to TAB file

    :param data: The exported dataset
    :type data: DatasetVector or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param str style_map_file: The path of the exported style map
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_tif": """
    Export dataset to TIF file

    :param data: The exported dataset
    :type data: DatasetImage or DatasetGrid or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param bool export_as_tile: Whether to export in blocks, the default is False
    :param bool export_transform_file: Whether to export the affine transformation information to an external file, the default is True, that is, export to an external tfw file, otherwise the projection information will be exported to a tiff file
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.export_to_vct": """
    Export dataset to VCT file

    :param data: The exported dataset collection
    :type data: DatasetVector or str or list[DatasetVector] or str
    :param str config_path: VCT configuration file path
    :param version: VCT version
    :type version: VCTVersion or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param str attr_filter: Export the filtering information of the target file
    :param ignore_fields: fields to ignore
    :type ignore_fields: list[str]
    :param target_file_charset: The character set type of the file to be exported
    :type target_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,

    "iobjectspy._jsuperpy.conversion.get_input_datasets": """""",

    "iobjectspy._jsuperpy.conversion.import_aibingrid": """
    Import AIBinGrid files. Linux platform does not support importing AIBinGrid files.

    :param str source_file: the imported AIBinGrid file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: mode to ignore color values
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param bool is_build_pyramid: whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_bmp": """
    Import the BMP file. Supports importing file directories.

    :param str source_file: the imported BMP file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: The mode of ignoring color values of BMP files
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param str world_file_path: The coordinate reference file path of the imported source image file
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param bool is_build_pyramid: whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_csv": """
    Import the CSV file. Supports importing file directories.

    :param str source_file: The imported csv file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: Import mode type, which can be ImportMode enumeration value or name
    :type import_mode: ImportMode or str
    :param str separator: The separator of the field in the source CSV file. The default is',' as the separator
    :param bool head_is_field: Whether the first line of the CSV file is a field name
    :param fields_as_point: Specify the field as X, Y or X, Y, Z coordinates. If the conditions are met, a point or three-dimensional point dataset will be generated
    :type fields_as_point: list[str] or list[int]
    :param int field_as_geometry: Specify the Geometry index position of the WKT string
    :param bool is_import_empty: Whether to import empty dataset, the default is False, that is, do not import
    :param source_file_charset: The original character set type of the CSV file
    :type source_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_dbf": """
    Import the dbf file into the datasource. Supports importing file directories.

    :param str source_file: the imported dbf file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: Import mode type, which can be ImportMode enumeration value or name
    :type import_mode: ImportMode or str
    :param bool is_import_empty: No to import empty dataset, the default is not to import. The default is False
    :param source_file_charset: the original character set type of the dbf file
    :type source_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]


    >>> result = import_dbf('E:/point.dbf','E:/import_dbf_out.udb')
    >>> print(len(result) == 1)
    >>> print(result[0])

    """,

    "iobjectspy._jsuperpy.conversion.import_dgn": """
    Import the DGN file. Supports importing file directories.

    :param str source_file: the imported dgn file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param bool is_import_empty: Whether to import an empty dataset, the default is False
    :param bool is_import_as_cad: Whether to import as a CAD dataset, the default is True
    :param str style_map_file: Set the storage path of the style comparison table. The style comparison table refers to the comparison file between the SuperMap system and other system styles (including symbols, line styles, fills, etc.). The style comparison table only works on CAD data, such as DXF, DWG, and DGN. Before setting up the style comparison table, you must ensure that the data is imported in CAD mode and the style is not ignored.
    :param bool is_import_by_layer: Whether to merge the CAD layer information in the source data in the imported data. CAD is stored as layer information. The default is False, that is, all layer information is merged into a CAD dataset. Otherwise, a CAD dataset is generated corresponding to each layer in the source data.
    :param bool is_cell_as_point: Whether to import cell (unit) objects as point objects (cell header) or all feature objects except cell header. By default, all feature objects except cell header are imported.
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_dwg": """
    Import DWG files. Linux platform does not support importing DWG files. Supports importing file directories.

    :param str source_file: the imported dwg file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: dataset import mode
    :type import_mode: ImportMode or str
    :param bool is_import_empty: Whether to import empty dataset, the default is False, that is, do not import
    :param bool is_import_as_cad: Whether to import as CAD dataset
    :param bool is_import_by_layer: Whether to merge the CAD layer information in the source data in the imported data. CAD is stored as layer information. The default is False, that is, all layer information is merged into a CAD dataset. Otherwise, a CAD dataset is generated corresponding to each layer in the source data.
    :param bool ignore_block_attrs: Whether to ignore block attributes when importing data. The default is True
    :param bool block_as_point: Whether to import the symbol block as a point object or a composite object, the default is False, that is, the original symbol block is imported as a composite object, otherwise the point object is used instead of the symbol block.
    :param bool import_external_data: Whether to import external data. The external data is the data similar to the attribute table in CAD. The format after importing is some extra fields, the default is False, otherwise the external data will be appended to the default field.
    :param bool import_xrecord: Whether to import user-defined fields and attribute fields as extended records.
    :param bool import_invisible_layer: whether to import invisible layers
    :param bool keep_parametric_part: Whether to keep the parameterized part in the Acad data
    :param bool ignore_lwpline_width: Whether to ignore the polyline width, the default is False.
    :param shx_paths: path of shx font library
    :type shx_paths: list[str]
    :param int curve_segment: curve fitting accuracy, the default is 73
    :param str style_map_file: storage path of style comparison table
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_dxf": """
    Import DXF files. Linux platform does not support importing DXF files. Supports importing file directories.

    :param str source_file: dxf file to be imported
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: dataset import mode
    :type import_mode: ImportMode or str
    :param bool is_import_empty: Whether to import empty dataset, the default is False, that is, do not import
    :param bool is_import_as_cad: Whether to import as CAD dataset
    :param bool is_import_by_layer: Whether to merge the CAD layer information in the source data in the imported data. CAD is stored as layer information. The default is False, that is, all layer information is merged into a CAD dataset. Otherwise, a CAD dataset is generated corresponding to each layer in the source data.
    :param bool ignore_block_attrs: Whether to ignore block attributes when importing data. The default is True
    :param bool block_as_point: Whether to import the symbol block as a point object or a composite object, the default is False, that is, the original symbol block is imported as a composite object, otherwise the point object is used instead of the symbol block.
    :param bool import_external_data: Whether to import external data. The external data is the data similar to the attribute table in CAD. The format after importing is some extra fields, the default is False, otherwise the external data will be appended to the default field.
    :param bool import_xrecord: Whether to import user-defined fields and attribute fields as extended records.
    :param bool import_invisible_layer: whether to import invisible layers
    :param bool keep_parametric_part: Whether to keep the parameterized part in the Acad data
    :param bool ignore_lwpline_width: Whether to ignore the polyline width, the default is False.
    :param shx_paths: path of shx font library
    :type shx_paths: list[str]
    :param int curve_segment: curve fitting accuracy, the default is 73
    :param str style_map_file: storage path of style comparison table
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_e00": """
    Import the E00 file. Support for importing file directories.

    :param str source_file: the imported E00 file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: dataset import mode
    :type import_mode: ImportMode or str
    :param bool is_ignore_attrs: Whether to ignore attribute information
    :param source_file_charset: The original character set of the E00 file
    :type source_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_ecw": """
    Import ECW files. Supports importing file directories.

    :param str source_file: ECW file to be imported
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: ECW file ignore color value mode
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param multi_band_mode: Multi-band import mode, which can be imported as multiple single-band dataset, single multi-band dataset or single single-band dataset.
    :type multi_band_mode: MultiBandImportMode or str
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_geojson": """
    Import GeoJson files

    :param str source_file: GeoJson file to be imported
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param bool is_import_empty: Whether to import an empty dataset, the default is False
    :param bool is_import_as_cad: Whether to import as CAD dataset
    :param source_file_charset: Original character set type of GeoJson file
    :type source_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_gif": """
    Import GIF files. Supports importing file directories.

    :param str source_file: GIF file to be imported
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: The mode of ignoring color values of GIF files
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param str world_file_path: The coordinate reference file path of the imported source image file
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param bool is_build_pyramid: whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_grd": """
    Import GRD file

    :param str source_file: the imported GRD file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: mode to ignore color values
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param bool is_build_pyramid: whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_img": """
    Import the Erdas Image file. Supports importing file directories.

    :param str source_file: the imported IMG file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: Erdas Image's mode to ignore color values
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param multi_band_mode: Multi-band import mode, which can be imported as multiple single-band dataset, single multi-band dataset or single single-band dataset.
    :type multi_band_mode: MultiBandImportMode or str
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param bool is_build_pyramid: whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_jp2": """
    Import the JP2 file. Supports importing file directories.

    :param str source_file: the imported JP2 file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: mode to ignore color values
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_jpg": """
    Import JPG files. Supports importing file directories.

    :param str source_file: the imported JPG file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: mode to ignore color values
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param str world_file_path: The coordinate reference file path of the imported source image file
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param bool is_build_pyramid: whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_kml": """
    Import KML files. Supports importing file directories.

    :param str source_file: KML file to be imported
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :type import_mode: ImportMode or str
    :param bool is_import_empty: whether to import an empty dataset
    :param bool is_import_as_cad: Whether to import as CAD dataset
    :param bool is_ignore_invisible_object: Whether to ignore invisible objects
    :param source_file_charset: The original character set of the KML file
    :type source_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_kmz": """
    Import the KMZ file. Supports importing file directories.

    :param str source_file: the imported KMZ file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: dataset import mode
    :type import_mode: ImportMode or str
    :param bool is_import_empty: whether to import an empty dataset
    :param bool is_import_as_cad: Whether to import as CAD dataset
    :param bool is_ignore_invisible_object: Whether to ignore invisible objects
    :param source_file_charset: the original character set of the KMZ file
    :type source_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_mapgis": """
    Import MapGIS files. Linux platform does not support importing MapGIS files.

    :param str source_file: the imported MAPGIS file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: dataset import mode
    :type import_mode: ImportMode or str
    :param bool is_import_as_cad: Whether to import as CAD dataset
    :param str color_index_file_path: MAPGIS color index table file path when importing data, the default file path is MapGISColor.wat under the system path
    :param bool import_network_topology: Whether to import the network dataset when importing
    :param source_file_charset: the original character set of the MAPGIS file
    :type source_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_mif": """
    Import the MIF file. Supports importing file directories.

    :param str source_file: the imported mif file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: dataset import mode
    :type import_mode: ImportMode or str
    :param bool is_ignore_attrs: Whether to ignore the attributes of the data when importing MIF format data, including the attribute information of vector data.
    :param bool is_import_as_cad: Whether to import as CAD dataset
    :param source_file_charset: the original character set of the mif file
    :type source_file_charset: Charset or str
    :param str style_map_file: storage path of style comparison table
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_mrsid": """
    Import MrSID file, Linux platform does not support importing MrSID file.

    :param str source_file: the imported MrSID file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: The mode of ignoring the color value of the MrSID file
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param multi_band_mode: Multi-band import mode, which can be imported as multiple single-band dataset, single multi-band dataset or single single-band dataset.
    :type multi_band_mode: MultiBandImportMode or str
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_osm": """
    Import OSM vector data, the Linux platform does not support OSM files. Supports importing file directories.

    :param str source_file: OSM file to be imported
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: dataset import mode
    :type import_mode: ImportMode or str
    :param source_file_charset: the original character set of the OSM file
    :type source_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_png": """
    Import Portal Network Graphic (PNG) files. Supports importing file directories.

    :param str source_file: PNG file to be imported
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: PNG file ignore color value mode
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param str world_file_path: The coordinate reference file path of the imported source image file
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param bool is_build_pyramid: whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_shape": """
    Import the shape file into the datasource. Supports importing file directories.

    :param str source_file: the imported shape file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: Import mode type, which can be ImportMode enumeration value or name
    :type import_mode: ImportMode or str
    :param bool is_ignore_attrs: Whether to ignore attribute information, the default value is False
    :param bool is_import_empty: No to import empty dataset, the default is not to import. The default is False
    :param source_file_charset: The original character set type of the shape file
    :type source_file_charset: Charset or str
    :param bool is_import_as_3d: Whether to import as a 3D dataset
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]

    >>> result = import_shape('E:/point.shp','E:/import_shp_out.udb')
    >>> print(len(result) == 1)
    >>> print(result[0])

    """,

    "iobjectspy._jsuperpy.conversion.import_simplejson": """
    Import SimpleJson file

    :param str source_file: SimpleJson file to be imported
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: dataset import mode
    :type import_mode: ImportMode or str
    :param bool is_import_empty: whether to import an empty dataset
    :param source_file_charset: The original character set of the SimpleJson file
    :type source_file_charset: Charset or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_sit": """
    Import the SIT file. Supports importing file directories.

    :param str source_file: SIT file to be imported
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: SIT file ignore color value mode
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param multi_band_mode: Multi-band import mode, which can be imported as multiple single-band dataset, single multi-band dataset or single single-band dataset.
    :type multi_band_mode: MultiBandImportMode or str
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param str password: password
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_tab": """
    Import TAB files. Supports importing file directories.

    :param str source_file: TAB file to be imported
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: dataset import mode
    :type import_mode: ImportMode or str
    :param bool is_ignore_attrs: Whether to ignore the attributes of the data when importing TAB format data, including the attribute information of vector data.
    :param bool is_import_empty: Whether to import empty dataset, the default is False, that is, do not import
    :param bool is_import_as_cad: Whether to import as CAD dataset
    :param source_file_charset: the original character set of the mif file
    :type source_file_charset: Charset or str
    :param str style_map_file: storage path of style comparison table
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_tif": """
    Import the TIF file. Supports importing file directories.

    :param str source_file: the imported TIF file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: Tiff/BigTIFF/GeoTIFF file ignore color value mode
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param multi_band_mode: Multi-band import mode, which can be imported as multiple single-band dataset, single multi-band dataset or single single-band dataset.
    :type multi_band_mode: MultiBandImportMode or str
    :param str world_file_path: The coordinate reference file path of the imported source image file
    :param bool is_import_as_grid: Whether to import as a Grid dataset
    :param bool is_build_pyramid: whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[DatasetImage] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_usgsdem": """
    Import the USGSDEM file.

    :param str source_file: the imported USGS DEM file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param ignore_mode: mode to ignore color values
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param bool is_build_pyramid: whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetGrid] or list[str]
    """,

    "iobjectspy._jsuperpy.conversion.import_vct": """
    Import the VCT file. Supports importing file directories.

    :param str source_file: The imported VCT file
    :param output: result datasource
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result dataset name
    :param import_mode: dataset import mode
    :type import_mode: ImportMode or str
    :param bool is_import_empty: whether to import an empty dataset
    :param source_file_charset: the original character set of the VCT file
    :type source_file_charset: Charset or str
    :param layers: The names of the layers to be imported. When set to None, all will be imported.
    :type layers: str or list[str]
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result dataset or result dataset name
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_bil" :"""
    Import the BIL file.

    :param str source_file: the imported BIL file
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param ignore_mode: Ignore the mode of the color value
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: the color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param bool is_build_pyramid: Whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetGrid] or list[str]
""",
"iobjectspy._jsuperpy.conversion.import_bip":
    """
    Import the BIP file.

    :param str source_file: the imported BIP file
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param ignore_mode: Ignore the mode of the color value
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: the color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param bool is_build_pyramid: Whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetGrid] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_bsq":
    """
    Import the BSQ file.

    :param str source_file: the imported BSQ file
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param ignore_mode: Ignore the mode of the color value
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: the color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param bool is_build_pyramid: Whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetGrid] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_vrt":
    """
    Import GDAL Virtual (VRT) files.

    :param str source_file: the imported VRT file
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param ignore_mode: Ignore the mode of the color value
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: the color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param multi_band_mode: Multi-band import mode, which can be imported as multiple single-band data sets, single multi-band data sets or single single-band data sets.
    :type multi_band_mode: MultiBandImportMode or str
    :param bool is_import_as_grid: Whether to import as Grid dataset
    :param bool is_build_pyramid: Whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetGrid] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_egc":
    """
    Import the EGC file.

    :param str source_file: the imported EGC file
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param int scale: scale
    :param ignore_mode: Ignore the mode of the color value
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: the color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param bool is_build_pyramid: Whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetGrid] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.iimport_raw":
    """
    Import RAW files.

    :param str source_file: the imported RAW file
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param ignore_mode: Ignore the mode of the color value
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: the color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param bool is_build_pyramid: Whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetGrid] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_gbdem":
    """
    Import the GBDEM file.

    :param str source_file: GBDEM file to be imported
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param ignore_mode: Ignore the mode of the color value
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: the color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param bool is_build_pyramid: Whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetGrid] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_grib":
    """
    Import the GRIB file.

    :param str source_file: GRIB file to be imported
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param ignore_mode: Ignore the mode of the color value
    :type ignore_mode: IgnoreMode or str
    :param ignore_values: the color values to ignore
    :type ignore_values: list[float] color values to ignore
    :param multi_band_mode: Multi-band import mode, which can be imported as multiple single-band data sets, single multi-band data sets or single single-band data sets.
    :type multi_band_mode: MultiBandImportMode or str
    :param bool is_import_as_grid: Whether to import as Grid dataset
    :param bool is_build_pyramid: Whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetGrid] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_file_gdb_vector":
    """
    Import the Esri Geodatabase exchange file. Only supports Windows.

    :param str source_file: The imported Esri Geodatabase exchange file
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param bool is_ignore_attrs: Whether to ignore attribute information.
    :param bool is_import_empty: Whether to import an empty data set, the default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_personal_gdb_vector":
    """
    Import Esri Personal Geodatabase vector files. Only supports Windows.

    :param str source_file: The imported Esri Personal Geodatabase vector file
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param bool is_import_3d_as_2d: Whether to import 3D objects as 2D objects.
    :param bool is_import_empty: Whether to import an empty data set, the default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_gjb":
    """
    Import the GJB file. Only supports Windows.

    :param str source_file: GJB file to be imported
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param layers: The names of the layers to be imported. When set to None, all will be imported.
    :type layers: str or list[str]
    :param str config_file: The configuration file path of a specific format that compares the font size and color transparency of the text
    :param bool is_import_empty: Whether to import an empty data set, the default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_gjb9121":
    """
    Import the GJB navigation file. Only supports Windows.

    :param str source_file: GJB file to be imported
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param layers: The names of the layers to be imported. When set to None, all will be imported.
    :type layers: str or list[str]
    :param bool is_import_empty: Whether to import an empty data set, the default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_lidar":
    """
    Import lidar files.

    :param str source_file: Lidar file to be imported.
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param bool is_ignore_attrs: Whether to ignore attribute information
    :param bool is_import_as_3d: Whether to import as a 3D dataset
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_orange_tab":
    """
    Import the Orange tab file.

    :param str source_file: Orange tab file to be imported.
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param bool is_ignore_attrs: Whether to ignore attribute information
    :param fields_as_point: Specify the field as X, Y or X, Y, Z coordinates. If the conditions are met, a two-dimensional point or three-dimensional point data set is generated.
    :type fields_as_point: list[str] or str
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_gpkg":
    """
    Import the OGC Geopackage vector file.

    :param str source_file: The imported OGC Geopackage vector file.
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param bool is_ignore_attrs: Whether to ignore attribute information
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_tems_building_vector":
    """
    Import telecom vector data.

    :param str source_file: The telecom vector plane data to be imported.
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param bool is_import_empty: Whether to import an empty data set.
    :param bool is_char_separator: Whether to split the field by characters, the default is False, and it is split by spaces.
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_tems_clutter":
    """
    Import telecom industry image data (TEMSClutter) files.

    :param str source_file: The imported telecom industry image data (TEMSClutter) file
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param bool is_build_pyramid: Whether to automatically build an image pyramid
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetGrid] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_tems_text_labels":
    """
    Import telecom vector feature labeling.

    :param str source_file: The imported telecom vector feature annotation.
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param bool is_import_empty: Whether to import an empty data set.
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.import_tems_vector":
    """
    Import telecom vector line data.

    :param str source_file: The imported telecom vector feature annotation.
    :param output: result data source
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: result data set name
    :param import_mode: import mode
    :type import_mode: ImportMode or str
    :param bool is_import_empty: Whether to import an empty data set.
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: the imported result data set or the name of the result data set
    :rtype: list[DatasetVector] or list[str]
    """,
"iobjectspy._jsuperpy.conversion.export_to_egc":
    """
    Export data set to EGC file

    :param data: the exported data set
    :type data: DatasetGrid or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,
"iobjectspy._jsuperpy.conversion.export_to_file_gdb_vector":
    """
    Export data set to ESRI GDB interchange format file

    :param data: the exported data set
    :type data: DatasetVector or str or list[DatasetVector] or list[str]
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,
"iobjectspy._jsuperpy.conversion.export_to_personal_gdb_vector":
    """
    Export data set to ESRI Personal GDB file

    :param data: the exported data set
    :type data: DatasetVector or str or list[DatasetVector] or list[str]
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,
"iobjectspy._jsuperpy.conversion.export_to_gjb":
    """
    Export data set to GJB file

    :param data: The exported data set and layer information. GJB files have fixed layers, and you need to specify the layer type and the exported data set when exporting.

                 -:py:attr:`GJBLayerType.GJB_S` metadata layer can only set one attribute table dataset to export bit metadata
                 -:py:attr:`GJBLayerType.GJB_R` metadata layer can only set multiple text datasets
                 -Other layers can set multiple point, line and surface data sets

    :type data: dict[GJBLayerType,DatasetVector] or dict[GJBLayerType, list[DatasetVector]]
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,
"iobjectspy._jsuperpy.conversion.export_to_gjb9121":
    """
    Export data set to GJB9121 file

    :param data: the exported data set
    :type data: DatasetVector or str or list[DatasetVector] or list[str]
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,
"iobjectspy._jsuperpy.conversion.export_to_tems_building_vector":
    """
    Export data set to telecom vector surface data file

    :param data: the exported data set
    :type data: DatasetVector or str or list[DatasetVector] or list[str]
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,
"iobjectspy._jsuperpy.conversion.export_to_tems_vector":
    """
    Export data set to telecom vector line data file

    :param data: the exported data set
    :type data: DatasetVector or str or list[DatasetVector] or list[str]
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,
"iobjectspy._jsuperpy.conversion.export_to_tems_clutter":
    """
    Export data sets to telecom industry image files

    :param data: the exported data set
    :type data: DatasetGrid or str
    :param str output: result file path
    :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
    :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
    :return: whether the export was successful
    :rtype: bool
    """,
"iobjectspy._jsuperpy.conversion.export_to_tems_text_labels":
     """
     Export data set to telecom vector line data file

     :param data: the exported data set
     :type data: DatasetVector or str or list[DatasetVector] or list[str]
     :param str output: result file path
     :param str label_field: The name of the text field to be exported
     :param bool is_over_write: Whether to force overwrite when there is a file with the same name in the export directory. The default is False
     :param function progress: progress information processing function, please refer to :py:class:`.StepEvent`
     :return: whether the export was successful
     :rtype: bool
     """,
}
 
_iobjectspy_ml_locale = {
"iobjectspy.ml.vision._sample" :"""""",
 
"iobjectspy.ml.toolkit" :"""""",
 
"iobjectspy.ml.toolkit._create_training_data_util" :"""""",
 
"iobjectspy.ml.toolkit._create_training_data_util.get_image_crs" :"""""",
 
"iobjectspy.ml.toolkit._create_training_data_util.get_image_transf" :"""""",
 
"iobjectspy.ml.toolkit._create_training_data_util.get_key" :"""
    Get key by value in the dictionary
    :param dict: the dictionary to be looked up
    :param value: value
    :return: key
    """,
 
"iobjectspy.ml.toolkit._create_training_data_util.get_tile_start_index" :"""
    Obtain the file index generated by the training data
   :param tile_start_index: file index number
   :param tile_count_yml: Training data configuration file (.sda)
   :return: tile_start_index
   """,
 
"iobjectspy.ml.toolkit._toolkit" :"""""",
 
"iobjectspy.ml.toolkit._toolkit.check_module" :"""Check whether the module exists
 
    :param modulename: module name
    :return: True or False
    """,
 
"iobjectspy.ml.toolkit._toolkit.checkpath" :""" Check if the file path is valid
 
    :param strpath: file path to be checked
    :param type: the file extension
    :return: True or False; When 'type' is not none, the file path must end with the file extension to return True
    """,
 
"iobjectspy.ml.toolkit._toolkit.compute_bbox_iou" :"""Calculates the IoU of a given bounding box with a set of bounding boxes.
    
    box: 1D array, [y1, x1, y2, x2] means [ymin,xmin,ymax,xmax]
    boxes: [N, (y1, x1, y2, x2)],the coordinates of a set of bounding boxes
    box_area: float. the area of the 'box'
    boxes_area: float. array of length boxes_count.
    Note: the areas are passed in rather than calculated here for efficiency.
          Calculate once in the caller to avoid duplicate work.
    :return: 1D array
    """,
 
"iobjectspy.ml.toolkit._toolkit.del_dir" :"""
       Delete folder
    """,
 
"iobjectspy.ml.toolkit._toolkit.find_element_in_list": """ Find the index of an element in a list
 
    :param element: the element to be positioned
    :param list_element: the list to be looked up
    :return: True or False. Whether the element can be found
    """,
 
"iobjectspy.ml.toolkit._toolkit.getStr_InList_ByKey" :""" search the string element

    -When 'list_v' is None, search the elements in 'list_i' directly according to the 'key' value
    -When 'list_v' is not None, search the elements in 'list_v' based on the index of the 'key' value in 'list_i'
        
    :param key: the key of the string to be searched
    :param list_i: the list to be searched
    :param list_v: the list used to match the search. Default: None
    :return: Return the element in list_v
    """,
 
"iobjectspy.ml.toolkit._toolkit.get_changedet_image_from_csv" :"""
    Read training data from the path in the csv file
    :param csv_path: csv file path
    :return: read training data (X, Y)
    """,
 
"iobjectspy.ml.toolkit._toolkit.get_config_from_yaml" :"""
    Get the config from a yml or yaml file
    :param yaml_file: the file path
    :param encoding: Default: utf8
    :return: config(namespace) or config(dictionary)
    """,
 
"iobjectspy.ml.toolkit._toolkit.get_image_from_csv" :"""
    Read training data from the path in the csv file
    :param csv_path: csv file path
    :return: read training data (X, Y)
    """,
 
"iobjectspy.ml.toolkit._toolkit.get_input_dataset" :"""""",
 
"iobjectspy.ml.toolkit._toolkit.get_percentclip_min_max" :"""""",
 
"iobjectspy.ml.toolkit._toolkit.get_pic_path_from_dir" :"""
    List the full image file paths with a specified extension of a directory
    :param input_dir: the path of the input file directory
    :type input_dir: str
    :param get_all_dir: Whether to search images in the subdirectories under the input path
    :type get_all_dir: bool
    :param suffix: Specify the image file extension
    :type suffix: list
 
    :return image_path_list: a list of all the image file paths
    :type image_path_list: list [image_path1,image_path2,...]
    """,
 
"iobjectspy.ml.toolkit._toolkit.get_scene_image_from_csv" :"""
    Read training data from the path in the csv file
    :param csv_path: csv file path
    :return: read training data (X, Y)
    """,
 
"iobjectspy.ml.toolkit._toolkit.list_file" :"""
    List the file directory under the specified folder
    :param folder: the specified folder
    :param pattern: filtered by file name
    :param ext: filtered by file extension
    :return: A list of file paths meet the requirements
    """,
 
"iobjectspy.ml.toolkit._toolkit.list_xy_file_fromtxt" :"""
    List the full file path of all images and masks through a txt file
    :param txt_path: txt file path
    :return: a list of all the image and mask file paths
    """,
 
"iobjectspy.ml.toolkit._toolkit.merge_number" :"""
    To merge numbers, CRFPP needs to merge the adjacent numeric character into one element
    Such as road number, building number, etc.
 
    :param rawss: a list of strings to be merged
    :return: a list of strings after merging the numbers
    """,
 
"iobjectspy.ml.toolkit._toolkit.mkdir_not_exist" :"""
    Create one or more non-existent file paths
    path_list[path1, path2, path3]
    :param path1: a file path that needs to be created
    type path1: str
    """,
 
"iobjectspy.ml.toolkit._toolkit.non_max_suppression" :"""
    Performs non-maximum suppression and returns the indexes of the reserved bboxes.
    boxes: [N, (y1, x1, y2, x2)]. Notice that (y2, x2) lays outside the box.
    scores: 1D array of the box scores.
    threshold: Float. Threshold to filter IoU.
    """,
 
"iobjectspy.ml.toolkit._toolkit.ordered_yaml_dump" :"""""",
 
"iobjectspy.ml.toolkit._toolkit.read_short_json_file" :"""
    convert json file to dict


    :param file_path: file path
    :param encoding: file encoding
    :return: dict object corresponding to the json characters
    """,
 
"iobjectspy.ml.toolkit._toolkit.save_config_to_yaml" :"""
    save the config to a yaml format file
    :param config:
    :param yaml_file:
    :param encoding:
    :return:
    """,
 
"iobjectspy.ml.toolkit._toolkit.save_pattle_png" :"""""",
 
"iobjectspy.ml.toolkit._toolkit.split_train_val_change_det" :"""
    Put multiple segmentation data together to divide the training and the validation dataset
    :param pre_image_dirs: directory of the initial or earlier raster
    :type pre_image_dirs: list
    :param next_image_dirs: directory of the final or later raster
    :type next_image_dirs: list
    :param mask_dirs: multiple mask directories, corresponding to the order of the image directories
    :type mask_dirs: list
    :param train_txt_path: '.txt' file path record in the training file
    :type train_txt_path: str
    :param val_scale: ratio of the validation dataset
    :type val_scale: float
    :param x_ext: image file extension
    :type x_ext: str
    :param y_ext: mask file extension
    :type y_ext: str
    :return: None
    """,
 
"iobjectspy.ml.toolkit._toolkit.split_train_val_image_classification" :"""
    Divided the scene classification dataset into validation and test datasets
    :param image_dirs:
    :param train_txt_path:
    :param val_scale:
    :return:
    """,
 
"iobjectspy.ml.toolkit._toolkit.split_train_val_scene_classification" :"""
    Divided the scene classification dataset into validation and test datasets
    :param image_dirs:
    :param train_txt_path:
    :param val_scale:
    :return:
    """,
 
"iobjectspy.ml.toolkit._toolkit.split_train_val_withdirs" :"""
    Put multiple segmentation data together to divide the training and the validation dataset, shuffle
    :param image_dirs: multiple image directories
    :type image_dirs: list
    :param mask_dirs: multiple mask directories, corresponding to the order of the image directories
    :type mask_dirs: list
    :param train_txt_path: '.txt' file path record in the training file
    :type train_txt_path: str
    :param val_scale: ratio of the validation dataset
    :type val_scale: float
    :param x_ext: image file extension
    :type x_ext: str
    :param y_ext: mask file extension
    :type y_ext: str
    :return: train_num,val_num,train_val_num
    """,
 
"iobjectspy.ml.toolkit._toolkit.stretch_min_max" :"""
        Scaling each band of image data to the range of 0-1
 
        :param bands: input image
        :param min: minimum value in the array
        :param max: Maximum value in the array
        :return: normalized image
        """,
 
"iobjectspy.ml.toolkit._toolkit.stretch_minmax" :"""
    Normalize image data to the range of 0-1
    :param bands: input image
    :param max_value: minimum value
    :param min_value: maximum value
    :return: normalized image
    """,
 
"iobjectspy.ml.toolkit._toolkit.stretch_n" :"""
    Normalize image data to the range of 0-1
 
 
    :param bands: input image
    :param lower_percent: minimum ratio
    :param higher_percent: maximum ratio
    :return: normalized image
    """,
 
"iobjectspy.ml.toolkit._toolkit.to_onehot" :"""
    Support up to 256 categories
    :param y:
    :param classes: supports up to 256 categories
    :return:
    """,
 
"iobjectspy.ml.toolkit._toolkit.to_onehot_image_cls" :"""
    Support up to 256 categories
    :param y:
    :param classes: supports up to 256 categories
    :return:
    """,
 
"iobjectspy.ml.toolkit._toolkit.view_bar" :"""
    The progress bar
    :param num: current progress
    :param total: total number of tasks
    :return:
    """,
 
"iobjectspy.ml.vision._sample.create_object_detection_data_mask" :"""""",
 
"iobjectspy.ml.vision._sample.create_object_detection_data_mask.CreateObjectDetectionDataMask" :"""""",
 
"iobjectspy.ml.vision._sample.create_object_detection_data_mask.CreateObjectDetectionDataMask.create_voc_mask" :"""""",
 
"iobjectspy.ml.vision._sample.create_object_detection_data" :"""""",
 
"iobjectspy.ml.vision._sample.create_object_detection_data.CreateObjectDetectionData" :"""""",
 
"iobjectspy.ml.vision._sample.create_object_detection_data.CreateObjectDetectionData.create_voc" :"""""",
 
"iobjectspy.ml.vision._dataprepare_collector.object_detection_training_data" :"""""",
 
"iobjectspy.ml.vision._dataprepare_collector.object_detection_training_data.create_voc_data" :"""""",
 
"iobjectspy.ml.vision._dataprepare_collector.object_detection_training_data.create_voc_mask_data" :"""""",
 
"iobjectspy.ml.vision._sample.create_multi_classification_data" :"""""",
 
"iobjectspy.ml.vision._sample.create_multi_classification_data.CreateMultiClassificationData" :"""""",
 
"iobjectspy.ml.vision._sample.create_multi_classification_data.CreateMultiClassificationData.create_multi_classification" :"""""",
 
"iobjectspy.ml.vision._dataprepare_collector.multi_classification_training_data" :"""""",
 
"iobjectspy.ml.vision._dataprepare_collector.multi_classification_training_data.create_multi_classification_data" :"""""",
 
"iobjectspy.ml.vision._sample.create_binary_classification_data" :"""""",
 
"iobjectspy.ml.vision._sample.create_binary_classification_data.CreateBinaryClassificationData" :"""""",
 
"iobjectspy.ml.vision._sample.create_binary_classification_data.CreateBinaryClassificationData.create_binary_classification" :"""""",
 
"iobjectspy.ml.vision._dataprepare_collector.binary_classification_training_data" :"""""",
 
"iobjectspy.ml.vision._dataprepare_collector.binary_classification_training_data.create_binary_classification_data" :"""""",
 
"iobjectspy.ml.vision._sample.create_secne_classification_data" :"""""",
 
"iobjectspy.ml.vision._sample.create_secne_classification_data.CreateSceneClassificationData" :"""""",
 
"iobjectspy.ml.vision._sample.create_secne_classification_data.CreateSceneClassificationData.create_scene_classification" :"""""",
 
"iobjectspy.ml.vision._dataprepare_collector.scene_classification_training_data" :"""""",
 
"iobjectspy.ml.vision._dataprepare_collector.scene_classification_training_data.create_scene_classification_data" :"""""",
 
"iobjectspy.ml.vision._dataprepare_collector" :"""""",
 
"iobjectspy.ml.vision._datapreparation" :"""""",
 
"iobjectspy.ml.vision._datapreparation.DataPreparation" :"""
    Image data preparation process entry
 
    """,
 
"iobjectspy.ml.vision._datapreparation.DataPreparation.create_training_data" :"""
        Training data generation
 
        | Generate the training sample image tiles in specified size from the input imagery with labeled vector data. 
        | The output includes pictures, annotations, and meta-information. The pictures and annotations name one-to-one correspondence.
 
        :param input_data: input image data, support image file
        :type input_data: str
        :param input_label: input vector label data, support vector dataset
        :type input_label: str or DatasetVector
        :param label_class_field: the field name represents the label categpries. If 'None' is specified, all labels are of the same category.
        :type label_class_field: str or None
        :param output_path: output training data storage path
        :type output_path: str
        :param training_data_format: output training data format, support four different formates: 'VOC', 'MULTI_C', 'BINARY_C', 'SCENE_C'.
        :type training_data_format: str
        :param tile_format: image tile format, support 'tif', 'jpg', 'png', and 'origin formates'
        :type tile_format: str
        :param tile_size_x: tile size in x direction
        :type tile_size_x: int
        :param tile_size_y: tile size in y direction
        :type tile_size_y: int
        :param tile_offset_x: tile offset in the x direction
        :type tile_offset_x: int
        :param tile_offset_y: tile offset in y direction
        :type tile_offset_y: int
        :param tile_start_index: the initial index value for naming the tiles. The default is 0 and set to -1 when using this function to process multiple images.
        :type tile_start_index: int
        :param save_nolabel_tiles: whether to save tiles without labels
        :type save_nolabel_tiles: bool
        :return: None
 
 
        VOC format:
         | ./VOC
         | ./VOC/Annotations/000000001.xml label tiles
         | ./VOC/Images/000000001.jpg image tiles
         | ./VOC/ImageSets/Main/train.txt, val.txt, test.txt, trainval.txt training dataset tile name, validation dataset tile name, test dataset tile name, training dataset and validation dataset tile name
         | ./VOC/VOC.sda training data configuration file
 
        MULTI_C format:
         | ./MULTI_C
         | ./MULTI_C/Images/00000000.tif image tiles
         | ./MULTI_C/Masks/00000000.png label tiles
         | ./MULTI_C/MULTI_C.sda training data configuration file
 
        BINARY_C format:
         | ./BINARY_C
         | ./BINARY_C/Images/00000000.tif image tiles
         | ./BINARY_C/Masks/00000000.png label tiles
         | ./BINARY_C/BINARY_C.sda training data configuration file
 
        SCENE_C format:
         | ./SCENE_C
         | ./SCENE_C/0/00000000.tif image tiles
         | ./SCENE_C/1/00000000.png image tiles
         | ./SCENE_C/2/00000000.tif image tiles
         | ....
         | ./SCENE_C/scene_classification.csv mapping the relationship between saved image file path and the categories.
         | ./SCENE_C/SCENE_C.sda Training data configuration file
 
         """,

"iobjectspy.ml.vision._trainer.Trainer.__init__" :"""
    Model training function entrance for satellite image data.
    
    :param train_data_path: training data path
    :type train_data_path: str
    :param config: configuration file path
    :type config: str
    :param epoch: number of iterations
    :type epoch: int
    :param batch_size: batch size
    :type batch_size: int
    :param lr: learning rate
    :type lr: float
    :param output_model_path: output model file path
    :type output_model_path: str
    :param output_model_name:  output model file name
    :type output_model_name: str
    :param backbone_name: backtrunk network name
    :type backbone_name: str
    :param backbone_weight_path: path to the trunk network model file. If it is None, the model weight is initialized randomly
    :type backbone_weight_path: str or None
    :param log_path: log and checkpoint output paths
    :type log_path: str
    :param reload_model: whether to reload the checkpoint model trained previously
    :type reload_model: bool
    :param pretrained_model_path: pre-trained model path (optional)
    :type pretrained_model_path: str or None
    """,

"iobjectspy.ml.vision._trainer.Trainer.object_detect_train" :"""
    Function entry for object detection model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.Trainer.binary_classify_train" :"""
    Function entry for binary classification model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.Trainer.multi_classify_train" :"""
    Function entry for ground object classification model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.Trainer.scene_classify_train" :"""
    Function entry for scene classification model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.Trainer.image_classify_train": """
    Function entry for iamge classification model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.Trainer.object_extract_train": """
    Function entry for objects classification model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.ImageryTrainer.__init__": """
    Model training function entrance for pictures.

    :param train_data_path: training data path
    :type train_data_path: str
    :param config: configuration file path
    :type config: str
    :param epoch: number of iterations
    :type epoch: int
    :param batch_size: batch size
    :type batch_size: int
    :param lr: learning rate
    :type lr: float
    :param output_model_path: output model file path
    :type output_model_path: str
    :param output_model_name:  output model file name
    :type output_model_name: str
    :param backbone_name: backtrunk network name
    :type backbone_name: str
    :param backbone_weight_path: path to the trunk network model file. If it is None, the model weight is initialized randomly
    :type backbone_weight_path: str or None
    :param log_path: log and checkpoint output paths
    :type log_path: str
    :param reload_model: whether to reload the checkpoint model trained previously
    :type reload_model: bool
    :param pretrained_model_path: pre-trained model path (optional)
    :type pretrained_model_path: str or None
    """,

"iobjectspy.ml.vision._trainer.ImageryTrainer.object_detect_train": """
    Function entry for object detection model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.ImageryTrainer.binary_classify_train": """
    Function entry for binary classification model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.ImageryTrainer.multi_classify_train": """
    Function entry for ground object classification model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.ImageryTrainer.scene_classify_train": """
    Function entry for scene classification model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.ImageryTrainer.object_extract_train": """
    Function entry for objects classification model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.PictureTrainer.__init__": """
    Function entry for picture data model training.
    
    :param train_data_path: training data path
    :type train_data_path: str
    :param config: configuration file path
    :type config: str
    :param epoch: number of iterations
    :type epoch: int
    :param batch_size: batch size
    :type batch_size: int
    :param lr: learning rate
    :type lr: float
    :param output_model_path: output model file path
    :type output_model_path: str
    :param output_model_name:  output model file name
    :type output_model_name: str
    :param backbone_name: backtrunk network name
    :type backbone_name: str
    :param backbone_weight_path: path to the trunk network model file. If it is None, the model weight is initialized randomly
    :type backbone_weight_path: str or None
    :param log_path: log and checkpoint output paths
    :type log_path: str
    :param reload_model: whether to reload the checkpoint model trained previously
    :type reload_model: bool
    :param pretrained_model_path: pre-trained model path (optional)
    :type pretrained_model_path: str or None
    """,

"iobjectspy.ml.vision._trainer.PictureTrainer.object_detect_train": """
    Function entry for object detection model training.
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,

"iobjectspy.ml.vision._trainer.PictureTrainer.picture_classify_train": """
    Function entry for picture classification model training. 
    The build model will be stored under the 'output_model_path' folder
    :return: None
    """,
 
"iobjectspy.ml.vision._models" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit.get_config_from_yaml" :"""
    Get the config from a yml or yaml file
    :param yaml_file: file path
    :param encoding: encoding default: utf8
    :return: config(namespace) or config(dictionary)
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit.get_preprocessing" :"""Construct preprocessing transformation.
 
    Args:
        preprocessing_fn (callbale): data normalization function
            (can be specific for each pretrained neural network)
    Return:
        transform: albumentations.Compose
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit.get_training_augmentation" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit.get_validation_augmentation" :"""
    Padding the image to make the image shape divisible by 32""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit.list_file" :"""
    List the file directory under the specified folder
    :param folder: the specified folder
    :param pattern: filtered by file name
    :param ext: filtered by file extension
    :return: A list of file paths that meet the requirements
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit.list_xy_file_fromtxt" :"""
    List the full file path of all images and masks through a txt file
    :param txt_path: txt file path
    :return:
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit.preprocess_input" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit.to_onehot" :"""
    Support up to 256 categories
    :param y:
    :param classes: supports up to 256 classes
    :return:
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit.to_tensor" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api._toolkit.vis_image_mask" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.dataset" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.dataset.BaseInferDataLoader" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.dataset.BaseInferDataLoader.close" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.dataset.BaseInferDataLoader.write_batch" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.dataset.SdaDataset" :"""
    CamVid Dataset. Read images, apply augmentation and preprocessing transformations.
 
    Args:
        images_dir (str): path to images folder
        masks_dir (str): path to segmentation masks folder
        class_values (list): values of classes to extract from segmentation mask
        augmentation (albumentations.Compose): data transfromation pipeline
            (e.g. flip, scale, etc.)
        preprocessing (albumentations.Compose): data preprocessing
            (e.g. noralization, shape manipulation, etc.)
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.dataset.SdaDataset.random_mixup" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.dataset.SegInferDataLoader" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.dataset.SegInferDataLoader.close" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.dataset.SegInferDataLoader.read_batch" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.dataset.SegInferDataLoader.write_batch" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._utils" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._utils.patch_first_conv" :"""Change the input channels of the first convolution layer.
    In case:
        in_channels == 1 or in_channels == 2 -> reuse the original weights
        in_channels> 3 -> Process random Kaiming normal initialization method
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._utils.replace_strides_with_dilation" :"""Patch Conv2d modules to replace the strides with dilation""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._base" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._base.EncoderMixin" :"""Add encoder functionality such as:
        -output channels specification of feature tensors (produced by encoder)
        -patching the first convolution for arbitrary input channels
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._base.EncoderMixin.get_stages" :"""The method should be overridden in the encoder""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._base.EncoderMixin.make_dilated" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._base.EncoderMixin.out_channels" :"""Return the channels dimensions for each tensor of the encoder forward output""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._base.EncoderMixin.set_in_channels" :"""Change the first convolution chennels""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.resnet" :""" Each encoder should have the following attributes and methods. T^he encoder can be inherited from `_base.EncoderMixin`
 
Attributes:
 
    _out_channels (list of int): specify the number of channels for each encoder feature tensor
    _depth (int): specify the number of stages in the decoder (in other words, the number of downsampling operations)
    _in_channels (int): the default number of input channels in the first Conv2d layer for encoder (usually 3)
 
Methods:
 
    forward(self, x: torch.Tensor)
        produce a list of features of different spatial resolutions, each feature is a 4D torch tensor of
        shape NCHW (features should be sorted in descending order according to the spatial resolution, starting
        with resolution same as input `x` tensor).
 
        Input: `x` with shape (1, 3, 64, 64)
        Output: [f0, f1, f2, f3, f4, f5]-features with corresponding shapes
                [(1, 3, 64, 64), (1, 64, 32, 32), (1, 128, 16, 16), (1, 256, 8, 8),
                (1, 512, 4, 4), (1, 1024, 2, 2)] (C-dim may differ)
 
        also should support number of features according to a specified depth, eg if depth = 5,
        number of feature tensors = 6 (one with same resolution as input and 5 downsampled),
        depth = 3 -> number of feature tensors = 4 (one with same resolution as input and 3 downsampled).
""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.resnet.ResNetEncoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.resnet.ResNetEncoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.resnet.ResNetEncoder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.resnet.ResNetEncoder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.resnet.ResNetEncoder.out_channels" :"""Return the channels dimensions for each tensor of the encoder forward output.""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.dpn.out_channels" :""" Each encoder should have the following attributes and methods. The encoder can be inherited from `_base.EncoderMixin`
 
Attributes:
 
    _out_channels (list of int): specify the number of channels for each encoder feature tensor
    _depth (int): specify the number of stages in the decoder (in other words, the number of downsampling operations)
    _in_channels (int): the default number of input channels in the first Conv2d layer for encoder (usually 3)
 
Methods:
 
    forward(self, x: torch.Tensor)
        produce a list of features of different spatial resolutions, each feature is a 4D torch tensor of
        shape NCHW (features should be sorted in descending order according to the spatial resolution, starting
        with resolution same as input `x` tensor).
 
        Input: `x` with shape (1, 3, 64, 64)
        Output: [f0, f1, f2, f3, f4, f5]-features with corresponding shapes
                [(1, 3, 64, 64), (1, 64, 32, 32), (1, 128, 16, 16), (1, 256, 8, 8),
                (1, 512, 4, 4), (1, 1024, 2, 2)] (C-dim may differ)
 
        also should support number of features according to specified depth, eg if depth = 5,
        number of feature tensors = 6 (one with same resolution as input and 5 downsampled),
        depth = 3 -> number of feature tensors = 4 (one with same resolution as input and 3 downsampled).
""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.dpn.DPNEncorder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.dpn.DPNEncorder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.dpn.DPNEncorder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.dpn.DPNEncorder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.dpn.DPNEncorder.out_channels" :"""Return channels dimensions for each tensor of forward output of encoder""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.vgg.out_channels" :""" Each encoder should have the following attributes and methods. The encoder can be inherited from `_base.EncoderMixin`
 
Attributes:
 
    _out_channels (list of int): specify the number of channels for each encoder feature tensor
    _depth (int): specify the number of stages in the decoder (in other words, the number of downsampling operations)
    _in_channels (int): the default number of input channels in the first Conv2d layer for encoder (usually 3)
 
Methods:
 
    forward(self, x: torch.Tensor)
        produce a list of features of different spatial resolutions, each feature is a 4D torch tensor of
        shape NCHW (features should be sorted in descending order according to the spatial resolution, starting
        with resolution same as input `x` tensor).
 
        Input: `x` with shape (1, 3, 64, 64)
        Output: [f0, f1, f2, f3, f4, f5]-features with corresponding shapes
                [(1, 3, 64, 64), (1, 64, 32, 32), (1, 128, 16, 16), (1, 256, 8, 8),
                (1, 512, 4, 4), (1, 1024, 2, 2)] (C-dim may differ)
 
        also should support number of features according to specified depth, eg if depth = 5,
        number of feature tensors = 6 (one with same resolution as input and 5 downsampled),
        depth = 3 -> number of feature tensors = 4 (one with same resolution as input and 3 downsampled).
""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.vgg.VGGEncoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.vgg.VGGEncoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.vgg.VGGEncoder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.vgg.VGGEncoder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.vgg.VGGEncoder.make_dilated" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.vgg.VGGEncoder.out_channels" :"""Return channels dimensions for each tensor of forward output of encoder""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.senet.out_channels" :""" Each encoder should have the following attributes and methods. The encoder can be inherited from `_base.EncoderMixin`
 
Attributes:
 
    _out_channels (list of int): specify the number of channels for each encoder feature tensor
    _depth (int): specify the number of stages in the decoder (in other words, the number of downsampling operations)
    _in_channels (int): the default number of input channels in the first Conv2d layer for encoder (usually 3)
 
Methods:
 
    forward(self, x: torch.Tensor)
        produce a list of features of different spatial resolutions, each feature is a 4D torch tensor of
        shape NCHW (features should be sorted in descending order according to the spatial resolution, starting
        with resolution same as input `x` tensor).
 
        Input: `x` with shape (1, 3, 64, 64)
        Output: [f0, f1, f2, f3, f4, f5]-features with corresponding shapes
                [(1, 3, 64, 64), (1, 64, 32, 32), (1, 128, 16, 16), (1, 256, 8, 8),
                (1, 512, 4, 4), (1, 1024, 2, 2)] (C-dim may differ)
 
        also should support number of features according to specified depth, eg if depth = 5,
        number of feature tensors = 6 (one with same resolution as input and 5 downsampled),
        depth = 3 -> number of feature tensors = 4 (one with same resolution as input and 3 downsampled).
""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.senet.SENetEncoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.senet.SENetEncoder.for ward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.senet.SENetEncoder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.senet.SENetEncoder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.senet.SENetEncoder.out_channels" :"""Return channels dimensions for each tensor of the encoder forward output""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.densenet.out_channels" :""" Each encoder should have the following attributes and methods. The encoder can be inherited from `_base.EncoderMixin`
 
Attributes:
 
    _out_channels (list of int): specify the number of channels for each encoder feature tensor
    _depth (int): specify the number of stages in the decoder (in other words, the number of downsampling operations)
    _in_channels (int): the default number of input channels in the first Conv2d layer for encoder (usually 3)
 
Methods:
 
    forward(self, x: torch.Tensor)
        produce a list of features of different spatial resolutions, each feature is a 4D torch tensor of
        shape NCHW (features should be sorted in descending order according to the spatial resolution, starting
        with resolution same as input `x` tensor).
 
        Input: `x` with shape (1, 3, 64, 64)
        Output: [f0, f1, f2, f3, f4, f5]-features with corresponding shapes
                [(1, 3, 64, 64), (1, 64, 32, 32), (1, 128, 16, 16), (1, 256, 8, 8),
                (1, 512, 4, 4), (1, 1024, 2, 2)] (C-dim may differ)
 
        also should support number of features according to specified depth, eg if depth = 5,
        number of feature tensors = 6 (one with same resolution as input and 5 downsampled),
        depth = 3 -> number of feature tensors = 4 (one with same resolution as input and 3 downsampled).
""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.densenet.DenseNetEncoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.densenet.DenseNetEncoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.densenet.DenseNetEncoder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.densenet.DenseNetEncoder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.densenet.DenseNetEncoder.make_dilated" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.densenet.DenseNetEncoder.out_channels" :"""Return channels dimensions for each tensor of the encoder forward output.""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.densenet.TransitionWithSkip" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.densenet.TransitionWithSkip.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionresnetv2" :""" Each encoder should have the following attributes and methods. The encoder can be inherited from `_base.EncoderMixin`
 
Attributes:
 
    _out_channels (list of int): specify the number of channels for each encoder feature tensor
    _depth (int): specify the number of stages in the decoder (in other words, the number of downsampling operations)
    _in_channels (int): the default number of input channels in the first Conv2d layer for encoder (usually 3)
 
Methods:
 
    forward(self, x: torch.Tensor)
        produce a list of features of different spatial resolutions, each feature is a 4D torch tensor of
        shape NCHW (features should be sorted in descending order according to the spatial resolution, starting
        with resolution same as input `x` tensor).
 
        Input: `x` with shape (1, 3, 64, 64)
        Output: [f0, f1, f2, f3, f4, f5]-features with corresponding shapes
                [(1, 3, 64, 64), (1, 64, 32, 32), (1, 128, 16, 16), (1, 256, 8, 8),
                (1, 512, 4, 4), (1, 1024, 2, 2)] (C-dim may differ)
 
        also should support number of features according to specified depth, eg if depth = 5,
        number of feature tensors = 6 (one with same resolution as input and 5 downsampled),
        depth = 3 -> number of feature tensors = 4 (one with same resolution as input and 3 downsampled).
""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionresnetv2.InceptionResNetV2Encoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionresnetv2.InceptionResNetV2Encoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionresnetv2.InceptionResNetV2Encoder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionresnetv2.InceptionResNetV2Encoder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionresnetv2.InceptionResNetV2Encoder.make_dilated" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionresnetv2.InceptionResNetV2Encoder.out_channels" :"""Return channels dimensions for each tensor of the encoder forward output""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionv4.out_channels" :""" Each encoder should have the following attributes and methods. The encoder can be inherited from `_base.EncoderMixin`
 
Attributes:
 
    _out_channels (list of int): specify the number of channels for each encoder feature tensor
    _depth (int): specify the number of stages in the decoder (in other words, the number of downsampling operations)
    _in_channels (int): the default number of input channels in the first Conv2d layer for encoder (usually 3)
 
Methods:
 
    forward(self, x: torch.Tensor)
        produce a list of features of different spatial resolutions, each feature is a 4D torch tensor of
        shape NCHW (features should be sorted in descending order according to the spatial resolution, starting
        with resolution same as input `x` tensor).
 
        Input: `x` with shape (1, 3, 64, 64)
        Output: [f0, f1, f2, f3, f4, f5]-features with corresponding shapes
                [(1, 3, 64, 64), (1, 64, 32, 32), (1, 128, 16, 16), (1, 256, 8, 8),
                (1, 512, 4, 4), (1, 1024, 2, 2)] (C-dim may differ)
 
        also should support number of features according to specified depth, eg if depth = 5,
        number of feature tensors = 6 (one with same resolution as input and 5 downsampled),
        depth = 3 -> number of feature tensors = 4 (one with same resolution as input and 3 downsampled).
""",

"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionv4.InceptionV4Encoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionv4.InceptionV4Encoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionv4.InceptionV4Encoder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionv4.InceptionV4Encoder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionv4.InceptionV4Encoder.make_dilated" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.inceptionv4.InceptionV4Encoder.out_channels" :"""Return channels dimensions for each tensor of the encoder forward output""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.efficientnet.out_channels" :""" Each encoder should have the following attributes and methods. The encoder can be inherited from `_base.EncoderMixin`
 
Attributes:
 
    _out_channels (list of int): specify the number of channels for each encoder feature tensor
    _depth (int): specify the number of stages in the decoder (in other words, the number of downsampling operations)
    _in_channels (int): the default number of input channels in the first Conv2d layer for encoder (usually 3)
 
Methods:
 
    forward(self, x: torch.Tensor)
        produce a list of features of different spatial resolutions, each feature is a 4D torch tensor of
        shape NCHW (features should be sorted in descending order according to the spatial resolution, starting
        with resolution same as input `x` tensor).
 
        Input: `x` with shape (1, 3, 64, 64)
        Output: [f0, f1, f2, f3, f4, f5]-features with corresponding shapes
                [(1, 3, 64, 64), (1, 64, 32, 32), (1, 128, 16, 16), (1, 256, 8, 8),
                (1, 512, 4, 4), (1, 1024, 2, 2)] (C-dim may differ)
 
        also should support number of features according to specified depth, eg if depth = 5,
        number of feature tensors = 6 (one with same resolution as input and 5 downsampled),
        depth = 3 -> number of feature tensors = 4 (one with same resolution as input and 3 downsampled).
""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.efficientnet.EfficientNetEncoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.efficientnet.EfficientNetEncoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.efficientnet.EfficientNetEncoder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.efficientnet.EfficientNetE ncoder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.efficientnet.EfficientNetEncoder.out_channels" :"""Return channels dimensions for each tensor of forward output of encoder""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.mobilenet.out_channels" :""" Each encoder should have the following attributes and methods. The encoder can be inherited from `_base.EncoderMixin`
 
Attributes:
 
    _out_channels (list of int): specify the number of channels for each encoder feature tensor
    _depth (int): specify the number of stages in the decoder (in other words, the number of downsampling operations)
    _in_channels (int): the default number of input channels in the first Conv2d layer for encoder (usually 3)
 
Methods:
 
    forward(self, x: torch.Tensor)
        produce a list of features of different spatial resolutions, each feature is a 4D torch tensor of
        shape NCHW (features should be sorted in descending order according to the spatial resolution, starting
        with resolution same as input `x` tensor).
 
        Input: `x` with shape (1, 3, 64, 64)
        Output: [f0, f1, f2, f3, f4, f5]-features with corresponding shapes
                [(1, 3, 64, 64), (1, 64, 32, 32), (1, 128, 16, 16), (1, 256, 8, 8),
                (1, 512, 4, 4), (1, 1024, 2, 2)] (C-dim may differ)
 
        also should support number of features according to specified depth, eg if depth = 5,
        number of feature tensors = 6 (one with same resolution as input and 5 downsampled),
        depth = 3 -> number of feature tensors = 4 (one with same resolution as input and 3 downsampled).
""",

"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.mobilenet.MobileNetV2Encoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.mobilenet.MobileNetV2 Encoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.mobilenet.MobileNetV2Encoder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.mobilenet.MobileNetV2Encoder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.mobilenet.MobileNetV2Encoder.out_channels" :"""Return channels dimensions for each tensor of the encoder forward output""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.out_channels" :"""
@author: tstandley
Adapted by cadene
Creates an Xception Model as defined in:
Francois Chollet
Xception: Deep Learning with Depthwise Separable Convolutions
This weights ported from the Keras implementation. Achieves the following performance on the validation set:
Loss:0.9173 Prec@1:78.892 Prec@5:94.292
REMEMBER to set your image size to 3x299x299 for both test and validation
normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],
                                  std=[0.5, 0.5, 0.5])
The resize parameter of the validation transform should be 333, and make sure to center crop at 299x299
""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.Block" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.Block.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.SeparableConv2d" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.SeparableConv2d.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.Xceptio n" :"""
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.Xception.__init__" :""" Constructor
        Args:
            num_classes: number of classes
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.Xception.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.Xception.get_layers" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.XceptionAtrousEncoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.XceptionAtrousEncoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.XceptionAtrousEncoder.get_layers" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.XceptionAtrousEncoder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.XceptionAtrousEncoder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.XceptionAtrousEncoder.out_channels" :"""Return channels dimensions for each tensor of the encoder forward output.""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception_atrous.xception" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception.XceptionEncoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception.XceptionEncoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception.XceptionEncoder.get_stages" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception.XceptionEncoder.load_state_dict" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception.XceptionEncoder.make_dilated" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.xception.XceptionEncoder.out_channels" :"""Return channels dimensions for each tensor of forward output of encoder""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._preprocessing.out_channels" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders._preprocessing.preprocess_input" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.get_encoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.get_encoder_names" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.get_preprocessing_fn" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.get_preprocessing_params" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.encoders.load_weighs_url" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.base" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.base.BaseTorchEstimation" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.base.BaseTorchEstimation.close_model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.base.BaseTorchEstimation.estimate_img" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.base.BaseTorchEstimation.estimate_tile" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.base.BaseTorchEstimation.load_model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.base.BaseTorchTrainer" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.base.BaseTorchTrainer.init_callbacks" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.base.BaseTorchTrainer.train" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.predict_api" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.predict_api.SegTorchEstimation" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.predict_api.SegTorchEstimation.close_model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.predict_api.SegTorchEstimation.estimate_img" :"""
 
        :param input_img:
        :param coversize:
        :param out_path:
        :param out_dataset_name:
        :param result_type: region or grid
        :param kwargs:
        :return:
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.predict_api.SegTorchEstimation.load_model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.initialization" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.initialization.initialize_decoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.initialization.initialize_head" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.model.SegmentationModel" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.model.SegmentationModel.forward" :"""Sequentially pass `x` trough model's encoder, decoder and heads""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.model.SegmentationModel.initialize" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.model.SegmentationModel.predict" :"""Inference method. Switch the model to `eval` mode, call '.forward(x)' with 'torch.no_grad( )'
 
        Args:
            x: 4D torch tensor with shape (batch_size, channels, height, width)
 
        Return:
            prediction: 4D torch tensor with shape (batch_size, classes, height, width)
 
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.modules" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.modules.Activation" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.modules.Activation.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.modules.Attention" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.modules.Attention.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.modules.Conv2dReLU" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.modules.Flatten" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.modules.Flatten.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.modules.SCSEModule" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.modules.SCSEModule.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.heads" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.heads.ClassificationHead" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base.heads.SegmentationHead" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.base" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.deeplabv3p.decoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.deeplabv3p.decoder.ASPP" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.deeplabv3p.decoder.ASPP.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.deeplabv3p.decoder.ASPPPooling" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.deeplabv3p.decoder.ASPPPooling.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.deeplabv3p.decoder.DeepLabV3PlusDecoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.deeplabv3p.decoder.DeepLabV3PlusDecoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.deeplabv3p.model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.deeplabv3p.model.DeepLabV3Plus" :"""DeepLabV3_ implemetation from "Rethinking Atrous Convolution for Semantic Image Segmentation"
    Args:
        encoder_name: name of the classification model (without last dense layers) used as feature
                extractor to build segmentation model.
        encoder_depth: number of stages used in decoder, the deeper the depth, the more features are generated.
            eg: a depth=3 encoder will generate list of features with following spatial shapes
            [(H,W), (H/2, W/2), (H/4, W/4), (H/8, W/8)], so in general the deepest feature will have
            spatial resolution (H/(2^depth), W/(2^depth)]
        encoder_weights: one of ``None`` (random initialization), ``imagenet`` (pre-training on ImageNet).
        decoder_channels: number of convolution filters in ASPP module (default: 256).
        in_channels: number of input channels for model, default is 3.
        classes: number of classes for output (output shape-``(batch, classes, h, w)'').
        activation (str, callable): activation function used in ``.predict(x)'' method for inference.
            One of [``sigmoid``, ``softmax2d``, callable, None]
        upsampling: optional, final upsampling factor
            (default is 8 to preserve input -> output spatial shape identity)
        aux_params: if the specified model will have additional classification auxiliary output
            build on top of encoder, supported params:
                -classes (int): number of classes
                -pooling (str): one of'max','avg'. Default is'avg'.
                -dropout (float): dropout factor in [0, 1)
                -activation (str): activation function to apply "sigmoid"/"softmax" (could be None to return logits)
    Returns:
        ``torch.nn.Module``: **DeepLabV3**
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.deeplabv3p" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder.Conv3x3GNReLU" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder.Conv3x3GNReLU.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder.FPNBlock" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder.FPNBlock.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder.FPNDecoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder.FPNDecoder.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder.MergeBlock" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder.MergeBlock.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder.SegmentationBlock" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.decoder.SegmentationBlock.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn.model.FPN" :"""FPN_ is a fully convolution neural network for image semantic segmentation
    Args:
        encoder_name: name of classification model (without last dense layers) used as feature
                extractor to build segmentation model.
        encoder_depth: number of stages used in decoder, larger depth-more features are generated.
            eg for depth=3 encoder will generate list of features with following spatial shapes
            [(H,W), (H/2, W/2), (H/4, W/4), (H/8, W/8)], so in general the deepest feature will have
            spatial resolution (H/(2^depth), W/(2^depth)]
        encoder_weights: one of ``None`` (random initialization), ``imagenet`` (pre-training on ImageNet).
        decoder_pyramid_channels: a number of convolution filters in Feature Pyramid of FPN_.
        decoder_segmentation_channels: a number of convolution filters in segmentation head of FPN_.
        decoder_merge_policy: determines how to merge outputs inside FPN.
            One of [``add``, ``cat``]
        decoder_dropout: spatial dropout rate in range (0, 1).
        in_channels: number of input channels for model, default is 3.
        classes: a number of classes for output (output shape-``(batch, classes, h, w)'').
        activation (str, callable): activation function used in ``.predict(x)'' method for inference.
            One of [``sigmoid``, ``softmax2d``, callable, None]
        upsampling: optional, final upsampling factor
            (default is 4 to preserve input -> output spatial shape identity)
        aux_params: if specified model will have additional classification auxiliary output
            build on top of encoder, supported params:
                -classes (int): number of classes
                -pooling (str): one of'max','avg'. Default is'avg'.
                -dropout (float): dropout factor in [0, 1)
                -activation (str): activation function to apply "sigmoid"/"softmax" (could be None to return logits)
 
    Returns:
        ``torch.nn.Module``: **FPN**
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.fpn" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.decoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.decoder.DLinknetDecoder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.decoder.DLinknetDecoder.forward" :"""
    dlinknet adds the center module of dilated convolution between the decoder and encoder to expand the acceptance range and save detailed spatial information.
 
    :param dilated_conv_out: dilated convolution layer
    :return:
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.decoder.DecoderBlock" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.decoder.DecoderBlock.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.decoder.Dilatedblock" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.decoder.Dilatedblock.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.decoder.TransposeX2" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.model.DLinknet" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet.model.DLinknet.forward" :"""Sequentially pass 'x' trough model's encoder, decoder and heads""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.dlinknet" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.model_builder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.model_builder.build_torch_seg_model" :"""
    :param in_channels: the channel number of the input image
    :param classes: number of categories
    :param backbone_name: backbone network: vgg19, resnet50, resnext50
    :param encoder_weights: str imagenet
    :param net_type: temporarily only supports fpn, and deeplabv3plus
    :return: keras.model
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.cus_dataloader" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.cus_dataloader.FastDataLoader" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.multiprocessing_context" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.base.multiprocessing_context" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.base.Activation" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.base.Activation.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.base.BaseObject" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.base.Loss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.base.Metric" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.base.MultipliedLoss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.base.SumOfLosses" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.functional" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.functional.accuracy" :"""Calculate the accuracy score between ground truth and prediction
    Args:
        pr (torch.Tensor): predicted tensor
        gt (torch.Tensor): ground truth tensor
        eps (float): epsilon to avoid zero division
        threshold: threshold for outputs binarization
    Returns:
        float: precision score
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.functional.f_score" :"""Calculate F-score between ground truth and prediction
    Args:
        pr (torch.Tensor): predicted tensor
        gt (torch.Tensor): ground truth tensor
        beta (float): positive constant
        eps (float): epsilon to avoid zero division
        threshold: threshold for outputs binarization
    Returns:
        float: F score
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.functional.iou" :"""Calculate Intersection over Union between ground truth and prediction
    Args:
        pr (torch.Tensor): predicted tensor
        gt (torch.Tensor): ground truth tensor
        eps (float): epsilon to avoid zero division
        threshold: threshold for outputs binarization
    Returns:
        float: IoU (Jaccard) score
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.functional.precision" :"""Calculate precision score between ground truth and prediction
    Args:
        pr (torch.Tensor): predicted tensor
        gt (torch.Tensor): ground truth tensor
        eps (float): epsilon to avoid zero division
        threshold: threshold for outputs binarization
    Returns:
        float: precision score
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.functional.recall" :"""Calculate Recall between ground truth and prediction
    Args:
        pr (torch.Tensor): list of predicted elements
        gt (torch.Tensor): list of elements that are to be predicted
        eps (float): epsilon to avoid zero division
        threshold: threshold for outputs binarization
    Returns:
        float: recall score
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.BCELoss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.BCEWithLogitsLoss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.CrossEntropyLoss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.CrossEntropyLoss.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.DiceJaccardLoss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.DiceJaccardLoss.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.DiceLoss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.DiceLoss.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.HrnetCrossEntropy" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.HrnetCrossEntropy.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.HrnetOhemCrossEntropy" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.HrnetOhemCrossEntropy.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.JaccardLoss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.JaccardLoss.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.L1Loss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.MSELoss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.losses.get_loss" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics.Accuracy" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics.Accuracy.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics.Fscore" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics.Fscore.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics.IoU" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics.IoU.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics.Precision" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics.Precision.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics.Recall" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.metrics.Recall.forward" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.ranger.ranger" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.ranger.ranger.Ranger" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.ranger.ranger.Ranger.step" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.ranger.ranger913A" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.ranger.ranger913A.RangerVA" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.ranger.ranger913A.RangerVA.step" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.ranger.rangerqh" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.ranger.rangerqh.RangerQH" :"""Implements the QHAdam optimization algorithm `(Ma and Yarats, 2019)`_.
    Along with Hinton/Zhang Lookahead.
    Args:
        params (iterable):
            iterable of parameters to optimize or dicts defining parameter
            groups
        lr (float, optional): learning rate (:math:`\alpha` from the paper)
            (default: 1e-3)
        betas (Tuple[float, float], optional): coefficients used for computing
            running averages of the gradient and its square
            (default: (0.9, 0.999))
        nus (Tuple[float, float], optional): immediate discount factors used to
            estimate the gradient and its square
            (default: (1.0, 1.0))
        eps (float, optional): term added to the denominator to improve
            numerical stability
            (default: 1e-8)
        weight_decay (float, optional): weight decay (default: 0.0)
        decouple_weight_decay (bool, optional): whether to decouple the weight
            decay from the gradient-based optimization step
            (default: False)
    Example:
        >>> optimizer = qhoptim.pyt.QHAdam(
        ... model.parameters(),
        ... lr=3e-4, nus=(0.8, 1.0), betas=(0.99, 0.999))
        >>> optimizer.zero_grad()
        >>> loss_fn(model(input), target).backward()
        >>> optimizer.step()
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.ranger.rangerqh.RangerQH.step" :"""Performs a single optimization step.
        Args:
            closure (callable, optional):
                A closure that reevaluates the model and returns the loss.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.ranger" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.meter" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.meter.AverageValueMeter" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.meter.AverageValueMeter.add" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.meter.AverageValueMeter.reset" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.meter.AverageValueMeter.value" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.meter.Meter" :"""Meters provide a way to keep track of important statistics in an online manner.
    This class is abstract, but provides a standard interface for all meters to follow.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.meter.Meter.add" :"""Log a new value to the meter
        Args:
            value: Next restult to include.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.meter.Meter.reset" :"""Resets the meter to default settings.""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.meter.Meter.value" :"""Get the value of the meter in current state.""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.Epoch" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.Epoch.batch_update" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.Epoch.on_epoch_start" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.Epoch.run" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.TrainEpoch" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.TrainEpoch.batch_update" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.TrainEpoch.on_epoch_start" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.TrainEpoch.run" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.ValidEpoch" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.ValidEpoch.batch_update" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.ValidEpoch.on_epoch_start" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.util.train.ValidEpoch.run" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.train_api" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.train_api.SegTorchTrainer" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.train_api.SegTorchTrainer.get_model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._torch_models.geo_api.train_api.SegTorchTrainer.train" :"""
 
        :param train_data_path:
        :param config:
        :param epoch:
        :param batch_size:
        :param lr:
        :param output_model_path:
        :param output_model_name:
        :param log_path:
        :param backbone_name:
        :param backbone_weight_path:
        :param reload_model:
        :param pretrained_model_path:
        :param kwargs:
        :return:
        """,
 
"iobjectspy.ml.vision._models.semantic_seg.fpn_torch" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.fpn_torch.FpnEstimation" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.fpn_torch.FpnTrainer" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.fpn_torch.FpnTrainer.get_model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.deeplabv3plus_torch" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.deeplabv3plus_torch.Deeplabv3PlusEstimation" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.deeplabv3plus_torch.Deeplabv3PlusTrainer" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.deeplabv3plus_torch.Deeplabv3PlusTrainer.get_model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.dlinknet_torch" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.dlinknet_torch.DLinknetEstimation" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.dlinknet_torch.DLinknetTrainer" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.dlinknet_torch.DLinknetTrainer.get_model" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.ModelCheckpointLatest" :"""
    save the latest checkpoint
    :param filepath: save dir
    :param name: file name ,default:'latest.h5'
    :param verbose: print out, 0 not out ,other out
    """,
 
"iobjectspy.ml.toolkit._keras_model_utils.ModelCheckpointLatest.on_epoch_end" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.ParallelModelCheckpoint" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.ParallelModelCheckpoint.set_model" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.ParallelModelCheckpointLatest" :"""
    Parallel train
    save the latest checkpoint
    :param filepath: save dir
    :param name: file name ,default'latest.h5'
    :param verbose: print out ,0 not out ,other out
    """,
 
"iobjectspy.ml.toolkit._keras_model_utils.ParallelModelCheckpointLatest.on_epoch_end" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.ParallelModelCheckpointLatest.set_model" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.average" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.bce_dice_loss" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.bianary_crossentropy" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.binary_focal_loss" :"""Implementation of Focal Loss from the paper in binary classification
 
    Formula:
        loss =-gt * alpha * ((1-pr)^gamma) * log(pr) \
               -(1-gt) * alpha * (pr^gamma) * log(1-pr)
 
    Args:
        gt: ground truth 4D keras tensor (B, H, W, C) or (B, C, H, W)
        pr: prediction 4D keras tensor (B, H, W, C) or (B, C, H, W)
        alpha: the same as weighting factor in balanced cross entropy, default 0.25
        gamma: focusing parameter for modulating factor (1-p), default 2.0
 
    """,
 
"iobjectspy.ml.toolkit._keras_model_utils.categorical_crossentropy" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.categorical_focal_loss" :"""Implementation of Focal Loss from the paper in multiclass classification
 
    Formula:
        loss =-gt * alpha * ((1-pr)^gamma) * log(pr)
 
    Args:
        gt: ground truth 4D keras tensor (B, H, W, C) or (B, C, H, W)
        pr: prediction 4D keras tensor (B, H, W, C) or (B, C, H, W)
        alpha: the same as weighting factor in balanced cross entropy, default 0.25
        gamma: focusing parameter for modulating factor (1-p), default 2.0
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
 
    """,
 
"iobjectspy.ml.toolkit._keras_model_utils.dice_coef" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.f_score" :"""The F-score (Dice coefficient) can be interpreted as a weighted average of the precision and recall,
    where an F-score reaches its best value at 1 and worst score at 0.
    The relative contribution of ``precision`` and ``recall`` to the F1-score are equal.
    The formula for the F score is:
 
    .. math:: F_\beta(precision, recall) = (1 + \beta^2) \frac{precision \cdot recall}
        {\beta^2 \cdot precision + recall}
 
    The formula in terms of *Type I* and *Type II* errors:
 
    .. math:: F_\beta(A, B) = \frac{(1 + \beta^2) TP} {(1 + \beta^2) TP + \beta^2 FN + FP}
 
 
    where:
        TP-true positive;
        FP-false positive;
        FN-false negative;
 
    Args:
        gt: ground truth 4D keras tensor (B, H, W, C) or (B, C, H, W)
        pr: prediction 4D keras tensor (B, H, W, C) or (B, C, H, W)
        class_weights: 1. or list of class weights, len(weights) = C
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        beta: f-score coefficient
        smooth: value to avoid division by zero
        per_image: if ``True``, metric is calculated as mean over images in batch (B),
            else over whole batch
        threshold: value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round
 
    Returns:
        F-score in range [0, 1]
 
    """,
 
"iobjectspy.ml.toolkit._keras_model_utils.find_last" :"""Finds the last checkpoint file of the last trained model in the
    model directory.
    Returns:
        The path of the last checkpoint file
    """,
 
"iobjectspy.ml.toolkit._keras_model_utils.gather_channels" :"""Slice tensors along channels axis by given indexes""",
 
"iobjectspy.ml.toolkit._keras_model_utils.get_reduce_axes" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.iou_score" :""" The `Jaccard index`_, also known as Intersection over Union and the Jaccard similarity coefficient
    (originally coined coefficient de communautÂ¨Â¦ by Paul Jaccard), is a statistic used for comparing the
    similarity and diversity of sample sets. The Jaccard coefficient measures similarity between finite sample sets,
    and is defined as the size of the intersection divided by the size of the union of the sample sets:
 
    .. math:: J(A, B) = \frac{A \cap B}{A \cup B}
 
    Args:
        gt: ground truth 4D keras tensor (B, H, W, C) or (B, C, H, W)
        pr: prediction 4D keras tensor (B, H, W, C) or (B, C, H, W)
        class_weights: 1. or list of class weights, len(weights) = C
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        smooth: value to avoid division by zero
        per_image: if ``True``, metric is calculated as mean over images in batch (B),
            else over whole batch
        threshold: value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round
 
    Returns:
        IoU/Jaccard score in range [0, 1]
    """,
 
"iobjectspy.ml.toolkit._keras_model_utils.mean_iou" :"""""",
 
"iobjectspy.ml.toolkit._keras_model_utils.precision" :"""Calculate precision between the ground truth (gt) and the prediction (pr).
 
    .. math:: F_\beta(tp, fp) = \frac{tp} {(tp + fp)}
 
    where:
         -tp-true positives;
         -fp-false positives;
 
    Args:
        gt: ground truth 4D keras tensor (B, H, W, C) or (B, C, H, W)
        pr: prediction 4D keras tensor (B, H, W, C) or (B, C, H, W)
        class_weights: 1. or ``np.array`` of class weights (``len(weights) = num_classes``)
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        smooth: Float value to avoid division by zero.
        per_image: If ``True``, metric is calculated as mean over images in batch (B),
            else over whole batch.
        threshold: Float value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round.
        name: Optional string, if ``None`` default ``precision`` name is used.
 
    Returns:
        float: precision score
    """,
 
"iobjectspy.ml.toolkit._keras_model_utils.recall" :"""Calculate recall between the ground truth (gt) and the prediction (pr).
 
    .. math:: F_\beta(tp, fn) = \frac{tp} {(tp + fn)}
 
    where:
         -tp-true positives;
         -fp-false positives;
 
    Args:
        gt: ground truth 4D keras tensor (B, H, W, C) or (B, C, H, W)
        pr: prediction 4D keras tensor (B, H, W, C) or (B, C, H, W)
        class_weights: 1. or ``np.array`` of class weights (``len(weights) = num_classes``)
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        smooth: Float value to avoid division by zero.
        per_image: If ``True``, metric is calculated as mean over images in batch (B),
            else over whole batch.
        threshold: Float value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round.
        name: Optional string, if ``None`` default ``precision`` name is used.
 
    Returns:
        float: recall score
    """,
 
"iobjectspy.ml.toolkit._keras_model_utils.round_if_needed" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.BinaryCELoss" :"""Creates a criterion that measures the Binary Cross Entropy between the
    ground truth (gt) and the prediction (pr).
 
    .. math:: L(gt, pr) =-gt \cdot \log(pr)-(1-gt) \cdot \log(1-pr)
 
    Returns:
        A callable ``binary_crossentropy`` instance. Can be used in ``model.compile(...)'' function
        or combined with other losses.
 
    Example:
 
    .. code:: python
 
        loss = BinaryCELoss()
        model.compile('SGD', loss=loss)
    """,
 
"iobjectspy.ml.toolkit._keras_loss.BinaryCELoss.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.BinaryFocalLoss" :"""Creates a criterion that measures the Binary Focal Loss between the
    ground truth (gt) and the prediction (pr).
 
    .. math:: L(gt, pr) =-gt \alpha (1-pr)^\gamma \log(pr)-(1-gt) \alpha pr^\gamma \log(1-pr)
 
    Args:
        alpha: Float or integer, the same as weighting factor in balanced cross entropy, default 0.25.
        gamma: Float or integer, focusing parameter for modulating factor (1-p), default 2.0.
 
    Returns:
        A callable ``binary_focal_loss`` instance. Can be used in ``model.compile(...)'' function
        or combined with other losses.
 
    Example:
 
    .. code:: python
 
        loss = BinaryFocalLoss()
        model.compile('SGD', loss=loss)
    """,
 
"iobjectspy.ml.toolkit._keras_loss.BinaryFocalLoss.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.CategoricalCELoss" :"""Creates a criterion that measures the Categorical Cross Entropy between the
    ground truth (gt) and the prediction (pr).
 
    .. math:: L(gt, pr) =-gt \cdot \log(pr)
 
    Args:
        class_weights: Array (``np.array'') of class weights (``len(weights) = num_classes'').
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
 
    Returns:
        A callable ``categorical_crossentropy`` instance. Can be used in ``model.compile(...)'' function
        or combined with other losses.
 
    Example:
 
    .. code:: python
 
        loss = CategoricalCELoss()
        model.compile('SGD', loss=loss)
    """,
 
"iobjectspy.ml.toolkit._keras_loss.CategoricalCELoss.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.CategoricalFocalLoss" :"""Creates a criterion that measures the Categorical Focal Loss between the
    ground truth (gt) and the prediction (pr).
 
    .. math:: L(gt, pr) =-gt \cdot \alpha \cdot (1-pr)^\gamma \cdot \log(pr)
 
    Args:
        alpha: Float or integer, the same as weighting factor in balanced cross entropy, default 0.25.
        gamma: Float or integer, focusing parameter for modulating factor (1-p), default 2.0.
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
 
    Returns:
        A callable ``categorical_focal_loss`` instance. Can be used in ``model.compile(...)'' function
        or combined with other losses.
 
    Example:
 
        .. code:: python
 
            loss = CategoricalFocalLoss()
            model.compile('SGD', loss=loss)
    """,
 
"iobjectspy.ml.toolkit._keras_loss.CategoricalFocalLoss.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.DiceLoss" :"""Creates a criterion to measure Dice loss:
 
    .. math:: L(precision, recall) = 1 - (1 + \beta^2) \frac{precision \cdot recall}
        {\beta^2 \cdot precision + recall}
 
    The formula in terms of *Type I* and *Type II* errors:
 
    .. math:: L(tp, fp, fn) = \frac{(1 + \beta^2) \cdot tp} {(1 + \beta^2) \cdot fp + \beta^2 \cdot fn + fp}
 
    where:
         -tp-true positives;
         -fp-false positives;
         -fn-false negatives;
 
    Args:
        beta: Float or integer coefficient for precision and recall balance.
        class_weights: Array (``np.array'') of class weights (``len(weights) = num_classes'').
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        per_image: If ``True`` loss is calculated for each image in batch and then averaged,
        else loss is calculated for the whole batch.
        smooth: Value to avoid division by zero.
 
    Returns:
        A callable ``dice_loss`` instance. Can be used in ``model.compile(...)`` function`
        or combined with other losses.
 
    Example:
 
    .. code:: python
 
        loss = DiceLoss()
        model.compile('SGD', loss=loss)
    """,
 
"iobjectspy.ml.toolkit._keras_loss.DiceLoss.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.FScore" :"""The F-score (Dice coefficient) can be interpreted as a weighted average of the precision and recall,
    where an F-score reaches its best value at 1 and worst score at 0.
    The relative contribution of ``precision`` and ``recall`` to the F1-score are equal.
    The formula for the F score is:
    .. math:: F_\beta(precision, recall) = (1 + \beta^2) \frac{precision \cdot recall}
        {\beta^2 \cdot precision + recall}
    The formula in terms of *Type I* and *Type II* errors:
    .. math:: L(tp, fp, fn) = \frac{(1 + \beta^2) \cdot tp} {(1 + \beta^2) \cdot fp + \beta^2 \cdot fn + fp}
    where:
         -tp-true positives;
         -fp-false positives;
         -fn-false negatives;
    Args:
        beta: Integer of float f-score coefficient to balance precision and recall.
        class_weights: 1. or ``np.array`` of class weights (``len(weights) = num_classes``)
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        smooth: Float value to avoid division by zero.
        per_image: If ``True``, metric is calculated as mean over images in batch (B),
            else over whole batch.
        threshold: Float value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round.
        name: Optional string, if ``None`` default ``f(beta)-score`` name is used.
    Returns:
        A callable ``f_score`` instance. Can be used in ``model.compile(...)'' function.
    Example:
    .. code:: python
        metric = FScore()
        model.compile('SGD', loss=loss, metrics=[metric])
    """,
 
"iobjectspy.ml.toolkit._keras_loss.FScore.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.IOUScore" :""" The `Jaccard index`_, also known as Intersection over Union and the Jaccard similarity coefficient
    (originally coined coefficient de communautÂ¨Â¦ by Paul Jaccard), is a statistic used for comparing the
    similarity and diversity of sample sets. The Jaccard coefficient measures similarity between finite sample sets,
    and is defined as the size of the intersection divided by the size of the union of the sample sets:
    .. math:: J(A, B) = \frac{A \cap B}{A \cup B}
    Args:
        class_weights: 1. or ``np.array`` of class weights (``len(weights) = num_classes``).
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        smooth: value to avoid division by zero
        per_image: if ``True``, metric is calculated as mean over images in batch (B),
            else over whole batch
        threshold: value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round
    Returns:
       A callable ``iou_score`` instance. Can be used in ``model.compile(...)'' function.
    Example:
    .. code:: python
        metric = IOUScore()
        model.compile('SGD', loss=loss, metrics=[metric])
    """,
 
"iobjectspy.ml.toolkit._keras_loss.IOUScore.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.JaccardLoss" :"""Creates a criterion to measure Jaccard loss:
 
    .. math:: L(A, B) = 1-\frac{A \cap B}{A \cup B}
 
    Args:
        class_weights: Array (``np.array'') of class weights (``len(weights) = num_classes'').
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        per_image: If ``True`` loss is calculated for each image in batch and then averaged,
            else loss is calculated for the whole batch.
        smooth: Value to avoid division by zero.
 
    Returns:
         A callable ``jaccard_loss`` instance. Can be used in ``model.compile(...)'' function
         or combined with other losses.
 
    Example:
 
    .. code:: python
 
        loss = JaccardLoss()
        model.compile('SGD', loss=loss)
    """,
 
"iobjectspy.ml.toolkit._keras_loss.JaccardLoss.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.KerasObject" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.KerasObject.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.Loss" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.Loss.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.Metric" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.Metric.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.MultipliedLoss" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.MultipliedLoss.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.Precision" :"""Creates a criterion that measures the Precision between the
    ground truth (gt) and the prediction (pr).
    .. math:: F_\beta(tp, fp) = \frac{tp} {(tp + fp)}
    where:
         -tp-true positives;
         -fp-false positives;
    Args:
        class_weights: 1. or ``np.array`` of class weights (``len(weights) = num_classes``).
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        smooth: Float value to avoid division by zero.
        per_image: If ``True``, metric is calculated as mean over images in batch (B),
            else over whole batch.
        threshold: Float value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round.
        name: Optional string, if ``None`` default ``precision`` name is used.
    Returns:
        A callable ``precision`` instance. Can be used in ``model.compile(...)'' function.
    Example:
    .. code:: python
        metric = Precision()
        model.compile('SGD', loss=loss, metrics=[metric])
    """,
 
"iobjectspy.ml.toolkit._keras_loss.Precision.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.Recall" :"""Creates a criterion that measures the Precision between the
    ground truth (gt) and the prediction (pr).
    .. math:: F_\beta(tp, fn) = \frac{tp} {(tp + fn)}
    where:
         -tp-true positives;
         -fn-false negatives;
    Args:
        class_weights: 1. or ``np.array`` of class weights (``len(weights) = num_classes``).
        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.
        smooth: Float value to avoid division by zero.
        per_image: If ``True``, metric is calculated as mean over images in batch (B),
            else over whole batch.
        threshold: Float value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round.
        name: Optional string, if ``None`` default ``recall`` name is used.
    Returns:
        A callable ``recall`` instance. Can be used in ``model.compile(...)'' function.
    Example:
    .. code:: python
        metric = Precision()
        model.compile('SGD', loss=loss, metrics=[metric])
    """,
 
"iobjectspy.ml.toolkit._keras_loss.Recall.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.SumOfLosses" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.SumOfLosses.set_submodules" :"""""",
 
"iobjectspy.ml.toolkit._keras_loss.focal_loss" :"""""",
 
"iobjectspy.ml" :"""""",
 
"iobjectspy.ml.utils" :"""
The utils module is responsible for some common small functions in data processing
""",
 
"iobjectspy.ml.utils.datasetraster_to_df_or_xarray" :"""
    Read data from raster dataset (DatasetGrid) or iamge dataset (DatasetImage) to 'pandas.DataFrame' or 'xarray.DataArray'. 
    The number of columns in the array is the width of the dataset, and the number of rows is the height of the dataset.
 
     * If it is a single-band dataset and it is not a RGB and RGBA pixel format, return a 2D array (DataFrame). The first dimension of the array is the row and the second dimension is the column.
     * If it is a single-band dataset in RGB and RGBA formate, return a 3D array (DataArray). The first dimension of the array is the band and the size will be 3 (for RGB pixel formate) or 4 (for RGBA formate), the second dimension is the row, and the third dimensions is column.
     * If it is a multispectral dataset, return a 3D array (DataArray). The first dimension is the band and the size is the number of bands, the second dimension is the row, and the third dimension is the column.
 
    :param source: The raster dataset or image dataset to be read. If the input is a string, you can use datasource information plus the dataset name to represented the dataset. For example, the datasource alias can be used as 'alias/imagedataset'. 
                   And the datasource connection information (a udb file path, a dcf file path, or a XML string which represent the datasource connection information) can also be used. For example, the input can be '/home/data/test.udb/imagedataset' when used a udb file path as connection information. 
                   When use the datasourse information, if the datasource which the connection information is already exists in the workspace, it will be directly obtained, otherwise, a new datasource object will be opened.
 
    :type source: DatasetGrid or DatasetImage or str
    :param float no_value: If the raster dataset and image dataset have NoData pixels, user can set a new value to represent them in the dataset by this prameter.
                           If this parameter is not None, the value set by the user will be used to replace the NoData grids or pixels in the returned DataFrame. 
                           The default is None, which means the NoData grids or pixels in the returned DataFrame will not change.
 
    :param bool origin_is_left_up: the position of (0,0) in the returned DataFrame or DataArray, the default is True.
                                   If it is True, the position of (0,0) means the upper left corner of the dataset, and DataFrame[i][j] is the i-th row and j-th column of the dataset.
                                   If it is False, the position of (0,0) means the lower left corner of the dataset, and DataFrame[i][j] is the (height-i) row j column of the dataset.
                                   
    :return: when the read dataset is a 2D array, returns a DataFrame; if the read dataset is a 3D array, return a 'xarray.DataArray'
    :rtype: pandas.DataFrame or xarray.DataArray
    """,
 
"iobjectspy.ml.utils.datasetraster_to_numpy_array" :"""
    Read data from raster dataset (DatasetGrid) or image dataset (DatasetImage) to a numpy array. 
    The number of columns in the array is the width of the dataset, and the number of rows is the height of the dataset.
    
     * If it is a single-band dataset, and it is not a RGB and RGBA pixel format, return a 2D array. The first dimension of the array is the row and the second dimension is the column.
     * If it is a single-band dataset in RGB and RGBA formate, return a 3D array. The first dimension of the array is the band and the size is 3 (for RGB pixel formate) or 4 (for RGBA formate), the second dimension is the row, and the third dimensions is column.
     * If it is a multispectral dataset, return a 3D array. The first dimension of the array is the band and the size is the number of bands, the second dimension is the row, and the third dimension is the column.
 
    :py:meth:`datasetraster_to_numpy_array` supports writing image datasets and raster datasets to a numpy ndarray. Image datasets can be multispectral images. 
    When writing out the image dataset:
 
     - If it is an image dataset in RGB or RGBA pixel format, it will be written as an 3D array, the first dimension of the array is 3 (RGB) or 4 (RGBA), the second dimension is the row , and the third dimension is the column.
     - If it is a single-band dataset, it will be written as an 2D array. The first dimension is the row and the second dimension is the column.
     - If the number of bands is greater than 1, a 3D array will be returned, where the first dimension is the band, the second dimension is the row, and the third dimension is the column.
 
    When writing out the multi-bands raster dataset, it will be written as a 2D array.
 
     - Read an RGB image dataset::
 
         >>> datasetraster_to_numpy_array(data_dir +'example_data.udb/seaport')
         >>> print(k_array.ndim)
         3
         >>> print(k_array.shape)
         (3, 1537, 1728)
         >>> print(k_array.dtype)
         uint8
         >>> print(k_array)
         [[[ 21 21 21 ... 192 194 191]
           [21 21 21 ... 191 192 190]
           [21 21 21 ... 190 192 193]
           ...
           [98 94 91 ... 31 31 29]
           [101 97 94 ... 30 30 29]
           [116 114 110 ... 24 24 24]]
 
          [[ 56 56 56 ... 196 198 195]
           [56 56 56 ... 195 196 194]
           [56 56 56 ... 194 196 197]
           ...
           [119 115 111 ... 25 25 26]
           [125 121 114 ... 24 24 26]
           [116 114 110 ... 24 24 24]]
 
          [[ 75 75 75 ... 179 181 181]
           [75 75 75 ... 178 179 180]
           [75 75 75 ... 177 179 183]
           ...
           [110 106 102 ... 35 35 33]
           [112 108 105 ... 34 34 33]
           [116 114 110 ... 24 24 24]]]
 
 
     - Read a raster dataset with pixel format BIT16::
 
        >>> datasetraster_to_numpy_array(data_dir +'example_data.udb/DEM')
        >>> print(k_array.ndim)
        2
        >>> print(k_array.shape)
        (4849, 5892)
        >>> print(k_array.dtype)
        int16
        >>> print(k_array)
        [[-32768 -32768 -32768 ... -32768 -32768 -32768]
         [-32768 -32768 -32768 ... -32768 -32768 -32768]
         [-32768 -32768 -32768 ... -32768 -32768 -32768]
         ...
         [-32768 -32768 -32768 ... -32768 -32768 -32768]
         [-32768 -32768 -32768 ... -32768 -32768 -32768]
         [-32768 -32768 -32768 ... -32768 -32768 -32768]]
 
    - In addition, it should be noted that the 'origin_is_left' parameter can specify whether the origin of the generated array (row 0, column 0) is the upper left corner or the lower left corner of the SuperMap raster dataset or image dataset.
      The raster dataset and image dataset in SuperMap defaults that Row 0 and column 0 is the upper left corner. The row number increases from top to bottom and the column number increase from the left to right ::
        
        [[(0,0),       (0,1),        (0,2), ...        (0, width-2),       (0, width-1)]
         [(1,0),       (1,1),        (1,2), ...        (1, width-2),       (1, width-1)]
         [(2,0),       (2,1),        (0,2), ...        (2, width-2),       (2, width-1)]
         ... ... ...
         [(height-2,0), (height-2,1), (height-2,2), ... (height-2, width-2), (height-2, width-1)]
         [(height-1,0), (height-1,1), (height-1,2), ... (height-1, width-2), (height-1, width-1)]]
 
      However, the 0th row and 0th column may be located in the lower left corner in other software, and the row increases when going up, and the column increases when going roght ::
 
        [(height-1,0), (height-1,1), (height-1,2), ... (height-1, width-2), (height-1, width-1)]]
        [(height-2,0), (height-2,1), (height-2,2), ... (height-2, width-2), (height-2, width-1)]
        ... ... ...
        [(2,0), (2,1), (0,2), ... (2, width-2), (2, width-1)]
        [(1,0), (1,1), (1,2), ... (1, width-2), (1, width-1)]
        [(0,0), (0,1), (0,2), ... (0, width-2), (0, width-1)]
 
      Therefore, the user can choose to use the upper left corner or the lower left corner as the origin of the array according to the specific usage.
 
 
    :param source: The raster dataset or image dataset to be read. If the input is a 'str', you can use datasource information plus the dataset name to represented the dataset. For example, the datasource alias can be used as 'alias/imagedataset'. 
                   And the datasource  connection information (a udb file path, a dcf file path, or a XML string which represent the datasource connection information) can also be used. For example, the input can be '/home/data/test.udb/imagedataset' when used a udb file path as connection information. 
                   When use the datasourse information, if the datasource which the connection information is already exists in the workspace, it will be directly obtained, otherwise, a new datasource object will be opened.
    :type source: DatasetGrid or DatasetImage or str
    :param float no_value: SuerpMapâ€™s raster dataset and image dataset have NoData pixels and the user can set a new value to represent them. 
                           If this parameter is not None, the value set by the user will be used to replace the NoData grids or pixels in the returned numpy array. 
                           The default is None, which means the NoData grids or pixels in the returned array will not be changed.                         
    :param bool origin_is_left_up: the position of (0,0) in the returned numpy array. The default is True. 
                                   If it is True, the position of (0,0) means the upper left corner of the dataset, and ndarray[i][j] is the i-th row and j-th column of the dataset,
                                   If it is False, the position of (0,0) means the lower left corner of the dataset, and ndarray[i][j] is the (height-i) row j column of the dataset.    
    :return: numpy multi-dimensional array
    :rtype: numpy.ndarray
    """,
 
"iobjectspy.ml.utils.datasetvector_to_df" :"""
    Write the vector dataset to pandas.DataFrame
 
    :param source: the vector dataset to be written to a 'pandas.Dataframe', supporting point, linear, surface, and attribute table datasets. Support the combination of datasource information and dataset name as input, such as'alias|point'.
    :type source: DatasetVector or str
    :param str attr_filter: attribute filter condition
    :param fields: fields that need to be wrote, if it is 'None', all non-system fields will be wrote.
    :type fields: list[str]
    :param is skip_null_value: whether to skip the records with null value. The integral type field does not supported null value in a DataFrame. If a integer field has null value, that field will be converted to floating-point. Therefore, if the field in the dataset contains null values, you need to fill them with a number. For floating-point fields, the null value is 'numpy.nan', for text (TEXT, WTEXT, CHAR, JSONB), it is an empty string, and for Boolean, binary, and time fields, it is None.
    :param null_values: the null value for the specified field. 'key' is the field name or field serial number, 'value' is a specified value to represent the null value. The 'value' type needs to match with the field type. For example, use 'null_values = {'ID': -9999}' to specify the null value of an integer field 'ID' as '-9999', 
    :type null_values: dict
    :return: Return a DataFrame object.
    :rtype: pandas.DataFrame
    """,
 
"iobjectspy.ml.utils.datasetvector_to_numpy_array" :"""
    Write the vector dataset to a numpy array
 
    :param source: the vector dataset to be written, supporting point, linear, surface, and attribute table datasets. Support the combination of datasource information and dataset name as input, such as'alias|point'.
    :type source: DatasetVector or str
    :param str attr_filter: attribute filter condition
    :param fields: fields that need to be wrote, if it is None, all non-system fields will be wrote.
    :type fields: list[str]
    :param bool export_spatial: whether export the spatial geometric objects. For point objects, write the points' X and Y coordinates into `SmX` and `SmY` fiels, and the points consist the linear and polygon objects will be written out to the `SmX` and `SmY` columns. Besides, linear objects will also have a `SmLength` field to represent the length of that line, and plygons will have `SmPerimeter` and `SmArea` field to show their perimeter and area.
    :param is skip_null_value: whether to skip records with null values. The integral type field does not supported null value in a numpy array. If a integer field has null value, that field will be converted to floating-point. Therefore, if the field in the dataset contains null values, you need to fill them with a number. For floating-point fields, the null value is 'numpy.nan', for text (TEXT, WTEXT, CHAR, JSONB), it is an empty string, and for Boolean, binary, and time fields, it is None.
    :param null_values: the null value for the specified field. 'key' is the field name or field serial number, 'value' is a specified value to represent the null value. The 'value' type needs to match with the field type. For example, use 'null_values = {'ID': -9999}' to specify the null value of an integer field 'ID' as '-9999', 
    :type null_values: dict
    :return: 1D arrary
    :rtype: numpy.ndarray
    """,
 
"iobjectspy.ml.utils.df_or_xarray_to_datasetraster" :"""
    Write the 'pandas.DataFrame', 'xarray.DataArray' or 'xarray.Dataset' to SuperMap raster dataset or image dataset. If it is a 'xarray.DataArray' or 'xarray.Dataset', you should install 'xarray' first.
 
    :param DataFrame data: the 'xarray.DataArray' or 'xarray.Dataset' to be written. Supports 2D and 3D numerical array. For a 3D array, it can only be written as an image dataset.
    :param float x_resolution: the resolution of the result dataset in the x direction 
    :param float y_resolution: the resolution of the result dataset in the y direction
    :param output: the output datasource object
    :type output: Datasource or DatasourceConnectionInfo or str
    :param float x_start: the X coordinate of the lower right corner
    :param float y_start: the Y coordinate of the lower right corner
    :param str out_dataset_name: the output dataset name
    :param float no_value: the specified value to represent the no_value. The default is -9999.
    :param bool origin_is_left_up: specify whether the 0th row and 0th column of the DataFrame is the upper left corner or the lower left corner of the raster dataset or image dataset.
    :param bool as_grid: whether to write as a : py:class:`DatasetGrid` dataset
    :return: the output dataset object or the dataset name.
    :rtype: DatasetGrid or DatasetImage or str
 
    """,
 
"iobjectspy.ml.utils.df_to_datasetvector" :"""
    Write pandas 'DataFrame' objects to a vector dataset
 
    :param df: the 'pandas DataFrame' object to be written
    :type df: pandas.DataFrame
    :param output: the output data source object
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: the output dataset name
    :param str x_col: the column where the X coordinats is located when writing to a point dataset. If it is empty, an attribute table dataset will be written.
    :param str y_col: the column where the Y coordinats is located when writing to a point dataset. If it is empty, an attribute table dataset will be written.
    :return: the output dataset object or dataset name.
    :rtype: DatasetVector or str
    """,
 
"iobjectspy.ml.utils.numpy_array_to_datasetraster" :"""
    Write the 'numpy' array to the SuperMap raster dataset or image dataset.
 
    Supports writing a 2D array or 3D array to an image dataset or raster dataset. The input can only be a 2D array if the output is a raster dataset. If the input is a 3D array and the output is a iamge dataset, the first dimension must be the band information, the second and third dimension must be the row and the column::
 
        >>> d = numpy.empty((100, 100), dtype='float32')
        >>> for i in range(100):
        ... for j in range(100):
        ... d[i][j] = i * j + i
        >>> iobjects.numpy_array_to_datasetraster(d, 0.1, 0.1, out_dir +'narray_out.udb', as_grid=True)
 
 
    :param numpy.ndarray narray: the numpy array to be written. It supports 2D numerical array or 3D numerical array. For a 3D array, it can only be written as an image dataset.
    :param float x_resolution: the resolution of the result dataset in the x direction
    :param float y_resolution: the resolution of the result dataset in the x direction
    :param output: the output datasource object
    :type output: Datasource or DatasourceConnectionInfo or str
    :param float x_start: the X coordinate of the lower right corner
    :param float y_start: the Y coordinate of the lower right corner
    :param str out_dataset_name: the output dataset name
    :param float no_value: the specified value to represent the no_value. The default is -9999.
    :param bool origin_is_left_up: specify whether the 0th row and 0th column of the DataFrame is the upper left corner or the lower left corner of the raster dataset or image dataset.
    :param bool as_grid: whether to write as a : py:class:`DatasetGrid` dataset
    :return: the output dataset object or the dataset name.
    :rtype: DatasetGrid or DatasetImage or str
    """,
 
"iobjectspy.ml.utils.numpy_array_to_datasetvector" :"""
    Write a 'numpy' array to a SuperMap vector dataset.
 
    Supports writing an 'ndarray' array containing 'dtype' information and column names into a SuperMap vector dataset. 
    It will be written to a point dataset, if the column names of the X and Y field are specified. Otherwise, it will be written to an attribute table dataset.
    Note that the 'ndarray' must contain column names before it can be written::
 
    >>> narray = np.empty(10, dtype=[('ID','int32'), ('X','float64'), ('Y','float64'), ('NAME', ' U10'), ('COUNT','int32')])
    >>> narray[0] = 1, 116.380351, 39.93393099,'Shichahai', 1023
    >>> narray[1] = 2, 116.365305, 39.89622499,'Guanganmen inner', 10
    >>> narray[2] = 3, 116.427342, 39.89467499,'Chongwenmenwai', 238
    >>> narray[3] = 4, 116.490881, 39.96567299,'jiuxianqiao', 1788
    >>> narray[4] = 5, 116.447486, 39.93767799,'Sanlitun', 8902
    >>> narray[5] = 6, 116.347435, 40.08078599,'Return to Dragon View', 903
    >>> narray[6] = 7, 116.407196, 39.83895899,'Big Red Gate', 88
    >>> narray[7] = 8, 116.396915, 39.88371499,'Skybridge', 5
    >>> narray[8] = 9, 116.334522, 40.03594199,'Qinghe', 77
    >>> narray[9] = 10, 116.03008, 39.87852799,'Tanzhe Temple', 1
    >>> result = numpy_array_to_datasetvector(narray, out_dir +'narray_out.udb', x_col='X', y_col='Y')
 
 
    :param numpy.ndarray narray: the 'numpy' array to be written
    :param output: the output datasource object
    :type output: Datasource or DatasourceConnectionInfo or str
    :param str out_dataset_name: the output dataset name
    :param str x_col: the column where the X coordinats is located when writing to a point dataset. If it is empty, an attribute table dataset will be written.
    :param str y_col: the column where the Y coordinats is located when writing to a point dataset. If it is empty, an attribute table dataset will be written.
    :return: The output dataset object or dataset name.
    :rtype: DatasetVector or str
    """,
 
"iobjectspy.ml.utils.recordset_to_df" :"""
    Write a record set to a 'pandas.DataFrame'. Supports write out the record sets of point, linear, surface, and attribute table dataset.
 
    :param Recordset recordset: the record set which the dataset has been write out.
    :param fields: name of the fields to be written out. If it is None, all non-system fields are written out
    :type fields: list[str]
    :param bool export_spatial: whether export the spatial geometric objects. For point objects, write the points' X and Y coordiantes into the `SmX` and `SmY` fiels, and the points consist the linear and polygon objects will be written out to the `SmX` and `SmY` columns. Besides, linear objects will also have a `SmLength` field to represent the length of that line, and the plygons will have `SmPerimeter` and `SmArea` field to show their perimeter and area.
    :param is skip_null_value: whether to skip records with null values. The integral type field does not supported null value in a DataFrame. If a integer field has null value, that field will be converted to floating-point. Therefore, if the field in the dataset contains null values, you need to fill them with a number. For floating-point fields, the null value is 'numpy.nan', for text (TEXT, WTEXT, CHAR, JSONB), it is an empty string, and for Boolean, binary, and time fields, it is None.
    :param null_values: the null value for the specified field. 'key' is the field name or field serial number, 'value' is a specified value to represent the null value. The 'value' type needs to match with the field type. For example, use 'null_values = {'ID': -9999}' to specify the null value of an integer field 'ID' as '-9999', 
    :type null_values: dict
    :return: Return a DataFrame object.
    :rtype: pandas.DataFrame
    """,
 
"iobjectspy.ml.utils.recordset_to_numpy_array" :"""
    Write out a record set to numpy.ndarray. Supports write out the record sets of point, linear, surface, and attribute table dataset.
 
    :py:meth:`recordset_to_numpy_array` and :py:meth:`datasetvector_to_numpy_array` are used to write vector data to 'ndarray'. 
    The output is a 1D array. Each element of the array contains multiple sub-elements. You can directly use the column name to get the column where the sub-item is located. For example, the vector data can be read directly by the following code:
 
        >>> narray = datasetvector_to_numpy_array(data_dir +'example_data.udb/Town_P', export_spatial=True)
        >>> print('ndarray.ndim: '+ str(narray.ndim))
        ndarray.ndim: 1
        >>> print('ndarray.dtype: '+ str(narray.dtype))
        ndarray.dtype: [('NAME','<U9'), ('SmX','<f8'), ('SmY','<f8')]
        >>> print(narray[:10])
        [('Baichigan Township', 115.917748, 39.53525099) ('Shichahai', 116.380351, 39.93393099)
         ('Yuetan', 116.344828, 39.91476099) ('Guanganmen inner', 116.365305, 39.89622499)
         ('Niujie', 116.36388, 39.88680299) ('Chongwenmenwai', 116.427342, 39.89467499)
         ('Outside Yongding Gate', 116.402249, 39.86559299) ('Cui Gezhuang', 116.515447, 39.99966499)
         ('Xiaoguan', 116.411727, 39.97737199) ('Panjiayuan', 116.467911, 39.87179299))
        >>> print(narray['SmX'][:10])
        [115.917748 116.380351 116.344828 116.365305 116.36388 116.427342
         116.402249 116.515447 116.411727 116.467911]
        >>> xy_array = np.c_[narray['SmX'], narray['SmY']][:10]
        >>> print(xy_array.ndim)
        2
        >>> print(xy_array.dtype)
        float64
        >>> print(xy_array)
        [[115.917748 39.53525099]
         [116.380351 39.93393099]
         [116.344828 39.91476099]
         [116.365305 39.89622499]
         [116.36388 39.88680299]
         [116.427342 39.89467499]
         [116.402249 39.86559299]
         [116.515447 39.99966499]
         [116.411727 39.97737199]
         [116.467911 39.87179299]]
 
    When writing the vector data, you can choose whether to write out the spatial information. 
    For point objects, the X coordiants and Y coordinats of the points will be written into the `SmX` and `SmY` columns. 
    For linear objects, the points consist of the line :py:meth:'GeoLine.get_inner_point' will be written to `SmX` and `SmY` column, and the lengthof that line will be written to `SmLength` field. 
    For a polygon object, write the inner point :py:meth:'GeoRegion.get_inner_point' to the `SmX` and `SmY` columns, and write the perimeter and area of that polygon to `SmPerimeter` and `SmArea` fields,
 
        >>> narray = datasetvector_to_numpy_array(data_dir +'example_data.udb/Landuse_R', export_spatial=True)
        >>> print(narray.dtype)
        [('LANDTYPE','<U4'), ('Area','<f4'), ('Area_1','<i2'), ('SmX','<f8'), ('SmY', '<f8'), ('SmPerimeter','<f8'), ('SmArea','<f8')]
        >>> print(narray[:10])
        [('Timber Forest', 132., 132, 116.47779337, 40.87251703, 0.75917921, 1.40894401e-02)
         ('Timber Forest', 97., 97, 116.6540059, 40.94696274, 0.4945153, 1.03534475e-02)
         ('Shrub', 36., 36, 116.58451795, 40.98712283, 0.25655489, 3.89923745e-03)
         ('Shrub', 36., 36, 116.89611418, 40.76792703, 0.59237713, 3.81791878e-03)
         ('Timber Forest', 1., 1, 116.37943683, 40.91435429, 0.03874328, 7.08450886e-05)
         ('Shrub', 126., 126, 116.49117083, 40.78302383, 0.53664074, 1.34577856e-02)
         ('Timber Forest', 83., 83, 116.69943237, 40.74456848, 0.39696365, 8.83225363e-03)
         ('Timber Forest', 128., 128, 116.8129727, 40.69116153, 0.56949408, 1.35877743e-02)
         ('Timber Forest', 29., 29, 116.24543769, 40.71076092, 0.30082509, 3.07221559e-03)
         ('Shrub', 467., 467, 116.43290772, 40.50875567, 1.91745792, 4.95537433e-02)]
 
 
    :param Recordset recordset: the record set of the dataset need to be written
    :param fields: name of the fields to be written out. If it is None, all non-system fields will be written out
    :type fields: list[str]
    :param bool export_spatial: whether export the spatial geometric objects. For point objects, write the points' X and Y coordinates into the `SmX` and `SmY` fiels, and the points consist the linear and polygon objects will be written out to the `SmX` and `SmY` columns. Besides, linear objects will also have a `SmLength` field to represent the length of that line, and the plygons will have `SmPerimeter` and `SmArea` field to show their perimeter and area.
    :param is skip_null_value: whether to skip records with null values. The integral type field does not supported null value in a numpy array. If a integer field has null value, that field will be converted to floating-point. Therefore, if the field in the dataset contains null values, you need to fill them with a number. For floating-point fields, the null value is 'numpy.nan', for text (TEXT, WTEXT, CHAR, JSONB), it is an empty string, and for Boolean, binary, and time fields, it is None.
    :param null_values: the null value for a specified field. 'key' is the field name or field serial number, 'value' is a specified value to represent the null value. The 'value' type needs to match with the field type. For example, use 'null_values = {'ID': -9999}' to specify the null value of an integer field 'ID' as '-9999', 
    :type null_values: dict
    :return: numpy array (1D array).
    :rtype: numpy.ndarray
    """,
 
"iobjectspy.ml.analyst._tabular" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_dataloader" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_dataloader.BaseDataloader" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_dataloader.BaseDataloader.load" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_estimater" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_estimater.BaseEstimater" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_estimater.BaseEstimater.estimate_file" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_estimater.BaseEstimater.estimate_line" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_trainer" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_trainer.BaseTrainer" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_trainer.BaseTrainer.find_best_params" :"""""",
 
"iobjectspy.ml.analyst._tabular.base.base_trainer.BaseTrainer.train" :"""""",
 
"iobjectspy.ml.analyst._tabular.base" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_data_loader" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_data_loader.ClsDataloader" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_data_loader.ClsDataloader.load" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_data_loader.create_cls_tabular_data" :"""
    Make training data
    :param input_data:
    :param label_class_field:
    :param output_path:
    :param output_name:
    :param class_count:
    :return:
    """,
 
"iobjectspy.ml.toolkit._tabular_utils" :"""""",
 
"iobjectspy.ml.toolkit._tabular_utils.f1_score" :"""
    Calculate the f1 score of the predict result
    :param truth_y: truth value
    :param predict_y: predicted value
    :param average: calculation method. Refers to 'sklearn', support 'micro' and 'macro' average as input
    :return: f1 value
    """,
 
"iobjectspy.ml.toolkit._tabular_utils.to_onehot_cls" :"""
    :param y: labels
    :param classes: list of categories
    :return: one_hot labels
    """,
 
"iobjectspy.ml.analyst._tabular.classification.cls_trainer" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_trainer.ClsTrainer" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_trainer.ClsTrainer.find_best_params" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_trainer.ClsTrainer.train" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_estimater" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_estimater.ClsEstimater" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_estimater.ClsEstimater.estimate_file" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification.cls_estimater.ClsEstimater.estimate_line" :"""""",
 
"iobjectspy.ml.analyst._tabular.classification" :"""""",
 
"iobjectspy.ml.analyst._datapreparation" :"""""",
 
"iobjectspy.ml.analyst._datapreparation.DataPreparation" :"""
    Table data preparation process entry
 
    """,
 
"iobjectspy.ml.analyst._datapreparation.DataPreparation.create_training_data" :"""
        Create training dataset for tabular data
 
        :param input_data: input data path, only supports 'csv'
        :param label_class_field: Name of the column where the label is located
        :param output_path: output path
        :param output_name: output file name
        :param training_data_format: Training data format to be produced
        :param kwargs: other additional parameters
        :return:
        """,
 
"iobjectspy.ml.analyst._inference" :"""""",
 
"iobjectspy.ml.analyst._inference.Inference" :"""""",
 
"iobjectspy.ml.analyst._inference.Inference.__init__" :"""
        Tabular data model inference initialization entry
 
        :param model_path: model storage path
        :type model_path: str
        """,
 
"iobjectspy.ml.analyst._inference.Inference.cls_tabular_infer" :"""
        Tabular data model inference function entrance
 
        :param input_data: input data path, only support 'csv'
        :param out_data: output data path, oinly support csv
        :param out_dataset_name: output file name
        :param kwargs: other parameters
        :return: (prediction result, output data path)
        """,
 
"iobjectspy.ml.analyst._trainer" :"""""",
 
"iobjectspy.ml.analyst._trainer.Trainer" :"""""",
 
"iobjectspy.ml.analyst._trainer.Trainer.__init__" :"""
        Tabular data training entrance
 
        :param train_data_path: training data path
        :param config: training configuration file
        :param lr: learning rate
        :param output_model_path: output model path
        :param output_model_name: output model name
        :param model_kwargs: additional model parameters
        :param kwargs: other parameters
        """,
 
"iobjectspy.ml.analyst._trainer.Trainer.tabular_cls_train" :"""
        Tabular data classification model training function
 
        The model will be stored under the 'output_model_path' you entered
 
        :return: None
        """,
 
"iobjectspy.ml.analyst" :"""""",
 
"iobjectspy.ml.geoparsing._ger" :"""""",
 
"iobjectspy.ml.geoparsing._ger.GER" :"""
    Geographic entity recognition category, including model training, label making, model inference and other functions.
    The background module framework supported is CRF++0.58
    """,
 
"iobjectspy.ml.geoparsing._ger.GER.gen_word_class" :"""
        Based on the given word and label, generate the corresponding entity category.
        This function merges the independent characters according to the label system such as BIES, and extracts the category extention information in the labels that correspond to the entities.
 
        :param words: input words
        :param tags: corresponding labels
        :return: return address entity and corresponding category
        """,
 
"iobjectspy.ml.geoparsing._ger.GER.load_config" :"""
        Read configuration information, the configuration information p0ath is provided by the member variable 'config_file'.
        """,
 
"iobjectspy.ml.geoparsing._ger.GER.parse" :"""
        Address text parsing function (single entry)
 
 
        :param str inputstr: address text to be parsed
        :param str model_path: model file path
        :param str extra_option: options near model analysis, the default is -v 3 -n2, please refer to the CRF++ manual
        :return: the geographic elements and label categories that parsed out.
        :rtype: dict
        """,
 
"iobjectspy.ml.geoparsing._ger.GER.parse_batch" :"""
        Batch analysis function
 
 
        :param in_data: input data, the first column by default contains multiple address texts to be parsed
        :type in_data: str or DatasetVector
        :param addr_field: the address field to be matched; when the input is a string, it means the field name; when the input is an integer, it means the column number to be parsed. The default is 0, which means the first column
        :param str model_path: model file path
        :param str out_name: the output dataset name, the default is 'result', which only takes effect when the output is 'Datasource'
        :param out_data: output data, can be a csv path, the datasource name, and the datasource path
        :type out_data: str or Datasource
        """,
 
"iobjectspy.ml.geoparsing._ger.GER.train" :"""
        Model training function
 
 
 
        :param str template: feature template file path
        :param str data: training data file path
        :param str model_path: model file path
 
        """,
 
"iobjectspy.ml.geoparsing._inference" :"""""",
 
"iobjectspy.ml.geoparsing._inference.Inference" :"""
    Prediction entry for related functions of geocoding tools
    
    """,
 
"iobjectspy.ml.geoparsing._inference.Inference.ger_infer" :"""
        Inference entry for address elements recognition. 
 
        :param input_data: input data
        :type input_data: str or dataset
        :param addr_field: field name or field index value of the address 
        :type addr_field: str or int
        :param model_path: model path
        :type model_path: str
        :param out_name: output file name
        :type out_name: str
        :param out_data: output file path or datasource
        :type out_data: str or datasource
        :return: None
        """,
 
"iobjectspy.ml.geoparsing" :"""""",
 
"iobjectspy.ml.spacetime._sample" :"""""",
 
"iobjectspy.ml.spacetime._sample.create_graph_st_adjmx" :"""""",
 
"iobjectspy.ml.spacetime._sample.create_graph_st_adjmx.CreateGraphST_AdjMX" :"""""",
 
"iobjectspy.ml.spacetime._sample.create_graph_st_adjmx.CreateGraphST_AdjMX.create_adj_matrix_pkl" :"""""",
 
"iobjectspy.ml.spacetime._sample.create_graph_st_regression_data" :"""""",
 
"iobjectspy.ml.spacetime._sample.create_graph_st_regression_data.CreateGraphST_RegressionData" :"""""",
 
"iobjectspy.ml.spacetime._sample.create_graph_st_regression_data.CreateGraphST_RegressionData.create_training_data" :"""""",
 
"iobjectspy.ml.spacetime._datapreparation" :"""""",
 
"iobjectspy.ml.spacetime._datapreparation.DataPreparation" :"""
    data preparation process entrance for graph spatial-temporal analysis 
    
    """,
 
"iobjectspy.ml.spacetime._datapreparation.DataPreparation.create_adj_mx": """ adjacency matrix generation
 
        :param input_pts_coords: input the point coordinates file
        :type input_pts_coords: str
        :param output_dir: output the directory for adjacency matrix
        :type output_dir: str
        :param id_col: index of the 'id' field, the default is "0"
        :type id_col: str
        :param long_col: index of the longitude field, the default is "1"
        :type long_col: str
        :param lat_col: index of the latitude field, the default is "2"
        :type lat_col: str
        :param dist_file: path of the distance information file, includes the 'from' node 'id' and 'to' node 'id'. And the distance between each 'from-to' pairs.
        :type dist_file: str
        """,
 
"iobjectspy.ml.spacetime._datapreparation.DataPreparation.create_training_data" :"""
        Training data generation
 
        :param input_data: path of the original tabular data, supports 'csv' format. Each column represents a sendort location, and each row represents a moment.
        :type input_data: str
        :param output_dir: output directory for training dataset, test dataset and other data.
        :type output_dir: str
        :param train_rate: the training dataset ratio, the default is 0.7
        :type train_rate: float
        :param test_rate: the test dataset ratio, default 0.2
        :type test_rate: float
        :param index_col: serial number of the 'time index' column, the default is "0"
        :type index_col: str or int
        :param period_len: length of the time period feature, the default is 3
        :type period_len: int
        :param step_rows: number of rows in a time step, the default is 12
        :type step_rows: int
        :param period_steps: number of time steps included in a time period, the default is 24
        :type period_steps: int
        :param period_units: time period unit, the default is "D", which means days
        :type period_units: str
        :param add_time_in_period: whether to add periodic features, the default is True
        :param add_time_in_period: bool
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.calculate_metrics" :"""
    Calculate the MAE, MAPE, RMSE
    :param df_pred:
    :param df_test:
    :param null_val:
    :return:
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.masked_mae_loss" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.masked_mae_np" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.masked_mae_torch" :"""
    Accuracy with masking.
    :param preds:
    :param labels:
    :param null_val:
    :return:
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.masked_mape_np" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.masked_mse_loss" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.masked_mse_np" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.masked_mse_torch" :"""
    Accuracy with masking.
    :param preds:
    :param labels:
    :param null_val:
    :return:
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.masked_rmse_loss" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.masked_rmse_np" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.metrics.masked_rmse_torch" :"""
    Accuracy with masking.
    :param preds:
    :param labels:
    :param null_val:
    :return:
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.model" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.DataLoader" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.DataLoader.__init__" :"""
 
        :param xs:
        :param ys:
        :param batch_size:
        :param pad_with_last_sample: pad with the last sample to make number of samples divisible to batch_size.
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.DataLoader.get_iterator" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.StandardScaler" :"""
    Standard the input
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.StandardScaler.inverse_transform" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.StandardScaler.transform" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.Timer" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.Timer.check" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.Timer.reset" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.calculate_normalized_laplacian" :"""
    # L = D^-1/2 (DA) D^-1/2 = I-D^-1/2 AD^-1/2
    # D = diag(A 1)
    :param adj:
    :return:
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.calculate_random_walk_matrix" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.calculate_reverse_random_walk_matrix" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.calculate_scaled_laplacian" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.config_logging" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.count_parameters" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.ensure_dir" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.get_logger" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.inf_loop" :"""
    wrapper function for endless data loader.
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.load_dataset" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.load_graph_data" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.load_pickle" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.read_json" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.read_yaml" :"""read_yaml. Read configuration file
    :param fname: the path of the configuration file
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.write_json" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.lib.utils.write_yaml" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.base.base_data_loader" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.base.base_data_loader.BaseDataLoader" :"""
    Base class for all data loaders
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.base.base_data_loader.BaseDataLoader.split_validation" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.base.base_model" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.base.base_model.BaseModel" :"""
    Base class for all models
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.base.base_model.BaseModel.__str__" :"""
        Model prints with number of trainable parameters
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn.base.base_model.BaseModel.forward" :"""
        Forward pass logic
 
        :return: Model output
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn.base.base_trainer" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.base.base_trainer.BaseTrainer" :"""
    Base class for all trainers
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.base.base_trainer.BaseTrainer.train" :"""
        Full training logic
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn.base" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_cell" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_cell.DCGRUCell" :"""
    Graph Convolution Gated Recurrent Unit Cell.
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_cell.DCGRUCell.__init__" :"""
        :param num_units: the hidden dim of rnn
        :param adj_mat: the (weighted) adjacency matrix of the graph, in numpy ndarray form
        :param max_diffusion_step: the max diffusion step
        :param num_nodes:
        :param num_proj: num of output dim, defaults to 1 (speed)
        :param activation: if None, don't do activation for cell state
        :param use_gc_for_ru: decide whether to use graph convolution inside rnn
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_cell.DCGRUCell.forward" :"""
        :param inputs: (B, num_nodes * input_dim)
        :param state: (B, num_nodes * num_units)
        :return:
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_cell.DCGRUCell.init_hidden" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_cell.DiffusionGraphConv" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_cell.DiffusionGraphConv.forward" :"""
        Diffusion Graph convolution with graph matrix
        :param inputs:
        :param state:
        :param output_size:
        :param bias_start:
        :return:
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_model" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_model.DCGRUDecoder" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_model.DCGRUDecoder.forward" :"""
        :param inputs: shape should be (seq_length+1, batch_size, num_nodes, input_dim)
        :param initial_hidden_state: the last hidden state of the encoder. (num_layers, batch, outdim)
        :param teacher_forcing_ratio:
        :return: outputs. (seq_length, batch_size, num_nodes*output_dim) (12, 50, 207*1)
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_model.DCRNNEncoder" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_model.DCRNNEncoder.forward" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_model.DCRNNEncoder.init_hidden" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_model.DCRNNModel" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.model.dcrnn_model.DCRNNModel.forward" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.logger.logger.output_dim" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.logger.logger.setup_logging" :"""
    Setup logging configuration
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.logger.visualization" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.logger.visualization.TensorboardWriter" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.logger.visualization.TensorboardWriter.__getattr__" :"""
        If visualization is configured to use:
            return add_data() methods of tensorboard with additional information (step, tag) added.
        Otherwise:
            return a blank function handle that does nothing
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn.logger.visualization.TensorboardWriter.set_step" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.logger" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.parse_config_yaml" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.parse_config_yaml.ConfigParser" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.parse_config_yaml.ConfigParser.get_logger" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.parse_config_yaml.ConfigParser.initialize" :"""
        finds a function handle with the name given as'type' in config, and returns the
        instance initialized with corresponding keyword args given as'args'.
        """,
 
"iobjectspy.ml.spacetime._models.dcrnn.trainer.dcrnn_trainer.save_dir" :"""""",
 
"iobjectspy.ml.spacetime._models.dcrnn.trainer.dcrnn_trainer.DCRNNTrainer" :"""
    DCRNN trainer class
    """,
 
"iobjectspy.ml.spacetime._models.dcrnn.trainer" :"""""",
 
"iobjectspy.ml.spacetime._models.torch_st_regression" :"""""",
 
"iobjectspy.ml.spacetime._models.torch_st_regression.GraphSTRegressionEstimation" :"""""",
 
"iobjectspy.ml.spacetime._models.torch_st_regression.GraphSTRegressionEstimation.estimate_dataset" :"""""",
 
"iobjectspy.ml.spacetime._models.torch_st_regression.GraphSTRegressionEstimation.estimate_datatable" :"""""",
 
"iobjectspy.ml.spacetime._models.torch_st_regression.GraphSTRegressionTrainer" :"""""",
 
"iobjectspy.ml.spacetime._models.torch_st_regression.GraphSTRegressionTrainer.train" :"""""",
 
"iobjectspy.ml.spacetime._models" :"""""",
 
"iobjectspy.ml.spacetime._trainer_collector.graph_st_regression_train" :"""""",
 
"iobjectspy.ml.spacetime._trainer_collector.graph_st_regression_train.GraphSTRegression" :"""""",
 
"iobjectspy.ml.spacetime._trainer_collector.graph_st_regression_train.GraphSTRegression.dcrnn_pytorch" :"""""",
 
"iobjectspy.ml.spacetime._trainer_collector.graph_st_regression_train.GraphSTRegression.train" :"""train.
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.spacetime._trainer_collector" :"""""",
 
"iobjectspy.ml.spacetime._trainer" :"""""",
 
"iobjectspy.ml.spacetime._trainer.Trainer" :"""""",
 
"iobjectspy.ml.spacetime._trainer.Trainer.__init__" :"""
        Entry of Deep Learning Training Function
 
        :param train_data_path: training data path
        :type train_data_path: str
        :param config: configuration file path
        :type config: str
        """,
 
"iobjectspy.ml.spacetime._trainer.Trainer.graphst_regression_train" :"""
        training function of graph space-time deep learning 
 
        The generated model will be stored in the 'output_model_path' you entered
 
        :return: None
        """,
 
"iobjectspy.ml.spacetime._inference_collector.graph_st_regression_inter" :"""""",
 
"iobjectspy.ml.spacetime._inference_collector.graph_st_regression_inter.GraphSTRegression" :"""""",
 
"iobjectspy.ml.spacetime._inference_collector.graph_st_regression_inter.GraphSTRegression.dcrnn_pytorch" :"""""",
 
"iobjectspy.ml.spacetime._inference_collector.graph_st_regression_inter.GraphSTRegression.infer" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.spacetime._inference_collector" :"""""",
 
"iobjectspy.ml.spacetime._inference" :"""""",
 
"iobjectspy.ml.spacetime._inference.Inference" :"""""",
 
"iobjectspy.ml.spacetime._inference.Inference.__init__" :"""
        Entrance of the graph spatio-temporal regression model inference
 
        :param input_data_dir: file directory where the data to be inferred
        :type input_data_dir: str
        :param model_path: model storage path
        :type model_path: str
        :param out_data: output file path
        :type out_data: str
        :param add_index_before: whether to automatically add a index field as the first column of the 'location_data' table when generate the prediction vector result. The default is 'False', indicating that the first column of location_data already has index information.
        :type add_index_before: bool
        :type location_data_path: str, data coordinate file which required to return the vector prediction results. The order of field names are [id field, observation location id, two fields in the 'fields_as_point']
        :type fields_as_point: (list[str] or list[int]) - Specify the X, Y fields to generate the point dataset, the default is [latitude, longitude]
        """,
 
"iobjectspy.ml.spacetime._inference.Inference.graph_st_regress_infer" :"""
        Traffic flow prediction based on graph spatial-temporal regression
 
        The input and output files are 'numpy' binary serialized files (*.npz)
 
        :param result_type: return result type
        :type result_type: list
        :return: if 'location_data_path' is provided, return the prediction result of the vector dataset, otherwise return the prediction result and GroundTruth list data
        
        """,
 
"iobjectspy.ml.spacetime" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.base_keras_models" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.base_keras_models.Estimation" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.base_keras_models.Estimation.close_model" :"""
        Close model
        :return:
        """,
 
"iobjectspy.ml.vision._models.semantic_seg.base_keras_models.Estimation.estimate_img" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.base_keras_models.Estimation.estimate_tile" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.base_keras_models.Estimation.load_model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.base_keras_models.Trainer" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.base_keras_models.Trainer.init_callbacks" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg.base_keras_models.Trainer.train" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.unet.blocks" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.unet.blocks.ConvRelu" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.unet.blocks.Transpose2D_block" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.unet.blocks.Upsample2D_block" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.unet.blocks.handle_block_names" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.utils" :""" Utility functions for segmentation models """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.utils.add_docstring" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.utils.extract_outputs" :"""
    Help extract intermediate layer outputs from model
    Args:
        model: Keras `Model`
        layer: list of integers/str, list of layers indexes or names to extract output
        include_top: bool, include final model layer output
 
    Returns:
        list of tensors (outputs)
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.utils.freeze_model" :"""""",

"iobjectspy.ml.toolkit._model_converter.freeze_model" :"""
    Convert the model generated by the training tool or the standard 'TensorFlow Saved Model' model into the 'Frozen Model'.
    
    Can be used on mobile terminal to do model inference.
    
    input can be 'sdm' file generated by 'model training' tool, or the 'Saved Model' folder.
    
    :param input_model_path: input the model generated by model training, or the 'Saved Model' folder path.
    :type input_model_path: str
    :param output_frozen_model_path: output file path
    :type output_frozen_model_path: str
    :param output_model_name: output model name
    :type output_model_name: str
    :param is_SDM: whether it is a model end with 'SDM'. The default is 'True' and it should be 'False' when the input is a 'Save Model' folder.
    :type is_sdm: bool
    :param output_node_names: The output node name of the input model, the default is None. If 'is_SDM' is True, this parameter is ineffective. If â€˜is_SDMâ€™ is False, this parameter is required.
    :type output_node_names: str
    :param saved_model_tags: Input model tag, default is None (optional)
    :type output_node_names: str
    :return: path to the Frozen Model generated. Failure is None.
    :rtype: str or None
    """,


"iobjectspy.ml.vision._models.semantic_seg._seg_models.utils.get_layer_number" :"""
    Help find layer in Keras model by name
    Args:
        model: Keras `Model`
        layer_name: str, name of layer
 
    Returns:
        index of layer
 
    Raises:
        ValueError: if model does not contains layer with such name
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.utils.recompile" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.utils.reverse" :"""Reverse list""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.utils.set_trainable" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.utils.to_tuple" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.unet.builder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.unet.builder.build_unet" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.preprocessing" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.preprocessing.preprocess_input" :"""input standardizing function
    Args:
        x: numpy.ndarray with shape (H, W, C)
        size: tuple (H_new, W_new), resized input shape
    Return:
        x: numpy.ndarray
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.params" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.params.get_bn_params" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.params.get_conv_params" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.blocks" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.blocks.basic_conv_block" :"""The identity block is the block that has no conv layer at shortcut.
    # Arguments
        input_tensor: input tensor
        kernel_size: default 3, the kernel size of
            middle conv layer at main path
        filters: list of integers, the filters of 3 conv layer at main path
        stage: integer, current stage label, used for generating layer names
        block:'a','b'..., current block label, used for generating layer names
    # Returns
        Output tensor for the block.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.blocks.basic_identity_block" :"""The identity block is the block that has no conv layer at shortcut.
    # Arguments
        kernel_size: default 3, the kernel size of
            middle conv layer at main path
        filters: list of integers, the filters of 3 conv layer at main path
        stage: integer, current stage label, used for generating layer names
        block:'a','b'..., current block label, used for generating layer names
    # Returns
        Output tensor for the block.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.blocks.conv_block" :"""The identity block is the block that has no conv layer at shortcut.
    # Arguments
        input_tensor: input tensor
        kernel_size: default 3, the kernel size of
            middle conv layer at main path
        filters: list of integers, the filters of 3 conv layer at main path
        stage: integer, current stage label, used for generating layer names
        block:'a','b'..., current block label, used for generating layer names
    # Returns
        Output tensor for the block.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.blocks.handle_block_names" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.blocks.identity_block" :"""The identity block is the block that has no conv layer at shortcut.
    # Arguments
        kernel_size: default 3, the kernel size of
            middle conv layer at main path
        filters: list of integers, the filters of 3 conv layer at main path
        stage: integer, current stage label, used for generating layer names
        block:'a','b'..., current block label, used for generating layer names
    # Returns
        Output tensor for the block.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.builder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.builder.build_resnet" :"""
    TODO
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.utils" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.utils.find_weights" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.utils.get_weights_default_path" :"""
 
    :param weights_collection:
    :param model_name:
    :param dataset:
    :param include_top:
    :return:
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.utils.load_efficient_model_weights" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.utils.load_model_weights" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.weights" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.models" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.models.ResNet101" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.models.ResNet152" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.models.ResNet18" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.models.ResNet34" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnet.models.ResNet50" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.preprocessing" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.preprocessing.preprocess_input" :"""input standardizing function
    Args:
        x: numpy.ndarray with shape (H, W, C)
        size: tuple (H_new, W_new), resized input shape
    Return:
        x: numpy.ndarray
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.params" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.params.get_bn_params" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.params.get_conv_params" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext. blocks" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.blocks.GroupConv2D" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.blocks.conv_block" :"""The conv block is the block that has conv layer at shortcut.
    # Arguments
        filters: integer, used for first and second conv layers, third conv layer double this value
        strides: tuple of integers, strides for conv (3x3) layer in block
        stage: integer, current stage label, used for generating layer names
        block: integer, current block label, used for generating layer names
    # Returns
        Output layer for the block.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.blocks.handle_block_names" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.blocks.identity_block" :"""The identity block is the block that has no conv layer at shortcut.
    # Arguments
        filters: integer, used for first and second conv layers, third conv layer double this value
        stage: integer, current stage label, used for generating layer names
        block: integer, current block label, used for generating layer names
    # Returns
        Output layer for the block.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.builder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.builder.build_resnext" :"""
    TODO
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.models" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.models.ResNeXt101" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.resnext.models.ResNeXt50" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.DropConnect" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.DropConnect.call" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.DropConnect.get_config" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.DropConnect.input" :"""Retrieves the input tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        ie if it is connected to one incoming layer.
 
        # Returns
            Input tensor or list of input tensors.
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.DropConnect.input_mask" :"""Retrieves the input mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        ie if it is connected to one incoming layer.
 
        # Returns
            Input mask tensor (potentially None) or list of input
            mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.DropConnect.input_shape" :"""Retrieves the input shape tuple(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        ie if it is connected to one incoming layer.
 
        # Returns
            Input shape tuple
            (or list of input shape tuples, one tuple per input tensor).
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.DropConnect.output" :"""Retrieves the output tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        ie if it is connected to one incoming layer.
 
        # Returns
            Output tensor or list of output tensors.
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.DropConnect.output_mask" :"""Retrieves the output mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        ie if it is connected to one incoming layer.
 
        # Returns
            Output mask tensor (potentially None) or list of output
            mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.DropConnect.output_shape" :"""Retrieves the output shape tuple(s) of a layer.
 
        Only applicable if the layer has one inbound node,
        or if all inbound nodes have the same output shape.
 
        # Returns
            Output shape tuple
            (or list of input shape tuples, one tuple per output tensor).
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.Swish" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.Swish.call" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.Swish.input" :"""Retrieves the input tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        ie if it is connected to one incoming layer.
 
        # Returns
            Input tensor or list of input tensors.
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.Swish.input_mask" :"""Retrieves the input mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        ie if it is connected to one incoming layer.
 
        # Returns
            Input mask tensor (potentially None) or list of input
            mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.Swish.input_shape" :"""Retrieves the input shape tuple(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        ie if it is connected to one incoming layer.
 
        # Returns
            Input shape tuple
            (or list of input shape tuples, one tuple per input tensor).
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.Swish.output" :"""Retrieves the output tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        ie if it is connected to one incoming layer.
 
        # Returns
            Output tensor or list of output tensors.
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.Swish.output_mask" :"""Retrieves the output mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        ie if it is connected to one incoming layer.
 
        # Returns
            Output mask tensor (potentially None) or list of output
            mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.layers.Swish.output_shape" :"""Retrieves the output shape tuple(s) of a layer.
 
        Only applicable if the layer has one inbound node,
        or if all inbound nodes have the same output shape.
 
        # Returns
            Output shape tuple
            (or list of input shape tuples, one tuple per output tensor).
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.weights" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockArgs" :"""BlockArgs(kernel_size, num_repeat, input_filters, output_filters, expand_ratio, id_skiratio, strides, se_ratio)""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockArgs.expand_ratio" :"""Alias for field number 4""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockArgs.id_skip" :"""Alias for field number 5""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockArgs.input_filters" :"""Alias for field number 2""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockArgs.kernel_size" :"""Alias for field number 0""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockArgs.num_repeat" :"""Alias for field number 1""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockArgs.output_filters" :"""Alias for field number 3""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockArgs.se_ratio" :"""Alias for field number 7""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockArgs.strides" :"""Alias for field number 6""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockDecoder" :"""Block Decoder for readability.""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockDecoder.decode" :"""Decodes a list of string notations to specify blocks inside the network.
 
    Args:
      string_list: a list of strings, each string is a notation of block.
 
    Returns:
      A list of namedtuples to represent blocks arguments.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.BlockDecoder.encode" :"""Encodes a list of Blocks to a list of strings.
 
    Args:
      blocks_args: A list of namedtuples to represent blocks arguments.
    Returns:
      a list of strings, each string is a notation of block.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.GlobalParams" :"""GlobalParams(batch_norm_momentum, batch_norm_epsilon, dropout_depth, data_format, epsilon, dropout_efficient, depth_coefficient, depth_coefficient, connect )""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.GlobalParams.batch_norm_epsilon" :"""Alias for field number 1""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.GlobalParams.batch_norm_momentum" :"""Alias for field number 0""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.p arams.GlobalParams.data_format" :"""Alias for field number 3""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.GlobalParams.depth_coefficient" :"""Alias for field number 6""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.GlobalParams.depth_divisor" :"""Alias for field number 7""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.GlobalParams.drop_connect_rate" :"""Alias for field number 9""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.GlobalParams.dropout_rate" :"""Alias for field number 2""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.GlobalParams.min_depth" :"""Alias for field number 8""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.GlobalParams.num_classes" :"""Alias for field number 4""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.GlobalParams.width_coefficient" :"""Alias for field number 5""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.efficientnet" :"""Creates a efficientnet model.""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.efficientnet_params" :"""Get efficientnet params based on model name.""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.params.get_model_params" :"""Get the block args and global params for a given model.""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.initializers" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.initializers.EfficientConv2DKernelInitializer" :"""Initialization for convolutional kernels.
 
    The main difference with tf.variance_scaling_initializer is that
    tf.variance_scaling_initializer uses a truncated normal with an uncorrected
    standard deviation, whereas here we use a normal distribution. Similarly,
    tf.contrib.layers.variance_scaling_initializer uses a truncated normal with
    a corrected standard deviation.
 
    Args:
      shape: shape of variable
      dtype: dtype of variable
      partition_info: unused
 
    Returns:
      an initialization for the variable
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.initializers.EfficientDenseKernelInitializer" :"""Initialization for dense kernels.
 
    This initialization is equal to
      tf.variance_scaling_initializer(scale=1.0/3.0, mode='fan_out',
                                      distribution='uniform').
    It is written out explicitly here for clarity.
 
    Args:
      shape: shape of variable
      dtype: dtype of variable
 
    Returns:
      an initialization for the variable
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.initializers.EfficientDenseKernelInitializer.__call__" :"""Initialization for dense kernels.
 
        This initialization is equal to
          tf.variance_scaling_initializer(scale=1.0/3.0, mode='fan_out',
                                          distribution='uniform').
        It is written out explicitly here for clarity.
 
        Args:
          shape: shape of variable
          dtype: dtype of variable
 
        Returns:
          an initialization for the variable
        """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model" :"""Contains definitions for EfficientNet model.
 
[1] Mingxing Tan, Quoc V. Le
  EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.
""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.EfficientNet" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.EfficientNetB0" :"""Re-Implementation of EfficientNet for Keras

    Args:
        input_shape: optional, if ``None`` default_input_shape is used
            EfficientNetB0-(224, 224, 3)
            EfficientNetB1-(240, 240, 3)
            EfficientNetB2-(260, 260, 3)
            EfficientNetB3-(300, 300, 3)
            EfficientNetB4-(380, 380, 3)
            EfficientNetB5-(456, 456, 3)
            EfficientNetB6-(528, 528, 3)
            EfficientNetB7-(600, 600, 3)
        include_top: whether to include the fully-connected
            layer at the top of the network.
        weights: one of `None` (random initialization),
              'imagenet' (pre-training on ImageNet).
        classes: optional number of classes to classify images
            into, only to be specified if `include_top` is True, and
            if no `weights` argument is specified.
 
    Returns:
        A Keras model instance.
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.EfficientNetB1" :"""Re-Implementation of EfficientNet for Keras

    Args:
        input_shape: optional, if ``None`` default_input_shape is used
            EfficientNetB0-(224, 224, 3)
            EfficientNetB1-(240, 240, 3)
            EfficientNetB2-(260, 260, 3)
            EfficientNetB3-(300, 300, 3)
            EfficientNetB4-(380, 380, 3)
            EfficientNetB5-(456, 456, 3)
            EfficientNetB6-(528, 528, 3)
            EfficientNetB7-(600, 600, 3)
        include_top: whether to include the fully-connected
            layer at the top of the network.
        weights: one of `None` (random initialization),
              'imagenet' (pre-training on ImageNet).
        classes: optional number of classes to classify images
            into, only to be specified if `include_top` is True, and
            if no `weights` argument is specified.
 
    Returns:
        A Keras model instance.
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.EfficientNetB2" :"""Re-Implementation of EfficientNet for Keras

    Args:
        input_shape: optional, if ``None`` default_input_shape is used
            EfficientNetB0-(224, 224, 3)
            EfficientNetB1-(240, 240, 3)
            EfficientNetB2-(260, 260, 3)
            EfficientNetB3-(300, 300, 3)
            EfficientNetB4-(380, 380, 3)
            EfficientNetB5-(456, 456, 3)
            EfficientNetB6-(528, 528, 3)
            EfficientNetB7-(600, 600, 3)
        include_top: whether to include the fully-connected
            layer at the top of the network.
        weights: one of `None` (random initialization),
              'imagenet' (pre-training on ImageNet).
        classes: optional number of classes to classify images
            into, only to be specified if `include_top` is True, and
            if no `weights` argument is specified.
 
    Returns:
        A Keras model instance.
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.EfficientNetB3" :"""Re-Implementation of EfficientNet for Keras

    Args:
        input_shape: optional, if ``None`` default_input_shape is used
            EfficientNetB0-(224, 224, 3)
            EfficientNetB1-(240, 240, 3)
            EfficientNetB2-(260, 260, 3)
            EfficientNetB3-(300, 300, 3)
            EfficientNetB4-(380, 380, 3)
            EfficientNetB5-(456, 456, 3)
            EfficientNetB6-(528, 528, 3)
            EfficientNetB7-(600, 600, 3)
        include_top: whether to include the fully-connected
            layer at the top of the network.
        weights: one of `None` (random initialization),
              'imagenet' (pre-training on ImageNet).
        classes: optional number of classes to classify images
            into, only to be specified if `include_top` is True, and
            if no `weights` argument is specified.
 
    Returns:
        A Keras model instance.
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.EfficientNetB4" :"""Re-Implementation of EfficientNet for Keras

    Args:
        input_shape: optional, if ``None`` default_input_shape is used
            EfficientNetB0-(224, 224, 3)
            EfficientNetB1-(240, 240, 3)
            EfficientNetB2-(260, 260, 3)
            EfficientNetB3-(300, 300, 3)
            EfficientNetB4-(380, 380, 3)
            EfficientNetB5-(456, 456, 3)
            EfficientNetB6-(528, 528, 3)
            EfficientNetB7-(600, 600, 3)
        include_top: whether to include the fully-connected
            layer at the top of the network.
        weights: one of `None` (random initialization),
              'imagenet' (pre-training on ImageNet).
        classes: optional number of classes to classify images
            into, only to be specified if `include_top` is True, and
            if no `weights` argument is specified.
 
    Returns:
        A Keras model instance.
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.EfficientNetB5" :"""Re-Implementation of EfficientNet for Keras

    Args:
        input_shape: optional, if ``None`` default_input_shape is used
            EfficientNetB0-(224, 224, 3)
            EfficientNetB1-(240, 240, 3)
            EfficientNetB2-(260, 260, 3)
            EfficientNetB3-(300, 300, 3)
            EfficientNetB4-(380, 380, 3)
            EfficientNetB5-(456, 456, 3)
            EfficientNetB6-(528, 528, 3)
            EfficientNetB7-(600, 600, 3)
        include_top: whether to include the fully-connected
            layer at the top of the network.
        weights: one of `None` (random initialization),
              'imagenet' (pre-training on ImageNet).
        classes: optional number of classes to classify images
            into, only to be specified if `include_top` is True, and
            if no `weights` argument is specified.
 
    Returns:
        A Keras model instance.
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.EfficientNetB6" :"""Re-Implementation of EfficientNet for Keras

    Args:
        input_shape: optional, if ``None`` default_input_shape is used
            EfficientNetB0-(224, 224, 3)
            EfficientNetB1-(240, 240, 3)
            EfficientNetB2-(260, 260, 3)
            EfficientNetB3-(300, 300, 3)
            EfficientNetB4-(380, 380, 3)
            EfficientNetB5-(456, 456, 3)
            EfficientNetB6-(528, 528, 3)
            EfficientNetB7-(600, 600, 3)
        include_top: whether to include the fully-connected
            layer at the top of the network.
        weights: one of `None` (random initialization),
              'imagenet' (pre-training on ImageNet).
        classes: optional number of classes to classify images
            into, only to be specified if `include_top` is True, and
            if no `weights` argument is specified.
 
    Returns:
        A Keras model instance.
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.EfficientNetB7" :"""Re-Implementation of EfficientNet for Keras

    Args:
        input_shape: optional, if ``None`` default_input_shape is used
            EfficientNetB0-(224, 224, 3)
            EfficientNetB1-(240, 240, 3)
            EfficientNetB2-(260, 260, 3)
            EfficientNetB3-(300, 300, 3)
            EfficientNetB4-(380, 380, 3)
            EfficientNetB5-(456, 456, 3)
            EfficientNetB6-(528, 528, 3)
            EfficientNetB7-(600, 600, 3)
        include_top: whether to include the fully-connected
            layer at the top of the network.
        weights: one of `None` (random initialization),
              'imagenet' (pre-training on ImageNet).
        classes: optional number of classes to classify images
            into, only to be specified if `include_top` is True, and
            if no `weights` argument is specified.
 
    Returns:
        A Keras model instance.
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.MBConvBlock" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.SEBlock" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.round_filters" :"""Round number of filters based on depth multiplier.""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.model.round_repeats" :"""Round number of filters based on depth multiplier.""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.preprocessing" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.preprocessing.center_crop_and_resize" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net.preprocessing.preprocess_input" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models.ef_net" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.cls_models.cls_models" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.inception_resnet_v2" :"""Inception-ResNet V2 model for Keras.
Model naming and structure follows TF-slim implementation (which has some additional
layers and different number of filters from the original arXiv paper):
https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_resnet_v2.py
Pre-trained ImageNet weights are also converted from TF-slim, which can be found in:
https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models
# Reference
-[Inception-v4, Inception-ResNet and the Impact of
   Residual Connections on Learning](https://arxiv.org/abs/1602.07261)
""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.inception_resnet_v2.InceptionResNetV2" :"""Instantiates the Inception-ResNet v2 architecture.
    Optionally loads weights pre-trained on ImageNet.
    Note that when using TensorFlow, for best performance you should
    set `"image_data_format": "channels_last"` in your Keras config
    at `~/.keras/keras.json`.
    The model and the weights are compatible with TensorFlow, Theano and
    CNTK backends. The data format convention used by the model is
    the one specified in your Keras config file.
    Note that the default input image size for this model is 299x299, instead
    of 224x224 as in the VGG16 and ResNet models. Also, the input preprocessing
    function is different (ie, do not use `imagenet_utils.preprocess_input()`
    with this model. Use `preprocess_input()` defined in this module instead).
    # Arguments
        include_top: whether to include the fully-connected
            layer at the top of the network.
        weights: one of `None` (random initialization),
              'imagenet' (pre-training on ImageNet),
              or the path to the weights file to be loaded.
        input_tensor: optional Keras tensor (ie output of `layers.Input()`)
            to use as image input for the model.
        input_shape: optional shape tuple, only to be specified
            if `include_top` is `False` (otherwise the input shape
            has to be `(299, 299, 3)` (with `'channels_last'` data format)
            or `(3, 299, 299)` (with `'channels_first'` data format).
            It should have exactly 3 inputs channels,
            and width and height should be no smaller than 139.
            Eg `(150, 150, 3)` would be one valid value.
        pooling: Optional pooling mode for feature binary_classification
            when `include_top` is `False`.
            -`None` means that the output of the model will be
                the 4D tensor output of the last convolutional layer.
            -`'avg'` means that global average pooling
                will be applied to the output of the
                last convolutional layer, and thus
                the output of the model will be a 2D tensor.
            -`'max'` means that global max pooling will be applied.
        classes: optional number of classes to classify images
            into, only to be specified if `include_top` is `True`, and
            if no `weights` argument is specified.
    # Returns
        A Keras `Model` instance.
    # Raises
        ValueError: in case of invalid argument for `weights`,
            or invalid input shape.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.inception_resnet_v2.conv2d_bn" :"""Utility function to apply conv + BN.
    # Arguments
        x: input tensor.
        filters: filters in `Conv2D`.
        kernel_size: kernel size as in `Conv2D`.
        strides: strides in `Conv2D`.
        padding: padding mode in `Conv2D`.
        activation: activation in `Conv2D`.
        use_bias: whether to use a bias in `Conv2D`.
        name: name of the ops; will become `name +'_ac'` for the activation
            and `name +'_bn'` for the batch norm layer.
    # Returns
        Output tensor after applying `Conv2D` and `BatchNormalization`.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.inception_resnet_v2.inception_resnet_block" :"""Adds a Inception-ResNet block.
    This function builds 3 types of Inception-ResNet blocks mentioned
    in the paper, controlled by the `block_type` argument (which is the
    block name used in the official TF-slim implementation):
        -Inception-ResNet-A: `block_type='block35'`
        -Inception-ResNet-B: `block_type='block17'`
        -Inception-ResNet-C: `block_type='block8'`
    # Arguments
        x: input tensor.
        scale: scaling factor to scale the residuals (ie, the output of
            passing `x` through an inception module) before adding them
            to the shortcut branch. Let `r` be the output from the residual branch,
            the output of this block will be `x + scale * r`.
        block_type: `'block35'`, `'block17'` or `'block8'`, determines
            the network structure in the residual branch.
        block_idx: an `int` used for generating layer names. The Inception-ResNet blocks
            are repeated many times in this network. We use `block_idx` to identify
            each of the repetitions. For example, the first Inception-ResNet-A block
            will have `block_type='block35', block_idx=0`, ane the layer names will have
            a common prefix `'block35_0'`.
        activation: activation function to use at the end of the block
            (see [activations](../activations.md)).
            When `activation=None`, no activation is applied
            (ie, "linear" activation: `a(x) = x`).
    # Returns
        Output tensor for the block.
    # Raises
        ValueError: if `block_type` is not one of `'block35'`,
            `'block17'` or `'block8'`.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.inception_resnet_v2.preprocess_input" :"""Preprocesses a numpy array encoding a batch of images.
    # Arguments
        x: a 4D numpy array consists of RGB values within [0, 255].
    # Returns
        Preprocessed array.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.inception_v3" :"""Inception V3 model for Keras.
Note that the input image format for this model is different than for
the VGG16 and ResNet models (299x299 instead of 224x224),
and that the input preprocessing function is also different (same as Xception).
""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.inception_v3.InceptionV3" :"""Instantiates the Inception v3 architecture.
    Optionally loads weights pre-trained
    on ImageNet. Note that when using TensorFlow,
    for best performance you should set
    `image_data_format='channels_last'` in your Keras config
    at ~/.keras/keras.json.
    The model and the weights are compatible with both
    TensorFlow and Theano. The data format
    convention used by the model is the one
    specified in your Keras config file.
    Note that the default input image size for this model is 299x299.
    # Arguments
        include_top: whether to include the fully-connected
            layer at the top of the network.
        weights: one of `None` (random initialization),
              'imagenet' (pre-training on ImageNet),
              or the path to the weights file to be loaded.
        input_tensor: optional Keras tensor (ie output of `layers.Input()`)
            to use as image input for the model.
        input_shape: optional shape tuple, only to be specified
            if `include_top` is False (otherwise the input shape
            has to be `(299, 299, 3)` (with `channels_last` data format)
            or `(3, 299, 299)` (with `channels_first` data format).
            It should have exactly 3 inputs channels,
            and width and height should be no smaller than 139.
            Eg `(150, 150, 3)` would be one valid value.
        pooling: Optional pooling mode for feature binary_classification
            when `include_top` is `False`.
            -`None` means that the output of the model will be
                the 4D tensor output of the
                last convolutional layer.
            -`avg` means that global average pooling
                will be applied to the output of the
                last convolutional layer, and thus
                the output of the model will be a 2D tensor.
            -`max` means that global max pooling will
                be applied.
        classes: optional number of classes to classify images
            into, only to be specified if `include_top` is True, and
            if no `weights` argument is specified.
    # Returns
        A Keras model instance.
    # Raises
        ValueError: in case of invalid argument for `weights`,
            or invalid input shape.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.inception_v3.conv2d_bn" :"""Utility function to apply conv + BN.
    # Arguments
        x: input tensor.
        filters: filters in `Conv2D`.
        num_row: height of the convolution kernel.
        num_col: width of the convolution kernel.
        padding: padding mode in `Conv2D`.
        strides: strides in `Conv2D`.
        name: name of the ops; will become `name +'_conv'`
            for the convolution and `name +'_bn'` for the
            batch norm layer.
    # Returns
        Output tensor after applying `Conv2D` and `BatchNormalization`.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.inception_v3.preprocess_input" :"""Preprocesses a numpy array encoding a batch of images.
    # Arguments
        x: a 4D numpy array consists of RGB values within [0, 255].
    # Returns
        Preprocessed array.
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.backbones" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.backbones.get_backbone" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.preprocessing" :"""
Image pre-processing functions.
Images are assumed to be read in uint8 format (range 0-255).
""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.preprocessing.<lambda>" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs.preprocessing.get_preprocessing" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.encs" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.unet.model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.unet.model.Unet" :"""
 
    Args:
        backbone_name: (str) look at list of available backbones.
        input_shape: (tuple) dimensions of input data (H, W, C)
        input_tensor: keras tensor
        encoder_weights: one of `None` (random initialization),'imagenet' (pre-training on ImageNet)
        freeze_encoder: (bool) Set encoder layers weights as non-trainable. Useful for fine-tuning
        skip_connections: if'default' is used take default skip connections,
            else provide a list of layer numbers or names starting from top of model
        decoder_block_type: (str) one of'upsampling' and'transpose' (look at blocks.py)
        decoder_filters: (int) number of convolution layer filters in decoder blocks
        decoder_use_batchnorm: (bool) if True add batch normalisation layer between `Conv2D` ad `Activation` layers
        n_upsample_blocks: (int) a number of upsampling blocks
        upsample_rates: (tuple of int) upsampling rates decoder blocks
        classes: (int) a number of classes for output
        activation: (str) one of keras activations for last model layer
 
    Returns:
        keras.models.Model instance
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.unet" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.change_net.builder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.change_net.builder.build_change_unet" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.change_net.model" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.change_net.model.ChangUNet" :"""
 
    Args:
        backbone_name: (str) look at list of available backbones.
        input_shape: (tuple) dimensions of input data (H, W, C)
        input_tensor: keras tensor
        encoder_weights: one of `None` (random initialization),'imagenet' (pre-training on ImageNet)
        freeze_encoder: (bool) Set encoder layers weights as non-trainable. Useful for fine-tuning
        skip_connections: if'default' is used take default skip connections,
            else provide a list of layer numbers or names starting from top of model
        decoder_block_type: (str) one of'upsampling' and'transpose' (look at blocks.py)
        decoder_filters: (int) number of convolution layer filters in decoder blocks
        decoder_use_batchnorm: (bool) if True add batch normalisation layer between `Conv2D` ad `Activation` layers
        n_upsample_blocks: (int) a number of upsampling blocks
        upsample_rates: (tuple of int) upsampling rates decoder blocks
        classes: (int) a number of classes for output
        activation: (str) one of keras activations for last model layer
 
    Returns:
        keras.models.Model instance
 
    """,
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.change_net" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.model_builder" :"""""",
 
"iobjectspy.ml.vision._models.semantic_seg._seg_models.model_builder.build_model" :"""
 
    :param width: input image width
    :param height: input image height
    :param depth: input image channel number
    :param classes: number of categories
    :param backbone_name: choose from 'vgg19', 'resnet50', 'resnext50'
    :param encoder_weights: str imagenet
    :param net_type: support 'unet', 'pspnet', 'linknet', 'fpn', and 'unetregression' will be supported soon
    :return: keras.model
    """,
 
"iobjectspy.ml.vision._models.image_classification.cls_models.model" :"""""",
 
"iobjectspy.ml.vision._models.image_classification.cls_models.model.ClassModel" :"""
 
    Args:
        backbone_name: (str) look at list of available backbones.
        input_shape: (tuple) dimensions of input data (H, W, C)
        input_tensor: keras tensor
        encoder_weights: one of `None` (random initialization),'imagenet' (pre-training on ImageNet)
        freeze_encoder: (bool) Set encoder layers weights as non-trainable. Useful for fine-tuning
        classes: (int) a number of classes for output
        activation: (str) one of keras activations for last model layer
 
    Returns:
        keras.models.Model instance
 
    """,
 
"iobjectspy.ml.vision._models.image_classification.cls_models.model.build_cls_model" :"""""",
 
"iobjectspy.ml.vision._models.image_classification.cls_models.builder" :"""""",
 
"iobjectspy.ml.vision._models.image_classification.cls_models.builder.build_model" :"""
 
    :param width: input image width
    :param height: input image height
    :param depth: input image channel number
    :param classes: number of categories
    :param backbone_name: choose from 'vgg19', 'resnet50', 'resnext50'
    :param encoder_weights: str imagenet
    :return: keras.model
    """,
 
"iobjectspy.ml.vision._models.image_classification.cls_models" :"""
 
""",
 
"iobjectspy.ml.vision._models.image_classification.keras_classification" :"""""",
 
"iobjectspy.ml.vision._models.image_classification.keras_classification.ClassificationEstimation" :"""""",
 
"iobjectspy.ml.vision._models.image_classification.keras_classification.ClassificationEstimation.close_model" :"""
        Close model
        :return:
        """,
 
"iobjectspy.ml.vision._models.image_classification.keras_classification.ClassificationEstimation.estimate_img" :"""""",
 
"iobjectspy.ml.vision._models.image_classification.keras_classification.ClassificationEstimation.estimate_tile" :"""""",
 
"iobjectspy.ml.vision._models.image_classification.keras_classification.ClassificationTrainer" :"""""",
 
"iobjectspy.ml.vision._models.image_classification.keras_classification.ClassificationTrainer.train" :"""""",
 
"iobjectspy.ml.vision._models.image_classification" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.image_classification_train" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.image_classification_train.ImageClassification" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.image_classification_train.ImageClassification.image_classification_keras" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.image_classification_train.ImageClassification.train" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'
        :return:
        """,
 
"iobjectspy.ml.vision._trainer_collector.object_detection_train" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.object_detection_train.ObjectDetection" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.object_detection_train.ObjectDetection.faster_rcnn_tensorflow" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.object_detection_train.ObjectDetection.ssd_pytorch" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.object_detection_train.ObjectDetection.train" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'
        :return:
        """,
 
"iobjectspy.ml.vision._trainer_collector.object_detection_train.ObjectDetection.yolo_keras" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification.cls_models.model" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification.cls_models.model.ClassModel" :"""
 
    Args:
        backbone_name: (str) look at list of available backbones.
        input_shape: (tuple) dimensions of input data (H, W, C)
        input_tensor: keras tensor
        encoder_weights: one of `None` (random initialization),'imagenet' (pre-training on ImageNet)
        freeze_encoder: (bool) Set encoder layers weights as non-trainable. Useful for fine-tuning
        classes: (int) a number of classes for output
        activation: (str) one of keras activations for last model layer
 
    Returns:
        keras.models.Model instance
 
    """,
 
"iobjectspy.ml.vision._models.scene_classification.cls_models.model.build_cls_model" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification.cls_models.builder" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification.cls_models.builder.build_model" :"""
 
    :param width: input image width
    :param height: input image height
    :param depth: channel number of the input image
    :param classes: number of categories
    :param backbone_name: choose from 'vgg19', 'resnet50', 'resnext50'
    :param encoder_weights: str imagenet
    :return: keras.model
    """,
 
"iobjectspy.ml.vision._models.scene_classification.cls_models" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification.keras_classification" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification.keras_classification.ClassificationEstimation" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification.keras_classification.ClassificationEstimation.close_model" :"""
        Close model
        :return:
        """,
 
"iobjectspy.ml.vision._models.scene_classification.keras_classification.ClassificationEstimation.estimate_img" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification.keras_classification.ClassificationEstimation.estimate_tile" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification.keras_classification.ClassificationTrainer" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification.keras_classification.ClassificationTrainer.train" :"""""",
 
"iobjectspy.ml.vision._models.scene_classification" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.scene_classification_train" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.scene_classification_train.SceneClassification" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.scene_classification_train.SceneClassification.image_classification_keras" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.scene_classification_train.SceneClassification.train" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'
        :return:
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.utils" :"""
Mask R-CNN
Common utility functions and classes.
Copyright (c) 2017 Matterport, Inc.
Licensed under the MIT License (see LICENSE for details)
Written by Waleed Abdulla
""",
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset" :"""
    
    The base class for dataset classes.
    
    To use it, create a new class that adds functions specific to the dataset. For example:
    
    class CatsAndDogsDataset(Dataset):
        def load_cats_and_dogs(self):
            ...
        def load_mask(self, image_id):
            ...
        def image_reference(self, image_id):
            ...
    See COCODataset and ShapesDataset as examples.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset.add_class" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset.add_image" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset.append_data" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset.get_source_class_id" :"""
    Map an internal class ID to the corresponding class ID in the source dataset.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset.image_reference" :"""
        Return the image link or image detail on its source Website that help looking it up or debugging it.
        It will override for your dataset, but it will pass to this function if the image is not in your dataset.
        """,






"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset.load_image" :"""
        Load the specified image and return a [H,W,3] Numpy array.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset.load_mask" :"""
        Load instance masks for the given image.
        Different datasets use different ways to store masks. Override this method to load instance masks and return them in an array of binary masks of shape [height, width, instances].
        Returns:
            masks: A bool array of shape [height, width, instance count] with a binary mask per instance.
            class_ids: a 1D array of class IDs of the instance masks.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset.map_source_class_id" :"""
        Takes a source class ID and returns the int class ID assigned to it. 
        For example: 
        dataset.map_source_class_id("coco.12") -> 23
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset.prepare" :"""
        Prepares the Dataset class for use.
        TODO: class map is not supported yet. When done, it should handle mapping classes from different datasets to the same class ID.
        """,





"iobjectspy.ml.vision._models.instance_segmentation.utils.Object_Extract_Dataset.source_image_link" :"""
        Returns the path or URL of the image. Override this to return a URL to the image if it's available online for easy debugging.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.analyze_xml" :"""
    Parse class and object location from the xml file
    :param file_name: xml file location
    :return: class, the box position of each category
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.apply_box_deltas" :"""
    Applies the given deltas to the given boxes.
    boxes: [N, (y1, x1, y2, x2)]. Note that (y2, x2) is outside the box.
    deltas: [N, (dy, dx, log(dh), log(dw))]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.batch_slice" :"""
    Splits inputs into slices and feeds each slice to a copy of the given computation graph and then combines the results. 
    It allows you to run a graph on a batch of inputs even if the graph is written to support one instance only.
    inputs: list of tensors. All must have the same first dimension length
    graph_fn: A function that returns a TF tensor that's part of a graph.
    batch_size: number of slices to divide the data into.
    names: if provided, assigns names to the resulting tensors.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.box_refinement" :"""
    Compute refinement needed to transform box to gt_box.
    box and gt_box are [N, (y1, x1, y2, x2)]. (y2, x2) is assumed to be outside the box.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.box_refinement_graph" :"""
    Compute refinement needed to transform box to gt_box.
    box and gt_box are [N, (y1, x1, y2, x2)]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.compute_ap" :"""
    Compute Average Precision at a set IoU threshold (default 0.5).
    Returns:
    mAP: Mean Average Precision
    precisions: List of precisions at different class score thresholds.
    recalls: List of recall values at different class score thresholds.
    overlaps: [pred_boxes, gt_boxes] IoU overlaps.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.compute_ap1" :"""
    Compute Average Precision at a set IoU threshold (default 0.5).
    Returns:
    mAP: Mean Average Precision
    precisions: List of precisions at different class score thresholds.
    recalls: List of recall values at different class score thresholds.
    overlaps: [pred_boxes, gt_boxes] IoU overlaps.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.compute_iou" :"""
    Calculates the IoU of a given box with the array of the given boxes.

    box: 1D vector [y1, x1, y2, x2]
    boxes: [boxes_count, (y1, x1, y2, x2)]
    box_area: float. the area of 'box'
    boxes_area: array of length boxes_count.
    Note: the areas are passed in rather than calculated here for efficency. Calculate once in the caller to avoid duplicate work.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.compute_matches" :"""
    Finds matches between prediction and ground truth instances.
 
    Returns:
        gt_match: 1-D array. For each GT box it has the index of the matched predicted box.
        pred_match: 1-D array. For each predicted box, it has the index of the matched ground truth box.
        overlaps: [pred_boxes, gt_boxes] IoU overlaps.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.compute_overlaps" :"""
    Computes IoU overlaps between two sets of boxes.
    boxes1, boxes2: [N, (y1, x1, y2, x2)].
    For better performance, pass the largest set first and the smaller second.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.compute_overlaps_masks" :"""
    Computes IoU overlaps between two sets of masks.
    masks1, masks2: [Height, Width, instances]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.compute_recall" :"""
    Compute the recall at the given IoU threshold. It's an indication of how many GT boxes were found by the given prediction boxes.
    pred_boxes: [N, (y1, x1, y2, x2)] in image coordinates
    gt_boxes: [N, (y1, x1, y2, x2)] in image coordinates
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.create_sda_voc_mask" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.expand_mask" :"""
    Resizes mini masks back to image size. Reverses the change of minimize_mask().
    See inspect_data.ipynb notebook for more details.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.extract_bboxes" :"""
    Compute bounding boxes from the masks.
    mask: [height, width, num_instances]. Mask pixels are either 1 or 0.
    Returns: bbox array [num_instances, (y1, x1, y2, x2)].
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.generate_anchors" :"""
    scales: 1D array of anchor sizes in pixels. Example: [32, 64, 128]
    ratios: 1D array of anchor ratios of width/height. Example: [0.5, 1, 2]
    shape: [height, width] spatial shape of the feature map over which to generate anchors.
    feature_stride: Stride of the feature map relative to the image in pixels.
    anchor_stride: Stride of anchors on the feature map. For example, if the value is 2 then generate anchors for every other feature map pixel.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.generate_pyramid_anchors" :"""
    Generate anchors at different levels of a feature pyramid. 
    Each scale is associated with a level of the pyramid, but each ratio is used in all levels of the pyramid.
    Returns:
    anchors: [N, (y1, x1, y2, x2)]. All generated anchors in one array. 
    Sorted with the same order of the given scales. So, anchors of scale[0] come first, then anchors of scale[1], and so on.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.get_mosaic_data" :"""
    Random preprocessing for real-time data augmentation
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.get_rgb" :"""
    Get RGB color
   :param v: hexadecimal color code
   :return: RGB color value
       """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.merge_bboxes" :"""
    For the bbox synthesized into the new image, a part that exceeds cutx, y, and the width and height of the new image is deleted or modified. And the bbox that is not less than the specified proportion of the original area is retained
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.minimize_mask" :"""
    Resize masks to a smaller version to cut memory load.
    Mini-masks can then resized back to image scale using expand_masks()
    See inspect_data.ipynb notebook for more details.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.mold_mask" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.non_max_suppression" :"""
    Performs non-maximum supression and returns indicies of kept boxes.
    boxes: [N, (y1, x1, y2, x2)]. Notice that (y2, x2) lays outside the box.
    scores: 1D array of box scores.
    threshold: Float. IoU threshold to use for filtering.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.rand" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.resize_image" :"""
    Resizes an image keeping the aspect ratio.
    min_dim: if provided, resizes the image such that it's smaller dimension == min_dim
    max_dim: if provided, ensures that the image longest side doesn't exceed this value.
    padding: If true, pads image with zeros so it's size is max_dim x max_dim
    Returns:
    image: the resized image
    window: (y1, x1, y2, x2). If max_dim is provided, padding might be inserted in the returned image. If so, this window is the coordinates of the image part of the full image (excluding the padding). The x2, y2 pixels are not included.
    scale: The scale factor used to resize the image
    padding: Padding added to the image [(top, bottom), (left, right), (0, 0)]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.resize_mask" :"""
    Resizes a mask using the given scale and padding.
    Typically, you get the scale and padding from resize_image() to ensure both, the image and the mask, are resized consistently.
    scale: mask scaling factor
    padding: Padding to add to the mask in the form [(top, bottom), (left, right), (0, 0)]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.show_two_image" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.trim_zeros" :"""
    It's common to have tensors larger than the available data and pad with zeros. This function removes rows that are all zeros.
    x: [rows, columns].
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.utils.unmold_mask" :"""
    Converts a mask generated by the neural network into a format similar to it's original shape.
    mask: [height, width] of type float. A small, typically 28x28 mask.
    bbox: [y1, x1, y2, x2]. The box to fit the mask in.
    Returns a binary mask with the same size as the original image.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model" :"""
    Mask R-CNN
    The main Mask R-CNN model implemenetation.
    Copyright (c) 2017 Matterport, Inc.
    Licensed under the MIT License (see LICENSE for details)
    Written by Waleed Abdulla
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.BatchNorm" :"""
    Batch Normalization class. Subclasses the Keras BN class and hardcodes training=False so the BN layer doesn't update during training.
    Batch normalization has a negative effect on training if batches are small so we disable it here.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.BatchNorm.call" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.BatchNorm.input" :"""
    Retrieves the input tensor(s) of a layer.
 
    Only applicable if the layer has exactly one inbound node,i.e. if it is connected to one incoming layer.
 
    # Returns
        Input tensor or list of input tensors.
 
    # Raises
        AttributeError: if the layer is connected to
        more than one incoming layers.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.BatchNorm.input_mask" :"""
        Retrieves the input mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input mask tensor (potentially None) or list of input mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.BatchNorm.input_shape" :"""
        Retrieves the input shape tuple(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node, i.e. if it is connected to one incoming layer.
 
        # Returns
            Input shape tuple (or list of input shape tuples, one tuple per input tensor).
 
        # Raises
            AttributeError: if the layer is connected to
            more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.BatchNorm.output" :"""
        Retrieves the output tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Output tensor or list of output tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.BatchNorm.output_mask" :"""
        Retrieves the output mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Output mask tensor (potentially None) or list of output mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.BatchNorm.output_shape" :"""
        Retrieves the output shape tuple(s) of a layer.
        Only applicable if the layer has one inbound node, or if all inbound nodes have the same output shape.
 
        # Returns
            Output shape tuple (or list of input shape tuples, one tuple per output tensor).
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionLayer" :"""
    Takes classified proposal boxes and their bounding box deltas and returns the final detection boxes.
    Returns:
    [batch, num_detections, (y1, x1, y2, x2, class_id, class_score)] where coordinates are in image domain
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionLayer.call" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionLayer.compute_output_shape" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionLayer.input" :"""
        Retrieves the input tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input tensor or list of input tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionLayer.input_mask" :"""
        Retrieves the input mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input mask tensor (potentially None) or list of input mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionLayer.input_shape" :"""
        Retrieves the input shape tuple(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input shape tuple (or list of input shape tuples, one tuple per input tensor).
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionLayer.output" :"""
        Retrieves the output tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Output tensor or list of output tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionLayer.output_mask" :"""
        Retrieves the output mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Output mask tensor (potentially None) or list of output mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionLayer.output_shape" :"""
        Retrieves the output shape tuple(s) of a layer.
 
        Only applicable if the layer has one inbound node, or if all inbound nodes have the same output shape.
 
        # Returns
            Output shape tuple (or list of input shape tuples, one tuple per output tensor).
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionTargetLayer" :"""
    Subsamples proposals and generates target box refinement, class_ids, and masks for each.
    Inputs:
    proposals: [batch, N, (y1, x1, y2, x2)] in normalized coordinates. Might be zero padded if there are not enough proposals.
    gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs.
    gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)] in normalized coordinates.
    gt_masks: [batch, height, width, MAX_GT_INSTANCES] of boolean type
    Returns: Target ROIs and corresponding class IDs, bounding box shifts, and masks.
    rois: [batch, TRAIN_ROIS_PER_IMAGE, (y1, x1, y2, x2)] in normalized coordinates
    target_class_ids: [batch, TRAIN_ROIS_PER_IMAGE]. Integer class IDs.
    target_deltas: [batch, TRAIN_ROIS_PER_IMAGE, NUM_CLASSES, (dy, dx, log(dh), log(dw), class_id)]
                   Class-specific bbox refinements.
    target_mask: [batch, TRAIN_ROIS_PER_IMAGE, height, width)
                 Masks cropped to bbox boundaries and resized to neural network output size.
    Note: Returned arrays might be zero padded if not enough target ROIs.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionTargetLayer.call" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionTargetLayer.compute_mask" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionTargetLayer.compute_output_shape" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionTargetLayer.input" :"""
        Retrieves the input tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input tensor or list of input tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionTargetLayer.input_mask" :"""
        Retrieves the input mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input mask tensor (potentially None) or list of input mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionTargetLayer.input_shape" :"""
        Retrieves the input shape tuple(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input shape tuple (or list of input shape tuples, one tuple per input tensor).
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionTargetLayer.output" :"""
        Retrieves the output tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Output tensor or list of output tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionTargetLayer.output_mask" :"""
        Retrieves the output mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Output mask tensor (potentially None) or list of output mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.DetectionTargetLayer.output_shape" :"""
        Retrieves the output shape tuple(s) of a layer.
 
        Only applicable if the layer has one inbound node, or if all inbound nodes have the same output shape.
 
        # Returns
            Output shape tuple (or list of input shape tuples, one tuple per output tensor).
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN" :"""
    Encapsulates the Mask RCNN model functionality. The actual Keras model is in the keras_model property.
    """,



"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.Squeeze_Attention_Block" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.__init__" :"""
        mode: choose from "training" or "inference" 
        config: a Sub-class of the Config class
        model_dir: directory to save training logs and trained weights
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.ancestor" :"""
        Finds the ancestor of a TF tensor in the computation graph.
        tensor: TensorFlow symbolic tensor.
        name: Name of ancestor tensor to find
        checked: For internal use. A list of tensors that were already searched to avoid loops in traversing the graph.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.build" :"""
        Build Mask R-CNN architecture.
            input_shape: The shape of the input image. 
            mode: "training" or "inference" corresponds to different model input and output
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.compile" :"""
    Gets the model ready for training. Adds losses, regularization, and metrics. Then calls the Keras compile() function.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.detect" :"""
        MaskRCNNRuns the detection pipeline.
        Return a list of dictionaries, one dictionary per image. The dictionary contains:
        rois: [N, (y1, x1, y2, x2)] detection bounding boxes
        class_ids: [N] int class IDs
        scores: [N] float probability scores for the class IDs
        masks: [H, W, N] instance binary masks
        """,



"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.find_last" :"""
        Finds the last checkpoint file of the last trained model in the model directory.
        Returns:
            log_dir: The directory where events and weights are saved
            checkpoint_path: the path to the last checkpoint file
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.find_trainable_layer" :"""
        If a layer is encapsulated by another layer, this function digs through the encapsulation and returns the layer that holds the weights.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.get_imagenet_weights" :"""
        Downloads ImageNet trained weights from Keras.
        Returns path to weights file.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.get_trainable_layers" :"""
        Returns a list of layers that have weights.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.load_optimizer_state ":"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.load_weights" :"""
        Modified version of the correspoding Keras function with the addition of multi-GPU support and the ability to exclude some layers from loading.
        exlude: list of layer names to excluce
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.mold_inputs" :"""
        Takes a list of images and modifies them to the format expected as an input to the neural network.
        images: List of image matricies [height,width,depth]. Images can have different sizes.
        Returns 3 Numpy matricies:
        molded_images: [N, h, w, 3]. Images resized and normalized.
        image_metas: [N, length of meta data]. Details about each image.
        windows: [N, (y1, x1, y2, x2)]. The portion of the image that has the original image (padding excluded).
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.run_graph" :"""
        Runs a sub-set of the computation graph that computes the given outputs.
        outputs: List of tuples (name, tensor) to compute. The tensors are symbolic TensorFlow tensors and the names are for easy tracking.
        Returns an ordered dict of results. Keys are the names received in the input and values are Numpy arrays.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.set_log_dir" :"""
        Sets the model log directory and epoch counter. 
        model_path: If None, or a format different from what this code uses then set a new log directory and start epochs from 0. Otherwise, extract the log directory and the epoch counter from the file name.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.set_trainable" :"""
    Sets model layers as trainable if their names match the given regular expression.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.train" :"""
        Train the model.
        train_dataset, val_dataset: Training and validation Dataset objects.
        learning_rate: The learning rate to train with
        epochs: Number of training epochs. Note that previous training epochs are considered to be done alreay, so this actually determines the epochs to train in total rather than in this particaular call.
        layers: Allows selecting wich layers to train. It can be:
            - A regular expression to match layer names to train
            - One of these predefined values:
              heads: The RPN, classifier and mask heads of the network
              all: All the layers
              3+: Train Resnet stage 3 and up
              4+: Train Resnet stage 4 and up
              5+: Train Resnet stage 5 and up
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.MaskRCNN.unmold_detections" :"""
        Reformats the detections of one image from the format of the neural network output to a format suitable for use in the rest of the application.
        detections: [N, (y1, x1, y2, x2, class_id, score)]
        mrcnn_mask: [N, height, width, num_classes]
        image_shape: [height, width, depth] Original size of the image before resizing
        window: [y1, x1, y2, x2] Box in the image where the real image is excluding the padding.
        Returns:
        boxes: [N, (y1, x1, y2, x2)] Bounding boxes in pixels_thre
        class_ids: [N] Integer class IDs for each bounding box
        scores: [N] Float probability scores of the class_id
        masks: [height, width, num_instances] Instance masks
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ModelCheckpoint_edit" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ModelCheckpoint_edit.on_epoch_end" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ProposalLayer" :"""
    Receives anchor scores and selects a subset to pass as proposal to the second stage. Filtering is done based on anchor scores and non-max suppression to remove overlaps. It also applies bounding box refinement deltas to anchors.
    Inputs:
        rpn_probs: [batch, anchors, (bg prob, fg prob)]
        rpn_bbox: [batch, anchors, (dy, dx, log(dh), log(dw))]
    Returns:
        Proposals in normalized coordinates [batch, rois, (y1, x1, y2, x2)]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ProposalLayer.__init__" :"""
        anchors: [N, (y1, x1, y2, x2)] anchors defined in image coordinates
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ProposalLayer.call" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ProposalLayer.compute_output_shape" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ProposalLayer.input" :"""
        Retrieves the input tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input tensor or list of input tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ProposalLayer.input_mask" :"""
        Retrieves the input mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input mask tensor (potentially None) or list of input mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ProposalLayer.input_shape" :"""
        Retrieves the input shape tuple(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input shape tuple (or list of input shape tuples, one tuple per input tensor).
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ProposalLayer.output" :"""
        Retrieves the output tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Output tensor or list of output tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
            """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ProposalLayer.output_mask" :"""
        Retrieves the output mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Output mask tensor (potentially None) or list of output mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.ProposalLayer.output_shape" :"""
        Retrieves the output shape tuple(s) of a layer.
 
        Only applicable if the layer has one inbound node, or if all inbound nodes have the same output shape.
 
        # Returns
            Output shape tuple (or list of input shape tuples, one tuple per output tensor).
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.PyramidROIAlign" :"""
    Implements ROI Pooling on multiple levels of the feature pyramid.
    Params:
    -pool_shape: [height, width] of the output pooled regions. Usually [7, 7]
    -image_shape: [height, width, channels]. Shape of input image in pixels
    Inputs:
    -boxes: [batch, num_boxes, (y1, x1, y2, x2)] in normalized coordinates. Possibly padded with zeros if not enough boxes to fill the array.
    -Feature maps: List of feature maps from different levels of the pyramid. Each is [batch, height, width, channels]
    Output:
    Pooled regions in the shape: [batch, num_boxes, height, width, channels]. The width and height are those specific in the pool_shape in the layer constructor.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.PyramidROIAlign.call" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.PyramidROIAlign.compute_output_shape" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.PyramidROIAlign.input" :"""
        Retrieves the input tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input tensor or list of input tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.PyramidROIAlign.input_mask" :"""
        Retrieves the input mask tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input mask tensor (potentially None) or list of inputmask tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.PyramidROIAlign.input_shape" :"""
        Retrieves the input shape tuple(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Input shape tuple (or list of input shape tuples, one tuple per input tensor).
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.PyramidROIAlign.output" :"""
        Retrieves the output tensor(s) of a layer.
 
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Output tensor or list of output tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.PyramidROIAlign.output_mask" :"""
        Retrieves the output mask tensor(s) of a layer.
        
        Only applicable if the layer has exactly one inbound node,
        i.e. if it is connected to one incoming layer.
 
        # Returns
            Output mask tensor (potentially None) or list of output mask tensors.
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.PyramidROIAlign.output_shape" :"""
        Retrieves the output shape tuple(s) of a layer.
 
        Only applicable if the layer has one inbound node, or if all inbound nodes have the same output shape.
 
        # Returns
            Output shape tuple (or list of input shape tuples, one tuple per output tensor).
 
        # Raises
            AttributeError: if the layer is connected to more than one incoming layers.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.apply_box_deltas_graph" :"""
    Applies the given deltas to the given boxes.
    boxes: [N, 4] where each row is y1, x1, y2, x2
    deltas: [N, 4] where each row is [dy, dx, log(dh), log(dw)]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.batch_pack_graph" :"""
    Picks different number of values from each row in x depending on the values in counts.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.build_detection_targets" :"""
    Generate targets for training Stage 2 classifier and mask heads. This is not used in normal training. It's useful for debugging or to train the Mask RCNN heads without using the RPN head.
    Inputs:
    rpn_rois: [N, (y1, x1, y2, x2)] proposal boxes.
    gt_class_ids: [instance count] Integer class IDs
    gt_boxes: [instance count, (y1, x1, y2, x2)]
    gt_masks: [height, width, instance count] Grund truth masks. Can be full size or mini-masks.
    Returns:
    rois: [TRAIN_ROIS_PER_IMAGE, (y1, x1, y2, x2)]
    class_ids: [TRAIN_ROIS_PER_IMAGE]. Integer class IDs.
    bboxes: [TRAIN_ROIS_PER_IMAGE, NUM_CLASSES, (y, x, log(h), log(w))]. Class-specific bbox refinements.
    masks: [TRAIN_ROIS_PER_IMAGE, height, width, NUM_CLASSES). Class specific masks cropped to bbox boundaries and resized to neural network output size.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.build_fpn_mask_graph" :"""
    Builds the computation graph of the mask head of Feature Pyramid Network.
    rois: [batch, num_rois, (y1, x1, y2, x2)] Proposal boxes in normalized coordinates.
    feature_maps: List of feature maps from diffent layers of the pyramid, [P2, P3, P4, P5]. Each has a different resolution.
    image_shape: [height, width, depth]
    pool_size: The width of the square feature map generated from ROI Pooling.
    num_classes: number of classes, which determines the depth of the results
    Returns: Masks [batch, roi_count, height, width, num_classes]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.build_rpn_model" :"""
    Builds a Keras model of the Region Proposal Network. It wraps the RPN graph so it can be used multiple times with shared weights.
    anchors_per_location: number of anchors per pixel in the feature map
    anchor_stride: Controls the density of anchors. Typically 1 (anchors for every pixel in the feature map), or 2 (every other pixel).
    depth: Depth of the backbone feature map.
    Returns a Keras Model object. The model outputs, when called, are:
    rpn_logits: [batch, H, W, 2] Anchor classifier logits (before softmax)
    rpn_probs: [batch, W, W, 2] Anchor classifier probabilities.
    rpn_bbox: [batch, H, W, (dy, dx, log(dh), log(dw))] Deltas to be applied to anchors.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.build_rpn_targets" :"""
    Given the anchors and GT boxes, compute overlaps and identify positive anchors and deltas to refine them to match their corresponding GT boxes.
    anchors: [num_anchors, (y1, x1, y2, x2)]
    gt_class_ids: [num_gt_boxes] Integer class IDs.
    gt_boxes: [num_gt_boxes, (y1, x1, y2, x2)]
    Returns:
    rpn_match: [N] (int32) matches between anchors and GT boxes. 1 = positive anchor, -1 = negative anchor, 0 = neutral
    rpn_bbox: [N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.clip_boxes_graph" :"""
    boxes: [N, 4] each row is y1, x1, y2, x2
    window: [4] in the form y1, x1, y2, x2
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.clip_to_window" :"""
    window: (y1, x1, y2, x2). The window in the image we want to clip to.
    boxes: [N, (y1, x1, y2, x2)]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.compose_image_meta" :"""
    Takes attributes of an image and puts them in one 1D array.
    image_id: An int ID of the image. Useful for debugging.
    image_shape: [height, width, channels]
    window: (y1, x1, y2, x2) in pixels. The area of the image where the real image is (excluding the padding)
    active_class_ids: List of class_ids available in the dataset from which the image came. Useful if training on images from multiple datasets where not all classes are present in all datasets.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.conv_block" :"""
    conv_block is the block that has a conv layer at shortcut
    # Arguments
        input_tensor: input tensor
        kernel_size: defualt 3, the kernel size of middle conv layer at main path
        filters: list of integers, the nb_filters of 3 conv layer at main path
        stage: integer, current stage label, used for generating layer names
        block:'a','b'..., current block label, used for generating layer names
    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)
    And the shortcut should have subsample=(2,2) as well
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.data_generator" :"""
    A generator that returns images and corresponding target class ids, bounding box deltas, and masks.
    dataset: The Dataset object to pick data from
    config: The model config object
    shuffle: If True, shuffles the samples before every epoch
    augment: If True, applies image augmentation to images (currently only horizontal flips are supported)
    random_rois: If> 0 then generate proposals to be used to train the network classifier and mask heads. Useful if training the Mask RCNN part without the RPN.
    batch_size: How many images to return in each call
    detection_targets: If True, generate detection targets (class IDs, bbox deltas, and masks). Typically for debugging or visualizations because in trainig detection targets are generated by DetectionTargetLayer.
    Returns a Python generator. Upon calling next() on it, the generator returns two lists, inputs and outputs. The containtes of the lists differs depending on the received arguments:
    inputs list:
    -images: [batch, H, W, C]
    -image_meta: [batch, size of image meta]
    -rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)
    -rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.
    -gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs
    -gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]
    -gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width are those of the image unless use_mini_mask is True, in which case they are defined in MINI_MASK_SHAPE.
    outputs list: Usually empty in regular training. But if detection_targets is True then the outputs list contains target class_ids, bbox deltas, and masks.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.detection_targets_graph" :"""
    Generates detection targets for one image. Subsamples proposals and generates target class IDs, bounding box deltas, and masks for each.
    Inputs:
    proposals: [N, (y1, x1, y2, x2)] in normalized coordinates. Might be zero padded if there are not enough proposals.
    gt_class_ids: [MAX_GT_INSTANCES] int class IDs
    gt_boxes: [MAX_GT_INSTANCES, (y1, x1, y2, x2)] in normalized coordinates.
    gt_masks: [height, width, MAX_GT_INSTANCES] of boolean type.
    Returns: Target ROIs and corresponding class IDs, bounding box shifts, and masks.
    rois: [TRAIN_ROIS_PER_IMAGE, (y1, x1, y2, x2)] in normalized coordinates
    class_ids: [TRAIN_ROIS_PER_IMAGE]. Integer class IDs. Zero padded.
    deltas: Class-specific bbox refinements. [TRAIN_ROIS_PER_IMAGE, NUM_CLASSES, (dy, dx, log(dh), log(dw))]
    masks: [TRAIN_ROIS_PER_IMAGE, height, width). Masks cropped to bbox boundaries and resized to neural network output size.
    Note: Returned arrays might be zero padded if not enough target ROIs.
    """,





"iobjectspy.ml.vision._models.instance_segmentation.model.fpn_classifier_graph" :"""
    Builds the computation graph of the feature pyramid network classifier and regressor heads.
    rois: [batch, num_rois, (y1, x1, y2, x2)] Proposal boxes in normalized coordinates.
    feature_maps: List of feature maps from diffent layers of the pyramid, [P2, P3, P4, P5]. Each has a different resolution.
    image_shape: [height, width, depth]
    pool_size: The width of the square feature map generated from ROI Pooling.
    num_classes: number of classes, which determines the depth of the results
    Returns:
        logits: [N, NUM_CLASSES] classifier logits (before softmax)
        probs: [N, NUM_CLASSES] classifier probabilities
        bbox_deltas: [N, (dy, dx, log(dh), log(dw))] Deltas to apply to proposal boxes
    """,




"iobjectspy.ml.vision._models.instance_segmentation.model.generate_random_rois" :"""
    Generates ROI proposals similar to what a region proposal network would generate.
    image_shape: [Height, Width, Depth]
    count: Number of ROIs to generate
    gt_class_ids: [N] Integer ground truth class IDs
    gt_boxes: [N, (y1, x1, y2, x2)] Ground truth boxes in pixels.
    Returns: [count, (y1, x1, y2, x2)] ROI boxes in pixels.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.identity_block" :"""
    The identity_block is the block that has no conv layer at shortcut
    # Arguments
        input_tensor: input tensor
        kernel_size: defualt 3, the kernel size of middle conv layer at main path
        filters: list of integers, the nb_filters of 3 conv layer at main path
        stage: integer, current stage label, used for generating layer names
        block:'a','b'..., current block label, used for generating layer names
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.load_image_gt" :"""
    Load and return ground truth data for an image (image, mask, bounding boxes).
    augment: If true, apply random image augmentation. Currently, only horizontal flipping is offered.
    use_mini_mask: If False, returns full-size masks that are the same height and width as the original image. These can be big, for example 1024x1024x100 (for 100 instances). Mini masks are smaller, typically, 224x224 and are generated by extracting the bounding box of the object and resizing it to MINI_MASK_SHAPE.
    Returns:
    image: [height, width, 3]
    shape: the original shape of the image before resizing and cropping.
    class_ids: [instance_count] Integer class IDs
    bbox: [instance_count, (y1, x1, y2, x2)]
    mask: [height, width, instance_count]. The height and width are those of the image unless use_mini_mask is True, in which case they are defined in MINI_MASK_SHAPE.
    """,







"iobjectspy.ml.vision._models.instance_segmentation.model.log" :"""
    Prints a text message. And, optionally, if a Numpy array is provided it prints it's shape, min, and max values.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.log2_graph" :"""
    Implementatin of Log2. TF doesn't have a native implemenation.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.mold_image" :"""
    Takes RGB images with 0-255 values and subtraces the mean pixel and converts it to float. Expects image colors in RGB order.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.mrcnn_bbox_loss_graph" :"""
    Loss for Mask R-CNN bounding box refinement.
    target_bbox: [batch, num_rois, (dy, dx, log(dh), log(dw))]
    target_class_ids: [batch, num_rois]. Integer class IDs.
    pred_bbox: [batch, num_rois, num_classes, (dy, dx, log(dh), log(dw))]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.mrcnn_class_loss_graph" :"""
    Loss for the classifier head of Mask RCNN. 
    target_class_ids: [batch, num_rois]. Integer class IDs. Uses zero padding to fill in the array.
    pred_class_logits: [batch, num_rois, num_classes]
    active_class_ids: [batch, num_classes]. Has a value of 1 for classes that are in the dataset of the image, and 0 for classes that are not in the dataset.
    """,

"iobjectspy.ml.vision._models.instance_segmentation.model.mrcnn_mask_loss_graph" :"""
    Mask binary cross-entropy loss for the masks head.
    target_masks: [batch, num_rois, height, width]. A float32 tensor of values 0 or 1. Uses zero padding to fill array.
    target_class_ids: [batch, num_rois]. Integer class IDs. Zero padded.
    pred_masks: [batch, proposals, height, width, num_classes] float32 tensor with values from 0 to 1.
    """,

"iobjectspy.ml.vision._models.instance_segmentation.model.overlaps_graph" :"""
    Computes IoU overlaps between two sets of boxes.
    boxes1, boxes2: [N, (y1, x1, y2, x2)].
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.parse_image_meta_graph" :"""
    Parses a tensor that contains image attributes to its components.
    See compose_image_meta() for more details.
    meta: [batch, meta length] where meta length depends on NUM_CLASSES
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.refine_detections_graph" :"""
    Refine classified proposals and filter overlaps and return final detections.
    Inputs:
        rois: [N, (y1, x1, y2, x2)] in normalized coordinates
        probs: [N, num_classes]. Class probabilities.
        deltas: [N, num_classes, (dy, dx, log(dh), log(dw))]. Class-specific bounding box deltas.
        window: (y1, x1, y2, x2) in image coordinates. The part of the image that contains the image excluding the padding.
    Returns detections shaped: [N, (y1, x1, y2, x2, class_id, score)] where coordinates are in image domain.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.resnet_graph" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.model.rpn_bbox_loss_graph" :"""
    Return the RPN bounding box loss graph.
    config: the model config object.
    target_bbox: [batch, max positive anchors, (dy, dx, log(dh), log(dw))]. Uses 0 padding to fill in unsed bbox deltas.
    rpn_match: [batch, anchors, 1]. Anchor match type. 1=positive, -1=negative, 0=neutral anchor.
    rpn_bbox: [batch, anchors, (dy, dx, log(dh), log(dw))]
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.rpn_class_loss_graph" :"""
    RPN anchor classifier loss.
    rpn_match: [batch, anchors, 1]. Anchor match type. 1=positive, -1=negative, 0=neutral anchor.
    rpn_class_logits: [batch, anchors, 2]. RPN classifier logits for FG/BG.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.rpn_graph" :"""
    Builds the computation graph of Region Proposal Network.
    feature_map: backbone features [batch, height, width, depth]
    anchors_per_location: number of anchors per pixel in the feature map
    anchor_stride: Controls the density of anchors. Typically 1 (anchors for every pixel in the feature map), or 2 (every other pixel).
    Returns:
        rpn_logits: [batch, H, W, 2] Anchor classifier logits (before softmax)
        rpn_probs: [batch, H, W, 2] Anchor classifier probabilities.
        rpn_bbox: [batch, H, W, (dy, dx, log(dh), log(dw))] Deltas to be applied to anchors.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.smooth_l1_loss" :"""
    Implements Smooth-L1 loss.
    y_true and y_pred are typicallly: [N, 4], but could be any shape.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.trim_zeros_graph" :"""
    Often boxes are represented with matricies of shape [N, 4] and are padded with zeros. This removes zero boxes.
    boxes: [N, 4] matrix of boxes.
    non_zeros: [N] a 1D boolean mask identifying the rows to keep
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.model.unmold_image" :"""
    Takes a image normalized with mold() and returns the original.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.config" :"""
Mask R-CNN
Base Configurations class.
Copyright (c) 2017 Matterport, Inc.
Licensed under the MIT License (see LICENSE for details)
Written by Waleed Abdulla
""",
 
"iobjectspy.ml.vision._models.instance_segmentation.config.Config" :"""
    Base configuration class. For custom configurations, create a sub-class that inherits from this one and override properties that need to be changed.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.config.Config.__init__" :"""Set values of computed attributes.""",
 
"iobjectspy.ml.vision._models.instance_segmentation.config.Config.display" :"""Display Configuration values.""",
 
"iobjectspy.ml.vision._models.instance_segmentation.config.Config.do_init" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.Mlflow_record" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.analyze_xml_class" :"""Parse all categories of xml""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.batch_mosaic" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.batch_multiprocess" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.check_mask_little" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.data_to_train" :"""
        Load and return training data
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.flip_augmentation" :"""
        Simply enhance the data to avoid adverse effects
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.func_data" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.get_ax" :"""
        Return a Matplotlib Axes array to be used in all visualizations in the notebook. 
        Provide a central point to control graph sizes. 
        
        Change the default size attribute to control the size of rendered images
    """,




"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.iter_image_index" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.iter_object_path" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.load_data_Linux" :"""
        Extract the mask of the corresponding object based on the bbox in the xml file, 
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.load_data_windows" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.mAP_cal" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.model_initiate" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.mosaic_data_augmentation" :"""
        Combined four training images into one, the corresponding mask and xml will also be generated, but not placed. Then extract the mask of the corresponding object according to the xml file Bbox
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.multiprocess_mosaic" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.multiscale" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.resize_image" :"""
        Resizes an image keeping the aspect ratio.
        min_dim: if provided, resizes the image such that it's smaller dimension == min_dim
        max_dim: if provided, ensures that the image longest side doesn't exceed this value.
        padding: If true, pads image with zeros so it's size is max_dim x max_dim
        Returns:
        image: the resized image
        window: (y1, x1, y2, x2). If max_dim is provided, padding might be inserted in the returned image. If so, this window is the coordinates of the image part of the full image (excluding the padding). The x2, y2 pixels are not included.
        scale: The scale factor used to resize the image
        padding: Padding added to the image [(top, bottom), (left, right), (0, 0)]
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.resize_mask" :"""
        Resizes a mask using the given scale and padding. 
        Typically, you get the scale and padding from resize_image() to ensure both, the image and the mask, are resized consistently.
        scale: mask scaling factor
        padding: Padding to add to the mask in the form [(top, bottom), (left, right), (0, 0)]
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.save_pb" :"""
           # Save weights
           # Typically not needed because callbacks save after every epoch
           # Uncomment to save manually
           """,
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.set_model_input_size" :"""
        According to the number of rows and columns of the cut out picture, take the nearest multiple of 64 as the model input
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.stages_train" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.train" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.MaskRcnnTrainer.warmup_train" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.ShapesDataset" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.ShapesDataset.image_reference" :"""
        Return the shapes data of the image.""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.ShapesDataset.load_image" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.ShapesDataset.load_mask" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.ShapesDataset.load_shapes" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.conver_config" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.export_savedmodel" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.saved_config_sdm" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.mask_segmentation.show_image" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.object_extraction_train" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.object_extraction_train.ObjectExtraction" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.object_extraction_train.ObjectExtraction.mask_rcnn_keras" :"""""",
 
"iobjectspy.ml.vision._trainer_collector.object_extraction_train.ObjectExtraction.train" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._models.dlinknet.estimation_tf" :"""""",
 
"iobjectspy.ml.vision._models.dlinknet.estimation_tf.DlinknetEstimationTf" :"""""",
 
"iobjectspy.ml.vision._models.dlinknet.estimation_tf.DlinknetEstimationTf.augment_data" :"""""",
 
"iobjectspy.ml.vision._models.dlinknet.estimation_tf.DlinknetEstimationTf.close_model" :"""""",
 
"iobjectspy.ml.vision._models.dlinknet.estimation_tf.DlinknetEstimationTf.estimate_img" :"""""",
 
"iobjectspy.ml.vision._models.dlinknet.estimation_tf.DlinknetEstimationTf.estimate_tile" :"""""",
 
"iobjectspy.ml.vision._models.dlinknet.estimation_tf.DlinknetEstimationTf.load_model" :"""""",
 
"iobjectspy.ml.vision._models.dlinknet" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassification" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassification.close_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassification.infer" :"""
        Execute the image prediction function 'estimate_img' according to 'self.estimation'
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassification.load_model" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithNumpy" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithNumpy.__init__" :"""
        Use numpy for feature extraction, both input and output are image arrays
        :param model_path: model path
        :param config: configuration file path
        :param kwargs:
        """,
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithNumpy.close_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithNumpy.infer" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithNumpy.infer_tile" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithNumpy.unet_keras_numpy" :"""
        Use numpy for feature extraction, both input and output are image arrays
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithNumpy.unet_keras_tile" :"""
        Use numpy for feature extraction, both input and output are image arrays
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithTile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithTile.__init__" :"""
        Use numpy for feature extraction, both input and output are image arrays
        :param model_path: model path
        :param config: configuration file path
        :param kwargs:
        """,
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithTile.close_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithTile.infer_tile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithTile.load_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithTile.unet_keras_load_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.binary_classification_infer.BinaryClassificationWithTile.unet_keras_tile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.image_classification_infer" :"""""",
 
"iobjectspy.ml.vision._inference_collector.image_classification_infer.ImageClassification" :"""""",
 
"iobjectspy.ml.vision._inference_collector.image_classification_infer.ImageClassification.cnn_keras" :"""""",
 
"iobjectspy.ml.vision._inference_collector.image_classification_infer.ImageClassification.infer" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.image_classification_infer.ImageClassificationSingle" :"""""",
 
"iobjectspy.ml.vision._inference_collector.image_classification_infer.ImageClassificationSingle.cnn_keras" :"""""",
 
"iobjectspy.ml.vision._inference_collector.image_classification_infer.ImageClassificationSingle.cnn_keras_load_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.image_classification_infer.ImageClassificationSingle.infer" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.image_classification_infer.ImageClassificationSingle.load_model" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer" :"""""",
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassification" :"""""",
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassification.close_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassification.infer" :"""
        Execute the corresponding image prediction function 'estimate_img' according to 'self.estimation'
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassification.load_model" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassificationWithTile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassificationWithTile.__init__" :"""
        Use numpy for feature extraction, both input and output are image arrays
        :param model_path: model path
        :param config: configuration file path
        :param kwargs:
        """,
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassificationWithTile.close_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassificationWithTile.infer_tile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassificationWithTile.load_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassificationWithTile.unet_keras_load_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.multi_classification_infer.MultiClassificationWithTile.unet_keras_tile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetection" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetection.faster_rcnn_tensorflow" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetection.faster_rcnn_tensorflow_pic" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetection.infer" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetection.infer_pic" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetection.yolo_keras_pic" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetectionWithTile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetectionWithTile.close_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetectionWithTile.faster_rcnn_tensorflow_tile" :"""
        Use numpy for target detection, both input and output are image arrays
            :return:
            """,
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetectionWithTile.infer_tile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_detection_infer.ObjectDetectionWithTile.load_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer" :"""""",
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassification" :"""""",
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassification.cnn_keras_grid" :"""""",
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassification.cnn_keras_region" :"""""",
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassification.infer" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassificationWithTile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassificationWithTile.__init__" :"""
        Use numpy for feature extraction, both input and output are image arrays
        :param model_path: model path
        :param config: configuration file path
        :param kwargs:
        """,
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassificationWithTile.close_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassificationWithTile.cnn_keras_load_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassificationWithTile.cnn_keras_tile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassificationWithTile.infer_tile" :"""""",
 
"iobjectspy.ml.vision._inference_collector.scene_classification_infer.SceneClassificationWithTile.load_model" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.close_model" :"""
        Close model
        :return:
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.do_prediction" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.get_image_mean_pixel" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.get_mean_pixel" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.get_model_output" :"""
        Input an array need to be inferenced.
        Return the inference result (mask, category id, credibility, the Minimum Bounding Rectangle of the mask) in the confidence interval. 
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.infer_geo_image" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.infer_large" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.infer_large_smooth" :"""
        Inferring large images or pictures
        is_geo_image: bool; whether it is this data have geographic coordinates
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.infer_large_smooth_mask" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.infer_pic_dir" :"""
        Infer a single picture or all pictures in a folder
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.infer_pic_only" :"""
        Only infer a single picture, applicable to both large and small pictures
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Pr ediction.infer_smallsize" :"""
        Predict small images or pictures
        is_geo_image: bool; whether it is this data have geographic coordinates
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.init_input_params" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.load_model" :"""
        Load the model, this function is only have one parameter 'model_path'
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.merge_block_mask_class" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.merge_mask" :"""
        Mapping the prediction results to different 2D arrays by categories, and the output at the overlap part will be the sum of each overlapped pixel every time.
        At the end, the none-zero pixels and the pixels which value is different than the assigned value in this 2D array will be changed to the assigned value (i.e. [0,k,l1,l2,l3] will eventually mapping to [0,k])
        Follow the above logic to mapping multiple 2D arrays to a 2D array with all zeros.
        Finally, the temporary data tif generated has been converted into a vector, then, merge the vector and determine whether to generate the minimum bounding rectangle according to the 'return_bbox' value
 
        almasks: a 1D list, each element in the list stores the masks of each block in the prediction result
        alleups: a 1D list, each element in the list stores the upper left corner coordinates of the predicted block on original image (a block shares the same point)
        alclass_ids: a 1D list, each element in the list stores the class codes of each block in the prediction result
 
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.process_large_output" :"""
                Perform 'nms' on the prediction result, process the inference result, de-duplicate the bbox, and map the mask to the original image. 
                        Suitable for both large and small images.
                        all_rois: a 1D list, each element in the list stores the MBR of the prediction result of each block
                        all_masks: a 1D list, each element in the list stores the mask of a single object, consistent with the order of the 'bbox' in 'all_rois'
                        all_scores: a 1D list, each element in the list stores all the scores of each block in the prediction result
                        all_class_ids: a 1D list, each element in the list stores the class codes of each block in the prediction result
                        all_leups: a 1D list, each element in the list stores the upper left corner coordinates of the predicted block on original image (have multiple same coordinate pairs)
                """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.Mask_Rcnn_Prediction.save_pic_out" :"""
        rois: [[], [], []]
        class_ids: [,, ,]
        whole_mask: 2D array
        applicaton: When train, all inference results are stored in the 'Annotation' and 'SegmentationObject' folder under the specified path; when displaying, only save the file structure 'mask' in the input directory.
        If only process one image, the bbox and mask will be saved into the 'xml' file in the 'Annotations' folder and the 'png' file in the 'SegmentationObject' folder.
        """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.cal_config" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.compose_image_meta" :"""
    Takes attributes of an image and puts them in one 1D array.
    image_id: An int ID of the image. Useful for debugging.
    image_shape: [height, width, channels]
    window: (y1, x1, y2, x2) in pixels. The area of the image where the real image is (excluding the padding)
    active_class_ids: List of class_ids available in the dataset from which the image came. Useful if training on images from multiple datasets where not all classes are present in all datasets.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.core_contours" :"""
    Extracts contours and the relationship between them from a binary mask.
    Args:
        mask: the binary mask to find contours in.
    Returns:
        The detected contours as a list of points and the contour hierarchy.
    Note: the hierarchy can be used to re-construct polygons with holes as one entity.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.cover_config" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.extract_image_from_dir" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.geo_process_masks_smooth_no_pinjie" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.geo_process_masks_smooth_save" :"""
 
    :param masks: stores the prediction results of each block
    :param class_ids: this parameter is useless now, it will be used when adding the category fields to objects later
    :param class_names:
    :param transform:
    :param leups: save the upper left corner of each block
    :param out_data_location: path of 'udbx'
    :param out_dataset_name: dataset name
    :param return_bbox: whether to generate the bbox of the object
    :return:
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.get_mask_poly" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.infer_config" :"""""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.infer_config.display" :"""Display Configuration values.""",
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.mold_image" :"""
    Takes RGB images with 0-255 values and subtraces the mean pixel and converts it to float. Expects image colors in RGB order.
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.mold_inputs" :"""
    Takes a list of images and modifies them to the format expected as an input to the neural network.
    images: List of image matricies [height,width,depth]. Images can have different sizes.
    Returns 3 Numpy matricies:
        molded_images: [N, h, w, 3]. Images resized and normalized.
        image_metas: [N, length of meta data]. Details about each image.
        windows: [N, (y1, x1, y2, x2)]. The portion of the image that has the original image (padding excluded).
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.nms_all_output" :"""
        Perform 'nms' on the prediction results and convert them to 'georegion' objects and save in a udbx
                all_rois: a 1D list, each element in the list stores the MBR of the prediction result of each block
                all_masks: a 1D list, each element in the list stores the mask of a single object, consistent with the order of the 'bbox' in 'all_rois'
                all_scores: a 1D list, each element in the list stores all the scores of each block in the prediction result
                all_class_ids: a 1D list, each element in the list stores the class codes of each block in the prediction result
                all_leups: a 1D list, each element in the list stores the upper left corner coordinates of the predicted block on original image (have multiple same coordinate pairs)
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.nms_large_output" :"""
        Perform 'nms' on the prediction results, the output is identical to the direct output form of the model, except the mask is stored in the order of the list.
            all_rois: a 1D list, each element in the list stores the MBR of the prediction result of each block
            all_masks: a 1D list, each element in the list stores the mask of a single object, consistent with the order of the 'bbox' in 'all_rois'
            all_scores: a 1D list, each element in the list stores all the scores of each block in the prediction result
            all_class_ids: a 1D list, each element in the list stores the class codes of each block in the prediction result
            all_leups: a 1D list, each element in the list stores the upper left corner coordinates of the predicted block on original image (have multiple same coordinate pairs)
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.save_udb" :"""
 
    :param rois: [h_min,w_min,h_max,w_max]
    :param masks:
    :param scores: scores of result
    :param class_ids: class names correspond ids
    :param class_name: class_ids corresponding class names
    :param out_dir: existing or creating udb location
    :param out_name: dataset name,just for one
    :return:
    """,
 
"iobjectspy.ml.vision._models.instance_segmentation.prediction_instance_seg.unmold_detections" :"""
    Reformats the detections of one image from the format of the neural network output to a format suitable for use in the rest of the application.
    detections: [N, (y1, x1, y2, x2, class_id, score)]
    mrcnn_mask: [N, height, width, num_classes]
    image_shape: [height, width, depth] Original size of the image before resizing
    window: [y1, x1, y2, x2] Box in the image where the real image is excluding the padding.
    Returns:
    boxes: [N, (y1, x1, y2, x2)] Bounding boxes in pixels
    class_ids: [N] Integer class IDs for each bounding box
    scores: [N] Float probability scores of the class_id
    masks: [height, width, num_instances] Instance masks
    """,
 
"iobjectspy.ml.vision._inference_collector.object_extraction_infer" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_extraction_infer.ObjectExtraction" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_extraction_infer.ObjectExtraction.close_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_extraction_infer.ObjectExtraction.infer" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.object_extraction_infer.ObjectExtraction.infer_pic" :"""
        Automatically execute the functions of each network according to the concatenation string by the use of 'func_str'.
        :return:
        """,
 
"iobjectspy.ml.vision._inference_collector.object_extraction_infer.ObjectExtraction.load_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_extraction_infer.ObjectExtraction.maskrcnn_keras" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_extraction_infer.ObjectExtraction.maskrcnn_keras_load_model" :"""""",
 
"iobjectspy.ml.vision._inference_collector.object_extraction_infer.ObjectExtraction.maskrcnn_keras_pic" :"""""",
 
"iobjectspy.ml.vision._inference_collector" :"""""",
 
"iobjectspy.ml.vision._inference" :"""""",
 
"iobjectspy.ml.vision._inference.ImageryInference" :"""""",

"iobjectspy.ml.vision._inference.ImageryInference.__init__" :"""
        Image data model inference function entry

        :param model_path: saved model path
        :type  model_path: str
        """,
 
"iobjectspy.ml.vision._inference.ImageryInference.binary_classify_infer" :"""
        Binary classification for satellite images.
        Supports image files such as tif, img (Erdas Image), and image files such as jpg, png. The output is a binary raster or vector file.
        Supports image datasets in SuperMap SDX, and the classification result is a vector or raster dataset.
 
        Keyword parameters can be added: parameter 'dsm_dataset' used to add the DSM data matching with the image which realize the extraction of building surface based on DOM and DSM.
        Images and DSM can be extracted from oblique photography data using SuperMap iDesktop:
            Open '3D scene', use '3D analysis' -> generate DOM; 3D analysis -> generate DSM. It is recommended to set the resolution to 0.1m.
 
        :param input_data: data to be inferred
        :type  input_data: str or Dataset
        :param out_data: output file (or datasource) path
        :type  out_data: str or Datasource or DatasourceConnectionInfo
        :param out_dataset_name: output file (or dataset) path
        :type  out_dataset_name: str
        :param offset: image block offset; To improve the prediction accuracy, large images need to be divided into blockes for prediction. The value is the overlap area between blocks.
        :type offset: int
        :param result_type: the result type returned, support vector area and raster, 'region' or 'grid'
        :type result_type: str
        :return: Dataset name
        """,
 
"iobjectspy.ml.vision._inference.ImageryInference.close" :"""
        Closed the loaded model
        """,
 
"iobjectspy.ml.vision._inference.ImageryInference.multi_classify_infer" :"""
        Multi-classification and ground object classification for remote sensing images. 
        Support image files such as tif, img (Erdas Image). The output is a binary raster or vector file.
        Supports image datasets in SuperMap SDX, and the classification outputs is a vector or raster dataset.
 
        :param input_data: dataset to be inferred
        :type  input_data: str or Dataset
        :param out_data: path of the output file (datasource)
        :type  out_data: str or Datasource or DatasourceConnectionInfo
        :param out_dataset_name: name of the output file (datsource)
        :type  out_dataset_name: str
        :param offset: image block offset; To improve the prediction accuracy, large images need to be divided into blockes for prediction. The value is the area of the overlap between blocks.
        :type offset: int
        :param result_type: the result type returned, support vector area and raster, 'region' or 'grid'
        :type result_type: str
        :return: dataset name
        """,
 
"iobjectspy.ml.vision._inference.ImageryInference.object_detect_infer" :"""
        Object detection for imagery data
 
        | TIF, IMG (ERDAS IMAGE) and other Image files are supported, and the detection results are vector surface data sets
 
        requires attention:
            -When 'input_data' is the data to be detected and 'out_data' is the output file path or a datasource, 'out_dataset_name' is the file name.
            -When 'input_data' is the file path to be detected and 'out_data' is the output file path or a datasource, 'out_dataset_name' is ineffective and 'dataset_name' is obtained from the 'input_data' file list.   
        
        :param input_data: data to be inferred
        :type  input_data: str or Dataset
        :param out_data: output file (or datasource) path
        :type  out_data: str or Datasource or DatasourceConnectionInfo
        :param out_dataset_name: output data (or dataset) name
        :type  out_dataset_name: str
        :param category_name: categories for object detection, support multi-categories detection
        :type category_name: list[str] or str
        :param nms_thresh: 'nms' threshold
        :type nms_thresh: float
        :param score_thresh: category score threshold
        :type score_thresh: float
        :return: None
        """,
 
"iobjectspy.ml.vision._inference.ImageryInference.object_extract_infer" :"""
        Object extraction for remote sensing image.
        Support imagery files such as tif, img (Erdas Image). The output is a vector file.
        Supports image datasets in SuperMap SDX, and the classification result is a vector file.
    
        :param input_data: data to be inferred
        :type  input_data: str or Dataset
        :param out_data: output file (or datasource) path
        :type  out_data: str or Datasource or DatasourceConnectionInfo
        :param out_dataset_name: output data (or dataset) name
        :type  out_dataset_name: str
        :param score_thresh: category score threshold
        :type score_thresh: float
        :param nms_thresh: 'nms' threshold
        :type nms_thresh: float
        :param return_bbox: whether to return the minimum bounding rectangle of the object
        :type return_bbox: bool
        :return: dataset name
        """,
 
"iobjectspy.ml.vision._inference.ImageryInference.scene_classify_infer" :"""
        Scene classification for remote sensing image.
        Support imagery files such as tif, img (Erdas Image). The output is a binary raster or vector file.
        Supports image datasets in SuperMap SDX, and the output is a vector or raster datasets.
 
        :param input_data: data to be inferred
        :type  input_data: str or Dataset
        :param out_data: output file (or datasource) path
        :type  out_data: str or Datasource or DatasourceConnectionInfo
        :param out_dataset_name: output data (or dataset) name
        :type  out_dataset_name: str
        :param result_type: the result type returned, support vector area and raster, 'region' or 'grid'
        :type result_type: str
        :return: dataset name
        """,
 
"iobjectspy.ml.vision._inference.Inference" :"""""",
 
"iobjectspy.ml.vision._inference.Inference.__init__" :"""
        The Inference category will deprecated, please use ImageryInference and PictureInference instead
        
        Model inference function entrance for satellite image data
 
        :param input_data: data to be inferred
        :type input_data: str or Dataset
        :param model_path: model storage path
        :type model_path: str
        :param out_data: output file (or datasource) path
        :type out_data: str or Datasource or DatasourceConnectionInfo
        :param out_dataset_name: output file (or dataset) name
        :type out_dataset_name: str
        """,
 
"iobjectspy.ml.vision._inference.Inference.binary_classify_infer" :"""
        Binary classification for satellite images.
        Supports image files such as tif, img (Erdas Image), and picture files such as jpg, png. The output is a binary raster or vector file.
        Supports image datasets in SuperMap SDX, and the classification result is a vector or raster dataset.
 
        Keyword parameters can be added: parameter 'dsm_dataset' used to add the DSM data matching with the image which realize the extraction of building surface based on DOM and DSM.
        Images and DSM can be extracted from oblique photography data using SuperMap iDesktop:
            Open '3D scene', use '3D analysis' -> generate DOM; 3D analysis -> generate DSM. It is recommended to set the resolution to 0.1m.
 
        :param offset: image block offset; To improve the prediction accuracy, large images need to be divided into blockes for prediction. The value is the overlap area between blocks.
        :type offset: int
        :param result_type: the result type returned, support vector area and raster, 'region' or'grid'
        :type result_type: str
        :return: dataset name
        """,
 
"iobjectspy.ml.vision._inference.Inference.image_classify_infer" :"""
        image classification
        Support image files such as tif, img (Erdas Image), and picture files such as jpg, png. The output is a binary raster or vector file.
        Supports image datasets in SuperMap SDX, and the classification result is a vector or raster dataset.
 
        :param result_type: the result type returned, support vector area and raster, 'region' or'grid'
        :type result_type: str
        :return: dataset name
        """,
 
"iobjectspy.ml.vision._inference.Inference.multi_classify_infer" :"""
        Multi-classification and ground object classification for remote sensing images. 
        Support image files such as tif, img (Erdas Image), and picture files such as jpg, png. The output is a binary raster or vector file.
        Supports image datasets in SuperMap SDX, and the classification outputs is a vector or raster dataset.
 
        :param offset: image block offset; To improve the prediction accuracy, large images need to be divided into blockes for prediction. The value is the area of the overlap between blocks.
        :type offset: int
        :param result_type: the result type returned, support vector area and raster, 'region' or 'grid'
        :type result_type: str
        :return: dataset name
        """,
 
"iobjectspy.ml.vision._inference.Inference.object_detect_infer" :"""
        Object detection for satellite images 
 
        | Support image data such as tif, img (Erdas Image), and picture files such as jpg, png. The output is a vector surface dataset.
 
        Attention:
            -When 'input_data' is the data to be detected and 'out_data' is the output datasource path (or data source object), 'out_dataset_name' is the dataset name.
            -When 'input_data' is the file path to be detected and 'out_data' is the output datasource path (or data source object), 'out_dataset_name' is ineffective and 'dataset_name' is obtained from the 'input_data' file list.
 
        :param category_name: categories for object detection, support multi-categories detection
        :type category_name: list[str] or str
        :param nms_thresh: 'nms' threshold
        :type nms_thresh: float
        :param score_thresh: category score threshold
        :type score_thresh: float
        :return: None
        """,
 
"iobjectspy.ml.vision._inference.Inference.object_detect_pic_infer" :"""
        Object detection for pictures
 
        | Support jpg, png and other picture files, the outputs are 'xml' files.
 
        requires attention:
            -When 'input_data' is the data to be detected and 'out_data' is the output file path, 'out_dataset_name' is the file name.
            -When 'input_data' is the file path to be detected and 'out_data' is the output file path, 'out_dataset_name' is ineffective and 'dataset_name' is obtained from the 'input_data' file list.   
        :param category_name: categories for object detection, support multi-categories detection
        :type category_name: list[str] or str
        :param nms_thresh: 'nms' threshold
        :type nms_thresh: float
        :param score_thresh: category score threshold
        :type score_thresh: float
        :return: None
        """,
 
"iobjectspy.ml.vision._inference.Inference.object_extract_infer" :"""
        Object extraction for remote sensing image.
        Support image files such as tif, img (Erdas Image), and picture files such as jpg, png. The output is a vector file.
        Supports image datasets in SuperMap SDX, and the classification result is a vector file.
    
        :param score_thresh: category score threshold
        :type score_thresh: float
        :param nms_thresh: 'nms' threshold
        :type nms_thresh: float
        :param return_bbox: whether to return the minimum bounding rectangle of the object
        :type return_bbox: bool
        :return: dataset name
        """,
 
"iobjectspy.ml.vision._inference.Inference.scene_classify_infer" :"""
        Scene classification for remote sensing image.
        Support image files such as tif, img (Erdas Image), and image files such as jpg, png. The output is a binary raster or vector file.
        Supports image datasets in SuperMap SDX, and the output is a vector or raster datasets.
 
        :param result_type: the result type returned, support vector area and raster, 'region' or 'grid'
        :type result_type: str
        :return: dataset name
        """,
 
"iobjectspy.ml.vision._inference.PictureInference" :"""""",

"iobjectspy.ml.vision._inference.PictureInference.__init__" :"""
        Model inference function entry for imagery data 

        :param model_path: model saved path
        :type  model_path: str
        """,

"iobjectspy.ml.vision._inference.PictureInference.close" :"""
        Close the loaded model
        """,
 
"iobjectspy.ml.vision._inference.PictureInference.object_detect_infer" :"""
        Object detection for pictures
 
        | Support jpg, png and other picture files, the outputs are 'xml' files.
 
        requires attention:
            -When 'input_data' is the data to be detected and 'out_data' is the output file path, 'out_dataset_name' is the file name.
            -When 'input_data' is the file path to be detected and 'out_data' is the output file path, 'out_dataset_name' is ineffective and 'dataset_name' is obtained from the 'input_data' file list.   
        
        :param input_data: data to be inferred
        :type  input_data: str or Dataset
        :param out_data: output file (or datasource) path
        :type  out_data: str or Datasource or DatasourceConnectionInfo
        :param out_dataset_name: output data (or dataset) name
        :type  out_dataset_name: str
        :param category_name: categories for object detection, support multi-categories detection
        :type category_name: list[str] or str
        :param nms_thresh: 'nms' threshold
        :type nms_thresh: float
        :param score_thresh: category score threshold
        :type score_thresh: float
        :return: None
        """,
 
"iobjectspy.ml.vision._inference.PictureInference.object_extract_infer" :"""
        Object extraction for pictures.
        Support picture files such as jpg, png. The output is a vector file.
    
        :param input_data: data to be inferred
        :type  input_data: str or Dataset
        :param out_data: output file (or datasource) path
        :type  out_data: str or Datasource or DatasourceConnectionInfo
        :param out_dataset_name: output data (or dataset) name
        :type  out_dataset_name: str
        :param score_thresh: category score threshold
        :type score_thresh: float
        :param nms_thresh: 'nms' threshold
        :type nms_thresh: float
        :param return_bbox: whether to return the minimum bounding rectangle of the object
        :type return_bbox: bool
        :return: dataset name
        """,
 
"iobjectspy.ml.vision._inference.PictureInference.picture_classify_infer" :"""
        Picture classification
        Support picture files such as jpg, png. The output is xml files.

        :param input_data: data to be inferred
        :type  input_data: str or Dataset
        :param out_data: output file (or datasource) path
        :type  out_data: str or Datasource or DatasourceConnectionInfo
        :param out_dataset_name: output data (or dataset) name
        :type  out_dataset_name: str
        :param result_type: result return type, support vector and raster: 'region' or 'grid'
        :type result_type: str
        :return: dataset name
        """,
 
}

_iobjectspy_3ddesigner_locale = {
    "iobjectspy._jsuperpy.threeddesigner": """""",

    "iobjectspy._jsuperpy.threeddesigner.BoolOperation3D": """""",

    "iobjectspy._jsuperpy.threeddesigner.BoolOperation3D.check": """
        Check whether the model object meets the Boolean operation condition
        :param geometry3d:
        :return:
        """,

    "iobjectspy._jsuperpy.threeddesigner.BoolOperation3D.erase": """
        Difference operation of two specified 3D geometric objects
        :param geometry3d:
        :param erase_geomety3d:
        :return: Return the difference Geometry3D object
        """,

    "iobjectspy._jsuperpy.threeddesigner.BoolOperation3D.intersect": """
        The intersection of two specified 3D geometric objects
        :param geometry3d:
        :param geomety3d:
        :return: return the intersection Geometry3D object
        """,

    "iobjectspy._jsuperpy.threeddesigner.BoolOperation3D.isClosed": """
        Check if Geometry3D object is closed
        :param geometry3d:
        :return: true means closing, false means not closing
        """,

    "iobjectspy._jsuperpy.threeddesigner.BoolOperation3D.union": """
        Union of two specified 3D geometric objects
        :param geometry3d:
        :param union_geomety3d:
        :return: return the union Geometry3D object
        """,

    "iobjectspy._jsuperpy.threeddesigner.ClassificationInfos": """
    Python object mapping for com.supermap.data.processing.ClassificationInfos
    Single oblique photography data OSGB, export object of S3M
    """,

    "iobjectspy._jsuperpy.threeddesigner.ClassificationInfos.labels": """
        Label list
        :return: list tag list
        """,

    "iobjectspy._jsuperpy.threeddesigner.ClassificationInfos.normals": """
        List of normals
        :return: list normal list
        """,

    "iobjectspy._jsuperpy.threeddesigner.ClassificationInfos.vertices": """
        Vertex list
        :return: list vertex list
        """,

    "iobjectspy._jsuperpy.threeddesigner.ClassificationOperator": """""",

    "iobjectspy._jsuperpy.threeddesigner.ClassificationOperator.add_labels_to_S3M_file": """
        Import OSGB oblique photography data, use tag array to generate S3M data, and save it in outputFolder
        :param osgbFilePath:OSGB oblique photography data
        :param outputFolder: path to save the result
        :param labelsArray: label array
        """,

    "iobjectspy._jsuperpy.threeddesigner.ClassificationOperator.extract_infos": """
        Import OSGB oblique photography data to get the vertex, normal and label information of the data
        :param osgbFilePath: OSGB data of original oblique photographic slice
        """,

    "iobjectspy._jsuperpy.threeddesigner.ClassificationOperator.generate_training_set": """
        Import S3M single data to get the vertex, normal and label information of the data
        :param diecretFilePath: Single S3M data
        """,

    "iobjectspy._jsuperpy.threeddesigner.Material3D": """
    Material related parameter settings, mainly color, texture picture and texture repeat mode and number of repeats
    """,

    "iobjectspy._jsuperpy.threeddesigner.Material3D.set_color": """""",

    "iobjectspy._jsuperpy.threeddesigner.Material3D.set_is_texture_times_repeat": """""",

    "iobjectspy._jsuperpy.threeddesigner.Material3D.set_texture_file": """""",

    "iobjectspy._jsuperpy.threeddesigner.Material3D.set_uTiling": """""",

    "iobjectspy._jsuperpy.threeddesigner.Material3D.set_vTiling": """""",

    "iobjectspy._jsuperpy.threeddesigner.ModelBuilder3D": """""",

    "iobjectspy._jsuperpy.threeddesigner.ModelBuilder3D.create_buffer": """
        Three-dimensional buffer, support line and surface buffer (expanded) into surface; model buffer (expanded) into three-dimensional solid model
        :param geometry: line, area and model objects
        :param offset: buffer distance
        :param bLonLat: Whether it is latitude and longitude
        :param joinType: Join style, including sharp corners, rounded corners, and beveled corners.
         The three-dimensional line buffering surface supports the sharp corner connection style, and the buffering body supports the sharp corner and round corner connection style.
         Three-dimensional surfaces only support buffering into three-dimensional surfaces, and the connection styles include sharp and rounded corners.
         The entity model only supports cached adult, no cohesive style
        :return:
        """,

    "iobjectspy._jsuperpy.threeddesigner.ModelBuilder3D.linear_extrude": """
        Linear stretch
        This method is only supported in the Windows platform version, not in the Linux version
        :param geometry: the surface to be linearly stretched
        :param bLonLat: Whether it is latitude and longitude
        :param height: stretch height
        :param twist: rotation angle
        :param scaleX: scale around the X axis
        :param scaleY: scale around the Y axis
        :param material: texture settings
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.threeddesigner.ModelBuilder3D.loft": """
        Stakeout, this method is only supported in the Windows platform version, not in the Linux version
        :param geometry: the cross section of the stakeout,
        Support two-dimensional objects: GeoLine, GeoLineEPS, GeoCirCle, GeoRegion, GeoRegionEPS, GeoEllipse, GeoRect
        Support three-dimensional objects: GeoLine3D, GeoCircle3D, GeoRegion3D
        :param line3D: the line object to be staked
        :param bLonLat: Whether it is latitude and longitude
        :param nChamfer: smoothness
        :param chamferStyle: chamfer style
        :param material: texture settings
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.threeddesigner.ModelBuilder3D.mirror": """
        : Get the model object of geomodel3d about plane mirroring
        :param plane: mirror plane
        :return: return the model object of 'geomodel3d' about plane mirroring
        """,

    "iobjectspy._jsuperpy.threeddesigner.ModelBuilder3D.plane_projection": """
        Planar projection, not available in the Linux version
        :param geomodel3d: the three-dimensional geometric model object to be cross-sectional projection
        :param plane: projection plane
        :return: return to the projection surface
        """,

    "iobjectspy._jsuperpy.threeddesigner.ModelBuilder3D.rotate_extrude": """
        This method of rotating and stretching is only supported in the Windows platform version, not in the Linux version
        :param geometry: area object (must be constructed in plane coordinate system)
        :param angle: rotation angle
        :param slices: number of slices
        :param isgroup: Whether to split into multiple objects
        :param hasStartFace: Do you need a starting face
        :param hasRingFace: Do you need a ring
        :param hasEndFace: Do you need an end face
        :return: return GeoModel3D object
        """,

    "iobjectspy._jsuperpy.threeddesigner.ModelBuilder3D.section_projection": """
        Sectional projection, not available in the Linux version
        :param geometry: the 3D geometric model object to be projected
        :param plane: projection plane
        :return: return to the projection surface
        """,

    "iobjectspy._jsuperpy.threeddesigner.ModelBuilder3D.straight_skeleton": """
        Straight skeleton generation
        :param geometry: the area object of the skeleton to be straight
        :param bLonLat: Whether it is latitude and longitude
        :param dAngle: split angle threshold
        :return: successfully returned to the 3D model
        """,

    "iobjectspy._jsuperpy.threeddesigner.ThreeDDesignerProgressListener": """
    Progress event, encapsulated in the middle layer, is not a StepEvent of data, so encapsulate another
    Currently only supports progress information, not cancellation
    """,

    "iobjectspy._jsuperpy.threeddesigner.ThreeDDesignerProgressListener.stepped": """""",

    "iobjectspy._jsuperpy.threeddesigner.build_house": """
    Build a house model: build a house model from polygons (walls, eaves, roofs can be built)
    :param input_data: The specified source vector dataset, supports two-dimensional and three-dimensional surface dataset
    :param out_data: output datasource
    :param out_dataset_name: output dataset name
    :param wallHeight: the height of the wall of the house
    :param wallMaterail: wall material parameters
    :param eaveHeight: eave height
    :param eaveWidth: eave width
    :param eaveMaterial: eave material parameters
    :param roofWidth: roof width
    :param roofSlope: roof slope, unit degree
    :param roofMaterail: roof material parameters
    :param progress: progress event
    :return: return the model dataset
    """,

    "iobjectspy._jsuperpy.threeddesigner.building_height_check": """
    Planning the height control inspection
    :param input_data: building model record set or dataset
    :param height: limit height
    :return: return the ID of the super high building
    """,

    "iobjectspy._jsuperpy.threeddesigner.compose_models": """""",

    "iobjectspy._jsuperpy.threeddesigner.linear_extrude": """
    Linear stretch: stretch the vector plane into a white mold model according to a given height
    :param input_data: the given face dataset
    :param out_data: output datasource
    :param out_dataset_name: output dataset name
    :param bLonLat:
    :param height:
    :param twist:
    :param scaleX:
    :param scaleY:
    :return:
    """,

    "iobjectspy._jsuperpy.threeddesigner.material3DToJavaObject": """""",

    "iobjectspy._jsuperpy.threeddesigner.rotate_extrude": """

    :param input_data:
    :param out_data:
    :param out_dataset_name:
    :param angle:
    :return:
    """,

}
 
iobjectspy_locale = {}
 
iobjectspy_locale.update(_jsuperpy_env_locale)
iobjectspy_locale.update(_jsuperpy_data_locale)
iobjectspy_locale.update(_jsuperpy_enums_locale)
iobjectspy_locale.update(_jsuperpy_analyst_locale)
iobjectspy_locale.update(_jsuperpy_conversions_locale)
iobjectspy_locale.update(_jsuperpy_mapping_locale)
iobjectspy_locale.update(_iobjectspy_ml_locale)
iobjectspy_locale.update(_iobjectspy_3ddesigner_locale)
