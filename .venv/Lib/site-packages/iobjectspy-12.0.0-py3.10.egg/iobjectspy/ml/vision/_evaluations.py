# !/usr/bin/env python3
# coding=utf-8

import os
from iobjectspy import DatasetVector
from iobjectspy._jsuperpy._utils import check_lic
from iobjectspy._logger import log_info, log_warning, log_error
from iobjectspy.ml.toolkit._toolkit import get_input_dataset
from iobjectspy.ml.vision._evaluation._base_utils import _get_unique_values
from enum import Enum, unique
import tempfile


@unique
class _ImageryInType(Enum):
    SINGLEFILE = 1
    FILELIST = 2
    FILEDIR = 3
    DATASETIMAGE = 4
    DATASETMOSAIC = 5


class ImageryEvaluation:
    def __init__(self):
        self.tmp_data_dir = tempfile.mkdtemp()

    @staticmethod
    def object_detection(inference_data, ground_truth_data, inference_class_value_field=None,
                         ground_truth_class_value_field='category',
                         metric_type=None, out_data='', out_data_name='metric', iou_thr=''):
        """ 影像目标检测模型评估接口，可基于输入的预测标签数据集与真实标签数据集计算结果计算指标（只支持规则正矩形数据）

        :param inference_data: 必选参数。推理结果数据集，输入的矢量面数据集来自于模型推理object_detect_infer
        :type inference_data: str or DatasetVector
        :param ground_truth_data: 必选参数。真实标签数据集，输入的矢量面数据集来自于真实的标签数据集
        :type ground_truth_data: str or DatasetVector
        :param inference_class_value_field: 可选参数。推理结果数据包含类别字段名。如果指定的字段为None，则默认去找'value'字段，若字段不存在，则所有记录都被认定为是同一个类。
        :type inference_class_value_field: str or None
        :param ground_truth_class_value_field: 可选参数。真实数据类别字段名。如果指定的字段为None，则默认去找'value'字段，若字段不存在，则所有记录都被认定为是同一个类。
        :type ground_truth_class_value_field: str or None
        :param metric_type: 可选参数。待计算的指标名称。默认为None，为None时输出该功能全部指标。支持的metric_type为：F1、Recall、Precision、AP、mAP。
        :type metric_type: str or None
        :param out_data: 可选参数。输出文件（或数据源）路径
        :type out_data: str or Datasource or DatasourceConnectionInfo
        :param out_data_name: 可选参数。输出文件（或数据集）名称
        :type out_data_name: str
        :param iou_thr: 可选参数。IoU(Intersection over Union)用作评估目标检测模型准确性的阈值的交集与并集的比率.分子是推理边界框和真实边界框之间的重叠区域,分母是两个边界框合并的区域。IoU值应在0到1的范围内,[0,1] 示例：0.5
        :type iou_thr: float
        :return: tuple (metric_type ,[dict, dict, ...])
        """
        from ._evaluation.object_detection_metrics import object_detection_all, object_detection_map, \
            object_detection_ap, object_detection_precision, object_detection_recall, object_detection_f1
        check_lic()

        ground_truth_data = get_input_dataset(ground_truth_data)
        if ground_truth_data is None:
            log_error('ground_truth_data is None')
            raise ValueError('ground_truth_data is None')
        if not isinstance(ground_truth_data, DatasetVector):
            log_error('ground_truth_data must be DatasetVector')
            raise Exception('ground_truth_data must be DatasetVector')

        inference_data = get_input_dataset(inference_data)
        if inference_data is None:
            log_error('inference_data is None')
            raise ValueError('inference_data is None')
        if not isinstance(inference_data, DatasetVector):
            log_error('inference_data must be DatasetVector')
            raise Exception('inference_data must be DatasetVector')

        # 从ground_truth_class_value_field与inference_class_value_field获取类别字典
        if ground_truth_class_value_field is None or inference_class_value_field is None:
            if ground_truth_class_value_field is None:
                ground_truth_class_value_field = 'value'
            if inference_class_value_field is None:
                inference_class_value_field = 'value'
            try:
                categorys = _get_unique_values(ground_truth_data, ground_truth_class_value_field)
                categorys.extend(_get_unique_values(inference_data, inference_class_value_field))
                categorys = list(set(categorys))
                categorys.sort()
            except:
                log_warning(
                    'ground_truth_class_value_field or inference_class_value_field is set to None; at the same time, there is no value field in inference_data or ground_truth_data; so categories are classified into the same category by default')
                categorys = ['unspecified']
                categorys.sort()
                ground_truth_class_value_field = None
                inference_class_value_field = None

        else:
            try:
                categorys = _get_unique_values(ground_truth_data, ground_truth_class_value_field)
                categorys.extend(_get_unique_values(inference_data, inference_class_value_field))
                categorys = list(set(categorys))
                categorys.sort()
            except:
                log_warning(
                    'ground_truth_class_value_field or inference_class_value_field is set to None; at the same time, there is no value field in inference_data or ground_truth_data; so categories are classified into the same category by default')
                categorys = ['unspecified']
                categorys.sort()
                ground_truth_class_value_field = None
                inference_class_value_field = None
        categorys_dict = {}
        for id, i in enumerate(categorys):
            categorys_dict[i] = id
        metric_dict = {}
        if metric_type is None:
            metric_dict = object_detection_all(inference_data, ground_truth_data,
                                               inference_class_value_field=inference_class_value_field,
                                               ground_truth_class_value_field=ground_truth_class_value_field,
                                               out_data=out_data, out_data_name=out_data_name,
                                               categorys_dict=categorys_dict, iou_thr=iou_thr)


        elif metric_type == 'mAP':
            metric_dict = object_detection_map(inference_data, ground_truth_data,
                                               inference_class_value_field=inference_class_value_field,
                                               ground_truth_class_value_field=ground_truth_class_value_field,
                                               out_data=out_data, out_data_name=out_data_name,
                                               categorys_dict=categorys_dict, iou_thr=iou_thr)

        elif metric_type == 'AP':
            metric_dict = object_detection_ap(inference_data, ground_truth_data,
                                              inference_class_value_field=inference_class_value_field,
                                              ground_truth_class_value_field=ground_truth_class_value_field,
                                              out_data=out_data, out_data_name=out_data_name,
                                              categorys_dict=categorys_dict, iou_thr=iou_thr)
        elif metric_type == 'Precision':
            metric_dict = object_detection_precision(inference_data, ground_truth_data,
                                                     inference_class_value_field=inference_class_value_field,
                                                     ground_truth_class_value_field=ground_truth_class_value_field,
                                                     out_data=out_data, out_data_name=out_data_name,
                                                     categorys_dict=categorys_dict, iou_thr=iou_thr)

        elif metric_type == 'Recall':
            metric_dict = object_detection_recall(inference_data, ground_truth_data,
                                                  inference_class_value_field=inference_class_value_field,
                                                  ground_truth_class_value_field=ground_truth_class_value_field,
                                                  out_data=out_data, out_data_name=out_data_name,
                                                  categorys_dict=categorys_dict, iou_thr=iou_thr)

        elif metric_type == 'F1':
            metric_dict = object_detection_f1(inference_data, ground_truth_data,
                                              inference_class_value_field=inference_class_value_field,
                                              ground_truth_class_value_field=ground_truth_class_value_field,
                                              out_data=out_data, out_data_name=out_data_name,
                                              categorys_dict=categorys_dict, iou_thr=iou_thr)
        log_info("The ImageryEvaluation Object Detection have done!")
        print("The ImageryEvaluation Object Detection have done!")
        return metric_dict

    @staticmethod
    def object_extraction(inference_data, ground_truth_data, inference_class_value_field=None,
                          ground_truth_class_value_field='category',
                          metric_type=None, out_data='', out_data_name='metric',
                          iou_thr=''):
        """ 影像对象提取模型评估接口，可基于输入的预测标签数据集与真实标签数据集计算结果计算指标

        :param inference_data: 必选参数。推理结果数据集，输入的矢量面数据集来自于模型推理object_detect_infer
        :type inference_data: str or DatasetVector
        :param ground_truth_data: 必选参数。真实标签数据集，输入的矢量面数据集来自于真实的标签数据集
        :type ground_truth_data: str or DatasetVector
        :param inference_class_value_field: 可选参数。推理结果数据包含类别字段名。如果指定的字段为None，则默认去找'value'字段，若字段不存在，则所有记录都被认定为是同一个类。
        :type inference_class_value_field: str or None
        :param ground_truth_class_value_field: 可选参数。真实数据类别字段名。如果指定的字段为None，则默认去找'value'字段，若字段不存在，则所有记录都被认定为是同一个类。
        :type ground_truth_class_value_field: str or None
        :param metric_type: 可选参数。待计算的指标名称。默认为None，为None时输出该功能全部指标。支持的metric_type为：F1、Recall、Precision、AP、mAP。
        :type metric_type: str or None
        :param out_data: 可选参数。输出文件（或数据源）路径
        :type out_data: str or Datasource or DatasourceConnectionInfo
        :param out_data_name: 可选参数。输出文件（或数据集）名称
        :type out_data_name: str
        :param iou_thr: 可选参数。IoU(Intersection over Union)用作评估目标检测模型准确性的阈值的交集与并集的比率.分子是推理边界框和真实边界框之间的重叠区域,分母是两个边界框合并的区域。IoU值应在0到1的范围内,[0,1] 示例：0.5
        :type iou_thr: float

        :return: tuple (metric_type ,[dict, dict, ...])
        """
        from ._evaluation.object_extraction_metrics import object_extraction_all, object_extraction_map, \
            object_extraction_ap, object_extraction_precision, object_extraction_recall, object_extraction_f1
        check_lic()

        ground_truth_data = get_input_dataset(ground_truth_data)
        if ground_truth_data is None:
            log_error('ground_truth_data is None')
            raise ValueError('ground_truth_data is None')
        if not isinstance(ground_truth_data, DatasetVector):
            log_error('ground_truth_data must be DatasetVector')
            raise Exception('ground_truth_data must be DatasetVector')

        inference_data = get_input_dataset(inference_data)
        if inference_data is None:
            log_error('inference_data is None')
            raise ValueError('inference_data is None')
        if not isinstance(inference_data, DatasetVector):
            log_error('inference_data must be DatasetVector')
            raise Exception('inference_data must be DatasetVector')

        # 从ground_truth_class_value_field与inference_class_value_field获取类别字典
        if ground_truth_class_value_field is None or inference_class_value_field is None:
            if ground_truth_class_value_field is None:
                ground_truth_class_value_field = 'value'
            if inference_class_value_field is None:
                inference_class_value_field = 'value'
            try:
                categorys = _get_unique_values(ground_truth_data, ground_truth_class_value_field)
                categorys.extend(_get_unique_values(inference_data, inference_class_value_field))
                categorys = list(set(categorys))
                categorys.sort()
            except:
                log_warning(
                    'ground_truth_class_value_field or inference_class_value_field is set to None; at the same time, there is no value field in inference_data or ground_truth_data; so categories are classified into the same category by default')
                categorys = ['unspecified']
                ground_truth_class_value_field = None
                inference_class_value_field = None

        else:
            try:
                categorys = _get_unique_values(ground_truth_data, ground_truth_class_value_field)
                categorys.extend(_get_unique_values(inference_data, inference_class_value_field))
                categorys = list(set(categorys))
                categorys.sort()
            except:
                log_warning(
                    'ground_truth_class_value_field or inference_class_value_field is not exist;  so categories are classified into the same category by default')
                categorys = ['unspecified']
                categorys.sort()
                ground_truth_class_value_field = None
                inference_class_value_field = None
        categorys_dict = {}
        for id, i in enumerate(categorys):
            categorys_dict[i] = id
        metric_dict = {}
        if metric_type is None:
            metric_dict = object_extraction_all(inference_data, ground_truth_data,
                                                inference_class_value_field=inference_class_value_field,
                                                ground_truth_class_value_field=ground_truth_class_value_field,
                                                out_data=out_data, out_data_name=out_data_name,
                                                categorys_dict=categorys_dict, iou_thr=iou_thr)


        elif metric_type == 'mAP':
            metric_dict = object_extraction_map(inference_data, ground_truth_data,
                                                inference_class_value_field=inference_class_value_field,
                                                ground_truth_class_value_field=ground_truth_class_value_field,
                                                out_data=out_data, out_data_name=out_data_name,
                                                categorys_dict=categorys_dict, iou_thr=iou_thr)

        elif metric_type == 'AP':
            metric_dict = object_extraction_ap(inference_data, ground_truth_data,
                                               inference_class_value_field=inference_class_value_field,
                                               ground_truth_class_value_field=ground_truth_class_value_field,
                                               out_data=out_data, out_data_name=out_data_name,
                                               categorys_dict=categorys_dict, iou_thr=iou_thr)
        elif metric_type == 'Precision':
            metric_dict = object_extraction_precision(inference_data, ground_truth_data,
                                                      inference_class_value_field=inference_class_value_field,
                                                      ground_truth_class_value_field=ground_truth_class_value_field,
                                                      out_data=out_data, out_data_name=out_data_name,
                                                      categorys_dict=categorys_dict)


        elif metric_type == 'Recall':
            metric_dict = object_extraction_recall(inference_data, ground_truth_data,
                                                   inference_class_value_field=inference_class_value_field,
                                                   ground_truth_class_value_field=ground_truth_class_value_field,
                                                   out_data=out_data, out_data_name=out_data_name,
                                                   categorys_dict=categorys_dict)

        elif metric_type == 'F1':
            metric_dict = object_extraction_f1(inference_data, ground_truth_data,
                                               inference_class_value_field=inference_class_value_field,
                                               ground_truth_class_value_field=ground_truth_class_value_field,
                                               out_data=out_data, out_data_name=out_data_name,
                                               categorys_dict=categorys_dict)
        log_info("The ImageryEvaluation Object Extraction have done!")
        print("The ImageryEvaluation Object Extraction have done!")
        return metric_dict

    @staticmethod
    def binary_classification(inference_data, ground_truth_data, inference_class_value_field=None,
                              ground_truth_class_value_field=None,
                              metric_type=None, out_data='', out_data_name='metric'):
        """
        影像二元分类模型评估接口，可基于输入的真实标签数据和预测标签数据计算结果，支持影像和影像数据计算，矢量和矢量数据计算。


        :param inference_data: 必选参数。推理结果数据集，输入的矢量面数据集来自于模型推理object_detect_infer
        :type inference_data: str or DatasetVector
        :param ground_truth_data: 必选参数。真实标签数据集，输入的矢量面数据集来自于真实的标签数据集
        :type ground_truth_data: str or DatasetVector
        :param inference_class_value_field: 可选参数。推理结果数据包含类别字段名。如果指定的字段为None，则默认去找'value'字段，若字段不存在，则所有记录都被认定为是同一个类
        :type inference_class_value_field: str or None
        :param ground_truth_class_value_field: 可选参数。真实数据类别字段名。如果指定的字段为None，则默认去找'value'字段，若字段不存在，则所有记录都被认定为是同一个类
        :type ground_truth_class_value_field: str or None
        :param metric_type: 可选参数。待计算的指标名称。默认为None，为None时输出该功能全部指标。支持的metric_type为：PA,IoU,F1,Kappa
        :type metric_type: str or None
        :param out_data: 可选参数。输出文件（或数据源）路径
        :type out_data: str or Datasource or DatasourceConnectionInfo
        :param out_data_name: 可选参数。输出文件（或数据集）名称
        :type out_data_name: str

        :return: tuple (metric_type ,[dict, dict, ...])
        """

        from ._evaluation.binary_classification_metrics import binary_classification_all, binary_classification_iou, \
            binary_classification_pixel_acc \
            , binary_classification_f1, binary_classification_kappa, \
            binary_classification_confusion_matrix

        metric_dict = {}
        if metric_type is None:

            metric_dict = binary_classification_all(inference_data, ground_truth_data,
                                                    inference_class_value_field=inference_class_value_field,
                                                    ground_truth_class_value_field=ground_truth_class_value_field,
                                                    out_data=out_data, out_data_name=out_data_name)


        elif metric_type == 'IoU':
            metric_dict = binary_classification_iou(inference_data, ground_truth_data,
                                                    inference_class_value_field=inference_class_value_field,
                                                    ground_truth_class_value_field=ground_truth_class_value_field,
                                                    out_data=out_data, out_data_name=out_data_name)


        elif metric_type == 'CPA':
            metric_dict = binary_classification_pixel_acc(inference_data, ground_truth_data,
                                                          inference_class_value_field=inference_class_value_field,
                                                          ground_truth_class_value_field=ground_truth_class_value_field,
                                                          out_data=out_data, out_data_name=out_data_name)


        elif metric_type == 'F1':
            metric_dict = binary_classification_f1(inference_data, ground_truth_data,
                                                   inference_class_value_field=inference_class_value_field,
                                                   ground_truth_class_value_field=ground_truth_class_value_field,
                                                   out_data=out_data, out_data_name=out_data_name)



        elif metric_type == 'Kappa':
            metric_dict = binary_classification_kappa(inference_data, ground_truth_data,
                                                      inference_class_value_field=inference_class_value_field,
                                                      ground_truth_class_value_field=ground_truth_class_value_field,
                                                      out_data=out_data, out_data_name=out_data_name)


        elif metric_type == 'confusion_matrix':
            metric_dict = binary_classification_confusion_matrix(inference_data, ground_truth_data,
                                                                 inference_class_value_field=inference_class_value_field,
                                                                 ground_truth_class_value_field=ground_truth_class_value_field,
                                                                 out_data=out_data, out_data_name=out_data_name)

        log_info("The ImageryEvaluation Binary Classification  have done!")
        print("The ImageryEvaluation Binary Classification  have done!")
        return metric_dict

    @staticmethod
    def multi_classification(inference_data, ground_truth_data, inference_class_value_field=None,
                             ground_truth_class_value_field=None,
                             metric_type=None, out_data='', out_data_name='metric'):
        """
        影像地物分类模型评估接口，可基于输入的真实标签数据和预测标签数据计算结果，支持影像和影像数据计算，矢量和矢量数据计算。


        :param inference_data: 必选参数。推理结果数据集，输入的矢量面数据集来自于模型推理object_detect_infer
        :type inference_data: str or DatasetVector
        :param ground_truth_data: 必选参数。真实标签数据集，输入的矢量面数据集来自于真实的标签数据集
        :type ground_truth_data: str or DatasetVector
        :param inference_class_value_field: 可选参数。推理结果数据包含类别字段名。如果指定的字段为None，则默认去找'value'字段，若字段不存在，则所有记录都被认定为是同一个类
        :type inference_class_value_field: str or None
        :param ground_truth_class_value_field: 可选参数。真实数据类别字段名。如果指定的字段为None，则默认去找'value'字段，若字段不存在，则所有记录都被认定为是同一个类
        :type ground_truth_class_value_field: str or None
        :param metric_type: 可选参数。待计算的指标名称。默认为None，为None时输出该功能全部指标。支持的metric_type为：F1,CPA,IoU,Kappa,mPA,mIoU
        :type metric_type: str or None
        :param out_data: 可选参数。输出文件（或数据源）路径
        :type out_data: str or Datasource or DatasourceConnectionInfo
        :param out_data_name: 可选参数。输出文件（或数据集）名称
        :type out_data_name: str

        :return: tuple (metric_type ,[dict, dict, ...])
        """

        from ._evaluation.multi_classification_metrics import multi_classification_all, multi_classification_iou, \
            multi_classification_pixel_acc, multi_classification_f1, multi_classification_mean_iou, \
            multi_classification_mean_pixel_acc, multi_classification_kappa, multi_classification_confusion_matrix
        metric_dict = {}
        if metric_type is None:

            metric_dict = multi_classification_all(inference_data, ground_truth_data,
                                                   inference_class_value_field=inference_class_value_field,
                                                   ground_truth_class_value_field=ground_truth_class_value_field,
                                                   out_data=out_data, out_data_name=out_data_name)





        elif metric_type == 'CPA':
            metric_dict = multi_classification_pixel_acc(inference_data, ground_truth_data,
                                                         inference_class_value_field=inference_class_value_field,
                                                         ground_truth_class_value_field=ground_truth_class_value_field,
                                                         out_data=out_data, out_data_name=out_data_name)

        elif metric_type == 'IoU':
            metric_dict = multi_classification_iou(inference_data, ground_truth_data,
                                                   inference_class_value_field=inference_class_value_field,
                                                   ground_truth_class_value_field=ground_truth_class_value_field,
                                                   out_data=out_data, out_data_name=out_data_name)


        elif metric_type == 'F1':
            metric_dict = multi_classification_f1(inference_data, ground_truth_data,
                                                  inference_class_value_field=inference_class_value_field,
                                                  ground_truth_class_value_field=ground_truth_class_value_field,
                                                  out_data=out_data, out_data_name=out_data_name)



        elif metric_type == 'Kappa':
            metric_dict = multi_classification_kappa(inference_data, ground_truth_data,
                                                     inference_class_value_field=inference_class_value_field,
                                                     ground_truth_class_value_field=ground_truth_class_value_field,
                                                     out_data=out_data, out_data_name=out_data_name)

        elif metric_type == 'mPA':
            metric_dict = multi_classification_mean_pixel_acc(inference_data, ground_truth_data,
                                                              inference_class_value_field=inference_class_value_field,
                                                              ground_truth_class_value_field=ground_truth_class_value_field,
                                                              out_data=out_data, out_data_name=out_data_name)

        elif metric_type == 'mIoU':
            metric_dict = multi_classification_mean_iou(inference_data, ground_truth_data,
                                                        inference_class_value_field=inference_class_value_field,
                                                        ground_truth_class_value_field=ground_truth_class_value_field,
                                                        out_data=out_data, out_data_name=out_data_name)
        elif metric_type == 'confusion_matrix':
            metric_dict = multi_classification_confusion_matrix(inference_data, ground_truth_data,
                                                                inference_class_value_field=inference_class_value_field,
                                                                ground_truth_class_value_field=ground_truth_class_value_field,
                                                                out_data=out_data, out_data_name=out_data_name)
        log_info("The ImageryEvaluation Multi Classification  have done!")
        print("The ImageryEvaluation Multi Classification  have done!")
        return metric_dict

    @staticmethod
    def general_change_detection(inference_data, ground_truth_data, inference_class_value_field=None,
                                 ground_truth_class_value_field=None,
                                 metric_type=None, out_data='', out_data_name='metric'):
        """
        影像通用变化检测模型评估接口，可基于输入的真实标签数据和预测标签数据计算结果，支持影像和影像数据计算，矢量和矢量数据计算。

        :param inference_data: 必选参数。推理结果数据集，输入的矢量面数据集来自于模型推理object_detect_infer
        :type inference_data: str or DatasetVector
        :param ground_truth_data: 必选参数。真实标签数据集，输入的矢量面数据集来自于真实的标签数据集
        :type ground_truth_data: str or DatasetVector
        :param inference_class_value_field: 可选参数。推理结果数据包含类别字段名。如果指定的字段为None，则默认去找'value'字段，若字段不存在，则所有记录都被认定为是同一个类
        :type inference_class_value_field: str or None
        :param ground_truth_class_value_field: 可选参数。真实数据类别字段名。如果指定的字段为None，则默认去找'value'字段，若字段不存在，则所有记录都被认定为是同一个类
        :type ground_truth_class_value_field: str or None
        :param metric_type: 可选参数。待计算的指标名称。默认为None，为None时输出该功能全部指标。支持的metric_type为：PA,IoU,F1,Kappa
        :type metric_type: str or None
        :param out_data: 可选参数。输出文件（或数据源）路径
        :type out_data: str or Datasource or DatasourceConnectionInfo
        :param out_data_name: 可选参数。输出文件（或数据集）名称
        :type out_data_name: str

        :return: tuple (metric_type ,[dict, dict, ...])
        """

        from ._evaluation.general_change_detection_metrics import general_change_detection_all, \
            general_change_detection_iou, \
            general_change_detection_pixel_acc \
            , general_change_detection_f1, general_change_detection_kappa, \
            general_change_detection_confusion_matrix
        metric_dict = {}
        if metric_type is None:

            metric_dict = general_change_detection_all(inference_data, ground_truth_data,
                                                       inference_class_value_field=inference_class_value_field,
                                                       ground_truth_class_value_field=ground_truth_class_value_field,
                                                       out_data=out_data, out_data_name=out_data_name)


        elif metric_type == 'IoU':
            metric_dict = general_change_detection_iou(inference_data, ground_truth_data,
                                                       inference_class_value_field=inference_class_value_field,
                                                       ground_truth_class_value_field=ground_truth_class_value_field,
                                                       out_data=out_data, out_data_name=out_data_name)


        elif metric_type == 'CPA':
            metric_dict = general_change_detection_pixel_acc(inference_data, ground_truth_data,
                                                             inference_class_value_field=inference_class_value_field,
                                                             ground_truth_class_value_field=ground_truth_class_value_field,
                                                             out_data=out_data, out_data_name=out_data_name)


        elif metric_type == 'F1':
            metric_dict = general_change_detection_f1(inference_data, ground_truth_data,
                                                      inference_class_value_field=inference_class_value_field,
                                                      ground_truth_class_value_field=ground_truth_class_value_field,
                                                      out_data=out_data, out_data_name=out_data_name)




        elif metric_type == 'Kappa':
            metric_dict = general_change_detection_kappa(inference_data, ground_truth_data,
                                                         inference_class_value_field=inference_class_value_field,
                                                         ground_truth_class_value_field=ground_truth_class_value_field,
                                                         out_data=out_data, out_data_name=out_data_name)


        elif metric_type == 'confusion_matrix':
            metric_dict = general_change_detection_confusion_matrix(inference_data, ground_truth_data,
                                                                    inference_class_value_field=inference_class_value_field,
                                                                    ground_truth_class_value_field=ground_truth_class_value_field,
                                                                    out_data=out_data, out_data_name=out_data_name)
        log_info("The ImageryEvaluation General Change Detection have done!")
        print("The ImageryEvaluation General Change Detection have done!")
        return metric_dict

    def __clean_tempdir(method):
        import shutil
        # 装饰器：是否成功完成都可以清理temp文件夹，避免在用户C盘产生冗余文件
        def wrapper(self,*args, **kwargs):
            try:
                return method(self,*args, **kwargs)
            except Exception as e:
                raise e
            finally:
                try:
                    shutil.rmtree(self.tmp_data_dir)
                    print("Successfully cleared temporary folder:{}".format(self.tmp_data_dir))
                except Exception as e:
                    print("Clearing temporary folder:{} failed,please check the folder".format(self.tmp_data_dir))
                    raise e

        return wrapper

    @__clean_tempdir
    def super_resolution(self,inference_data, ground_truth_data, metric_type=None, out_data='', out_data_name='metric',
                         **kwargs):
        """
        影像超分模型评估接口，可基于输入的真实图像数据和预测图像数据计算结果，仅支持影像和影像计算。
        :param inference_data: 必选参数。推理结果数据集
        :type inference_data: str or DatasetVector
        :param ground_truth_data: 必选参数。推理结果相对应的高分辨率数据集
        :type ground_truth_data: str or DatasetVector
        :param metric_type: 可选参数。待计算的指标名称。默认为None，为None时输出该功能全部指标。支持的metric_type为：PSNR,SSIM,FID
        :type metric_type: str or None
        :param out_data: 可选参数。输出文件（或数据源）路径
        :type out_data: str or Datasource or DatasourceConnectionInfo
        :param out_data_name: 可选参数。输出文件（或数据集）名称
        :type out_data_name: str

        :return: tuple (metric_type ,[dict, dict, ...])
        """
        from ._evaluation.super_resolution_metrics import super_resolution_all, super_resolution_psnr, \
            super_resolution_fid, \
            super_resolution_ssim
        # 对输入数据进行前置处理
        inference_data_list = self.__get_input_data_list(inference_data)
        ground_truth_data_list = self.__get_input_data_list(ground_truth_data)
        if len(inference_data_list) != len(ground_truth_data_list) or len(inference_data_list) == 0\
                or len(ground_truth_data_list) == 0:
            raise ValueError('The quantity of the input data is incorrect.')
        metric_dict = {}
        if metric_type is None:
            metric_dict = super_resolution_all(inference_data_list, ground_truth_data_list, out_data, out_data_name, **kwargs)
        elif metric_type == 'PSNR':
            metric_dict = super_resolution_psnr(inference_data_list, ground_truth_data_list, out_data, out_data_name)
        elif metric_type == 'SSIM':
            metric_dict = super_resolution_ssim(inference_data_list, ground_truth_data_list, out_data, out_data_name)
        elif metric_type == 'FID':
            metric_dict = super_resolution_fid(inference_data_list, ground_truth_data_list, out_data, out_data_name, **kwargs)
        log_info("The ImageryEvaluation Super Resolution have done!")
        print("The ImageryEvaluation Super Resolution have done!")
        return metric_dict

    def __get_input_data_list(self, input_data):
        from iobjectspy import DatasetImage, DatasetMosaic
        from ..toolkit._toolkit import _is_image_file, _get_dataset_readonly, get_pic_path_from_dir
        import traceback
        infer_list = []
        if isinstance(input_data, DatasetImage):
            # 单张影像数据集对象
            self.__imagery_in_type = _ImageryInType.DATASETIMAGE
            log_info('Infer Data Type: DatasetImage.')
            infer_list.append(self.__get_dataset_to_tmp_tif_path(input_data))

        elif isinstance(input_data, DatasetMosaic):
            # 镶嵌数据集对象
            self.__imagery_in_type = _ImageryInType.DATASETMOSAIC
            log_info('Infer Data Type: DatasetMosaic.')
            infer_list = input_data.list_files()
            infer_list.sort()

        elif isinstance(input_data, list):
            # 影像文件路径list对象
            self.__imagery_in_type = _ImageryInType.FILELIST
            log_info('Infer Data Type: Imagery File List.')
            infer_list = input_data

        elif isinstance(input_data, str):
            if os.path.isdir(input_data):
                # 含有影像文件的目录
                self.__imagery_in_type = _ImageryInType.FILEDIR
                log_info('Infer Data Type: Imagery File Directory.')
                suffix = ['.tif', '.TIF', '.tiff', '.TIFF', '.img', '.IMG', '.jpg', '.JPG', '.png', '.PNG', '.bmp', '.BMP']
                infer_list = get_pic_path_from_dir(input_data, True, suffix)
                infer_list.sort()

            elif _is_image_file(input_data):
                # 单张影像文件
                self.__imagery_in_type = _ImageryInType.SINGLEFILE
                log_info('Infer Data Type: Single Imagery File.')
                infer_list.append(input_data)

            else:
                # 字符串形式输入的数据集形式，支持单张影像数据集和镶嵌数据集
                try:
                    input_data = _get_dataset_readonly(input_data)
                except Exception:
                    traceback.print_exc()
                    raise TypeError('Input Data Type is not Supported!')

                if isinstance(input_data, DatasetMosaic):
                    self.__imagery_in_type = _ImageryInType.DATASETMOSAIC
                    log_info('Infer Data Type: DatasetMosaic.')
                    infer_list = input_data.list_files()

                elif isinstance(input_data, DatasetImage):
                    self.__imagery_in_type = _ImageryInType.DATASETIMAGE
                    log_info('Infer Data Type: DatasetImage.')
                    infer_list.append(self.__get_dataset_to_tmp_tif_path(input_data))
                else:
                    raise TypeError('Input Data Type is not Supported!')
        else:
            raise TypeError('Input Data Type is not Supported!')

        return infer_list

    def __get_dataset_to_tmp_tif_path(self, input_data):
        from iobjectspy import conversion
        self.tmp_data_dir = tempfile.mkdtemp()
        temp_tif_path = os.path.join(self.tmp_data_dir, input_data.name + '.tif')
        conversion.export_to_tif(input_data, temp_tif_path)
        log_info('Tmp Imagery is Saved in: {}'.format(temp_tif_path))
        return temp_tif_path
