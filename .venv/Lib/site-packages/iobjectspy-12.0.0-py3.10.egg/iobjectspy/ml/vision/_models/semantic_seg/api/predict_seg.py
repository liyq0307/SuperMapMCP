import os

import numpy as np
import torch
from tqdm import tqdm

from iobjectspy._jsuperpy.data._util import get_output_datasource
from iobjectspy._logger import log_warning
from ..api.base_torch_estimation import BaseTorchEstimation
from ..dataio import SegDataIO
from ..tools import SaveTools
from .....toolkit._toolkit import get_available_filename
from ...device_utils import Device_type


class SegTorchEstimation(BaseTorchEstimation):
    def _predict_with_rasterio(self, dom_path, out_ds, dst_name, single_threshold=0.5,
                               result_type='grid', batch_size=1, infer_region=None, confidence_map=False):

        out_tmp_name, tmp_file = self._prepare_output_file(out_ds, dst_name)

        seg_dataloader = self._create_dataio(dom_path, tmp_file, batch_size, infer_region, confidence_map)

        self._process_batches(seg_dataloader, single_threshold, confidence_map)

        result = self._finalize_result(result_type, out_ds, dst_name, tmp_file, out_tmp_name, infer_region)

        return result

    def _prepare_output_file(self, out_ds, dst_name):
        """
        准备推理数据
        :param out_ds:
        :param dst_name:
        :return:
        """
        is_tif = any(dst_name.lower().endswith(ext) for ext in ['.tif', '.tiff'])
        if is_tif:
            return get_available_filename(out_ds, dst_name)
        else:
            out_ds = get_output_datasource(out_ds)
            return get_available_filename(os.path.dirname(out_ds.connection_info.server), dst_name + '.tif')

    def _create_dataio(self, dom_path, tmp_file, batch_size, infer_region, confidence_map):
        """
        实例化dataloader
        :param dom_path:
        :param tmp_file:
        :param batch_size:
        :param infer_region:
        :param confidence_map:
        :return:
        """
        return SegDataIO(
            input_path=dom_path,
            out_path=tmp_file,
            block_size=self.seg_size,
            batch_size=batch_size,
            cut_edge=self.half_oversize,
            color_map=self.color_map,
            preprocessing_fn=self.preprocessing,
            band_index=[i + 1 for i in range(self.input_bands)],
            infer_region=infer_region,
            confidence_map=confidence_map
        )

    def _process_batches(self, seg_dataio, single_threshold, confidence_map):
        """
        批量推理流程，这里是将大影像按行读取到内存进行批量推理，然后保存结果
        :param seg_dataio:
        :param single_threshold:
        :param confidence_map:
        :return:
        """
        for i in tqdm(range(len(seg_dataio)), desc='Model Infer'):
            data, batch_blocks = seg_dataio[i]
            mask_block = self._predict_on_batch(data)
            out_data = self._process_mask(mask_block, single_threshold, confidence_map)
            seg_dataio.write_batch(out_data, batch_blocks)

        seg_dataio.close_src()
        seg_dataio.write_large_patch()
        seg_dataio.close_dst()

    @torch.no_grad()
    def _predict_on_batch(self, predict_tiles):
        batch_data = predict_tiles
        x_tensor = torch.from_numpy(batch_data).to(self.device)

        with torch.no_grad():
            pr_mask = self.model.forward(x_tensor)
        pr_mask = (pr_mask.cpu().detach().numpy())

        return pr_mask

    def _process_mask(self, mask_block, single_threshold, confidence_map):
        if self.output_msk_num > 1:
            mask = np.argmax(mask_block, axis=1)[:, np.newaxis, :, :]
        elif confidence_map:
            mask = mask_block
        else:
            mask = mask_block > single_threshold

        mask = mask.astype(np.float32 if confidence_map else np.uint8)
        return mask[:, np.newaxis, :, :] if len(mask.shape) < 4 else mask

    def _finalize_result(self, result_type, out_ds, dst_name, tmp_file, out_tmp_name, infer_region):
        """
        保存结果数据
        :param result_type:
        :param out_ds:
        :param dst_name:
        :param tmp_file:
        :param out_tmp_name:
        :return:
        """
        if result_type.strip() == 'grid':
            return SaveTools.finalize_grid_result(out_ds, dst_name, tmp_file, out_tmp_name)
        elif result_type.strip() == 'region':
            return SaveTools.finalize_region_result(out_ds, dst_name, tmp_file, self.back_or_no_value, infer_region)
        else:
            raise ValueError('Invalid result_type')

    def close_model(self):
        # todo close model
        try:
            del self.model
            Device_type.empty_cache()
        except Exception as e:
            log_warning('Close model error : {}'.format(e))
        pass
