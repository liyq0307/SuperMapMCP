import sys

import numpy as np
import torch
import torch.distributed as dist
from tqdm import tqdm as tqdm
import re
from .._torch_models.util.meter import AverageMeter, intersectionAndUnionGPU
from .base_epoch import Epoch


class SegEpoch(Epoch):

    def __init__(self, model, loss, metrics, stage_name,
                 device='cpu', verbose=True, **kwargs):
        self.model = model
        self.loss = loss
        self.metrics = metrics
        self.stage_name = stage_name
        self.verbose = verbose
        self.device = device
        self._to_device()

    def _to_device(self):
        self.model.to(self.device)
        self.loss.to(self.device)
        for metric in self.metrics:
            metric.to(self.device)

    def run(self, epoch_info, dataloader, multiprocessing_distributed, Rank):
        self.multiprocessing_distributed = multiprocessing_distributed
        self.Rank = Rank
        self.on_epoch_start()

        logs = {}
        meters = {
            'loss': AverageMeter(),
            'intersection': AverageMeter(),
            'union': AverageMeter(),
            'target': AverageMeter(),
            **{metric.__name__: AverageMeter() for metric in self.metrics}
        }
        stage_name = epoch_info + ' ' + self.stage_name
        # 总步数
        total_steps = len(dataloader)
        local_progress = 0  # 当前进程的进度
        world_size = dist.get_world_size() if self.multiprocessing_distributed else 1
        # 主进程初始化合并进度条
        if Rank == 0:
            pbar = tqdm(total=total_steps * world_size, desc=stage_name, dynamic_ncols=True, file=sys.stdout)

        for step, (x, y) in enumerate(dataloader):
            if self.device == 'cuda':
                x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)
            else:
                x, y = x.to(self.device), y.to(self.device)

            loss, y_pred, output_bands = self._batch_update(x, y)

            if hasattr(self, 'optimizer'):
                self._update_lr_logs(logs)

            self._update_loss_logs(loss, x.size(0), meters, logs)
            self._update_metrics_logs(y_pred, y, output_bands, meters, logs)

            local_progress += 1  # 当前进程的进度加 1

            # 进度同步（确保所有 GPU 进度一致）
            if self.multiprocessing_distributed:
                progress_tensor = torch.tensor([local_progress], dtype=torch.float32).to(self.device)
                dist.all_reduce(progress_tensor, op=dist.ReduceOp.SUM)  # 求所有进程的进度和
                global_progress = int(progress_tensor.item())
            else:
                global_progress = local_progress  # 单 GPU 直接使用本地进度

            if Rank == 0:
                # 主进程更新进度条
                pbar.update(global_progress - pbar.n)
                if self.verbose:
                    pbar.set_postfix_str(self._format_logs(logs), refresh=True)

        if Rank == 0:
            pbar.close()

        return logs, y_pred

    def _update_lr_logs(self, logs):
        lr = self.optimizer.param_groups[0]['lr']
        logs['lr'] = lr

    def _update_loss_logs(self, loss, batch_size, meters, logs):
        if self.multiprocessing_distributed:
            loss, batch_size = self._reduce_loss(loss, batch_size)

        meters['loss'].update(loss.item(), batch_size)
        loss_name = self.loss.__name__
        loss_name = re.sub(r'\s*\+\s*', '___', loss_name)
        logs[loss_name] = meters['loss'].val

    def _reduce_loss(self, loss, batch_size):
        loss = loss * batch_size
        count = torch.tensor([batch_size], dtype=torch.long, device=self.device)
        dist.all_reduce(loss)
        dist.all_reduce(count)
        return loss / count.item(), count.item()

    def _update_metrics_logs(self, y_pred, y, output_bands, meters, logs):
        metric_class = 2 if output_bands == 1 else output_bands
        intersection, union, target = intersectionAndUnionGPU(y_pred, y, metric_class, self.device)

        if self.multiprocessing_distributed:
            dist.all_reduce(intersection)
            dist.all_reduce(union)
            dist.all_reduce(target)

        intersection, union, target = intersection.cpu().numpy(), union.cpu().numpy(), target.cpu().numpy()
        meters['intersection'].update(intersection)
        meters['union'].update(union)
        meters['target'].update(target)

        iou_class = meters['intersection'].sum / (meters['union'].sum + 1e-10)
        accuracy_class = meters['intersection'].sum / (meters['target'].sum + 1e-10)
        recall_class = meters['intersection'].sum / (
                meters['union'].sum - meters['target'].sum + meters['intersection'].sum + 1e-10)
        f1_class = 2 * accuracy_class * recall_class / (accuracy_class + recall_class + 1e-10)

        F1 = f1_class[1] if output_bands == 1 else np.mean(f1_class)
        IoU = iou_class[1] if output_bands == 1 else np.mean(iou_class)

        for metric_fn in self.metrics:
            value = IoU if metric_fn.__name__ == 'iou_score' else F1
            meters[metric_fn.__name__].update(value)
            logs[metric_fn.__name__] = meters[metric_fn.__name__].val


class TrainEpoch(SegEpoch):
    def __init__(self, model, loss, metrics, optimizer, device='cpu', verbose=True, **kwargs):
        super().__init__(
            model=model,
            loss=loss,
            metrics=metrics,
            stage_name='train',
            device=device,
            verbose=verbose,
        )
        self.optimizer = optimizer
        self.init_lr = self.optimizer.param_groups[0]['lr']
        self.global_step = kwargs.get('start_epoch')[0] * kwargs.get('start_epoch')[1]
        self.lr_sh = kwargs.get('lr_sh')
        self.scheduler = kwargs.get('scheduler')

    def on_epoch_start(self):
        self.model.train()

    def _batch_update(self, x, y):
        self.global_step += 1
        self.scheduler(self.optimizer, self.global_step)
        self.optimizer.zero_grad()
        prediction = self.model.forward(x, y)
        if isinstance(prediction, tuple):
            _, output_bands, _, _ = prediction[1].size()
            loss = prediction[0]
        else:
            _, output_bands, _, _ = prediction.size()
            if output_bands == 1:
                loss = self.loss(prediction.squeeze(dim=1), y.float())
            else:
                loss = self.loss(prediction, y)
        if not self.multiprocessing_distributed:
            loss = torch.mean(loss)
        loss.backward()
        self.optimizer.step()
        if isinstance(prediction, tuple):
            prediction_out = prediction[1]
        else:
            if output_bands == 1:
                prediction_out = torch.cat((1 - prediction, prediction), 1)
            else:
                prediction_out = prediction
        return loss, prediction_out.max(1)[1], output_bands


class ValidEpoch(SegEpoch):

    def __init__(self, model, loss, metrics, device='cpu', verbose=True):
        super().__init__(
            model=model,
            loss=loss,
            metrics=metrics,
            stage_name='valid',
            device=device,
            verbose=verbose,
        )

    def on_epoch_start(self):
        self.model.eval()

    def _batch_update(self, x, y):
        with torch.no_grad():
            prediction = self.model.forward(x, y)
            loss, prediction_out = self._process_prediction(prediction, y)
            output_bands = prediction_out.size(1)
        return loss, prediction_out.max(1)[1], output_bands

    def _process_prediction(self, prediction, y):
        if isinstance(prediction, tuple):
            return prediction[0], prediction[1]

        _, output_bands, _, _ = prediction.size()
        if output_bands == 1:
            loss = self.loss(prediction.squeeze(dim=1), y.float())
            prediction_out = torch.cat((1 - prediction, prediction), 1)
        else:
            loss = self.loss(prediction, y)
            prediction_out = prediction

        return loss, prediction_out
