import math

import torch

from iobjectspy._logger import log_info
from .._torch_models.util.ranger import Ranger, RangerVA, RangerQH


class LRScheduler(object):
    """Learning Rate Scheduler Parameters
    ----------
    :param mode: Modes for learning rate scheduler.Currently it supports 'constant', 'step', 'linear', 'poly' and 'cosine'.
    :type mode: str
    :param base_lr: Base learning rate, i.e. the starting learning rate.
    :type base_lr: float
    :param target_lr: Target learning rate, i.e. the ending learning rate.With constant mode target_lr is ignored.
    :param nepochs: Number of epochs to be scheduled.
    :type nepochs: int
    :param iters_per_epoch: Number of iterations in each epoch.
    :type iters_per_epoch: int
    :param power: Power parameter of poly scheduler.
    :type power: float
    :param step_ratio: A list of step ratio to decay the learning rate.
    :type step_ratio: list
    :param step_factor: Learning rate decay factor.
    :type step_factor : float
    ----------
    """

    def __init__(self, warmup_mode='Exp', decay_mode='Exp', base_lr=0.01, target_lr=0, nepochs=0, iters_per_epoch=0,
                 power=0.9, step_ratio=[0.4, 0.7, 0.9], step_factor=0.1, warmup_epochs=0):
        super(LRScheduler, self).__init__()
        assert (warmup_mode in ['Constant', 'Step', 'Linear', 'Exp', 'CosineAnnealing', 'Fixed', 'Close', 'Poly'])
        assert (decay_mode in ['Constant', 'Step', 'Linear', 'Exp', 'CosineAnnealing', 'Fixed', 'Close', 'Poly'])

        self.niters = nepochs * iters_per_epoch
        self.iters_per_epoch = iters_per_epoch
        self.step = [int(s * self.niters) for s in step_ratio]

        self.step_factor = step_factor
        self.base_lr = base_lr
        self.target_lr_warmup = base_lr if warmup_mode == 'Constant' or warmup_mode == 'Fixed' or warmup_mode == 'Close' else target_lr
        self.target_lr_decay = base_lr if decay_mode == 'Constant' or decay_mode == 'Fixed' or decay_mode == 'Close' else target_lr
        self.power = power
        self.warmup_iters = 0 if warmup_mode == 'Close' else warmup_epochs * iters_per_epoch
        if nepochs == 1:
            self.warmup_iters = 0
        self.warmup_mode = warmup_mode
        self.decay_mode = decay_mode
        log_info(f'Warmup mode is {warmup_mode}')
        log_info(f'The number of warmup_iters is {self.warmup_iters}')
        log_info(f'Decay mode is {decay_mode}')

    def __call__(self, optimizer, num_update):
        self.update(num_update)
        assert self.learning_rate >= 0
        self._adjust_learning_rate(optimizer, self.learning_rate)

    def update(self, num_update):
        T = num_update
        N = self.niters - self.warmup_iters
        # warm up lr scheduler
        if self.warmup_iters > 0 and T < self.warmup_iters:
            if self.warmup_mode == "Linear" or self.warmup_mode == "Step":
                factor = 1.0 * T / self.warmup_iters
            elif self.warmup_mode == "Exp":
                factor = pow(T / self.warmup_iters, self.power)
            elif self.warmup_mode == "Poly":
                factor = pow(T / self.warmup_iters, self.power)
            elif self.warmup_mode == "CosineAnnealing":
                factor = 1 - (1 + math.cos(math.pi * T / self.warmup_iters)) / 2
            elif self.warmup_mode == "Constant" or self.warmup_mode == 'Fixed':
                factor = 0
            else:
                raise ValueError("Unknown warmup scheduler type: {}".format(self.warmup_mode))
            self.learning_rate = self.target_lr_warmup + (self.base_lr - self.target_lr_warmup) * factor
        else:
            T = T - self.warmup_iters
            T = min(max(0, T), N)
            if self.decay_mode == 'Constant' or self.decay_mode == 'Fixed' or self.decay_mode == 'Close':
                factor = 0
            elif self.decay_mode == 'Linear':
                factor = 1 - T / N
            elif self.decay_mode == 'Poly':
                factor = pow(1 - T / N, self.power)
            elif self.decay_mode == 'Exp':
                factor = pow(0.99, T / self.iters_per_epoch)
            elif self.decay_mode == 'CosineAnnealing':
                factor = (1 + math.cos(math.pi * T / N)) / 2
            elif self.decay_mode == 'Step':
                count = sum([1 for s in self.step if s <= T])
                factor = pow(self.step_factor, count)
            else:
                raise ValueError("Unknown lr scheduler type: {}".format(self.decay_mode))

            if self.decay_mode == 'Step':
                self.learning_rate = self.base_lr * factor
            else:
                self.learning_rate = self.target_lr_decay + (self.base_lr - self.target_lr_decay) * factor

    def _adjust_learning_rate(self, optimizer, lr):
        optimizer.param_groups[0]['lr'] = lr
        # enlarge the lr at the head
        for i in range(1, len(optimizer.param_groups)):
            optimizer.param_groups[i]['lr'] = lr  # * 10


def OptimScheduler(params, optim='adam', learning_rate=None, batch_size=2, **kwargs):
    assert (optim in ['adam', 'adamw', 'sgd', 'ranger', 'rangerva', 'rangerqh'])

    optim_default = {
        'adam': {'batch_size': 2.0, 'learning_rate': 0.0001, 'max_learning_rate': 0.005},
        'adamw': {'batch_size': 2.0, 'learning_rate': 0.00001, 'max_learning_rate': 0.00006},
        'sgd': {'batch_size': 2.0, 'learning_rate': 0.0005, 'max_learning_rate': 0.01},
        'ranger': {'batch_size': 2.0, 'learning_rate': 0.0001, 'max_learning_rate': 0.005},
        'rangerva': {'batch_size': 2.0, 'learning_rate': 0.0001, 'max_learning_rate': 0.005},
        'rangerqh': {'batch_size': 2.0, 'learning_rate': 0.0001, 'max_learning_rate': 0.005},
    }

    if learning_rate is None:
        lr = (batch_size / optim_default[optim]['batch_size']) * optim_default[optim]['learning_rate']
        lr = min(lr, optim_default[optim]['max_learning_rate'])
        log_info(f'The learning rate is empty and automatically initialized with a value of {lr}')
    else:
        lr = learning_rate

    if optim == 'adam':
        optimizer = torch.optim.Adam(params)
    elif optim == 'adamw':
        optimizer = torch.optim.AdamW(params, lr=lr, betas=(0.9, 0.999), weight_decay=0.01)
    elif optim == 'sgd':
        optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=0.0005, nesterov=False)
    elif optim == 'ranger':
        optimizer = Ranger(params=params, lr=lr)
    elif optim == 'rangerva':
        optimizer = RangerVA(params=params, lr=lr)
    elif optim == 'rangerqh':
        optimizer = RangerQH(params=params, lr=lr)
    else:
        raise Exception('Optimizer do not support {}'.format(optim))

    return optimizer, lr
