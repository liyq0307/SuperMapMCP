import copy
import os
import platform

import torch
import torch.distributed as dist
import torch.multiprocessing as mp
from tensorboardX import SummaryWriter

from iobjectspy._logger import log_error, log_warning, log_info

from ..trainer import BaseTorchTrainer
from ..datasets import DatasetBuilder
from ..dataloader import DataLoaderBuilder
from ..epoch import EpochBuilder
from ..scheduler import LRScheduler, OptimScheduler
from ..tools import ConfigLoader
from .._torch_models import build_torch_seg_model
from .._torch_models.encoders import get_preprocessing_fn
from .._torch_models.util.losses import get_loss
from .._torch_models.util.metrics import IoU, Fscore
from ...device_utils import Device_type
from .....toolkit._toolkit import split_train_val_withdirs, split_train_val_change_det
from .....toolkit._torch_model_utils import find_last
from .utils import find_free_port, count_requires_grad_parameters
import torch.nn as nn


class GELU(nn.Module):
    def forward(self, x):
        return torch.nn.functional.gelu(x)


class CompatibleUpsamplingBilinear2d(nn.Module):
    def __init__(self, size=None, scale_factor=None):
        super().__init__()
        self.size = size
        self.scale_factor = scale_factor

    def forward(self, x):
        return torch.nn.functional.interpolate(
            x,
            size=self.size,
            scale_factor=self.scale_factor,
            mode='bilinear',
            align_corners=False
        )


def modify_state_dict(state_dict):
    # 处理GELU层的版本兼容性
    modified_state_dict = {}
    for key, value in state_dict.items():
        if 'gelu' in key.lower():
            # 确保GELU层使用新的实现
            new_key = key.replace('gelu.approximate', 'gelu')
            modified_state_dict[new_key] = value
        else:
            modified_state_dict[key] = value
    return modified_state_dict


def replace_upsampling(module):
    for name, child in module.named_children():
        if isinstance(child, nn.UpsamplingBilinear2d):
            setattr(module, name, CompatibleUpsamplingBilinear2d(
                size=child.size,
                scale_factor=child.scale_factor
            ))
        else:
            replace_upsampling(child)


class SegTorchTrainer(BaseTorchTrainer):
    def __init__(self):
        super().__init__()

    def _generate_train_data(self):
        """
        根据任务类型将调用数据集生成接口，划分训练集和验证集
        """
        if self.sda_data_config.dataset.data_type.strip() == 'general_change_detection':
            split_train_val_change_det(
                pre_image_dirs=[os.path.join(self.train_data_path, 'Images1')],
                next_image_dirs=[os.path.join(self.train_data_path, 'Images2')],
                mask_dirs=[os.path.join(self.train_data_path, 'Masks')],
                train_txt_path=os.path.join(self.train_data_path, 'csv_path'),
                x_ext=self.sda_data_config.dataset.x_ext,
                y_ext=self.sda_data_config.dataset.y_ext,
                val_scale=self.sdt_trainer_config.trainer.validation_split
            )
        else:
            split_train_val_withdirs(
                image_dirs=[os.path.join(self.train_data_path, 'Images')],
                mask_dirs=[os.path.join(self.train_data_path, 'Masks')],
                train_txt_path=os.path.join(self.train_data_path, 'csv_path'),
                x_ext=self.sda_data_config.dataset.x_ext,
                y_ext=self.sda_data_config.dataset.y_ext,
                val_scale=self.sdt_trainer_config.trainer.validation_split
            )

    def _load_local_backbone_weight(self, backbone_weight_path, load_device):
        """
        加载本地预训练的骨干网络权重。

        该方法从指定的路径加载骨干网络的预训练权重，并将其加载到模型中。
        在加载权重时，会检查是否有缺失的键或意外的键。如果有缺失的键或意外的键，
        该方法会尝试通过调整策略加载权重。

        1. 首先尝试加载权重，并在加载时忽略与头部（head）相关的权重。
        2. 如果出现加载错误，会尝试不严格的加载（不强制键匹配）。
        3. 最后，输出日志，表明权重已经成功加载。

        :param backbone_weight_path: 预训练骨干网络权重文件的路径。
        :param load_device: 指定加载权重的设备（如 CPU 或 GPU等）。
        """
        model_dict = torch.load(backbone_weight_path, map_location=load_device)
        try:
            missing_keys, unexpected_keys = self.model.encoder.load_state_dict(
                model_dict, self.sda_data_config.dataset.x_bandnum, strict=False
            )
            keys_to_exclude = {'head.weight', 'head.bias'}
            unexpected_keys = [key for key in unexpected_keys if key not in keys_to_exclude]

            assert not missing_keys, f"Missing keys in state_dict: {missing_keys}"
            assert not unexpected_keys, f"Unexpected keys in state_dict: {unexpected_keys}"

        except Exception as e:
            self.model.encoder.load_state_dict(
                model_dict, self.sda_data_config.dataset.x_bandnum
            )

        log_info('load backbone pre-training weight from backbone_weight_path:{}'.format(backbone_weight_path))

    def _load_local_pretrained_model(self, pretrained_model_path):
        """
        加载本地预训练模型的权重。

        该方法首先检查提供的预训练模型路径是否以 `.sdm` 结尾。如果是，则尝试加载模型的 `.pth` 文件，
        或者如果 `.pth` 文件不可用，则检查是否存在加密的 `.pim` 文件并解密它。解密后，加载模型的权重。

        具体步骤：
        1. 如果 `.sdm` 文件对应的 `.pth` 权重文件存在，直接加载。
        2. 如果 `.sdm` 文件对应的 `.pim` 加密文件存在，解密并加载。
        3. 如果无法找到相应文件，尝试加载最后的 `.pth` 权重文件。
        4. 如果文件扩展名无效，抛出 `ValueError`。

        :param pretrained_model_path: 预训练模型的路径，必须以 `.sdm` 结尾
        """
        if pretrained_model_path.endswith('.sdm'):
            pretrained_model_pth_path = pretrained_model_path.replace('.sdm', '.pth')
            pretrained_model_pim_path = pretrained_model_path.replace('.sdm', '.pim')
            if os.path.exists(pretrained_model_pth_path):
                self.model.load_state_dict(torch.load(pretrained_model_pth_path).state_dict())
                log_info('Loading pre trained model from {}'.format(pretrained_model_path))
            elif os.path.exists(pretrained_model_pim_path):
                # 解密预训练权重文件
                from iobjectspy._jsuperpy._utils import check_pretrain_lic
                from ...crypto._crypto.crypto_ops import CryptoOps
                import io
                crypto = CryptoOps()
                # 读取模型id
                model_id = crypto.read_model_id(pretrained_model_pim_path)
                try:
                    check_pretrain_lic(model_id)
                except RuntimeError:
                    raise RuntimeError(f"No pretrained model License for {pretrained_model_pim_path}!")
                decrypted_data = crypto.decrypt_pth_file(pretrained_model_pim_path)
                decrypted_pth = io.BytesIO(decrypted_data)
                decrypted_model = torch.load(decrypted_pth)

                # torch版本更新引起的异常处理流
                # 如果加载的是state_dict
                if isinstance(decrypted_model, dict):
                    state_dict = modify_state_dict(decrypted_model)
                    self.model.load_state_dict(state_dict)
                else:
                    # 如果加载的是整个模型
                    for module in decrypted_model.modules():
                        if isinstance(module, torch.nn.GELU):
                            # 替换为兼容的GELU实现
                            module.__class__ = GELU
                    self.model = decrypted_model
                replace_upsampling(self.model)

                self.pim = True
                self.model_id = model_id
            else:
                latest_pth = find_last(pretrained_model_path, self.config.application.name, 'pth', 'pth')
                if latest_pth and os.path.exists(latest_pth):
                    log_info('Loading pre trained model from {}'.format(latest_pth))
                    self.model.load_state_dict(torch.load(latest_pth).state_dict())
                else:
                    log_error('There are no pre trained models in {}'.format(self.pretrained_model_path))
        else:
            raise ValueError(f"Invalid file extension for {pretrained_model_path}. Expected .sdm")

    def _load_local_pth(self, backbone_weight_path, pretrained_model_path):
        """
        加载本地模型的权重文件。

        该方法根据提供的路径加载两个权重文件：
        1. 加载骨干网络（backbone）的权重，通常是模型的编码器部分（encoder）。
        2. 加载整个网络的预训练权重。

        加载过程中会根据设备类型（如 NPU、GPU、CPU）选择合适的设备来加载权重。

        :param backbone_weight_path: 预训练骨干网络（encoder）权重文件路径。
        :param pretrained_model_path: 预训练模型（包括整个网络）权重文件路径。
        :return: None
        """
        if Device_type._device == 'npu':
            load_device = 'cpu'
        elif backbone_weight_path and "resnet" in backbone_weight_path:
            # 为了解决resnet backbone权重文件不能直接load到device的问题
            load_device = 'cpu'
        else:
            load_device = Device_type._device
        if backbone_weight_path:
            self._load_local_backbone_weight(backbone_weight_path, load_device)

        if pretrained_model_path:
            self._load_local_pretrained_model(pretrained_model_path)

    def _get_model(self):
        """
        构建并返回一个图像分割模型。

        该方法使用 `build_torch_seg_model` 函数来构建一个基于配置参数的图像分割模型。
        模型的构建包括选择输入通道数、类别数、骨干网络类型、编码器权重等。
        它还会调用 `get_loss_type()` 来获取损失函数类型，并初始化一个 `pim` 标志。

        :return: 返回构建的模型。
        """
        model = build_torch_seg_model(
            in_channels=self.sda_data_config.dataset.x_bandnum,
            classes=len(self.sda_data_config.dataset.class_type) if
            len(self.sda_data_config.dataset.class_type) > 2 else 1,
            backbone_name=self.sdt_trainer_config.model.backbone_name,
            encoder_weights=self.encoder_weights,
            net_type=self.model_architecture,
            activation=self.activation,
        )
        self.get_loss_type()
        self.pim = False

        return model

    def _build_optimizerscheduler(self):
        """
        初始化优化器，并根据是否重新加载模型的标志决定是否从 checkpoint 恢复优化器的状态。

        如果需要重新加载模型，则从保存的 checkpoint 中恢复学习率、批量大小、当前 epoch、总 epoch 数等参数，并加载优化器的状态。
        如果不需要重新加载模型，则根据当前配置初始化新的优化器。

        :return:
            - optimizer: 初始化后的优化器对象
            - new_lr: 初始化后的学习率
        """
        if self.reload_model:
            lr = self.checkpoint['lr']
            self.sdt_trainer_config.trainer.lr_method.decay = self.checkpoint['lr_decay']
            self.sdt_trainer_config.trainer.batch_size = self.checkpoint['batch_size']
            self.start_epoch = self.checkpoint['current_epoch']
            self.sdt_trainer_config.trainer.num_epochs = self.checkpoint['num_epochs']
            optimizer_state_dict = self.checkpoint['optimizer']
            optimizer, new_lr = OptimScheduler(
                self.model.parameters(),
                self.sdt_trainer_config.trainer.optimizer,
                lr,
                self.sdt_trainer_config.trainer.batch_size
            )
            optimizer.load_state_dict(optimizer_state_dict)
            log_info('Continue training.....')
            log_info(f'batch_size :{self.sdt_trainer_config.trainer.batch_size}')
            log_info(f'start_epoch :{self.start_epoch}')
            log_info(f'num_epochs :{self.sdt_trainer_config.trainer.num_epochs}')
            log_info(f'lr :{lr}')
            log_info(f'lr_decay :{self.sdt_trainer_config.trainer.lr_method.decay}')
        else:
            optimizer, new_lr = OptimScheduler(
                self.model.parameters(),
                self.sdt_trainer_config.trainer.optimizer,
                self.sdt_trainer_config.trainer.learning_rate,
                self.sdt_trainer_config.trainer.batch_size
            )

        return optimizer, new_lr

    def _setup_distributed(self):
        """
        设置分布式通信端口。

        该方法查找一个可用的端口，并构建一个分布式通信的 URL，通常用于在多节点的分布式训练中，
        设置各个进程之间的通信端口。此方法会调用 `find_free_port()` 来自动寻找一个空闲端口，
        并返回一个表示该端口的通信 URL。

        :return:
            - dist_url: 一个字符串，表示分布式训练使用的通信 URL（包含端口号）。
        """
        port = find_free_port()
        dist_url = f"tcp://127.0.0.1:{port}"
        return dist_url

    def _initialize_train_config(self, train_data_path, config, **kwargs):
        """
        初始化属性
        """
        self.init_attribute(train_data_path=train_data_path, config=config, **kwargs)

    def _prepare_training_data(self, init_data):
        """
        划分数据集
        """
        if init_data or not os.path.exists(os.path.join(self.train_data_path, 'csv_path')):
            if not os.path.exists(os.path.join(self.train_data_path, 'csv_path')):
                log_warning('parameter init_data should be true when csv_path is none, it will default to true')
            self._generate_train_data()

    def _setup_distributed_training(self, gpus):
        """
        设置分布式训练的配置。

        该方法根据传入的 GPU 列表，设置分布式训练的相关配置。包括配置环境变量以指定使用的 GPU，并检查是否使用多进程分布式训练。

        :param gpus: 一个包含用于分布式训练的 GPU ID 的列表。
        """
        self.gpus = gpus
        os.environ[Device_type.env_str] = ','.join(str(x) for x in gpus)
        self.multiprocessing_distributed = self._multiprocessing_distributed_status()

    def _multiprocessing_distributed_status(self):
        """
        检查是否启用了多进程分布式训练。

        该方法根据输入的 GPU 数量和系统中可用的 GPU 数量，判断是否需要使用多进程分布式训练。它还会检查输入的 GPU 是否在有效范围内，并验证是否超出了系统的设备数量。

        :return:
            - 如果启用了多进程分布式训练，返回 `True`，否则返回 `False`。
        """
        if len(self.gpus) == 1:
            num_gpus = Device_type.device_count()
            self.gpus = [0] if self.gpus[-1] > (num_gpus - 1) else self.gpus
            return False
        else:
            num_gpus = Device_type.device_count()
            CUDA_VISIBLE_DEVICES = [int(x) for x in os.environ.get(Device_type.env_str).split(',')]
            assert max(self.gpus) <= max(CUDA_VISIBLE_DEVICES), "The input gpu number exceeds the index."
            assert len(self.gpus) <= num_gpus, "The number of input gpu exceeds the number of devices."
            return True

    def _start_training(self, config, **kwargs):
        """
        启动训练过程。

        该方法根据是否启用多进程分布式训练来启动训练过程：
        1. 如果启用了多进程分布式训练，使用 `mp.spawn()` 启动多个进程，每个进程对应一个 GPU。
        2. 如果没有启用分布式训练（即只使用一个 GPU），则直接调用 `main_worker` 启动训练。

        :param config: 配置对象，包含训练过程中的超参数和设置。
        :param kwargs: 额外的参数，用于传递给训练过程中的 `main_worker` 函数。
        :return: None
        """
        ngpus_per_node = len(self.gpus)
        if self._multiprocessing_distributed_status():
            dist_url = self._setup_distributed()
            argss = (self.train_data_path, config, dist_url, kwargs)
            mp.spawn(self.main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, argss))
        else:
            dist_url = 'tcp://127.0.0.1:6789'
            argss = (self.train_data_path, config, dist_url, kwargs)
            self.main_worker(self.gpus[0], ngpus_per_node, argss)

    def _init_logger(self):
        """
        初始化日志记录器。

        该方法初始化日志回调，并设置 TensorBoard 日志记录器。通过 `init_callbacks` 方法初始化日志路径，
        然后创建一个 `SummaryWriter` 实例，用于将训练过程中的信息（如损失、准确率等）记录到 TensorBoard。

        :return: None
        """
        self.init_callbacks(self.log_path)
        self.writers = SummaryWriter(self.sdt_trainer_config.trainer.callbacks.tensorboard_log_dir)

    def _get_image_normalization_parameters(self):
        """
        获取图像的归一化参数。

        该方法从预处理函数 `get_preprocessing_fn` 中获取归一化所需的均值（mean）和标准差（std），
        然后将这些值保存到 `self.sda_data_config.dataset` 中，供后续图像预处理使用。

        :return: None
        """
        _, mean, std = get_preprocessing_fn(self.sdt_trainer_config.model.backbone_name, self.encoder_weights)
        self.sda_data_config.dataset.image_mean = mean
        self.sda_data_config.dataset.image_std = std

    def _get_datasets(self):
        """
        获取训练和验证数据集。

        该方法通过 `DatasetBuilder` 类创建数据集构建器实例，使用给定的路径和配置加载训练数据集和验证数据集。
        然后，将加载的数据集分别赋值给 `self.train_dataset` 和 `self.valid_dataset` 属性。

        :return: None
        """
        datasetbuilder = DatasetBuilder(self.sda_path, self.sda_data_config, self.output_bands)
        self.train_dataset = datasetbuilder.get_train_dataset()
        self.valid_dataset = datasetbuilder.get_valid_dataset()

    def _set_dataloader(self, data_works, ngpus_per_node):
        """
        设置训练和验证数据加载器。

        该方法根据当前系统平台（通过 `platform.system()` 获取）以及训练配置创建一个 `DataLoaderBuilder` 实例，
        然后使用该实例生成训练和验证数据加载器，最终将它们赋值给 `self.train_loader` 和 `self.valid_loader`。
        同时，生成训练数据的采样器并赋值给 `self.train_sampler`。

        :param data_works: 数据加载的工作方式，通常是指数据加载的模式（如单进程或多进程）。
        :param ngpus_per_node: 每个节点上的 GPU 数量，用于分布式训练。
        :return: None
        """
        syst = platform.system()
        dataloaderbuilder = DataLoaderBuilder(
            syst,
            self.sdt_trainer_config,
            self.sdt_trainer_config.trainer.batch_size,
            self.train_dataset,
            self.valid_dataset,
            data_works,
            ngpus_per_node,
            self.multiprocessing_distributed
        )
        self.train_loader = dataloaderbuilder.get_train_loader()
        self.valid_loader = dataloaderbuilder.get_valid_loader()
        self.train_sampler = dataloaderbuilder.get_train_sampler()

    def _init_model(self, gpu, **kwargs):
        """
        初始化模型，并根据需要加载模型架构和微调设置。

        该方法首先检查是否提供了 `backbone_name` 参数，如果提供，则更新模型配置中的骨干网络名称。
        然后，调用 `_instantiate_and_load_model` 来实例化并加载模型。接着，如果启用了微调（`finetune`），
        则通过 `SupervisedFineTuneFactory` 来创建微调后的模型。最后，计算并打印模型的可训练参数数量，
        并将模型加载到指定的设备（如 GPU）上。

        :param gpu: 要加载模型的设备（如 GPU）的编号。
        :param kwargs: 其他可能的配置参数，如 `backbone_name` 等。
        :return: None
        """
        if kwargs.get('backbone_name', None) is not None or self.sdt_trainer_config.model.backbone_name.strip() != '':
            self.sdt_trainer_config.model.backbone_name = kwargs.get('backbone_name')
            log_warning('backbone_name is not None, it will use backbone_name : {}'.format(
                self.sdt_trainer_config.model.backbone_name))

        self._instantiate_and_load_model(**kwargs)

        # 微调
        if self.finetune:
            from ..sft import SupervisedFineTuneFactory
            self.model = SupervisedFineTuneFactory.create(self.sdt_trainer_config.model.name, self.model, self.finetune)

        total_params = count_requires_grad_parameters(self.model)
        log_info(f"Total trainable parameters: {total_params}")

        self._set_model_device(gpu)

    def _instantiate_and_load_model(self, **kwargs):
        """
        实例化并加载模型。

        该方法根据提供的参数初始化模型，并根据是否需要重新加载模型的标志来加载本地权重或从最新的 checkpoint 文件恢复模型状态。
        具体步骤包括：
        1. 如果提供了骨干网络或预训练模型的权重路径，则先进行相应的处理。
        2. 调用 `_get_model` 来实例化模型。
        3. 如果 `reload_model` 为 `False`，则加载本地权重文件。
        4. 如果 `reload_model` 为 `True`，则从最新的 checkpoint 文件恢复模型状态。

        :param kwargs: 包含可能的模型权重路径和其他配置参数（如 `backbone_weight_path`, `pretrained_model_path`, `reload_model` 等）。
        :return: None
        """
        backbone_weight_path = kwargs.get('backbone_weight_path', None)
        pretrained_model_path = kwargs.get('pretrained_model_path', None)
        if backbone_weight_path or pretrained_model_path:
            self.encoder_weights = None

        self.model = self._get_model()

        self.reload_model = kwargs.get('reload_model', None)
        if not self.reload_model:
            self._load_local_pth(backbone_weight_path, pretrained_model_path)
        else:
            checkpoint_dir = self.sdt_trainer_config.trainer.callbacks.checkpoint_dir
            try:
                self.checkpoint = torch.load(
                    os.path.join(checkpoint_dir, 'latest.pth'), map_location=Device_type.get_device()
                )
            except:
                raise FileNotFoundError('There are no latest.pth file in {}'.format(checkpoint_dir))

            try:
                self.model.load_state_dict(self.checkpoint['model'].state_dict())
            except:
                self.model.module.load_state_dict(self.checkpoint['model'].state_dict())

    def _set_model_device(self, gpu):
        """
        设置模型的设备。

        该方法根据是否启用了多进程分布式训练，决定将模型加载到哪个设备（如 CPU 或 GPU）。如果是分布式训练，
        使用 `Device_type.distributed()` 将模型分发到多个 GPU 上；如果不是分布式训练，则将模型加载到指定的 GPU 上。
        如果是主进程，还会克隆模型以备后用。

        :param gpu: 目标设备的 GPU 编号或 CPU 设备。
        :return: None
        """
        if self._main_process():
            self.model_clone = copy.deepcopy(self.model)

        if self.multiprocessing_distributed:
            self.model = Device_type.distributed(self.model, gpu, find_unused_parameters=True)
        else:
            self.model = Device_type.to_device(self.model, gpu)

    def _set_schedule(self, gpu):
        """
        设置优化器、学习率调度器和损失函数。

        该方法用于初始化优化器和学习率调度器，并设置损失函数和评估指标。
        根据训练配置初始化学习率调度器，并将其与优化器一起应用于训练过程。
        同时，初始化损失函数和评估指标，确保训练过程中的损失计算和模型评估。

        :param gpu: 设备（GPU）的编号，用于将模型、损失函数和指标移到指定设备。
        :return: None
        """
        device = Device_type.get_device()
        self.optimizer, new_lr = self._build_optimizerscheduler()
        self.sdt_trainer_config.trainer.learning_rate = new_lr
        self.scheduler = LRScheduler(
            warmup_mode=self.sdt_trainer_config.trainer.lr_method.warmup,
            decay_mode=self.sdt_trainer_config.trainer.lr_method.decay,
            base_lr=self.sdt_trainer_config.trainer.learning_rate,
            nepochs=self.sdt_trainer_config.trainer.num_epochs,
            iters_per_epoch=len(self.train_dataset) // self.sdt_trainer_config.trainer.batch_size,
            power=0.9, step_ratio=[0.4, 0.7, 0.9], step_factor=0.1,
            warmup_epochs=self.sdt_trainer_config.trainer.lr_method.warmup_epoch
        )

        self.loss = get_loss(self.loss_type)

        if self.multiprocessing_distributed:
            self.loss = Device_type.to_device(self.loss, device_id=gpu)
        else:
            self.loss = Device_type.to_device(self.loss)
        self.metrics = [IoU(threshold=0.5, ignore_channels=[]), Fscore(), ]

        self.epoch = EpochBuilder(
            self.model, self.sda_data_config, self.sdt_trainer_config,
            self.loss, self.metrics, self.optimizer,
            device, self.scheduler, self.start_epoch, self.train_dataset,
            self.sdt_trainer_config.trainer.batch_size
        )

    def _sdm_parameters(self, **kwargs):
        """
        设置 sdm 配置文件相关参数。

        该方法根据传入的 `output_model_path` 和 `output_model_name` 配置路径，并生成相应的模型存储路径。
        它计算并设置模型的基础文件名以及预期的 `.pth` 和 `.sdm` 文件路径。

        :param kwargs: 包含模型路径和模型名称的参数，如 `output_model_path` 和 `output_model_name`。
        :return: None
        """
        output_model_path = kwargs.get('output_model_path')
        output_model_name = kwargs.get('output_model_name')
        output_model_path = self.create_output_model_path(output_model_path, output_model_name)
        self.model_base_name = os.path.basename(output_model_path.rstrip(os.path.sep))
        self.torch_model_path = os.path.join(output_model_path, self.model_base_name + '.pth')
        self.sdm_path = os.path.join(output_model_path, self.model_base_name + '.sdm')

    def _run_epoch(self):
        """
        运行一个训练周期（epoch）。

        该方法负责执行一个完整的训练周期。它会循环遍历每个 epoch，根据训练进度进行训练和验证：
        1. 执行训练步骤并记录训练日志。
        2. 在指定的间隔或训练达到 80% 时进行验证。
        3. 在每个 epoch 结束时保存最新的模型和相关信息。

        如果当前进程是主进程，还会关闭 TensorBoard 的写入器。

        :return: `max_score`: 在训练过程中验证集上的最佳得分。
        """
        max_score = 0
        num_epochs = self.sdt_trainer_config.trainer.num_epochs
        interval_validation = self.sdt_trainer_config.trainer.interval_validation
        total_steps_per_epoch = len(self.train_loader)

        for i in range(self.start_epoch, num_epochs):
            if self.multiprocessing_distributed:
                self.train_sampler.set_epoch(i)
            try:
                epoch_info = f'Epoch: {i + 1}/{num_epochs}'

                train_logs, _ = self.epoch.run_tarin_epoch(
                    epoch_info, self.train_loader, self.multiprocessing_distributed, self.Rank
                )
                self._log_metrics(train_logs, 'train', i)

                # 间隔验证，节省时间，interval_validation为验证间隔；超过0.8的epoch比例开始完全验证
                if i > int(num_epochs * 0.80) or int(i % interval_validation) == 0:
                    valid_logs, y_pred = self.epoch.run_valid_epoch(
                        epoch_info, self.valid_loader, self.multiprocessing_distributed, self.Rank
                    )
                    max_score = self._validate_and_save(i, max_score, valid_logs)

                if self._main_process():
                    self._save_latest_model(i + 1, self.model, self.model_clone, self.optimizer)
                    self._saving_latest_model_sdl(i + 1, max_score)

            finally:
                if 'train_logs' in locals():
                    del train_logs

        if self._main_process():
            self.writers.close()
            return self._saving_model_sdm(), max_score

    def _log_metrics(self, logs, phase, epoch_num):
        """
        记录训练或验证阶段的指标到 TensorBoard。

        该方法会遍历传入的日志字典 `logs`，并将每个指标记录到 TensorBoard 中，
        用于后续的可视化分析。日志会根据传入的 `phase`（如 'train' 或 'valid'）进行分类，
        并与 epoch 数（`epoch_num`）一起记录。

        :param logs: 包含指标名称和对应数值的字典（如损失、准确率等）。
        :param phase: 当前阶段（'train' 或 'valid'），用于分类日志（例如 'train/loss'）。
        :param epoch_num: 当前的 epoch 数，用于在 TensorBoard 上标记每个指标的训练进度。
        :return: None
        """
        if self._main_process():
            for k, v in logs.items():
                self.writers.add_scalar(f'{phase}/{k}', v, epoch_num)

    def _validate_and_save(self, epoch_num, score, logs):
        """
        验证模型性能并在验证得分更高时保存模型。

        该方法会在每个验证阶段进行模型验证，并记录验证阶段的指标。如果当前验证得分（如 IoU）高于
        之前的得分，模型会被保存。它还会记录验证过程中的指标到 TensorBoard。

        :param epoch_num: 当前训练的 epoch 数，用于标记验证阶段的进度。
        :param score: 当前验证的最佳得分，通常是 IoU 或其他评估指标。
        :param logs: 包含验证阶段指标（如 'iou_score'）的字典。
        :return: 更新后的最佳得分（`score`）。
        """
        self._log_metrics(logs, 'valid', epoch_num)
        if score <= logs['iou_score']:
            score = logs['iou_score']
            if self._main_process():
                self._save_model(epoch_num, score)

        return score

    def train(self, train_data_path, config, **kwargs):
        """
        上层调用的训练流程入口。

        该方法是训练过程的主要入口，负责设置设备、初始化训练配置、准备训练数据、配置分布式训练环境，
        然后启动训练过程。它按顺序调用一系列方法来完成整个训练流程。

        :param train_data_path: 训练数据的路径。
        :param config: 配置对象，包含训练的超参数和设置。
        :param kwargs: 额外的参数，包含设备设置（`device`）、GPU 列表（`gpus`）、数据初始化标志（`init_data`）等。
        :return: None
        """
        Device_type.setup(kwargs.get('device'))

        # Initialize training data configuration
        self._initialize_train_config(train_data_path, config, **kwargs)

        # Generate train data
        self._prepare_training_data(kwargs.get('init_data', True))

        # Set environment variables
        self._setup_distributed_training(kwargs.get('gpus', [0]))

        # Training
        self._start_training(config, **kwargs)

    def main_worker(self, gpu, ngpus_per_node, argss):
        """
        训练主流程。

        该方法是每个进程（尤其是分布式训练中的每个 GPU）执行的主训练流程。它负责：
        - 初始化必要的属性
        - 配置训练设备
        - 初始化数据加载器、模型和优化器
        - 执行训练周期

        :param gpu: 当前进程使用的 GPU 编号。
        :param ngpus_per_node: 每个节点上的 GPU 数量。
        :param argss: 其他参数，包括训练数据路径、配置、分布式 URL 和额外参数。
        :return: None
        """
        train_data_path, config, dist_url, kwargs = argss
        self.init_attribute(
            train_data_path=train_data_path,
            config=config,
            **kwargs,
        )
        self.finetune = kwargs.get('finetune', False)
        self.Rank = gpu if self.multiprocessing_distributed else 0

        Device_type.setup(kwargs.get('device'))
        Device_type.before_train()
        if self.multiprocessing_distributed:
            Device_type.init_dist(ip=dist_url, world_size=ngpus_per_node, rank=gpu)

        assert (self.sda_data_config.dataset.data_type in
                ('multi_classification', 'binary_classification', 'general_change_detection',)), \
            'data_type should be multi_classification or binary_classification or general_change_detection'
        assert self.sda_data_config.dataset.x_bandnum >= 1, \
            'The number of input bands should be greater than or equal 1'
        assert self.output_bands >= 1, \
            'The number of output bands should be greater than or equal 1'

        cuda_count = Device_type.device_count()
        data_works = cuda_count * 2 + 1 if kwargs.get('data_works') is None else kwargs.get('data_works')

        # log日志参数初始化
        self._init_logger()

        # 获取影像归一化参数
        self._get_image_normalization_parameters()

        # 构建Dataset
        self._get_datasets()

        # 构建DataLoader
        self._set_dataloader(data_works, ngpus_per_node)

        # 初始化模型
        self._init_model(gpu, **kwargs)

        # 设置策略
        self._set_schedule(gpu)

        # 保存的一些参数
        self._sdm_parameters(**kwargs)

        self._run_epoch()

    def get_loss_type(self):
        raise NotImplementedError("Subclasses must implement get_loss_type method")
