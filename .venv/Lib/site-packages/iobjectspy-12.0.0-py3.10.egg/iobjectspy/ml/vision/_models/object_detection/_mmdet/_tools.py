# !/usr/bin/env python3
# coding=utf-8
import argparse, rasterio, json, copy
import os, re
import sys
import random
import cv2
from collections import OrderedDict
from shutil import copyfile
import yaml
from dotmap import DotMap
from tqdm import tqdm
import cv2 as cv
from itertools import groupby
import xml.etree.ElementTree as ET
import numpy as np
from iobjectspy.ml.toolkit._toolkit import save_config_to_yaml
from mmengine.config import ConfigDict


def load_image_set_number(train_data_path):
    """
    Load the indexes listed numbers in this dataset's image set file.
    """
    json_path = os.path.join(train_data_path, 'train.json')
    if os.path.exists(json_path):
        with open(json_path, "r", encoding='utf-8') as f:
            row_data = json.load(f)
        img_num = len(row_data['images'])
    else:
        if os.path.exists(os.path.join(train_data_path, 'Annotations_train')):
            img_num = len(os.listdir(os.path.join(train_data_path, 'Annotations_train')))
        else:
            image_set_file = os.path.join(train_data_path, 'ImageSets', 'Main',
                                          'trainval.txt')
            assert os.path.exists(image_set_file), \
                'Path does not exist: {}'.format(image_set_file)
            with open(image_set_file, encoding='utf-8') as f:
                image_index = [x.strip() for x in f.readlines()]
            img_num = len(image_index)
    return img_num


def creat_output_model_folder(output_model_path, output_model_name):

    model_path = os.path.join(output_model_path, output_model_name)
    if not os.path.exists(model_path):
        os.makedirs(model_path)
        return model_path
    else:
        i = 2
        new_model_path = model_path + '_' + str(i)
        while os.path.exists(new_model_path):
            i += 1
            new_model_path = model_path + "_" + str(i)
        os.makedirs(new_model_path)
        return new_model_path


def get_classname_from_traindata(config, train_data_path):
    """
    从训练数据中获取类别名称
    :param config: sda文件
    :type : dict
    :param train_data_path: 训练数据路径
    :type train_data_path: str
    :return: list 类别
    """
    train_data_folder_name = os.path.basename(train_data_path)
    sda_name = train_data_folder_name + '.sda'
    sda_path = os.path.join(train_data_path, sda_name)
    with open(sda_path, 'r', encoding='utf-8') as f:
        config_dict = yaml.load(f, Loader=yaml.FullLoader)
        classes = config_dict['dataset']['classes']
        classes.remove('background') if 'background' in classes else classes

        training_data_format = config_dict['dataset']['data_type']
        input_bandnum = int(config_dict['dataset']['input_bandnum'])

    return classes, training_data_format, input_bandnum


def replace_num_classes(cfg, num_classes):
    """
    更新配置文件中类别数量相关的参数
    """
    if cfg.model.type == 'MaskRCNN':
        cfg.model.roi_head.bbox_head.num_classes = num_classes
        cfg.model.roi_head.mask_head.num_classes = num_classes
    elif cfg.model.type == 'CascadeRCNN':
        cfg.model.roi_head.bbox_head[0].num_classes = num_classes
        cfg.model.roi_head.bbox_head[1].num_classes = num_classes
        cfg.model.roi_head.bbox_head[2].num_classes = num_classes
    elif cfg.model.type == 'mmdet.CascadeRCNN':
        cfg.model.roi_head.bbox_head[0].num_classes = num_classes
        cfg.model.roi_head.bbox_head[1].num_classes = num_classes
    elif cfg.model.type == 'RTMDet':
        cfg.model.bbox_head.num_classes = num_classes
        if isinstance(cfg.param_scheduler, list):
            if cfg.param_scheduler[1].type == 'CosineAnnealingLR':
                cfg.param_scheduler[1].begin = cfg.train_cfg.max_epochs // 2
                cfg.param_scheduler[1].end = cfg.train_cfg.max_epochs
                cfg.param_scheduler[1].T_max = cfg.train_cfg.max_epochs // 2
        else:
            if cfg.param_scheduler.type == 'CosineAnnealingLR':
                cfg.param_scheduler.begin = cfg.train_cfg.max_epochs // 2
                cfg.param_scheduler.end = cfg.train_cfg.max_epochs
                cfg.param_scheduler.T_max = cfg.train_cfg.max_epochs // 2
    return cfg


def generate_palette(chars):
    palette = []
    for char in chars:
        # 生成一个随机的RGB值，确保RGB值都不相同
        r, g, b = random.sample(range(256), 3)
        palette.append((r, g, b))
    return palette


def check_class_name(input_list):
    # 定义正则表达式来匹配中文字符
    pattern = re.compile('[\u4e00-\u9fa5]')

    # 遍历列表中的每个元素
    for item in input_list:
        if pattern.search(item):
            return True

    # 如果没有任何元素包含中文字符，返回False
    return False


def check_path(path):
    # 定义正则表达式来匹配中文字符和特殊符号
    pattern = re.compile('[\u4e00-\u9fa5！@#￥%…&*]')

    # 使用正则表达式进行匹配
    if pattern.search(path):
        return True
    else:
        # 如果路径不包含中文字符，返回False
        return False

def update_dataset_config(cfg ,args):
    """
    更新配置文件中数据集类型以及路径
    """
    cfg.data_root = args.train_data_path
    cfg.metainfo = dict(classes=args.class_names, palette=generate_palette(args.class_names))
    # 先判断类别名称有无中文
    class_pattern = check_class_name(args.class_names)
    # 在判断train_data_path有无中文
    path_pattern = check_path(args.train_data_path)

    # 实例分割
    if args.config.application.name == 'object_extraction':
        # 如果class_pattern和path_pattern都为False，即类别和路径都没有中文或特殊字符，使用coco格式
        if class_pattern == False and path_pattern == False:
            custome_imports_dict = ConfigDict\
                (imports=['iobjectspy.ml.vision._models.base_framework._mmdet.data.sm_coco'],
                 allow_failed_imports=False)
            cfg.custom_imports = custome_imports_dict

            cfg.dataset_type = 'SMCocoDataset'
            cfg.default_hooks.checkpoint['save_best'] = 'coco/bbox_mAP'

            if cfg.train_dataloader.dataset.type == 'RepeatDataset':
                cfg.train_dataloader.dataset.dataset.data_root = cfg.data_root
                cfg.train_dataloader.dataset.dataset.ann_file = os.path.join(cfg.data_root, 'train.json')
                cfg.train_dataloader.dataset.dataset.data_prefix.img = os.path.join(cfg.data_root, 'Images')
                cfg.train_dataloader.dataset.dataset.metainfo = cfg.metainfo
                cfg.train_dataloader.dataset.dataset.type = cfg.dataset_type
            else:
                cfg.train_dataloader.dataset.data_root = cfg.data_root
                cfg.train_dataloader.dataset.ann_file = os.path.join(cfg.data_root, 'train.json')
                cfg.train_dataloader.dataset.data_prefix.img = os.path.join(cfg.data_root, 'Images')
                cfg.train_dataloader.dataset.metainfo = cfg.metainfo
                cfg.train_dataloader.dataset.type = cfg.dataset_type

            cfg.val_dataloader.dataset.data_root = cfg.data_root
            cfg.val_dataloader.dataset.ann_file = os.path.join(cfg.data_root, 'val.json')
            cfg.val_dataloader.dataset.data_prefix.img = os.path.join(cfg.data_root, 'Images')
            cfg.val_dataloader.dataset.metainfo = cfg.metainfo
            cfg.val_dataloader.dataset.type = cfg.dataset_type

            val_evaluator_dict = ConfigDict\
                (type='CocoMetric',
                ann_file=cfg.val_dataloader.dataset.ann_file,
                metric=['bbox', 'segm'],
                format_only=False,
                backend_args=None)
            cfg.val_evaluator = val_evaluator_dict

        # 默认使用voc_mask,支持中文
        else:
            cfg.train_dataloader.dataset.metainfo = cfg.metainfo
            cfg.train_dataloader.dataset.data_root = cfg.data_root
            cfg.train_dataloader.dataset.ann_file = os.path.join(cfg.data_root, 'ImageSets', 'Main', 'trainval.txt')
            cfg.train_dataloader.dataset.data_prefix.sub_data_root = cfg.data_root

            cfg.val_dataloader.dataset.metainfo = cfg.metainfo
            cfg.val_dataloader.dataset.data_root = cfg.data_root
            cfg.val_dataloader.dataset.ann_file = os.path.join(cfg.data_root, 'ImageSets', 'Main', 'test.txt')
            cfg.val_dataloader.dataset.data_prefix.sub_data_root = cfg.data_root
    # 目标检测
    else:
        if cfg.dataset_type == 'SMRotateDataset':
            cfg.train_dataloader.dataset.data_root = cfg.data_root
            cfg.train_dataloader.dataset.ann_file = os.path.join(cfg.data_root, 'Annotations_train')
            cfg.train_dataloader.dataset.data_prefix.img_path = os.path.join(cfg.data_root, 'Images')
            cfg.train_dataloader.dataset.metainfo = cfg.metainfo
            cfg.val_dataloader.dataset.data_root = cfg.data_root
            cfg.val_dataloader.dataset.ann_file = os.path.join(cfg.data_root, 'Annotations_val')
            cfg.val_dataloader.dataset.data_prefix.img_path = os.path.join(cfg.data_root, 'Images')
            cfg.val_dataloader.dataset.metainfo = cfg.metainfo
        elif cfg.dataset_type == 'SMODDataset':
            cfg.train_dataloader.dataset.data_root = cfg.data_root
            cfg.train_dataloader.dataset.ann_file = os.path.join(cfg.data_root, 'Annotations_train')
            cfg.train_dataloader.dataset.data_prefix.img_path = os.path.join(cfg.data_root, 'Images')
            cfg.train_dataloader.dataset.metainfo = cfg.metainfo
            cfg.val_dataloader.dataset.data_root = cfg.data_root
            cfg.val_dataloader.dataset.ann_file = os.path.join(cfg.data_root, 'Annotations_val')
            cfg.val_dataloader.dataset.data_prefix.img_path = os.path.join(cfg.data_root, 'Images')
            cfg.val_dataloader.dataset.metainfo = cfg.metainfo
        else:
            if cfg.train_dataloader.dataset.type == 'RepeatDataset':
                cfg.train_dataloader.dataset.dataset.data_root = cfg.data_root
                cfg.train_dataloader.dataset.dataset.ann_file = \
                    os.path.join(cfg.data_root, 'ImageSets', 'Main', 'trainval.txt')
                cfg.train_dataloader.dataset.dataset.data_prefix.sub_data_root = cfg.data_root
                cfg.train_dataloader.dataset.dataset.metainfo = cfg.metainfo
            else:
                cfg.train_dataloader.dataset.data_root = cfg.data_root
                cfg.train_dataloader.dataset.ann_file = \
                    os.path.join(cfg.data_root, 'ImageSets', 'Main', 'trainval.txt')
                cfg.train_dataloader.dataset.data_prefix.sub_data_root = cfg.data_root
                cfg.train_dataloader.dataset.metainfo = cfg.metainfo

            cfg.val_dataloader.dataset.ann_file = os.path.join(cfg.data_root, 'ImageSets', 'Main', 'test.txt')
            cfg.val_dataloader.dataset.data_prefix.sub_data_root = cfg.data_root
            cfg.val_dataloader.dataset.metainfo = cfg.metainfo
    return cfg


def saving_mmdet_model(log_path, model_path, blocksize, class_names, config):
    """
    保存mmdet的模型文件和SDM配置文件

    :param log_path: mmdet 日志路径
    :type log_path: str
    :param model_path: 模型的保存路径
    :type model_path: str
    :param blocksize: 影像切块的尺寸
    :type blocksize: int
    :param class_names: 类别名
    :type class_names: dict
    :param config: sdt配置文件的字典
    :type config: dict
    """
    development_kit = config.development_kit.name
    model_architecture = config.model.name
    model_type = config.application.name
    framework = config.framework.name
    tile_offset = blocksize / 2
    model_name = os.path.basename(model_path)
    sdm_path = os.path.join(model_path, model_name + '.sdm')
    files = os.listdir(log_path)
    config_file = os.path.splitext([f for f in files if f.endswith('.py')][0])[0]
    if str(config.trainer.checkpoint_save_best_only) == 'True' or str(config.trainer.checkpoint_save_best_only) == 'true':
        best_ckpt_file = [f for f in files if f.startswith('best') and f.endswith('.pth')]
        try:
            best_ckpt_file_path = os.path.join(log_path, best_ckpt_file[-1])
            copyfile(best_ckpt_file_path, os.path.join(model_path, model_name + '.pth'))
        except:
            with open(os.path.join(log_path, 'last_checkpoint')) as f:
                best_ckpt_file_path = f.readlines()[0]
            copyfile(best_ckpt_file_path, os.path.join(model_path, model_name + '.pth'))
        print('{} has been saved!'.format(best_ckpt_file_path))
    else:
        try:
            with open(os.path.join(log_path, 'last_checkpoint'), encoding='utf-8') as f:
                a = f.read()
            copyfile(a, os.path.join(model_path, model_name + '.pth'))
        except IOError as e:
            print("Unable to copy file. %s" % e)
            exit(1)
        except:
            print("Unexpected error:", sys.exc_info())
            exit(1)
    dict_detection = OrderedDict(
        {'framework': framework,
         'development_kit': development_kit,
         'model_type': model_type,
         'model_architecture': model_architecture,
         'config_file': config_file,
         'signature_name': 'predict',
         'model': {'blocksize': blocksize,
                   'tile_offset': tile_offset,
                   'categorys': ["tree"]}
         })
    dict_detection['model']['categorys'] = class_names
    save_config_to_yaml(dict_detection, sdm_path)


def get_mmdet_argument_parser(train_data_path, config, epoch, batch_size,
                              lr, log_path, reload_model, output_model_name,
                              backbone_name, backbone_weight_path, pretrained_model_path,
                              gpus, num_machines,
                              input_bandnum, class_names, training_data_format,
                              sdt_config_path, output_model_path,
                              iters=None, epilog=None, device=None):
    """
      解析接口传参
    """
    parser = argparse.ArgumentParser(epilog=epilog)
    parser.add_argument("--train_data_path", default=train_data_path, help="path to training data ")
    parser.add_argument("--config", default=config, help="config dict")
    parser.add_argument("--epoch", default=epoch, help="The number of epoch to run during the training phase")
    parser.add_argument("--iters", default=iters, help="The number of iterations to run during the training phase")
    parser.add_argument("--batch_size", default=batch_size, help="Batch size for mini batch gradient descent")
    parser.add_argument("--backbone_name", default=backbone_name, help="Batch size for mini batch gradient descent")
    parser.add_argument("--backbone_weight_path", default=backbone_weight_path, help="Backbone path")
    parser.add_argument("--lr", default=lr, help="lr")
    parser.add_argument("--log_path", default=log_path, help="path to log file")
    parser.add_argument(
        "--reload_model", default=reload_model,
        action="store_true",
        help="Whether to attempt to resume from the checkpoint directory. "
             "See documentation of `DefaultTrainer.resume_or_load()` for what it means.",
    )
    parser.add_argument("--device", default=device, help="device")
    parser.add_argument("--pretrained_model_path", default=pretrained_model_path, help="pretrained model")
    parser.add_argument("--eval-only", action="store_true", help="perform evaluation only")
    parser.add_argument("--gpus", type=list, default=gpus, help="number of gpus *per machine*")
    parser.add_argument("--num-machines", type=int, default=num_machines, help="total number of machines")
    parser.add_argument("--class_names", default=class_names, help="class_names")
    parser.add_argument("--training_data_format", default=training_data_format, help="training_data_format")
    parser.add_argument("--sdt_config_path", type=str, default=sdt_config_path, help="sdt_config_path")
    parser.add_argument("--output_model_name", default=output_model_name, help="output_model_name")
    parser.add_argument("--output_model_path", default=output_model_path, help="output_model_path")
    parser.add_argument("--input_bandnum", default=input_bandnum, help="input_bandnum")
    return parser


def _find_reload_model(log_path, model_name):
    "从文件夹中找到上次训练的模型,model_name即功能名"
    last_model_path = None
    date_dir = os.listdir(log_path)
    date_dir = list(filter(lambda _: os.path.isdir(os.path.join(log_path, _)), date_dir))
    date_dir = sorted(date_dir)[::-1]

    for _ in date_dir:
        model_dir = os.path.join(log_path, _, model_name)

        if os.path.isdir(model_dir):
            pth_model = os.listdir(model_dir)
            # 最后生成的文件排最后
            pth_model = list(sorted(pth_model, key=lambda x: os.path.getmtime(os.path.join(model_dir, x))))
            pth_model = list(filter(lambda x: x.endswith('.pth'), pth_model))

            if 'model_final.pth' in pth_model:
                pth_model.remove('model_final.pth')

            if len(pth_model) > 0:
                last_model_path = os.path.join(model_dir, pth_model[-1])
                break
    return last_model_path


# def convert_model(src: str, dst: str, tmp: str) -> None:
#     """Convert Detectron2 checkpoint to MMDetection style.
#     Args:
#         src (str): The Detectron2 checkpoint path, should endswith `pkl`.
#         dst (str): The MMDetection checkpoint path.
#         tmp (str): The MMDetection checkpoint path.
#     """
#     import torch
#     # load arch_settings
#     old_model = torch.load(src)
#     tmp_model = torch.load(tmp)
#     # convert to mmdet style
#     # new: 'enhance_model.generator.model.encoder.0.0.convs.0.conv.weight'
#     # old: 'enhance_model.encoder.0.0.convs.0.conv.weight'
#     #                     encoder.0.0.convs.0.conv.weight
#     dst_state_dict = OrderedDict()
#     for name, value in old_model.items():
#         new_name = 'backbone.' + name
#         dst_state_dict[new_name] = value
#     mmdet_model = dict(state_dict=dst_state_dict, meta=dict())
#     save_checkpoint(mmdet_model, dst)
#     print(f'Convert Detectron2 model {src} to MMDetection model {dst}')


def vocmask2coco(data_root, class_names, json_name=None):
    """
    vocmask2coco.
    """

    train_dict = {'images': [], 'annotations': [], 'categories': []}
    images_train = []
    annotations_train = []
    categories = []

    if json_name=='train.json':
        # 打开trainval.txt
        train_ann_file = os.path.join(data_root, 'ImageSets', 'Main', 'trainval.txt')
    else:
        train_ann_file = os.path.join(data_root, 'ImageSets', 'Main', 'test.txt')
    train_data_file = open(train_ann_file, 'r')

    # 得到每一张训练图片和验证图片的编号
    train_data_numbers = train_data_file.readlines()

    # 关闭文件
    train_data_file.close()

    # 获取图片尾缀、宽、高
    img_prefix = os.path.join(data_root, 'Images')
    data_list = os.listdir(img_prefix)
    temp_data = os.path.join(img_prefix, data_list[0])
    suffix = os.path.splitext(temp_data)[-1]
    with rasterio.open(temp_data, encoding='utf-8') as ds:
        height = ds.height
        width = ds.width
    ds.close()

    for i_class, class_name in enumerate(class_names):
        category = {'id': i_class, 'name': class_name}
        categories.append(category)

    # 拿到每一个训练数据编码
    for train_data_number in tqdm(train_data_numbers):
        image = {}
        # 去掉换行符，拿到真实训练数据编号
        train_data_number_remove = train_data_number.replace('\n', '')
        # 写入image字典
        image['id'] = int(train_data_number_remove)
        image['file_name'] = train_data_number_remove + suffix
        image['height'] = height
        image['width'] = width
        images_train.append(image)
        # 解析每一张图的标签信息，写入annotations
        # 得到一张图的所有标签信息，随后将逐个实例信息追加到annotations
        instance_infos = get_ann_info_to_dict(train_data_number_remove, data_root, class_names)
        for j, instance_info in enumerate(instance_infos):
            if isinstance(instance_info["segmentation"], list):
                # segmentation长度必须大于4，不然pycocotools会报错
                if len(instance_info["segmentation"][0]) > 4:
                    # 第一次直接写入annotations（这时候annotations是空的）
                    if len(annotations_train) == 0:
                        annotations_train.append(instance_info)
                    # 第二次，取annotations最后一个instance_info的id号，让其+1
                    else:
                        instance_info['id'] = annotations_train[-1]['id'] + 1
                        annotations_train.append(instance_info)
            else:
                if len(annotations_train) == 0:
                    annotations_train.append(instance_info)
                # 第二次，取annotations最后一个instance_info的id号，让其+1
                else:
                    instance_info['id'] = annotations_train[-1]['id'] + 1
                    annotations_train.append(instance_info)

    train_dict['images'] = images_train
    train_dict['annotations'] = annotations_train
    train_dict['categories'] = categories

    # 保存
    train_json_str = json.dumps(train_dict, indent=2, ensure_ascii=False)
    with open(os.path.join(data_root, json_name), 'w', encoding='utf-8') as train_json_file:
        train_json_file.write(train_json_str)

    train_json_file.close()


def extract_sub_mask_from_ROI_TRANS_by_using_BGR(ROI_TRANS, original_color, mask, bbox):

    mask_final = (ROI_TRANS[0, :, :] == original_color[0]) & \
                 (ROI_TRANS[1, :, :] == original_color[1]) & \
                 (ROI_TRANS[2, :, :] == original_color[2])
    mask_final = mask_final + 0
    arr_final = np.zeros((mask_final.shape[0], mask_final.shape[1], 3))
    arr_final[:, :, 0] = mask_final
    arr_final[:, :, 1] = mask_final
    arr_final[:, :, 2] = mask_final
    seg_final, area = single_mask_generates_polygon_or_rle(mask, bbox, arr_final)

    return seg_final, area


def get_ann_info_to_dict(idx, data_root, class_names):
    """Get whole instance information from XML and PNG file by index.

    Args:
        idx (str): Index of data.
    Returns:
        list: whole instance information of specified image.
    """

    xml_path = os.path.join(data_root, 'Annotations', f'{idx}.xml')
    mask_path = os.path.join(data_root, 'SegmentationObject', f'{idx}.png')
    # 读取整幅mask, HWC
    mask = cv.imdecode(np.fromfile(mask_path, dtype=np.uint8), -1)[:,:,:3]
    tree = ET.parse(xml_path)
    root = tree.getroot()
    instance_infos = []
    for obj in root.findall('object'):
        name = obj.find('name').text
        if name not in class_names:
            continue
        cat2label = {cat: i for i, cat in enumerate(class_names)}
        label = cat2label[name]
        difficult = obj.find('difficult')
        difficult = 0 if difficult is None else int(difficult.text)
        bnd_box = obj.find('bndbox')
        # TODO: check whether it is necessary to use int
        # Coordinates may be float type
        bbox = [
            int(float(bnd_box.find('xmin').text)),
            int(float(bnd_box.find('ymin').text)),
            int(float(bnd_box.find('xmax').text)),
            int(float(bnd_box.find('ymax').text))
        ]
        if int((bbox[2] - bbox[0]) * (bbox[3] - bbox[1])) <= 9:
            continue
        # 通过bbox，从图像上提ROI
        ROI = mask[bbox[1]:bbox[3], bbox[0]:bbox[2], :]
        # 查看ROI
        ROI_TRANS = ROI.transpose(2, 0, 1)

        # 如果object中记录了RBG,先提取出来
        if obj.find('color') is not None:
            color_ids = ((obj.find('color')).text).strip('()').split(',')
            original_color = [int(color_id) for color_id in color_ids]
            # 从ROI_TRANS中取出该mask，进入单个mask生成polygon/RLE逻辑
            # （由于xml记录的是RGB，ROI_TRANS是BGR, 需要转置）
            original_color.reverse()
            seg_final, area = extract_sub_mask_from_ROI_TRANS_by_using_BGR(ROI_TRANS, original_color, mask, bbox)

        # 如果object中没有记录RBG，就反算该物体的RBG值
        else:
            # 记录有几种颜色, 先设置一个color_index列表，并将黑色BGR记录上去
            # 最后返回的color_index，如果不是拥挤多边形，它的长度就是2，反之，大于2
            color_index = [[0, 0, 0]]
            # 遍历sub-mask
            for x in range(ROI_TRANS.shape[2]):
                for y in range(ROI_TRANS.shape[1]):
                    # 提取每一个点的BGR值
                    color = ROI_TRANS[:, y, x]
                    color_list = color.tolist()
                    # 如果color_index里面没有该点的RGB值
                    # 就往color_index追加一个RGB值
                    if color_list not in color_index:
                        color_index.append(color_list)

            # =============== 如果color_index的长度大于2，那该sub-mask就是拥挤多边形 =============== #
            if len(color_index) > 2:
                # 先复制一个color_index
                color_index_deepcopy = copy.deepcopy(color_index)
                # 计算gt_bbox的面积
                gt_bbox_area = (bbox[3] - bbox[1]) * (bbox[2] - bbox[0])
                area_list = []
                # 循环读取color_index的RGB值，循环次数为len(color_index)-1
                # 每次都提color_index的最后一个RGB值，这样就不会提[0,0,0]
                for _ in range(1, len(color_index)):
                    # 为了方便理解，这部分的运算都是CHW
                    # 提取color_index最后一个RGB值的mask
                    mask_temp = (ROI_TRANS[0, :, :] == color_index[-1][0]) & \
                                (ROI_TRANS[1, :, :] == color_index[-1][1]) & \
                                (ROI_TRANS[2, :, :] == color_index[-1][2])
                    # color_index删除最后一个color
                    color_index.pop(-1)
                    # 布尔型转整形
                    mask_temp = mask_temp + 0
                    # 生成一张跟mask_temp大小一样的灰度图
                    arr = np.zeros((mask_temp.shape[0], mask_temp.shape[1], 3))
                    arr[:, :, 0] = mask_temp
                    arr[:, :, 1] = mask_temp
                    arr[:, :, 2] = mask_temp
                    arr = arr.astype(np.uint8)
                    arr_gray = cv2.cvtColor(arr, cv2.COLOR_BGR2GRAY)
                    # 生成一个bbox(不管是不是空洞多边形，都会生成外接正四边形)
                    # 并放到bbox_list中
                    nums_labels, lables, calcu_boxes, centroids = cv.connectedComponentsWithStats(arr_gray, connectivity=8)
                    # 从ROI中单独抽取出来的对象，如果是连通的，则通过上式生成的box，长度是2；反之，长度大于2
                    if len(calcu_boxes) > 2:
                        # 删除calcu_boxes第一个元素, 并将所有剩余bbox由xywh转成x1y1x2y2
                        box_data = np.delete(calcu_boxes, 0, 0)
                        bbox_trans = []
                        for i_box in box_data:
                            bbox_trans.append([i_box[0], i_box[1],
                                           i_box[0] + i_box[2], i_box[1] + i_box[3]])
                        bbox_trans = np.array(bbox_trans)
                        # 比较所有bbox的x1y1，取最小值
                        # 比较所有bbox的x2y2，取最大值
                        # 作为最终bbox
                        clo_min = np.min(bbox_trans, axis=0)
                        clo_max = np.max(bbox_trans, axis=0)

                        w = clo_max[2] - clo_min[0]
                        h = clo_max[3] - clo_min[1]
                        area_temp = w * h
                    else:
                        area_temp = calcu_boxes[1][2] * calcu_boxes[1][3]
                    area_list.append(area_temp)
                # 将area_list倒序,并将color_index里面的黑色RGB删除
                # 如此，area_list[0]对应color_index[0], area_list[1]对应color_index[1] .....
                area_list.reverse()
                color_index_deepcopy.pop(0)
                # 判断取舍,返回最接近gt_bbox的bbox的索引,并从color_index中
                # 拿到该索引对应的RGB
                idx_color = find_nearest(area_list, gt_bbox_area)
                color_final = color_index_deepcopy[idx_color]

                # 从ROI_TRANS中取出该mask，进入单个mask生成polygon/RLE逻辑
                seg_final, area = extract_sub_mask_from_ROI_TRANS_by_using_BGR(ROI_TRANS, color_final, mask, bbox)

                # # 从原图mask上清理掉color_final
                #
                # mask_zero = np.zeros([mask.shape[0], mask.shape[1], mask.shape[2]], mask.dtype)
                # # 将arr_final放到全0图上
                # mask_zero[bbox[1]:bbox[3], bbox[0]:bbox[2], :] = arr_final
                # mask[:, :, 0][mask_zero[:, :, 0] != 0] = 0
                # mask[:, :, 1][mask_zero[:, :, 1] != 0] = 0
                # mask[:, :, 2][mask_zero[:, :, 2] != 0] = 0

            # ================= 否则就不是拥挤多边形,进入单个sub-mask生成polygon/RLE逻辑 ================= #
            else:
                seg_final, area = single_mask_generates_polygon_or_rle(mask, bbox, ROI)

        # annotations字段存储所有目标的所有实例
        # instance_info存储单个实例
        instance_info = {'image_id': int(idx),
                         'id': 0,
                         'category_id': label,
                         'bbox': [bbox[0], bbox[1],
                                  bbox[2] - bbox[0],
                                  bbox[3] - bbox[1]],
                         'area': area,
                         'segmentation': seg_final,
                         'iscrowd': 0
                         }
        instance_infos.append(instance_info)

    return instance_infos


def single_mask_generates_polygon_or_rle(mask, bbox, ROI):
    # 生成一张与原图大小一致的全0图,HWC
    mask_zero = np.zeros([mask.shape[0], mask.shape[1], mask.shape[2]], mask.dtype)
    # 将ROI放到全0图上
    mask_zero[bbox[1]:bbox[3], bbox[0]:bbox[2], :] = ROI
    seg_final, area = get_contours_info(mask_zero)
    return seg_final, area


def find_nearest(array, value):
    array = np.asarray(array)
    idx = (np.abs(array - value)).argmin()
    return idx


def get_contours_info(mask):
    """Get contours information from each sub-mask file by whole mask file.

    Args:
        mask (ndarray): sub-mask information.

    Returns:
        seg_list: contours info of specified sub-mask.
        area: area of encoded masks
    """
    # 转成灰度图
    gray = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)
    ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY)
    # 如果传进来的binary有岛洞的存在，contours返回多个值
    # 反之，只有一个，即该mask的外包边界
    contours, hierarchy = cv.findContours(binary, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
    area = np.count_nonzero(binary)
    if len(contours) > 1:
        rle = binary_mask_to_rle(binary)
        seg_final = rle
    else:
        contours_squeezed = np.squeeze(contours[0])
        contours_list = contours_squeezed.flatten()
        seg_list = [[]]
        for i, contour in enumerate(contours_list):
            seg_list[0].append(contour)
        seg_final = [[float(i) for i in seg_list[0]]]

    return seg_final, area


def binary_mask_to_rle(binary_mask):
    """Get RLE from binary_mask.

            Args:
                binary_mask (ndarray): ndarray with 2 dimension.
            Returns:
                rle
    """
    rle = {'counts': [], 'size': list(binary_mask.shape)}
    counts = rle.get('counts')
    for i, (value, elements) in enumerate(groupby(binary_mask.ravel(order='F'))):
        if i == 0 and value == 1:
            counts.append(0)
        counts.append(len(list(elements)))
    return rle


def saving_latest_model_sdl(args, cfg):

    if isinstance(cfg.param_scheduler, list):
        warmup = cfg.param_scheduler[0].type
    else:
        warmup = 'close'

    if isinstance(cfg.param_scheduler, list):
        decay = cfg.param_scheduler[1].type
    else:
        decay = 'close'

    if str(args.config.lr_method.warmup_epoch) == 'default':
        warmup_epoch = 1
    else:
        warmup_epoch = args.config.lr_method.warmup_epoch

    # if args.config.model.name == 'rtmdet':
    #     model_name = 'example_object_det_mm_rtmdet'
    # elif args.config.model.name == 'rtmdet-ins':
    #     model_name = 'example_object_ext_mm_rtmdet-ins'
    # elif args.config.model.name == 'mask_rcnn':
    #     model_name = 'example_object_ext_mm_mask_rcnn'
    # elif args.config.model.name == 'cascade_rcnn':
    #     model_name = 'example_object_det_mm_cascade_rcnn'
    # else:
    #     model_name = None
    config = OrderedDict({
        'train_data_path': args.train_data_path,
        'model_path': args.output_model_path,
        'train_config': args.sdt_config_path,
        'model_type': args.config.application.name,
        'framework': 'pytorch',
        'model_architecture': args.config.model.name,
        'model_name': args.output_model_name,
        'batch_size': args.batch_size,
        'encoder': args.config.model.backbone_name,
        'num_epochs': args.epoch,
        'current_epoch': None,
        'learning_rate': cfg.optim_wrapper.optimizer.lr,
        'lr_method': [{'warmup': warmup},
                      {'decay': decay},
                      {'warmup_epoch': warmup_epoch}],
        'metrics': None
    })
    sdl_path = os.path.join(args.log_path, 'latest.sdl')
    return save_config_to_yaml(config, sdl_path)