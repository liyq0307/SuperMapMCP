import os
import torch
import torch.nn as nn
from typing import Dict
from .transformer_decoder.pixel_decoder import MSDeformAttnPixelDecoder
from .transformer_decoder.decoder import MultiScaleMaskedTransformerDecoder
from .criterion.matcher import HungarianMatcher
from .criterion.criterion import SetCriterion
from ......toolkit._toolkit import get_config_from_yaml

class Mask2FormerHead(nn.Module):
    def __init__(self, num_classes: int = 19, input_shape: Dict = dict()):
        super().__init__()
        self.num_classes = num_classes
        self.cfg = get_config_from_yaml(os.path.join(os.path.dirname(os.path.abspath(__file__)),'base.yaml'))
        self.pixel_decoder_head = self.pixel_decoder(self.cfg, input_shape)
        self.transformer_decoder_head = self.transformer_decoder(self.cfg)
        self.criterion = self.setcriterion(self.cfg)


    def pixel_decoder(self, cfg, input_shape):
        common_stride = cfg.MODEL.SEM_SEG_HEAD.COMMON_STRIDE
        transformer_dropout = cfg.MODEL.MASK_FORMER.DROPOUT
        transformer_nheads = cfg.MODEL.MASK_FORMER.NHEADS
        # transformer_dim_feedforward = cfg.MODEL.MASK_FORMER.DIM_FEEDFORWARD
        transformer_dim_feedforward = 1024  # use 1024 for deformable transformer encoder
        transformer_enc_layers = cfg.MODEL.SEM_SEG_HEAD.TRANSFORMER_ENC_LAYERS
        conv_dim = cfg.MODEL.SEM_SEG_HEAD.CONVS_DIM
        mask_dim = cfg.MODEL.SEM_SEG_HEAD.MASK_DIM
        norm = cfg.MODEL.SEM_SEG_HEAD.NORM
        transformer_in_features = cfg.MODEL.SEM_SEG_HEAD.DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES  # ["res3", "res4", "res5"]

        pixel_decoder = MSDeformAttnPixelDecoder(input_shape,
                                                 transformer_dropout,
                                                 transformer_nheads,
                                                 transformer_dim_feedforward,
                                                 transformer_enc_layers,
                                                 conv_dim,
                                                 mask_dim,
                                                 norm,
                                                 transformer_in_features,
                                                 common_stride)
        return pixel_decoder

    def transformer_decoder(self, cfg):
        in_channels = cfg.MODEL.SEM_SEG_HEAD.CONVS_DIM
        num_classes = self.num_classes # cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES
        hidden_dim = cfg.MODEL.MASK_FORMER.HIDDEN_DIM
        num_queries = cfg.MODEL.MASK_FORMER.NUM_OBJECT_QUERIES
        nheads = cfg.MODEL.MASK_FORMER.NHEADS
        dim_feedforward = cfg.MODEL.MASK_FORMER.DIM_FEEDFORWARD

        # NOTE: because we add learnable query features which requires supervision,
        # we add minus 1 to decoder layers to be consistent with our loss
        # implementation: that is, number of auxiliary losses is always
        # equal to number of decoder layers. With learnable query features, the number of
        # auxiliary losses equals number of decoders plus 1.
        assert cfg.MODEL.MASK_FORMER.DEC_LAYERS >= 1
        dec_layers = cfg.MODEL.MASK_FORMER.DEC_LAYERS - 1
        pre_norm = cfg.MODEL.MASK_FORMER.PRE_NORM
        mask_dim = cfg.MODEL.SEM_SEG_HEAD.MASK_DIM
        enforce_input_project = cfg.MODEL.MASK_FORMER.ENFORCE_INPUT_PROJ
        mask_classification = True
        transformer_decoder = MultiScaleMaskedTransformerDecoder(in_channels,
                                                       num_classes,
                                                       mask_classification,
                                                       hidden_dim,
                                                       num_queries,
                                                       nheads,
                                                       dim_feedforward,
                                                       dec_layers,
                                                       pre_norm,
                                                       mask_dim,
                                                       enforce_input_project)
        return transformer_decoder

    def forward(self, *features, mask=None):
        mask_features, transformer_encoder_features, multi_scale_features = self.pixel_decoder_head.forward_features(features[-4:])
        predictions = self.transformer_decoder_head(multi_scale_features, mask_features, mask)
        mask_cls_results = predictions["pred_logits"]
        mask_pred_results = predictions["pred_masks"]
        # upsample masks
        mask_pred_results = torch.nn.functional.interpolate(
            mask_pred_results,
            size=(features[0].shape[-2], features[0].shape[-1]),
            mode="bilinear",
            align_corners=False,
        )
        if self.training or len(features[0].shape) == 3:
            losses = self.criterion(predictions, features[0])
            loss_ce = 0.0
            loss_dice = 0.0
            loss_mask = 0.0
            for k in list(losses.keys()):
                if k in self.criterion.weight_dict:
                    losses[k] *= self.criterion.weight_dict[k]
                    if '_ce' in k:
                        loss_ce += losses[k]
                    elif '_dice' in k:
                        loss_dice += losses[k]
                    elif '_mask' in k:
                        loss_mask += losses[k]
                else:
                    # remove this loss if not specified in `weight_dict`
                    losses.pop(k)
            loss = loss_ce + loss_dice + loss_mask
            return [loss, mask_cls_results, mask_pred_results]
        else:
            return [mask_cls_results, mask_pred_results]

    def setcriterion(self, cfg):
        deep_supervision = cfg.MODEL.MASK_FORMER.DEEP_SUPERVISION
        no_object_weight = cfg.MODEL.MASK_FORMER.NO_OBJECT_WEIGHT

        # loss weights
        class_weight = cfg.MODEL.MASK_FORMER.CLASS_WEIGHT
        dice_weight = cfg.MODEL.MASK_FORMER.DICE_WEIGHT
        mask_weight = cfg.MODEL.MASK_FORMER.MASK_WEIGHT

        # building criterion
        matcher = HungarianMatcher(
            cost_class=class_weight,
            cost_mask=mask_weight,
            cost_dice=dice_weight,
            num_points=cfg.MODEL.MASK_FORMER.TRAIN_NUM_POINTS,
        )

        weight_dict = {"loss_ce": class_weight, "loss_mask": mask_weight, "loss_dice": dice_weight}

        if deep_supervision:
            dec_layers = cfg.MODEL.MASK_FORMER.DEC_LAYERS
            aux_weight_dict = {}
            for i in range(dec_layers - 1):
                aux_weight_dict.update({k + f"_{i}": v for k, v in weight_dict.items()})
            weight_dict.update(aux_weight_dict)

        losses = ["labels", "masks"]

        criterion = SetCriterion(
            self.num_classes,
            matcher=matcher,
            weight_dict=weight_dict,
            eos_coef=no_object_weight,
            losses=losses,
            num_points=cfg.MODEL.MASK_FORMER.TRAIN_NUM_POINTS,
            oversample_ratio=cfg.MODEL.MASK_FORMER.OVERSAMPLE_RATIO,
            importance_sample_ratio=cfg.MODEL.MASK_FORMER.IMPORTANCE_SAMPLE_RATIO,
        )

        return criterion