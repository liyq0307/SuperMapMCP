import torch

from .api import SegTorchTrainer
from .api import SegTorchEstimation
from ._torch_models import build_torch_seg_model


class SamTrainer(SegTorchTrainer):

    def get_model(self):
        self.model = build_torch_seg_model(
            in_channels=self.sda_data_config.dataset.x_bandnum,
            classes=len(self.sda_data_config.dataset.class_type),
            backbone_name=self.sdt_trainer_config.model.backbone_name,
            encoder_weights=self.encoder_weights,
            net_type=self.model_architecture,
            activation=self.activation,
        )
        if self.finetune:
            self.model_architecture = 'sam_' + self.finetune

        self.get_loss_type()

        return self.model

    def get_loss_type(self):
        if len(self.sda_data_config.dataset.class_type) > 2:
            self.loss_type = 'crossentropyloss'
        else:
            self.loss_type = 'dice_loss+bce_loss'

    def load_loacl_pth(self, model, backbone_weight_path, pretrained_model_path):
        """
        模型加载权重文件，backbone是encoder中的权重，pretrained是整个网络权重
        :param model:
        :param backbone_weight_path:
        :param pretrained_model_path:
        :return:
        """
        if pretrained_model_path:
            state_dict = torch.load(pretrained_model_path)
            new_state_dict = self.model.get_new_state_dict(state_dict)
            self.model.load_state_dict(new_state_dict)
            print('load backbone pre-training weight from pretrained_model_path:{}'.format(pretrained_model_path))


class SamEstimation(SegTorchEstimation):
    def __init__(self, model_path, config, gpus, batch_size, test_aug=False, **kwargs):
        super(SamEstimation, self).__init__(model_path, config, gpus, batch_size, test_aug, **kwargs)
        pass
