import cv2
import numpy as np
import torch
import torch.nn.functional as F


class Compose(object):
    # Composes segtransforms: segtransform.Compose([segtransform.RandScale([0.5, 2.0]), segtransform.ToTensor()])
    def __init__(self, segtransform):
        self.segtransform = segtransform

    def __call__(self, image, label):
        sample = {
            'image': image,
            'segmentation': label.copy()}
        for t in self.segtransform:
            sample = t(sample)
        return sample['image'], sample['segmentation']


class Compose_test(object):
    # Composes segtransforms: segtransform.Compose([segtransform.RandScale([0.5, 2.0]), segtransform.ToTensor()])
    def __init__(self, segtransform):
        self.segtransform = segtransform

    def __call__(self, image):
        sample = {
            'image': image}
        for t in self.segtransform:
            sample = t(sample)
        return sample['image']


class Resize(object):
    def __init__(self, scale_range=(0.5, 2.0), **kwargs):
        # set attribute
        self.output_size = None
        self.scale_range = scale_range
        self.img_interpolation = kwargs.get('img_interpolation', 'bilinear')
        self.seg_interpolation = kwargs.get('seg_interpolation', 'nearest')
        self.keep_ratio = kwargs.get('keep_ratio', True)
        # interpolation to cv2 interpolation
        self.interpolation_dict = {
            'nearest': cv2.INTER_NEAREST,
            'bilinear': cv2.INTER_LINEAR,
            'bicubic': cv2.INTER_CUBIC,
            'area': cv2.INTER_AREA,
            'lanczos': cv2.INTER_LANCZOS4
        }

    def __call__(self, sample):
        # parse
        image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
        self.output_size = image[0].shape[:2]
        if self.scale_range is not None:
            rand_scale = np.random.random_sample() * (self.scale_range[1] - self.scale_range[0]) + self.scale_range[0]
            output_size = int(self.output_size[0] * rand_scale), int(self.output_size[1] * rand_scale)
        else:
            output_size = self.output_size[0], self.output_size[1]
        # resize image and segmentation
        if self.keep_ratio:
            scale_factor = min(max(output_size) / max(image[0].shape[:2]), min(output_size) / min(image[0].shape[:2]))
            dsize = int(image[0].shape[1] * scale_factor + 0.5), int(image[0].shape[0] * scale_factor + 0.5)
            image = [cv2.resize(img, dsize=dsize, interpolation=self.interpolation_dict[self.img_interpolation])
                     for img in image]
            segmentation = cv2.resize(segmentation, dsize=dsize,
                                      interpolation=self.interpolation_dict[self.seg_interpolation])
        else:
            if image[0].shape[0] > image[0].shape[1]:
                dsize = min(output_size), max(output_size)
            else:
                dsize = max(output_size), min(output_size)
            image = [cv2.resize(img, dsize=dsize, interpolation=self.interpolation_dict[self.img_interpolation]) for img
                     in image]
            segmentation = cv2.resize(segmentation, dsize=dsize,
                                      interpolation=self.interpolation_dict[self.seg_interpolation])
        # update and return sample
        sample['image'], sample['segmentation'] = image, segmentation
        return sample


class Resize_val(object):
    def __init__(self, dsize, **kwargs):
        # set attribute
        self.output_size = tuple(dsize)
        self.img_interpolation = kwargs.get('img_interpolation', 'bilinear')
        self.seg_interpolation = kwargs.get('seg_interpolation', 'nearest')
        self.keep_ratio = kwargs.get('keep_ratio', True)
        # interpolation to cv2 interpolation
        self.interpolation_dict = {
            'nearest': cv2.INTER_NEAREST,
            'bilinear': cv2.INTER_LINEAR,
            'bicubic': cv2.INTER_CUBIC,
            'area': cv2.INTER_AREA,
            'lanczos': cv2.INTER_LANCZOS4
        }

    def __call__(self, sample):
        # parse
        image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
        image = [cv2.resize(img, dsize=self.output_size,
                            interpolation=self.interpolation_dict[self.img_interpolation]) for img in image]
        segmentation = cv2.resize(segmentation, dsize=self.output_size,
                                  interpolation=self.interpolation_dict[self.seg_interpolation])
        sample['image'], sample['segmentation'] = image, segmentation
        return sample


class RandomCrop(object):
    def __init__(self, crop_size, **kwargs):
        self.crop_size = crop_size
        if isinstance(crop_size, int): self.crop_size = (crop_size, crop_size)
        self.ignore_index = kwargs.get('ignore_index', 255)
        self.one_category_max_ratio = kwargs.get('one_category_max_ratio', 0.75)

    def __call__(self, sample):
        # avoid the cropped image is filled by only one category
        for _ in range(10):
            # --parse
            image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
            h_ori, w_ori = image[0].shape[:2]
            h_out, w_out = min(self.crop_size[0], h_ori), min(self.crop_size[1], w_ori)
            # --random crop
            top, left = np.random.randint(0, h_ori - h_out + 1), np.random.randint(0, w_ori - w_out + 1)
            image = [img[top: top + h_out, left: left + w_out] for img in image]
            segmentation = segmentation[top: top + h_out, left: left + w_out]
            # --judge
            labels, counts = np.unique(segmentation, return_counts=True)
            counts = counts[labels != self.ignore_index]
            # 保证每次裁剪的类别均衡
            if len(counts) > 1 and np.max(counts) / np.sum(counts) < self.one_category_max_ratio: break
        # update and return sample
        sample['image'], sample['segmentation'] = image, segmentation
        return sample


class RandomFlip(object):
    def __init__(self, prob=0.5):
        self.flip_prob = prob

    def __call__(self, sample):
        if np.random.rand() > self.flip_prob: return sample
        factor = np.random.randint(0, 3)
        image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
        if factor == 0:
            # Horizontalflip image
            image, segmentation = [np.flip(img, axis=1) for img in image], np.flip(segmentation, axis=1)
        elif factor == 1:
            # Verticalflip image
            image, segmentation = [np.flip(img, axis=0) for img in image], np.flip(segmentation, axis=0)
        else:
            # Transpose image
            image, segmentation = [np.transpose(img, (1, 0, 2)) for img in image], np.transpose(segmentation, (1, 0))
        sample['image'], sample['segmentation'] = image, segmentation
        return sample


class RandomHorizontalFlip(object):
    def __init__(self, prob=0.5):
        self.flip_prob = prob

    def __call__(self, sample):
        if np.random.rand() > self.flip_prob: return sample
        image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
        image, segmentation = [np.flip(img, axis=1) for img in image], np.flip(segmentation, axis=1)
        sample['image'], sample['segmentation'] = image, segmentation
        return sample


class RandomVerticalFlip(object):
    def __init__(self, prob=0.5):
        self.flip_prob = prob

    def __call__(self, sample):
        if np.random.rand() > self.flip_prob: return sample
        image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
        image, segmentation = [np.flip(img, axis=0) for img in image], np.flip(segmentation, axis=0)
        sample['image'], sample['segmentation'] = image, segmentation
        return sample


class RandomTranspose(object):
    def __init__(self, prob=0.5):
        self.flip_prob = prob

    def __call__(self, sample):
        if np.random.rand() > self.flip_prob: return sample
        image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
        image, segmentation = [np.transpose(img, (1, 0, 2)) for img in image], np.transpose(segmentation, (1, 0))
        sample['image'], sample['segmentation'] = image, segmentation
        return sample


class PhotoMetricDistortion(object):
    def __init__(self, **kwargs):
        self.brightness_delta = kwargs.get('brightness_delta', 32)
        self.contrast_lower, self.contrast_upper = kwargs.get('contrast_range', (0.5, 1.5))
        self.saturation_lower, self.saturation_upper = kwargs.get('saturation_range', (0.5, 1.5))
        self.hue_delta = kwargs.get('hue_delta', 18)

    def __call__(self, sample):
        image = sample['image'].copy()
        image = self.brightness(image)
        mode = np.random.randint(2)
        if mode == 1: image = self.contrast(image)
        # if image[0].shape[2] == 3:
        image = self.saturation(image)
        image = self.hue(image)
        if mode == 0: image = self.contrast(image)
        sample['image'] = image
        return sample

    def brightness(self, image):
        """brightness distortion"""
        if not np.random.randint(2): return image
        return self.convert(image, beta=np.random.uniform(-self.brightness_delta, self.brightness_delta))

    '''contrast distortion'''

    def contrast(self, image):
        if not np.random.randint(2): return image
        return self.convert(image, alpha=np.random.uniform(self.contrast_lower, self.contrast_upper))

    '''rgb2hsv'''

    def rgb2hsv(self, image):
        return [np.concatenate([cv2.cvtColor(img[:, :, 0:3], cv2.COLOR_RGB2HSV), img[:, :, 3:]], axis=2) for img in
                image]

    '''hsv2rgb'''

    def hsv2rgb(self, image):
        return [np.concatenate([cv2.cvtColor(img[:, :, 0:3], cv2.COLOR_HSV2RGB), img[:, :, 3:]], axis=2) for img in
                image]

    '''saturation distortion'''

    def saturation(self, image):
        if not np.random.randint(2): return image
        image = self.rgb2hsv(image)
        alpha = np.random.uniform(self.saturation_lower, self.saturation_upper)
        temp = []
        for i in range(len(image)):
            temp.append(image[i][..., 1])
        temp = self.convert(temp, alpha=alpha)
        for i in range(len(temp)):
            image[i][..., 1] = temp[i]
        image = self.hsv2rgb(image)
        return image

    '''hue distortion'''

    def hue(self, image):
        if not np.random.randint(2): return image
        image = self.rgb2hsv(image)
        alpha = np.random.randint(-self.hue_delta, self.hue_delta)
        for i in range(len(image)):
            image[i][..., 0] = (image[i][..., 0].astype(int) + alpha) % 180
        image = self.hsv2rgb(image)
        return image

    '''multiple with alpha and add beat with clip'''

    def convert(self, image, alpha=1, beta=0):
        image = [img.astype(np.float32) * alpha + beta for img in image]
        image = [np.clip(img, 0, 255) for img in image]
        return [img.astype(np.uint8) for img in image]


'''gaussian blur'''


class RandomGaussianBlur(object):
    def __init__(self, prob=0.5, radius=5):
        self.radius = radius
        self.gs_prob = prob

    def __call__(self, sample):
        if np.random.rand() > self.gs_prob: return sample
        image = sample['image'].copy()
        image = [cv2.GaussianBlur(img, (self.radius, self.radius), 0) for img in image]
        sample['image'] = image
        return sample


'''random rotate image'''
# RandomRotation后需接Normalize，因为填充使数据为float
# class RandomRotation(object):
#     def __init__(self, prob=0.5, mean=(115.6545965, 117.62014299, 106.01483799)*60, angle_upper=15, ignore_label=255, **kwargs):
#         # set attributes
#         self.angle_upper = angle_upper  # kwargs.get('angle_upper', 15)
#         self.rotation_prob = prob  # kwargs.get('rotation_prob', 0.5)
#         self.img_fill_value = mean
#         # self.default_fill_value = kwargs.get('img_fill_value', 0)
#         self.seg_fill_value = ignore_label  # kwargs.get('seg_fill_value', 255)
#         self.img_interpolation = kwargs.get('img_interpolation', 'bilinear')
#         self.seg_interpolation = kwargs.get('seg_interpolation', 'nearest')
#         # interpolation to cv2 interpolation
#         self.interpolation_dict = {
#             'nearest': cv2.INTER_NEAREST,
#             'bilinear': cv2.INTER_LINEAR,
#             'bicubic': cv2.INTER_CUBIC,
#             'area': cv2.INTER_AREA,
#             'lanczos': cv2.INTER_LANCZOS4
#         }
#
#     '''call'''
#     def __call__(self, sample):
#         if np.random.rand() > self.rotation_prob: return sample
#         image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
#         h_ori, w_ori, channel = image[0].shape
#         rand_angle = np.random.randint(-self.angle_upper, self.angle_upper)
#         matrix = cv2.getRotationMatrix2D(center=(w_ori / 2, h_ori / 2), angle=rand_angle, scale=1)
#         image = [np.float32(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) if channel == 3 else np.float32(img) for img in image]
#         image = [cv2.warpAffine(img, matrix, (w_ori, h_ori), flags=self.interpolation_dict[self.img_interpolation],
#                                 borderValue=self.img_fill_value[:channel]) for img in image]
#         segmentation = cv2.warpAffine(segmentation, matrix, (w_ori, h_ori),
#                                       flags=self.interpolation_dict[self.seg_interpolation],
#                                       borderValue=self.seg_fill_value)
#         image = [cv2.cvtColor(img, cv2.COLOR_RGB2BGR) if channel == 3 else img for img in image]
#         sample['image'], sample['segmentation'] = image, segmentation
#         return sample


'''random cutout image'''
# class RandomCutout(object):
#     def __init__(self, prob=0.5, num_holes=16, max_h_size=8, max_w_size=8, fill_value=0):
#         self.num_holes = num_holes
#         self.max_h_size = max_h_size
#         self.max_w_size = max_w_size
#         self.fill_value = fill_value
#         self.prob = prob
#
#     '''call'''
#     def __call__(self, sample):
#         if np.random.rand() > self.prob: return sample
#         image = sample['image'].copy()#, sample['segmentation'].copy()
#         h = image[0].shape[0]
#         w = image[0].shape[1]
#         for _ in range(self.num_holes):
#             y = np.random.randint(h)
#             x = np.random.randint(w)
#             y1 = np.clip(max(0, y - self.max_h_size // 2), 0, h)
#             y2 = np.clip(max(0, y + self.max_h_size // 2), 0, h)
#             x1 = np.clip(max(0, x - self.max_w_size // 2), 0, w)
#             x2 = np.clip(max(0, x + self.max_w_size // 2), 0, w)
#             for i in range(len(image)):
#                 image[i][y1: y2, x1: x2, :] = self.fill_value
#         sample['image'] = image
#         return sample

'''random rotation mirror fill'''


class RandomRotationMirror(object):
    def __init__(self, prob=0.3, angle_upper=30, **kwargs):
        # set attributes
        self.angle_upper = angle_upper
        self.rotation_prob = prob
        self.img_interpolation = kwargs.get('img_interpolation', 'bilinear')
        self.seg_interpolation = kwargs.get('seg_interpolation', 'nearest')
        # interpolation to cv2 interpolation
        self.interpolation_dict = {
            'nearest': cv2.INTER_NEAREST,
            'bilinear': cv2.INTER_LINEAR,
            'bicubic': cv2.INTER_CUBIC,
            'area': cv2.INTER_AREA,
            'lanczos': cv2.INTER_LANCZOS4
        }

    '''call'''

    def __call__(self, sample):
        if np.random.rand() > self.rotation_prob: return sample
        image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
        h_ori, w_ori, channel = image[0].shape
        rand_angle = np.random.randint(-self.angle_upper, self.angle_upper)
        matrix = cv2.getRotationMatrix2D(center=(w_ori / 2, h_ori / 2), angle=rand_angle, scale=1)
        image = [cv2.warpAffine(img, matrix, (w_ori, h_ori), flags=self.interpolation_dict[self.img_interpolation],
                                borderMode=cv2.BORDER_REFLECT_101) for img in image]
        segmentation = cv2.warpAffine(segmentation, matrix, (w_ori, h_ori),
                                      flags=self.interpolation_dict[self.seg_interpolation],
                                      borderMode=cv2.BORDER_REFLECT_101)
        sample['image'], sample['segmentation'] = image, segmentation
        return sample


'''random rotate image 90*N'''


class RandomRotation90(object):
    def __init__(self, prob=0.5):
        # random rotate 90*N, N = [0,1,2,3]
        self.rotation_prob = prob

    '''call'''

    def __call__(self, sample):
        if np.random.rand() > self.rotation_prob: return sample
        factor = np.random.randint(1, 4)
        image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
        image = [np.rot90(img, factor) for img in image]
        segmentation = np.rot90(segmentation, factor)
        sample['image'], sample['segmentation'] = image, segmentation
        return sample


'''random shift image'''
# class RandomShift(object):
#     def __init__(self, prob=0.3, limit=0.1):
#         self.limit = limit
#         self.shift_prob = prob
#
#     '''call'''
#     def __call__(self, sample):
#         if np.random.rand() > self.shift_prob: return sample
#         image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
#         limit = int(self.limit * image[0].shape[0])
#         dx = round(np.random.uniform(-limit, limit))
#         dy = round(np.random.uniform(-limit, limit))
#         height, width, channel = image[0].shape
#         y1 = limit + 1 + dy
#         y2 = y1 + height
#         x1 = limit + 1 + dx
#         x2 = x1 + width
#         image = [cv2.copyMakeBorder(img, limit + 1, limit + 1, limit + 1, limit + 1, borderType=cv2.BORDER_REFLECT_101)
#                  for img in image]
#         segmentation = cv2.copyMakeBorder(segmentation, limit + 1, limit + 1, limit + 1, limit + 1,
#                                           borderType=cv2.BORDER_REFLECT_101)
#         image = [img[y1:y2, x1:x2, :] for img in image]
#         segmentation = segmentation[y1:y2, x1:x2]
#         sample['image'], sample['segmentation'] = image, segmentation
#         return sample


'''pad image'''


class Padding(object):
    def __init__(self, output_size, ignore_label=255, data_type='numpy', **kwargs):
        self.output_size = output_size
        if isinstance(output_size, int): self.output_size = (output_size, output_size)
        assert data_type in ['numpy', 'tensor'], 'unsupport data type %s...' % data_type
        self.data_type = data_type
        self.img_fill_value = kwargs.get('img_fill_value', 0)
        self.seg_fill_value = ignore_label  # kwargs.get('seg_fill_value', 255)
        self.output_size_auto_adaptive = kwargs.get('output_size_auto_adaptive', True)

    '''call'''

    def __call__(self, sample):
        output_size = self.output_size[0], self.output_size[1]
        if self.output_size_auto_adaptive:
            if self.data_type == 'numpy':
                h_ori, w_ori = sample['image'][0].shape[:2]
            else:
                h_ori, w_ori = sample['image'][0].shape[1:]
            h_out, w_out = output_size
            if (h_ori > w_ori and h_out < w_out) or (h_ori < w_ori and h_out > w_out):
                output_size = (w_out, h_out)
        if self.data_type == 'numpy':
            image, segmentation = sample['image'].copy(), sample['segmentation'].copy()
            h_ori, w_ori = image[0].shape[:2]
            top = (output_size[0] - h_ori) // 2
            bottom = output_size[0] - h_ori - top
            left = (output_size[1] - w_ori) // 2
            right = output_size[1] - w_ori - left
            image = [cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=self.img_fill_value)
                     for img in image]
            segmentation = cv2.copyMakeBorder(segmentation, top, bottom, left, right, cv2.BORDER_CONSTANT,
                                              value=[self.seg_fill_value])
            sample['image'], sample['segmentation'] = image, segmentation
        else:
            image, segmentation = sample['image'], sample['segmentation']
            h_ori, w_ori = image[0].shape[1:]
            top = (output_size[0] - h_ori) // 2
            bottom = output_size[0] - h_ori - top
            left = (output_size[1] - w_ori) // 2
            right = output_size[1] - w_ori - left
            image = [F.pad(img, pad=(left, right, top, bottom), value=self.img_fill_value) for img in image]
            segmentation = F.pad(segmentation, pad=(left, right, top, bottom), value=self.seg_fill_value)
            sample['image'], sample['segmentation'] = image, segmentation

        return sample


'''np.array to torch.Tensor'''


class ToTensor(object):
    '''call'''

    def __call__(self, sample):
        sample['image'] = [torch.from_numpy((img.transpose((2, 0, 1))).astype(np.float32)) for img in sample['image']]
        sample['segmentation'] = torch.from_numpy(sample['segmentation'].astype(np.int64))  # .long()
        return sample


class ToTensor_test(object):
    '''call'''

    def __call__(self, sample):
        sample['image'] = [torch.from_numpy((img.transpose((2, 0, 1))).astype(np.float32)) for img in sample['image']]
        return sample


'''normalize the input image'''


class Normalize(object):
    def __init__(self, mean, std, **kwargs):
        self.mean = np.array(mean)
        self.std = np.array(std)
        self.to_rgb = kwargs.get('to_rgb', True)

    '''call'''

    def __call__(self, sample):
        for key in sample.keys():
            if key == 'image':
                image = [img.astype(np.float32) for img in sample[key]]
                mean = np.float64(self.mean.reshape(1, -1))
                stdinv = 1 / np.float64(self.std.reshape(1, -1))
                self.to_rgb = True if image[0].shape[2] == 3 else False
                if self.to_rgb:
                    image = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in image]
                image = [cv2.subtract(img, mean) for img in image]
                image = [cv2.multiply(img, stdinv) for img in image]
                sample[key] = image
        return sample
