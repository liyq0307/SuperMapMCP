import functools
import os
import io
import glob
import warnings

import numpy as np
import torch
import torch.nn as nn

from iobjectspy._logger import log_error
from .._torch_models.encoders import preprocess_input, get_preprocessing_fn
from .._torch_models.model_builder import build_torch_seg_model
from ..tools import get_preprocessing
from ...device_utils import Device_type


class GELU(nn.Module):
    def forward(self, x):
        return torch.nn.functional.gelu(x)


class CompatibleUpsamplingBilinear2d(nn.Module):
    def __init__(self, size=None, scale_factor=None):
        super().__init__()
        self.size = size
        self.scale_factor = scale_factor

    def forward(self, x):
        return torch.nn.functional.interpolate(
            x,
            size=self.size,
            scale_factor=self.scale_factor,
            mode='bilinear',
            align_corners=False
        )


def modify_state_dict(state_dict):
    # 处理GELU层的版本兼容性
    modified_state_dict = {}
    for key, value in state_dict.items():
        if 'gelu' in key.lower():
            # 确保GELU层使用新的实现
            new_key = key.replace('gelu.approximate', 'gelu')
            modified_state_dict[new_key] = value
        else:
            modified_state_dict[key] = value
    return modified_state_dict


def replace_upsampling(module):
    for name, child in module.named_children():
        if isinstance(child, nn.UpsamplingBilinear2d):
            setattr(module, name, CompatibleUpsamplingBilinear2d(
                size=child.size,
                scale_factor=child.scale_factor
            ))
        else:
            replace_upsampling(child)


class BaseEstimation:
    def __init__(self, model_path, config):
        pass

    def estimate_img(self):
        pass

    def estimate_tile(self):
        pass

    def load_model(self, model_path):
        pass

    def close_model(self):
        pass

    @torch.no_grad()
    def _predict_tile_local(self, predict_tile, out_shape):
        pass

    @torch.no_grad()
    def _predict_on_batch(self, predict_tiles, out_shape):
        pass


class BaseTorchEstimation(BaseEstimation):
    def __init__(self, model_path, sdm_config, gpus=[0, ], batch_size=1, test_aug=False, **kwargs):
        """
        初始化模型及其相关配置。

        该构造函数负责初始化模型和设备的设置，加载预处理步骤，并准备训练/推理所需的参数。
        它会根据给定的 GPU 列表和其他配置（如批次大小、数据增强等）设置环境，并加载模型。

        :param model_path: 模型存储路径，包含模型文件和配置文件。
        :param sdm_config: SDM 配置，包含模型类型和输入输出信息等。
        :param gpus: 使用的 GPU 列表，默认为 [0]。
        :param batch_size: 批次大小，默认为 1，设置为 GPU 数量时会自动调整。
        :param test_aug: 是否启用测试数据增强，默认为 `False`。
        :param kwargs: 其他额外的配置参数，如设备设置等。
        :return: None
        """
        self._setup_gpu(gpus)
        self._validate_model_path(model_path)
        self._setup_model_parameters(sdm_config)
        self._setup_device(kwargs.get('device'), gpus)

        self.test_aug = test_aug
        self.batch_size = len(gpus) if batch_size < len(gpus) else batch_size

        # preprocess image
        self._setup_preprocessing()
        # 获取目录下的所有文件
        all_files = glob.glob(os.path.join(model_path, '*'))
        # 过滤掉以.sdm结尾的文件
        self.torch_model_path = [file for file in all_files if not file.endswith('.sdm')][0]
        self._load_model()

    def _setup_gpu(self, gpus):
        """
        设置gpu环境变量
        :param gpus:
        :return:
        """
        self.gpus = gpus
        os.environ["CUDA_VISIBLE_DEVICES"] = ",".join(map(str, gpus)) if gpus else ""

    @staticmethod
    def _validate_model_path(model_path):
        """
        检查model文件有效
        :param model_path:
        :return:
        """
        if not isinstance(model_path, str):
            raise TypeError('model_path should be str')
        if not os.path.exists(model_path):
            raise Exception('model_path does not exist')

    def _setup_model_parameters(self, config):
        """
        用模型的参数初始化属性
        :param config:
        :return:
        """
        self.model_input = config.model_input[0]
        self.model_output = config.model_output[0]
        self._set_model_dimensions()
        self.class_type = config.class_type
        self.color_map = {c.class_value: tuple(c.class_color) for c in self.class_type}
        self.model_config = config
        self.model_name = config.model_architecture

    def _set_model_dimensions(self):
        """
        判断输入影像的波段格式是(C,W,H)还是(W,H,C)
        :return:
        """
        if np.argmin(self.model_input.shape) == 0:
            self._setup_first_band_order()
        else:
            self._setup_last_band_order()
        if self.model_input.shape[1] != self.model_input.shape[2]:
            raise ValueError("Model input width and height should be equal!")

    def _setup_first_band_order(self):
        self.band_order = 'first'
        self.seg_size = self.model_input.shape[1]
        self.input_bands = self.model_input.shape[0]
        self.out_width_height = [self.model_output.shape[1], self.model_output.shape[2]]
        self.output_msk_num = self.model_output.shape[0]

    def _setup_last_band_order(self):
        self.band_order = 'last'
        self.seg_size = self.model_input.shape[1]
        self.input_bands = self.model_input.shape[-1]
        self.out_width_height = [self.model_output.shape[0], self.model_output.shape[1]]
        self.output_msk_num = self.model_output.shape[-1]

    def _setup_device(self, device, gpus):
        """
        设置推理device
        :param device:
        :param gpus:
        :return:
        """
        if device is None:
            Device_type.setup()
        if gpus[0] == -1:
            Device_type.setup('cpu')
        else:
            Device_type.setup(device)
        self.device = Device_type.get_device()

    def _setup_preprocessing(self):
        """
        设置影像归一化参数
        :return:
        """
        self.image_min = self.model_config.image_min
        self.image_max = self.model_config.image_max
        self.encoder = self.model_config.encoder
        self.encoder_weights = self.model_config.encoder_weights

        if self.input_bands == 3:
            self._setup_three_band_preprocessing()
        else:
            self._setup_multi_band_preprocessing()

    def _setup_three_band_preprocessing(self):
        if self.encoder_weights is None:
            warnings.warn('encoder_weights is None, preprocessing using ImageNet weights')
            preprocessing_fn, self.mean, self.std = get_preprocessing_fn(self.encoder)
        else:
            preprocessing_fn, self.mean, self.std = get_preprocessing_fn(self.encoder, self.encoder_weights)
        self.preprocessing = get_preprocessing(preprocessing_fn)

    def _setup_multi_band_preprocessing(self):
        mean = [123.675, 116.280, 103.530]
        std = [58.395, 57.120, 57.375]
        self.mean = (mean * 60)[:self.input_bands]
        self.std = (std * 60)[:self.input_bands]

        if len(self.image_min) > 1:
            preprocessing_fn = functools.partial(preprocess_input,
                                                 mean=self.mean, std=self.std, input_max=self.image_max,
                                                 input_min=self.image_min)
        else:
            preprocessing_fn = functools.partial(preprocess_input, mean=self.mean, std=self.std)

        self.preprocessing = get_preprocessing(preprocessing_fn)

    def _load_model(self):
        """
        加载模型。

        该方法根据模型文件的扩展名来决定如何加载模型。如果模型文件是加密格式（`.pim`），则调用 `_load_encrypted_model()`
        加载加密模型；如果是普通格式（如 `.pth`），则调用 `_load_normal_model()` 加载普通模型。加载模型后，会将模型移到
        适当的设备（GPU 或 CPU），并将其设置为评估模式（`eval()`）。如果有多个 GPU 可用，则使用数据并行（`DataParallel`）
        来加速推理。

        :return: None
        """
        if self.torch_model_path.endswith('.pim'):
            self._load_encrypted_model(self.torch_model_path)
        else:
            self._load_normal_model(self.torch_model_path)

        Device_type.to_device(self.model, self.gpus[0])
        self.model.eval()

        if Device_type.device_count() > 1:
            self.model = Device_type.dataparallel(self.model, self.gpus)

    def _load_normal_model(self, model_path):
        # TODO: If torch new version fix operator bugs, please delete new model code, only use else code!
        if len(self.model_config.framework_version) == 0:
            self._setup_output_bands()
            self._load_new_model(model_path)
        else:
            self.model = torch.load(model_path, map_location=self.device)

    def _load_encrypted_model(self, model_path):
        from ......_jsuperpy._utils import check_pretrain_lic
        from ...crypto import CryptoOps

        crypto = CryptoOps()
        model_id = crypto.read_model_id(model_path)
        try:
            check_pretrain_lic(model_id)
        except RuntimeError:
            raise RuntimeError(f"No pretrained model License for {model_path}!")

        decrypted_data = crypto.decrypt_pth_file(model_path)
        decrypted_pth = io.BytesIO(decrypted_data)
        decrypted_model = torch.load(decrypted_pth)

        # 如果加载的是state_dict
        if isinstance(decrypted_model, dict):
            state_dict = modify_state_dict(decrypted_model)
            self.model.load_state_dict(state_dict)
        else:
            # 如果加载的是整个模型
            for module in decrypted_model.modules():
                if isinstance(module, torch.nn.GELU):
                    # 替换为兼容的GELU实现
                    module.__class__ = GELU
            model = decrypted_model

        replace_upsampling(model)
        self.model = decrypted_model

    def _setup_output_bands(self):
        """
        设置模型的输出波段数。

        该方法根据模型的类型（`model_type`）设置输出波段数。它会根据模型类型进行不同的配置：
        - 对于多分类模型（`multi_classification`），输出波段数为类别数（`class_type` 的长度）。
        - 对于二分类（`binary_classification`）和一般变化检测（`general_change_detection`）模型，输出波段数为 1。
        - 如果 `model_type` 不是这三种类型之一，则抛出异常并记录错误。

        :return: None
        """
        model_type = self.model_config.model_type.strip()
        if model_type == 'multi_classification':
            self.output_bands = len(self.class_type)
        elif model_type in ['general_change_detection', 'binary_classification']:
            self.output_bands = 1
        else:
            error_msg = 'model_type should be multi_classification or binary_classification or general_change_detection'
            log_error(error_msg)
            raise ValueError(error_msg)

    def _load_new_model(self, model_path):
        pretrained_model = torch.load(model_path)
        head_merge_method = self._get_head_merge_method(pretrained_model)

        self.model = build_torch_seg_model(
            in_channels=self.input_bands,
            classes=len(self.class_type) if len(self.class_type) > 2 else 1,
            backbone_name=self.encoder,
            encoder_weights=None,
            net_type=self.model_config.model_architecture,
            activation='sigmoid' if self.output_bands == 1 else None,
            head_merge_method=head_merge_method
        )
        self.model.load_state_dict(pretrained_model.state_dict(), strict=True)
        del pretrained_model

    @staticmethod
    def _get_head_merge_method(model):
        head = str(type(model.segmentation_head).__name__)
        _all_head_merge_method = ['add', 'cat', 'subtract']
        for method in _all_head_merge_method:
            if method in head:
                return method
        return 'subtract'

    def estimate_img(self, input_img, coversize, out_path, out_dataset_name, result_type, infer_region, **kwargs):
        """
        :param input_img: inference image
        :param coversize: inferece patch expand size
        :param out_path: output dataset path
        :param out_dataset_name: output dataset name
        :param result_type: region or grid
        :param seg_size: inference patch size
        :param infer_region: inference area, vector or rectangle coordinate
        :param kwargs:
        :return:
        """
        self.half_oversize = coversize
        # 更改推理尺寸，大尺寸可引入更多上下文信息
        if kwargs.get("seg_size") is not None:
            self.seg_size = kwargs.get("seg_size")
        dsm_dataset = kwargs.get('dsm_dataset')
        assert result_type in ['grid', 'region'], 'result_type should be grid or region'
        if self.output_msk_num > 1:
            self.back_or_no_value = -9999
        else:
            self.back_or_no_value = 0

        try:
            confidence_map = kwargs.get('confidence_map')
        except:
            confidence_map = False

        result_dataset = self._predict_with_rasterio(input_img, out_path,
                                                     out_dataset_name, result_type=result_type,
                                                     batch_size=self.batch_size, infer_region=infer_region,
                                                     confidence_map=confidence_map)

        return result_dataset
