# !/usr/bin/env python3
# coding=utf-8


""" Eval metrics and related

Hacked together by / Copyright 2020 Ross Wightman
"""
import torch
import torch.distributed as dist
import torch.nn.functional as F

class AverageMeter:
    """Computes and stores the average and current value"""
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

    def synchronize_between_processes(self):
        """
        Warning: does not synchronize the deque!
        """
        t = torch.tensor([self.count, self.total], dtype=torch.float64, device='cuda')
        dist.barrier()
        dist.all_reduce(t)
        t = t.tolist()
        self.count = int(t[0])
        self.total = t[1]

def accuracy(output, target, topk=(1,)): # 类别数量少时，topk的最大值应设置小于类别数
    """Computes the accuracy over the k top predictions for the specified values of k"""
    maxk = max(topk)
    batch_size = target.size(0)
    _, pred = output.topk(maxk, 1, True, True)
    pred = pred.t()
    correct = pred.eq(target.reshape(1, -1).expand_as(pred))
    return [correct[:k].reshape(-1).float().sum(0) * 100. / batch_size for k in topk]

class SoftTargetCrossEntropy(torch.nn.Module):
    def __init__(self):
        super(SoftTargetCrossEntropy, self).__init__()

    def forward(self, x, target):
        loss = torch.sum(-target * F.log_softmax(x, dim=-1), dim=-1)
        return loss.mean()

def one_hot(x, num_classes=4, on_value=1., off_value=0., device='cuda'):
    x = x.long().view(-1, 1)
    return torch.full((x.size()[0], num_classes), off_value, device=device).scatter_(1, x, on_value)

def adjust_learning_rate(optimizer, base_lr, global_steps, warm_steps, max_steps, power=0.9):
    for i in range(0, len(optimizer.param_groups)):
        optimizer.param_groups[i]['lr'] = base_lr * (float(global_steps) / warm_steps) ** power
    # else:
    #     curr_steps = global_steps - warm_steps
    #     max_steps = max_steps - warm_steps
    #     optimizer.param_groups[0]['lr'] = base_lr * (1 - float(curr_steps) / max_steps) ** power

def poly_learning_rate(base_lr, curr_iter, max_iter, power=0.9):
    """poly learning rate policy"""
    lr = base_lr * (1 - float(curr_iter) / max_iter) ** power
    return lr