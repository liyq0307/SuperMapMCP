# !/usr/bin/env python3
# coding=utf-8

from albumentations import Compose, Resize
from dotmap import DotMap
import platform
import sys
import traceback
from iobjectspy._logger import log_error, log_debug, log_warning, log_fatal, log_info
import os
import os.path as osp
import shutil
import tempfile
import copy
import warnings
import time
from collections import OrderedDict
import math
import numpy as np
from tqdm import tqdm
import cv2
from decimal import Decimal
import torch
import torch.distributed as dist
import torch.multiprocessing as mp
from tensorboardX import SummaryWriter
import rasterio
from rasterio.plot import reshape_as_image
from rasterio import transform as rio_transform
from rasterio.windows import Window
import pandas as pd
from iobjectspy import Dataset, FieldInfo, FieldType, \
    Feature, Rectangle, import_tif, DatasourceConnectionInfo, Datasource, raster_to_vector, EngineType, DatasetType
from .base_torch_models import Trainer, Estimation

from .cls_models.dataset import get_scene_image_from_csv
from ....toolkit._toolkit import split_train_val_scene_classification, split_train_val_image_classification,\
         stretch_n, get_config_from_yaml, preprocess_input, get_available_filename
from .cls_models import build_model
from .cls_models.train import TrainEpoch, ValidEpoch
from iobjectspy.ml.toolkit._toolkit import bounds_transform_coord
from ..semantic_seg.scheduler import LRScheduler, OptimScheduler
from .cls_models.utils import SoftTargetCrossEntropy
from ..device_utils import Device_type


class ClassificationEstimation(Estimation):
    def __init__(self, model_path, config, gpus=[0, ], batch_size=1):
        # 推理设备设置
        os.environ["CUDA_VISIBLE_DEVICES"] = ','.join(str(x) for x in gpus)
        self.gpus = gpus
        Device_type.setup('cpu') if gpus[0] == -1 else Device_type.setup()
        self.device = Device_type.get_device()
        if not isinstance(model_path, str):
            raise TypeError('model_path data type is incorrect, it should be str')
        if not os.path.exists(model_path):
            raise Exception('model_path does not exist')
        self.model_input = config.model_input[0]
        self.model_output = config.model_output[0]
        if np.argmin(self.model_input.shape) == 0:
            self.band_order = 'first'
            self.input_bands = self.model_input.shape[0]
            self.seg_size = self.model_input.shape[1]
        else:
            self.band_order = 'last'
            self.seg_size = self.model_input.shape[1]
            self.input_bands = self.model_input.shape[-1]
        self.tile_size = config.tile_size
        self.class_nums = self.model_output.shape[0]
        self.class_types = {class_type.class_id: class_type.class_name for class_type in config.class_type}
        self.is_stretch = config.is_stretch
        self.model_path = model_path
        self.torch_model_path = os.path.join(self.model_path, os.path.basename(self.model_path) + '.pth')
        self.load_model(self.torch_model_path)
        self.batch_size = len(gpus) if batch_size < len(gpus) else batch_size
        self.band_index = [i + 1 for i in range(self.input_bands)]

    def estimate_corregion_img(self, input_img, infer_region, field_name, **kwargs):
        try:
            rasterio.open(input_img)
        except:
            raise ValueError("input img is error")

        # input img is DOM imagery
        result_dataset = self._predict_with_rasterio_corregion(input_img, infer_region, field_name)

        return result_dataset

    def _predict_with_rasterio_corregion(self, input_img, infer_region=None, field_name=None):
        """
        基于raster_io预测得到的预测结果矢量数据

        :param input_img: 影像文件路径
        结果保存在infer_region的数据集中
        :return: 矢量结果数据集
        """
        if infer_region is None:
            raise ValueError("infer region is empty")
        if not isinstance(infer_region, Dataset):  # 仅支持矢量数据集
            raise TypeError('The type of infer region is not supported!')

        aug = Compose([
            Resize(self.seg_size, self.seg_size, p=1)]
        )

        type_Fieldname = 'class_type' if field_name is None else field_name
        pro_Fieldname = 'class_pro'
        # 如果已有字段，则覆盖原字段的数值
        if infer_region.is_available_field_name(type_Fieldname):
            type_fi = FieldInfo(type_Fieldname, FieldType.TEXT, max_length=50)
            infer_region.create_field(type_fi)

        if infer_region.is_available_field_name(pro_Fieldname):
            pro_fi = FieldInfo(pro_Fieldname, FieldType.DOUBLE)
            infer_region.create_field(pro_fi)

        infer_recordset = infer_region.get_recordset()
        if infer_recordset.is_empty():
            raise ValueError("DataVetctor is empty!")

        try:
            with rasterio.open(input_img) as ds:
                assert (self.input_bands <= ds.count), \
                    'The number of image bands should be greater than or equal to the training.'

                bounds = ds.bounds
                transf = ds.transform
                coordsy = ds.crs
                if coordsy is None:
                    raise ValueError("Input Imagery Lacks a CoordSy")
                img_bounds = Rectangle(bounds.left,bounds.bottom,bounds.right,bounds.top)
                infer_recordset = infer_region.query_with_bounds(bounds=img_bounds)

                infer_recordset.batch_edit()
                pbar = tqdm(total=infer_recordset.get_record_count(), desc='Model Infer')
                while infer_recordset.has_next():
                    if infer_recordset.is_bof():
                        infer_recordset.move_next()
                    each_feature = infer_recordset.get_feature()

                    feature_bounds = each_feature.bounds

                    rectangle_ymin, rectangle_xmin = rasterio.transform.rowcol(transf, feature_bounds.left,
                                                                               feature_bounds.top)
                    rectangle_ymax, rectangle_xmax = rasterio.transform.rowcol(transf, feature_bounds.right,
                                                                               feature_bounds.bottom)
                    block_xmin = rectangle_xmin
                    block_ymin = rectangle_ymin
                    tile_size_x = rectangle_xmax - rectangle_xmin
                    tile_size_y = rectangle_ymax - rectangle_ymin
                    # 超过区域范围的矢量面对象不进行任何操作，输出字段不填入数值
                    img = ds.read(self.band_index,
                                  window=Window(block_xmin, block_ymin, tile_size_x, tile_size_y))
                    shape_img = img.shape
                    if any(i == 0 for i in shape_img):
                        infer_recordset.move_next()
                        pbar.update(1)

                    else:
                        block = reshape_as_image(img)
                        all_block = preprocess_input(block, int8=True)
                        if tile_size_x == self.seg_size and tile_size_y == self.seg_size:
                            aug = Compose([])
                        augmented = aug(image=all_block)
                        all_block = augmented['image'][np.newaxis, :, :, :]
                        out_shape = self.class_nums
                        cls_pros = self._predict_tile_local(all_block, out_shape)
                        infer_class_index = np.argmax(cls_pros)
                        class_name = self.class_types[infer_class_index]
                        predict_pro = cls_pros[infer_class_index]

                        update_keys = {type_Fieldname: class_name,
                                       pro_Fieldname: predict_pro}

                        infer_recordset.set_values(update_keys)
                        infer_recordset.move_next()
                        pbar.update(1)

                pbar.close()
                infer_recordset.batch_update()
                infer_recordset.dispose()
                result = infer_region.name
                return result
        except:
            raise TypeError('The type of input image is not supported!')

    def estimate_img(self, input_img, out_path, out_dataset_name, result_type, infer_region, **kwargs):
        result_dataset = self._predict_with_rasterio(input_img, out_path, out_dataset_name, result_type, infer_region)
        return result_dataset

    def estimate_picture(self, input_img, out_path, out_dataset_name, **kwargs):
        result_dataset = self._predict_picture(input_img, out_path, out_dataset_name)
        return result_dataset

    def estimate_tile(self, input_img):
        if self.band_order == 'first':
            assert input_img.shape[0] == self.model_input.shape[0], "The channel sequence is incorrect or the number of channels does not match"
            assert input_img.shape[1] <= self.seg_size, "Input image length and width should be less than or equal to {}".format(self.seg_size)
            assert input_img.shape[2] <= self.seg_size, "Input image length and width should be less than or equal to {}".format(self.seg_size)
            input_width_height = [input_img.shape[1], input_img.shape[2]]

            process_img = np.pad(input_img, (
                (0, 0), (0, self.seg_size - input_img.shape[1]), (0, self.seg_size - input_img.shape[2])), 'constant')
        else:
            assert input_img.shape[2] == self.model_input.shape[2], "The channel sequence is incorrect or the number of channels does not match"
            assert input_img.shape[0] <= self.seg_size, "Input image length and width should be less than or equal to {}".format(self.seg_size)
            assert input_img.shape[1] <= self.seg_size, "Input image length and width should be less than or equal to {}".format(self.seg_size)
            input_width_height = [input_img.shape[0], input_img.shape[1]]

            process_img = np.pad(input_img, (
                (0, self.seg_size - input_img.shape[0]), (0, self.seg_size - input_img.shape[1]), (0, 0)), 'constant')
        out_shape = (self.class_nums,)
        cls_pros = self._predict_tile_local(process_img[np.newaxis, ...], out_shape=out_shape)
        class_index = np.argmax(cls_pros)
        class_name = self.class_types[class_index]
        predict_pro = cls_pros[class_index]
        rec = Rectangle(0, 0, input_img.shape[0], input_img.shape[1])
        region = rec.to_region()
        type_fi = FieldInfo('class_type', FieldType.TEXT, max_length=50)
        pro_fi = FieldInfo('class_pro', FieldType.DOUBLE)
        feature = Feature(region, {'class_type': class_name, 'class_pro': predict_pro},
                          field_infos=[type_fi, pro_fi])
        return feature
        pass

    # todo udb数据集支持
    # def _predict_with_matix(self, image_matix, out_ds, dst_name, band_order='last', coord_array=[1, 0, 0, 1, 0, 0]):
    #     """
    #     基于输入的图像矩阵，得到的预测结果二值图和矢量数据
    #
    #     :param image_matix: ndarray输入的原始图像矩阵
    #     :param out_ds: 输出矢量数据要存储的数据源
    #     :param dst_name: 输出矢量数据集的名字
    #     :param band_order: 输入数据集的band所在维度 'last' or 'first'
    #     :param coord_array: array 数组，依次为 0——X方向上的象素分辨素， 1——X方向的旋转系数，2——Y方向的旋转系数，
    #         3——Y方向上的象素分辨率，4——栅格地图左下角象素中心X坐标，5——栅格地图左下角象素中心Y坐标
    #     :return: （predict_int,result） predict_int——ndarray 二值或多值二维矩阵,result——矢量数据集
    #     """
    #
    #     if self.band_order is not band_order:
    #         if band_order is 'first':
    #             image_matix = np.transpose(image_matix, (1, 2, 0))
    #         elif band_order is 'last':
    #             image_matix = np.transpose(image_matix, (2, 0, 1))
    #         else:
    #             raise Exception('band_order parameter error')
    #
    #     predict_msk = self.__predict(image_matix)
    #     if self.output_msk_num > 1:
    #         predict_int = np.argmax(predict_msk, 0 if self.band_order == 'first' else -1)
    #     else:
    #         predict_msk = predict_msk[0, :, :] if self.band_order == 'first' else predict_msk[:, :, 0]
    #         predict_int = predict_msk > single_thresold
    #
    #     predict_int = predict_int.astype(np.int)
    #
    #     tmp_dsc = DatasourceConnectionInfo(server=':memory:', engine_type=EngineType.MEMORY)
    #     tmp_ds = Datasource().create(tmp_dsc)
    #
    #     result_dst = numpy_array_to_datasetraster(predict_int, coord_array[0], coord_array[3], tmp_ds,
    #                                               coord_array[4], coord_array[5], 'tmp', as_grid=False)
    #
    #     result = raster_to_vector(result_dst, 'class_type', out_dataset_type=DatasetType.REGION,
    #                               back_or_no_value=self.back_or_no_value,
    #                               is_thin_raster=True, out_data=out_ds, out_dataset_name=dst_name)
    #     tmp_ds.delete_all()
    #     tmp_ds.close()
    #
    #     return predict_int, result

    def _predict_with_rasterio(self, dom_path, out_ds, dst_name, result_type='region', infer_region=None):
        """
        基于raster_io预测得到的预测结果矢量数据

        :param dom_path: DOM文件路径
        :param out_ds: 输出数据源
        :param dst_name: 输出数据集名字
        :return: 矢量结果数据集
        """
        from iobjectspy._jsuperpy.data._util import check_output_datasource, get_output_datasource
        blocksize = self.tile_size
        region_mask = None
        if self.tile_size != self.seg_size:
            aug = Compose([
                Resize(self.seg_size, self.seg_size, p=1)]
            )
        else:
            aug = Compose([])
        tif_ext = ['.tif', '.TIF', '.tiff', '.TIFF']
        is_tif = [dst_name.endswith(e) for e in tif_ext]
        is_tif = True if True in is_tif else False
        dst_name = os.path.basename(dst_name).split('.')[0]
        out_ds = get_output_datasource(out_ds)
        out_tmp_name, tmp_file = get_available_filename(os.path.dirname(out_ds.connection_info.server), dst_name + '.tif')
        check_output_datasource(out_ds)
        if dst_name is None:
            dst_name = 'NewDataset'

        try:
            with rasterio.open(dom_path) as ds:
                assert (self.input_bands <= ds.count), 'The number of image bands should be greater than or equal to the training.'
                if infer_region is not None:
                    rectangle_ymin, rectangle_xmin, bounds, width, height, transform, \
                        out_region_mask = bounds_transform_coord(ds, infer_region, mode='general')
                    if out_region_mask is not None:
                        with warnings.catch_warnings():
                            warnings.simplefilter("ignore")
                            region_mask = rasterio.open(out_region_mask)
                else:
                    bounds = ds.bounds
                    width, height = ds.width, ds.height
                    rectangle_ymin, rectangle_xmin = 0, 0
                    transform = ds.transform
                rdst = rasterio.open(tmp_file, 'w', driver='GTiff', width=width, height=height,
                                     count=1, crs=ds.crs, transform=transform, dtype=np.uint8)

                # rdst.write_colormap(1, self.color_map)
                width_block = width // blocksize
                height_block = height // blocksize
                ds_transform = ds.transform
                pbar = tqdm(total=(height_block + 1) * (width_block + 1), desc='Model Infer')

                for i in range(height_block + 1):
                    for j in range(width_block + 1):
                        # slice the image
                        block = np.zeros([self.input_bands, blocksize, blocksize], dtype=np.float64)

                        x, y = j * blocksize + rectangle_xmin, i * blocksize + rectangle_ymin
                        if j * blocksize + blocksize > width:
                            x = width - blocksize + rectangle_xmin
                        if i * blocksize > height:
                            y = height - blocksize + rectangle_ymin
                        img = ds.read(self.band_index, window=Window(x, y, blocksize, blocksize), boundless=True)
                        if region_mask is not None:
                            mask = region_mask.read(window=Window(x - rectangle_xmin, y - rectangle_ymin, blocksize, blocksize), boundless=True)
                            img = img * mask
                        block[:, :img.shape[1], :img.shape[2]] = img[:self.input_bands, :, :]
                        all_block = reshape_as_image(block)
                        if self.is_stretch:
                            # todo 基于rasterio 窗口实现计算最大最小值
                            if 'all_max' not in dir() or 'all_min' not in dir():
                                all_block = stretch_n(all_block)
                            # else:
                            #     all_block = stretch_min_max(all_block, all_min, all_max)
                            all_block = preprocess_input(all_block, int8=False)
                        else:
                            all_block = preprocess_input(all_block, int8=True)
                        augmented = aug(image=all_block)
                        all_block = augmented['image'][np.newaxis, :, :, :]

                        out_shape = (self.class_nums)
                        cls_pros = self._predict_tile_local(all_block, out_shape)
                        class_index = np.argmax(cls_pros)
                        min_col, min_row, max_col, max_row = j * blocksize + rectangle_xmin, i * blocksize + rectangle_ymin, \
                                                             j * blocksize + rectangle_xmin + blocksize, i * blocksize + rectangle_ymin + blocksize

                        if j * blocksize + blocksize > width:
                            max_col = width + rectangle_xmin
                        if i * blocksize + blocksize > height:
                            max_row = height + rectangle_ymin

                        if ds.crs is not None:
                            min_x, max_y = rio_transform.xy(ds_transform, min_row, min_col)
                            max_x, min_y = rio_transform.xy(ds_transform, max_row, max_col)
                        else:
                            min_x, max_y = ds.height - min_col, min_row
                            max_x, min_y = ds.height - max_col, max_row

                        w, h = img.shape[2], img.shape[1]
                        if j * blocksize + blocksize > width:
                            w = width - j * blocksize
                        if i * blocksize + blocksize > height:
                            h = height - i * blocksize

                        out_block = np.ones([1, h, w], dtype=np.uint8) * class_index
                        rdst.write(out_block,
                                   window=Window(j * blocksize, i * blocksize,
                                                 w, h))
                        pbar.update(1)
                pbar.close()
                rdst.close()
                self.close_model()
                if region_mask is not None:
                    region_mask.close()
                    os.remove(out_region_mask)
                if result_type.strip() == 'grid':
                    if is_tif:
                        result = out_tmp_name
                    else:
                        try:
                            result = import_tif(tmp_file, output=out_ds, out_dataset_name=dst_name,
                                                is_import_as_grid=True)
                            result = result[0] if isinstance(result, list) and len(result) > 0 else result
                            os.remove(tmp_file)
                        except Exception as e:
                            log_error('Import Datasource Failed! Error is {}'.format(e))
                            sys.stderr.write(
                                'Import TIF to Dataset Failed! Copy Raster File to Out Datasource\'s Directory. '
                                'Please check iobjectspy.log for error.')
                            result = out_tmp_name
                elif result_type.strip() == 'region':
                    try:
                        tmp_udb_file = os.path.join(tempfile.mkdtemp(), 'tmp.udbx')
                        tmp_dsc = DatasourceConnectionInfo(server=tmp_udb_file, engine_type=EngineType.UDBX)
                        tmp_ds = Datasource().create(tmp_dsc)
                        dst_mask_tmp = import_tif(tmp_file, output=tmp_ds, out_dataset_name='mask_tmp',
                                                  is_import_as_grid=True)

                        dst_mask = dst_mask_tmp[0] if isinstance(dst_mask_tmp, list) and len(
                            dst_mask_tmp) > 0 else 'mask_tmp'
                        result = raster_to_vector(tmp_ds[dst_mask], 'class_type', out_dataset_type=DatasetType.REGION,
                                                  is_thin_raster=True, out_data=out_ds, out_dataset_name=dst_name)
                        result = result.name if result is not None else ''
                        tmp_ds.delete_all()
                        tmp_ds.close()
                        os.remove(tmp_file)
                        os.remove(tmp_udb_file)
                    except Exception as e:
                        log_error(traceback.format_exc())
                        result = ''

                return result
        except:
            raise TypeError("Unsupport image format")


    def _predict_picture(self, dom_path, out_ds, out_dataset_name):
        """
        picture预测得到的预测结果

        :param dom_path: DOM文件路径
        :param out_ds: 输出数据源
        :return:
        """
        path_list = []
        label_index_list = []
        label_list = []
        probability_list = []
        if not os.path.exists(dom_path):
            print("there is no such path", dom_path)
        if os.path.exists(out_ds):
            print("exist out path", out_ds)
        else:
            os.makedirs(out_ds, exist_ok=True)
            print("creat out path", out_ds)
        out_list = os.listdir(out_ds)
        out_list = [i for i in out_list
                    if (i.endswith(".csv") and i.startswith(out_dataset_name))]
        out_list.sort()  # (key=lambda x: int(x[-6:-4]))
        if len(out_list) == 0:
            out_dataset_name = out_dataset_name + ".csv"
        elif (len(out_list) == 1) and (out_list[-1][-6:-4] != "_1"):  # sun 0224 bug add
            out_dataset_name = out_dataset_name + "_1.csv"
        else:
            out_dataset_name = out_dataset_name + "_" \
                               + str(int(out_list[-1][-5]) + 1) + ".csv"
        out_dataset_path = os.path.join(out_ds, out_dataset_name)
        img_list = os.listdir(dom_path)
        p = 0
        pbar = tqdm(total=len(img_list), desc='Model Infer')
        for img_name in img_list:
            img_path = os.path.join(dom_path, img_name)
            path_list.append(img_path)
            ####################读入图像###############################
            # image = cv2.imread(img_path, cv2.IMREAD_COLOR)
            if img_path.endswith('.tif'):
                image = rasterio.open(img_path).read()
                image = reshape_as_image(image)
            else:
                try:
                    image = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # sun
                except:
                    try:
                        image = rasterio.open(img_path).read()
                        image = reshape_as_image(image)
                    except:
                        raise TypeError("Unsupport image format")
            res = cv2.resize(image, (self.seg_size, self.seg_size))  # width, height
            image_np = np.array(res, dtype=int)  # / 255.0
            image_np = preprocess_input(image_np, int8=True)
            image_np = image_np[np.newaxis, :, :, :]
            out_shape = (self.class_nums)
            cls_pros = self._predict_tile_local(image_np, out_shape)
            class_index = np.argmax(cls_pros)
            label_index_list.append(class_index)
            class_name = self.class_types[class_index]
            label_list.append(class_name)
            predict_pro = cls_pros[class_index]
            predict_pro = Decimal(float(predict_pro)).quantize(Decimal("0.0000"))
            probability_list.append(predict_pro)
            ####################写入图像########################
            # save_path = os.path.join(out_ds, class_name)
            # if not os.path.exists(save_path):
            #     os.makedirs(save_path)
            # cv2.imwrite(os.path.join(save_path, img_name), res)
            # print("%s has been predicted and saved!" % img_name)
            # p += 1
            # view_bar(p, len(img_list))
            pbar.update(1)
        pbar.close()
        df_dict = {
            "path": path_list,
            "label_index": label_index_list,
            "label": label_list,
            "probability": probability_list
        }
        df = pd.DataFrame(data=df_dict)
        df.to_csv(out_dataset_path, header=True)  # index=True,
        self.close_model()
        return out_dataset_name

class ClassificationTrainer(Trainer):
    def __init__(self):
        super().__init__()
        self.callbacks = []
        self.loss = []
        self.acc = []
        self.val_loss = []
        self.val_acc = []
        self.model_architecture = 'cnn'

    def train(self, train_data_path, config, epoch=1, batch_size=1, lr=0.0001, output_model_path='./',
              output_model_name='unet',
              log_path=None, backbone_name='efficientnet-b3', backbone_weight_path=None, reload_model=False,
              pretrained_model_path=None, gpus=[0,], init_data=True, **kwargs):

        self.config = config
        self.init_data = init_data
        self.train_data_path = train_data_path
        self.data_config = get_config_from_yaml(
            os.path.join(self.train_data_path, os.path.basename(self.train_data_path) + '.sda'))
        self.data_type = self.data_config.dataset.data_type
        self.kwargs = kwargs

        # dataset settings
        if self.init_data:
            self._init_data()
            print('Training Data is inited!')
        if not self.init_data and not os.path.exists(os.path.join(self.train_data_path, 'csv_path')):
            log_warning('parameter init_data should be true when csv_path is none, it will default to true')
            self._init_data()
            print('Training Data is inited!')

        # 训练设备设置
        os.environ["CUDA_VISIBLE_DEVICES"] = ','.join(str(x) for x in gpus)
        multiprocessing_distributed = True
        dist_url = 'tcp://127.0.0.1:6789'
        ngpus_per_node = len(gpus)
        if len(gpus) == 1 or None:
            multiprocessing_distributed = False
        argss = [train_data_path, config, epoch, batch_size, lr, output_model_path, output_model_name, log_path,
                 backbone_name, backbone_weight_path, reload_model, pretrained_model_path, multiprocessing_distributed,
                 dist_url, kwargs]
        if multiprocessing_distributed:
            port = self.find_free_port()
            dist_url = f"tcp://127.0.0.1:{port}"
            argss[-2] = dist_url
            mp.spawn(self.main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, argss))
        else:
            self.main_worker(gpus, ngpus_per_node, argss)

    def main_worker(self, gpu, ngpus_per_node, argss):
        global args
        args = argss
        train_data_path, config, epoch, batch_size, lr, output_model_path, output_model_name, log_path, backbone_name, \
        backbone_weight_path, reload_model, pretrained_model_path, multiprocessing_distributed, dist_url, kwargs = args
        # multi-gpu settings

        self.multiprocessing_distributed = multiprocessing_distributed
        self.Rank = gpu if self.multiprocessing_distributed else 0
        Device_type.setup(kwargs.get('device'))
        Device_type.before_train()
        device = Device_type.get_device()
        self.cuda_count = Device_type.device_count()
        self.data_works = self.cuda_count * 2 + 1 if kwargs.get('data_works') is None else kwargs.get('data_works')
        if self.multiprocessing_distributed:
            Device_type.init_dist(ip=dist_url, world_size=ngpus_per_node, rank=gpu)

        # data params
        self.train_data_path = train_data_path
        self.data_config = get_config_from_yaml(
            os.path.join(self.train_data_path, os.path.basename(self.train_data_path) + '.sda'))
        self.data_type = self.data_config.dataset.data_type
        assert self.data_type in (
            'image_classification', 'scene_classification'), 'data_type should be image_classification or scene_classification '
        self.class_type = self.data_config.dataset.class_type
        self.label_dict = {c.class_name: c.class_id for c in self.class_type}
        self.tile_size = self.data_config.dataset.tile_size
        image_counts = np.array([c.image_count for c in self.class_type])
        self.class_weight = list((image_counts.sum(dtype=np.float64) / image_counts.shape[0]) / (image_counts + 1.0))

        # model params
        self.model_type = self.data_type
        self.input_bands = self.data_config.dataset.x_bandnum
        self.model_min_tile_size = self.config.model.min_tile_size
        self.model_size = max(self.model_min_tile_size, self.tile_size)
        self.model_input = [(self.input_bands, self.model_size, self.model_size)]
        self.model_output = [(len(self.class_type),)]
        self.interval = self.config.trainer.interval_validation

        assert self.input_bands >= 1, 'The number of input bands should be greater than or equal 1'
        self.backbone_name = backbone_name
        if self.backbone_name is None or self.backbone_name.strip() == '':
            self.backbone_name = self.config.model.backbone_name
            log_warning('backbone_name is None, it will use default backbone_name: {}'.format(self.backbone_name))

        # train params
        self.config = config
        self.config_path = kwargs.get('config_path')
        self.epoch = epoch
        self.start_epoch = 0
        self.batch_size = batch_size
        self.lr = lr
        self.win_workers = self.config.trainer.workers
        self.lr_scheduler = self.config.trainer.lr_scheduler
        self.optimizer = self.config.trainer.optimizer
        self.update_freq = self.config.trainer.update_freq
        self.output_model_path_base = output_model_path
        self.output_model_name = output_model_name
        self.backbone_weight_path = backbone_weight_path
        self.pretrained_model_path = pretrained_model_path
        self.log_path = log_path
        self.reload_model = reload_model
        self.init_callbacks(log_path)
        self.writers = SummaryWriter(self.config.trainer.callbacks.tensorboard_log_dir)
        self.checkpoint_dir = self.config.trainer.callbacks.checkpoint_dir
        self.output_model_path = osp.join(self.output_model_path_base, self.output_model_name)
        file_num = 1
        origin_output_model_path = self.output_model_path
        while os.path.exists(self.output_model_path) and os.path.exists(osp.join(self.output_model_path,
                osp.basename(self.output_model_path.rstrip(osp.sep)) + '.sdm')):
            self.output_model_path = origin_output_model_path + ('_' + str(file_num))
            file_num += 1
        if self.main_process(self.multiprocessing_distributed, self.Rank):
            if not osp.exists(self.output_model_path):
                os.makedirs(self.output_model_path)
        self.model_base_name = osp.basename(self.output_model_path.rstrip(osp.sep))
        self.torch_model_path = osp.join(self.output_model_path, self.model_base_name + '.pth')
        self.sdm_path = osp.join(self.output_model_path, self.model_base_name + '.sdm')
        self.sdl_path = osp.join(self.log_path, 'latest.sdl')

        # change config params
        self.config.trainer.num_epochs = epoch
        self.config.trainer.batch_size = batch_size
        self.config.trainer.learning_rate = lr
        self.warmup_epochs = self.config.trainer.lr_method.warmup_epoch
        self.lr_warmup = self.config.trainer.lr_method.warmup
        self.lr_decay = self.config.trainer.lr_method.decay

        # self.output_class = self.config.model.output_class
        self.output_class = len(self.class_type)
        self.model = build_model(self.output_class, backbone_name=self.backbone_name,
                                 in_channels=self.data_config.dataset.x_bandnum, encoder_weights='imagenet')
        if self.main_process(self.multiprocessing_distributed, self.Rank):
            self.model_clone = copy.deepcopy(self.model)
        model_params = self.model.parameters()

        if not self.reload_model:
            if self.pretrained_model_path is not None:
                # self.model = build_model(self.output_class, backbone_name=self.backbone_name, encoder_weights=None)
                if self.pretrained_model_path.endswith('.sdm') or self.pretrained_model_path.endswith('.pth'):
                    log_info('loaded backbone model from {}'.format(self.pretrained_model_path))
                    try:
                        self.model.load_state_dict(torch.load(self.pretrained_model_path.replace('.sdm', '.pth')).state_dict(), strict=False)
                    except:
                        self.model.load_state_dict(torch.load(self.pretrained_model_path.replace('.sdm', '.pth')), strict=False)
                else:
                    log_error('The pre-trained model: {} does not exist'.format(self.pretrained_model_path))
            elif self.backbone_weight_path is not None:
                log_info('loaded backbone model from {}'.format(self.backbone_weight_path))
                # self.model = build_model(self.output_class, backbone_name=self.backbone_name, encoder_weights=None)
                try:
                    self.model.load_state_dict_ext(torch.load(self.backbone_weight_path).state_dict(), in_channels=self.data_config.dataset.x_bandnum, strict=False)
                except:
                    self.model.load_state_dict_ext(torch.load(self.backbone_weight_path), in_channels=self.data_config.dataset.x_bandnum, strict=False)

        if self.multiprocessing_distributed:
            batch_size_train = int(self.config.trainer.batch_size / ngpus_per_node)
            batch_size_val = int(self.config.trainer.batch_size / ngpus_per_node)
            workers = int(self.data_works / ngpus_per_node)
            self.model = Device_type.distributed(self.model, device_ids=gpu, find_unused_parameters=True)
        else:
            batch_size_train = self.config.trainer.batch_size
            batch_size_val = self.config.trainer.batch_size
            workers = self.data_works
            self.model = Device_type.to_device(self.model, gpu[0])

        if self.reload_model:
            try:
                self.checkpoint = torch.load(os.path.join(self.checkpoint_dir, 'latest.pth'),
                                             map_location=Device_type.get_device())
            except:
                raise FileNotFoundError('There are no latest.pth file in {}'.format(self.checkpoint_dir))
            self.lr_decay = self.checkpoint['lr_decay']
            self.lr = self.checkpoint['lr']
            self.batch_size = self.checkpoint['batch_size']
            self.start_epoch = self.checkpoint['current_epoch']
            try:
                self.model.load_state_dict(self.checkpoint['model'].state_dict())
            except:
                self.model.module.load_state_dict(self.checkpoint['model'].state_dict())
            self.optimizer_state_dict = self.checkpoint['optimizer']
            self.epoch = self.checkpoint['num_epochs']
            optimizer, self.lr = OptimScheduler(model_params, self.optimizer, self.lr, self.batch_size)
            optimizer.load_state_dict(self.optimizer_state_dict)
        else:
            optimizer, self.lr = OptimScheduler(model_params, self.optimizer, self.lr, self.batch_size)

        train_path = os.path.join(self.train_data_path, 'csv_path', 'train.csv')
        val_path = os.path.join(self.train_data_path, 'csv_path', 'val.csv')

        train_dataset = self._get_data_from_csv(train_path, True, image_size=self.model_size)
        valid_dataset = self._get_data_from_csv(val_path, False, image_size=self.model_size)
        syst = platform.system()
        num_tasks = self.get_world_size()
        if syst == 'Windows':
            workers = self.win_workers
        train_sampler = torch.utils.data.DistributedSampler(
            train_dataset, num_replicas=num_tasks, rank=self.Rank, shuffle=True, seed=1234)  # seed=args.seed,
        if self.multiprocessing_distributed:
            val_sampler = torch.utils.data.DistributedSampler(
                valid_dataset, num_replicas=num_tasks, rank=self.Rank, shuffle=False)
        else:
            val_sampler = torch.utils.data.SequentialSampler(valid_dataset)

        train_loader = torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size_train,
                                                   num_workers=workers, pin_memory=True, drop_last=True)
        valid_loader = torch.utils.data.DataLoader(valid_dataset, sampler=val_sampler, batch_size=batch_size_val,
                                                   shuffle=False, num_workers=workers, pin_memory=True)
        scheduler = LRScheduler(warmup_mode=self.lr_warmup, decay_mode=self.lr_decay, base_lr=self.lr, nepochs=self.epoch,
                                iters_per_epoch=len(train_dataset) // self.batch_size,
                                power=0.9, step_ratio=[0.4, 0.7, 0.9], step_factor=0.1,
                                warmup_epochs=self.warmup_epochs)

        loss = torch.nn.CrossEntropyLoss()  # SoftTargetCrossEntropy()
        if self.multiprocessing_distributed:
            loss = Device_type.to_device(loss, gpu)
        else:
            loss = Device_type.to_device(loss)

        train_epoch = TrainEpoch(self.model, loss=loss, optimizer=optimizer, device=device, verbose=True,
                                 update_freq=self.update_freq, base_lr=self.lr,
                                 scheduler=scheduler, start_epoch=[self.start_epoch, len(train_dataset) // self.batch_size])
        valid_epoch = ValidEpoch(self.model, loss=loss, device=device, verbose=True)

        max_score = 0
        if self.config.trainer.num_epochs > 0:
            for i in range(self.start_epoch, self.epoch):
                if self.multiprocessing_distributed:
                    train_loader.sampler.set_epoch(epoch)
                train_logs, valid_logs = None, None
                try:
                    if self.main_process(self.multiprocessing_distributed, self.Rank):
                        print('\nEpoch: {}/{}'.format(i + 1, epoch))
                    train_logs = train_epoch.run(train_loader, self.multiprocessing_distributed, self.Rank)
                    if self.main_process(self.multiprocessing_distributed, self.Rank):
                        for k, v in train_logs.items():
                            self.writers.add_scalar('train/' + str(k), v, i)
                    # 间隔验证，节省时间，设置10为验证间隔，超过0.8的epoch比例开始完全验证
                    if i > int(epoch * 0.80) and int(i % self.interval) != 0:
                        valid_logs = valid_epoch.run(valid_loader, self.multiprocessing_distributed, self.Rank)
                        if self.main_process(self.multiprocessing_distributed, self.Rank):
                            for k, v in valid_logs.items():
                                self.writers.add_scalar('valid/' + str(k), v, i)

                        if max_score <= valid_logs['acc']:
                            max_score = valid_logs['acc']
                            if self.main_process(self.multiprocessing_distributed, self.Rank):
                                self._save_model_pth(i, self.model, self.model_clone, max_score, **kwargs)
                                print('Model saved!')
                    elif int(i % self.interval) == 0:
                        valid_logs = valid_epoch.run(valid_loader, self.multiprocessing_distributed, self.Rank)
                        if self.main_process(self.multiprocessing_distributed, self.Rank):
                            for k, v in valid_logs.items():
                                self.writers.add_scalar('valid/' + str(k), v, i)

                        if max_score <= valid_logs['acc']:
                            max_score = valid_logs['acc']
                            if self.main_process(self.multiprocessing_distributed, self.Rank):
                                self._save_model_pth(i, self.model, self.model_clone, max_score, **kwargs)
                                print('Model saved!')
                    if self.main_process(self.multiprocessing_distributed, self.Rank):
                        self._save_latest_model_pth(i + 1, self.model, self.model_clone, optimizer)
                        self._saving_latest_model_sdl(i + 1, max_score)

                finally:
                    del train_logs, valid_logs
            if self.main_process(self.multiprocessing_distributed, self.Rank):
                self.writers.close()
                return self._saving_model(), max_score

    # def _init_classtype(self):
    #     scene_classification_path = os.path.join(self.train_data_path, 'scene_classification_id.csv')
    #     self.class_type = []
    #     self.label_dict = {}
    #     with open(scene_classification_path, 'r', encoding='utf8') as f:
    #         for line in f:
    #             line = line.strip().split(',')
    #             self.class_type.append(DotMap(OrderedDict([('class_name', line[1]), ('class_value', int(line[0]))])))
    #             self.label_dict[line[1]] = int(line[0])

    def _init_data(self):
        if self.data_type == 'image_classification':
            return split_train_val_image_classification([self.train_data_path],
                                                    os.path.join(self.train_data_path, 'csv_path'),
                                                    val_scale=self.config.trainer.validation_split)
        else:
            return split_train_val_scene_classification([self.train_data_path],
                                                                os.path.join(self.train_data_path, 'csv_path'),
                                                                val_scale=self.config.trainer.validation_split)

    def _get_data_from_csv(self, data_path, is_aug=False, image_size=None):
        if data_path.endswith('.csv'):
            return get_scene_image_from_csv(data_path, self.label_dict, self.input_bands, is_aug,
                                            image_size=image_size)
        else:
            raise Exception('You should input a *.csv file')
