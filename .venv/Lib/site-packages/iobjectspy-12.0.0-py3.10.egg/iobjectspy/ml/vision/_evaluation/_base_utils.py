# !/usr/bin/env python3
# coding=utf-8

import os
from collections import OrderedDict

import numpy as np
import yaml
from dotmap import DotMap
from sklearn.metrics import confusion_matrix as sk_confusion_matrix

from iobjectspy import DatasetVector, Feature, FieldInfo
from iobjectspy import overlay, OverlayMode, Datasource,clip_vector
from iobjectspy._jsuperpy.data._util import get_output_datasource, DatasetType, FieldType
from iobjectspy.ml.toolkit._create_training_data_util import _get_input_feature
from iobjectspy.ml.toolkit._toolkit import save_config_to_yaml


def _confusion_matrix(y_true, y_pred, labels=None):
    """
    根据y_true 和 y_pred 计算两者的混淆矩阵，支持单类和多类

    :param y_true: 一维的ndarray
    :param y_pred: 一维的ndarray，应与y_true的size一致
    :param labels: 支持输入label值
    :return: 混淆矩阵 n×n n为类别数,pred,col为true
    """

    categorys = []
    for i in labels:
        categorys.append(labels[i])
    return np.transpose(sk_confusion_matrix(y_true, y_pred, labels=categorys))


def _confusion_matrix_vector(y_true, y_pred, true_field, pred_field, labels, compute_type, field_name_not_exist):
    """
    根据y_true 和 y_pred 计算两者的混淆矩阵，支持单类和多类

    :param y_true: 真实数据 ,面数据集
    :type y_true: DatasetVector
    :param y_pred: 预测数据，面数据集
    :type y_pred: DatasetVector
    :param true_field: 真实数据类别字段值
    :type true_field: str
    :param pred_field: 预测数据类别字段值
    :type pred_field: str
    :param labels: 支持输入label值
    :return: 混淆矩阵 n×n n为类别数
    """
    temp_true_field = None
    if compute_type == 'multi':
        if true_field == None or pred_field == None:
            raise ValueError("The class_value_field cannot be None")
        if y_true.get_field_info(true_field).type != y_pred.get_field_info(pred_field).type:
            raise ValueError("The types of class_value_field must be same")
        if true_field != pred_field and true_field.upper() == pred_field.upper():
            # 这里的if语句内的内容是为了处理真值数据集和推理数据集分类字段名称为DLMC，dlmc这种字母相同，大小写不同造成叠加分析（合并）后数据集中无法同时保留这两个字段的问题
            i = 1
            while not y_pred.is_available_field_name('{}_{}'.format(true_field, i)):
                i += 1
            temp_true_field = '{}_{}'.format(true_field, i)
            y_pred.create_field(FieldInfo(temp_true_field, y_true.get_field_info(true_field).type, max_length=255))
            y_pred.update_field_express(temp_true_field, pred_field)
            pred_field = temp_true_field
    temp_ds = Datasource.create(':memory:')
    categorys = labels
    confusion_matrix = np.zeros((len(categorys), len(categorys)), dtype=float)
    bounds = y_true.bounds.intersect(y_pred.bounds)
    y_true_record = clip_vector(input_data=y_true,clip_region=bounds.to_region(),out_data=temp_ds,out_dataset_name='y_true_record')
    y_pred_record = clip_vector(input_data=y_pred,clip_region=bounds.to_region(),out_data=temp_ds,out_dataset_name='y_pred_record')
    # y_true_record = y_true.query_with_bounds(bounds)
    # y_pred_record = y_pred.query_with_bounds(bounds)

    if compute_type == 'binary' or field_name_not_exist:

        out_dataset = overlay(y_true_record, y_pred_record, OverlayMode.INTERSECT, out_data=temp_ds, out_dataset_name='intersect')
        tmp_record = out_dataset.query_with_filter()
        confusion_matrix[1, 1] = _get_vector_area(tmp_record)
    else:
        if compute_type == 'multi':
            if true_field is None:
                true_field = 'value'
            if pred_field is None:
                pred_field = 'value'
        out_dataset = overlay(y_true_record, y_pred_record, OverlayMode.UNION, source_retained=[true_field, ],
                              overlay_retained=[pred_field, ],
                              out_data=temp_ds, out_dataset_name='intersect')
        if not temp_true_field is None:
            y_pred.remove_field(temp_true_field)
        overlay_field_infos = out_dataset.field_infos
        overlay_field_names = [o.name for o in overlay_field_infos]
        if true_field == pred_field:
            overlay_true_field = true_field if true_field in overlay_field_names else true_field + '_1'
            overlay_pred_field = pred_field if pred_field in overlay_field_names else pred_field + '_2'
        else:
            overlay_true_field = true_field
            overlay_pred_field = pred_field

        # if isinstance(categorys[1], str):
        # out_dataset.update_field(overlay_true_field, 'background', '{} is null'.format(overlay_true_field))
        #     out_dataset.update_field(overlay_pred_field, 'background', '{} is null'.format(overlay_pred_field))
        # else:
        #     out_dataset.update_field(overlay_true_field, 0, '{} is null'.format(overlay_true_field))
        #     out_dataset.update_field(overlay_pred_field, 0, '{} is null'.format(overlay_pred_field))

        for i in range(len(categorys)):
            for j in range(len(categorys)):
                if isinstance(categorys[i], str):
                    if i == 0:
                        tmp_record = out_dataset.query_with_filter(
                            '({} is null or {} == "background") and {} == {}'.format(overlay_true_field,
                                                                                     overlay_true_field,
                                                                                     overlay_pred_field, str(
                                    '{0}{1}{0}'.format('\"', categorys[j]))),
                            cursor_type='STATIC')
                    elif j == 0:
                        tmp_record = out_dataset.query_with_filter(
                            '({} is null or {} == "background") and {} == {}'.format(overlay_pred_field,
                                                                                     overlay_pred_field,
                                                                                     overlay_true_field, str(
                                    '{0}{1}{0}'.format('\"', categorys[i]))),
                            cursor_type='STATIC')

                    else:
                        tmp_record = out_dataset.query_with_filter(
                            overlay_true_field + '==' + str(
                                '{0}{1}{0}'.format('\"', categorys[i])) + ' and ' + overlay_pred_field + '==' + str(
                                '{0}{1}{0}'.format('\"', categorys[j])),
                            cursor_type='STATIC')

                else:
                    if i == 0:
                        tmp_record = out_dataset.query_with_filter(
                            '({} is null or {} == 0) and {} == {}'.format(overlay_true_field, overlay_true_field,
                                                                          overlay_pred_field, str(categorys[j])),
                            cursor_type='STATIC')
                    elif j == 0:
                        tmp_record = out_dataset.query_with_filter(
                            '({} is null or {} == 0) and {} == {}'.format(overlay_pred_field, overlay_pred_field,
                                                                          overlay_true_field, str(categorys[i])),
                            cursor_type='STATIC')

                    else:
                        tmp_record = out_dataset.query_with_filter(
                            overlay_true_field + '==' + str(categorys[i]) + ' and ' + overlay_pred_field + '==' + str(
                                categorys[j]),
                            cursor_type='STATIC')
                confusion_matrix[j, i] = _get_vector_area(tmp_record)
        all_area = bounds.width * bounds.height
        record_area = _get_vector_area(out_dataset)
        confusion_matrix[0, 0] = confusion_matrix[0, 0] + (all_area - record_area)

    if max(categorys) == 1:
        # 取交集计算面积
        all_area = bounds.width * bounds.height
        true_area = _get_vector_area(y_true_record)
        predict_area = _get_vector_area(y_pred_record)
        confusion_matrix[1, 0] = predict_area - confusion_matrix[1, 1]
        confusion_matrix[0, 1] = true_area - confusion_matrix[1, 1]
        confusion_matrix[0, 0] = all_area - (confusion_matrix[1][1] + confusion_matrix[0][1] + confusion_matrix[1][0])

    temp_ds.close()
    return confusion_matrix


def get_tp_fp_tn_fn_matrix(y_true, y_pred, labels=None):
    cm = _confusion_matrix(y_true.flatten(), y_pred.flatten(), labels)
    cm_shape = cm.shape
    tp = np.zeros((cm_shape[0]))
    fp = np.zeros((cm_shape[0]))
    tn = np.zeros((cm_shape[0]))
    fn = np.zeros((cm_shape[0]))
    for i in range(cm_shape[0]):
        tp[i] = cm[i, i]
        fp[i] = np.sum(cm[i, :]) - tp[i]
    for i in range(cm_shape[1]):
        tn[i] = np.sum(tp) - tp[i]
        # fn为列之和减去tp
        fn[i] = np.sum(cm[:, i]) - tp[i]
        # fn[i] = np.sum(cm) - (tp[i] + fp[i] + tn[i])
    return tp, fp, tn, fn, cm


def get_tp_fp_tn_fn_matrix_vector(y_true, y_pred, true_field, pred_field, labels, compute_type, field_name_not_exist):
    confusion_matrix = _confusion_matrix_vector(y_true, y_pred, true_field, pred_field, labels, compute_type,
                                                field_name_not_exist)
    confusion_matrix_shape = confusion_matrix.shape

    tp = np.zeros((confusion_matrix_shape[0]))
    fp = np.zeros((confusion_matrix_shape[0]))
    tn = np.zeros((confusion_matrix_shape[0]))
    fn = np.zeros((confusion_matrix_shape[0]))
    for i in range(confusion_matrix_shape[0]):
        tp[i] = confusion_matrix[i, i]
        fp[i] = np.sum(confusion_matrix[i, :]) - tp[i]
    for i in range(confusion_matrix_shape[0]):
        tn[i] = np.sum(tp) - tp[i]
        # fn为列之和减去tp
        fn[i] = np.sum(confusion_matrix[:, i]) - tp[i]
        # fn[i] = np.sum(confusion_matrix) - (tp[i] + fp[i] + tn[i])
    return tp, fp, tn, fn, confusion_matrix


def _get_unique_values(dataset_vector, value_field):
    """ 通过矢量数据集获取类别信息
        :param dataset_vector: 数据集
        :type dataset_vector: DataSetVector
        :param value_field:
        :type value_field: str
        :return categorys : 全部类别
        :rtype: list
        """
    categorys = []
    for feature in dataset_vector.get_features():
        category = feature.get_value(value_field)
        if category not in categorys:
            categorys.append(category)
    return categorys


def _get_vector_area(dataset):
    area = 0.0
    for f in dataset.get_features():
        area += f.geometry.area
    return area


def get_classe_names_from_dataset(dataset, label_class_field, out_path=None, out_name=None):
    """ class_names = get_classe_names(dataset, label_class_field, out_path=None)

        通过矢量数据集获取记录集中的所有类别

        :param dataset: 数据集
        :type dataset: DataSetVector
        :param label_class_field: 游标类型，可以为枚举值或名称
        :type label_class_field: CursorType or str
        :param out_path: 输出文件路径
        :type out_path: str
        :param out_name: 输出文件名称
        :type out_name: str
        :return class_names : 记录集中类别信息
        :rtype: list
        """
    class_names = []
    if out_path is not None:
        if not os.path.exists(out_path):
            os.makedirs(out_path)
        try:
            with open(os.path.join(out_path, out_name + '.yml')) as f:
                config_dict = yaml.load(f, Loader=yaml.FullLoader)
            voc_config = DotMap(config_dict)
            class_names = voc_config.get('class_names')
        except:
            print(
                '`{:s}`.yml is not exist, please modify the directory, or enter "None" as "out path" '.format(out_name))
    else:
        class_names = []

    temp_input_label = _get_input_feature(dataset)
    for i in temp_input_label:
        category = str(i.get_value(label_class_field))
        # 获取数据集中category字段保存的类别
        if category not in class_names:
            class_names.append(category)
    if out_path is not None:
        dic_voc_yml = OrderedDict({'class_names': class_names
                                   })
        save_config_to_yaml(dic_voc_yml, os.path.join(out_path, out_name + '.yml'))

    return class_names


def get_classe_names_from_model(model_config, out_path=None, out_name=None):
    """ class_names = get_classe_names(dataset, label_class_field, out_path=None)

        通过矢量数据集获取记录集中的所有类别

        :param dataset: 数据集
        :type dataset: DataSetVector
        :param label_class_field: 游标类型，可以为枚举值或名称
        :type label_class_field: CursorType or str
        :param out_path: 输出文件路径
        :type out_path: str
        :param out_name: 输出文件名称
        :type out_name: str
        :return class_names : 记录集中类别信息
        :rtype: list
        """
    with open(model_config) as f:
        config_dict = yaml.load(f, Loader=yaml.FullLoader)
    config = DotMap(config_dict)
    config.get("model").get("categorys").remove("__background__")
    class_names = config.get("model").get("categorys")

    if out_path is not None & out_name is not None:
        if not os.path.exists(out_path):
            os.makedirs(out_path)
        dic_voc_yml = OrderedDict({'class_names': class_names
                                   })
        save_config_to_yaml(dic_voc_yml, os.path.join(out_path, out_name + '.yml'))

    return class_names


def save_metric_dict_to_attribute_table(metric_dict, out_data, out_data_name):
    # 输入指标的字典，将指标写入数据集的属性字段
    if out_data is not None:
        if out_data_name is None:
            out_data_name = 'default_metric'

        ds = get_output_datasource(out_data)
        adjust_name = True
        if not ds.is_available_dataset_name(out_data_name) and adjust_name:
            out_name = ds.get_available_dataset_name(out_data_name)

        metric_dataset = ds.create_vector_dataset(out_data_name, DatasetType.TABULAR, adjust_name=adjust_name)

        field_infos = []
        region = None
        locals()['type_metric' + 'class'] = FieldInfo('class', FieldType.TEXT, max_length=50)
        metric_dataset.create_field(locals()['type_metric' + 'class'])
        field_infos.append(locals()['type_metric' + 'class'])

        for i in metric_dict:
            if i != 'confusion_matrix':
                locals()['type_metric' + str(i)] = FieldInfo(i, FieldType.TEXT, max_length=50)
                metric_dataset.create_field(locals()['type_metric' + str(i)])
                field_infos.append(locals()['type_metric' + str(i)])
        features = []
        temp_metric_dict = {}
        first_metric_dice_key = list(metric_dict.keys())[0]
        for label in metric_dict[first_metric_dice_key]:
            temp_metric_dict['class'] = label
            for i in metric_dict:
                if i != 'confusion_matrix':
                    # if (i == 'mAP') & (label != 'ALL_Classes'):
                    #     temp_metric_dict[i] = ''
                    # elif (i == 'AP') & (label == 'ALL_Classes'):
                    #     temp_metric_dict[i] = ''
                    # elif (i == 'CPA') & (label == 'ALL_Classes'):
                    #     temp_metric_dict[i] = ''
                    # elif (i == 'IoU') & (label == 'ALL_Classes'):
                    #     try:
                    #         temp_metric_dict[i] = round(metric_dict[i][label], 4)
                    #     except:
                    #         temp_metric_dict[i] = ''
                    # elif (i == 'mPA') & (label != 'ALL_Classes'):
                    #     temp_metric_dict[i] = ''
                    # elif (i == 'mIoU') & (label != 'ALL_Classes'):
                    #     temp_metric_dict[i] = ''
                    # elif (i == 'Kappa') & (label != 'ALL_Classes'):
                    #     temp_metric_dict[i] = ''
                    # else:
                    #     temp_metric_dict[i] = round(metric_dict[i][label], 4)
                    # if (i == 'IoU') & (label == 'ALL_Classes'):
                    #     # if label not in metric_dict[i]:
                    #     #     temp_metric_dict[i] = ''
                    #     # else:
                    #     #     temp_metric_dict[i] = round(metric_dict[i][label], 4)
                    #     try:
                    #         temp_metric_dict[i] = round(metric_dict[i][label], 4)
                    #     except:
                    #         temp_metric_dict[i] = ''
                    #
                    # else:
                    #     temp_metric_dict[i] = round(metric_dict[i][label], 4)
                    if label not in metric_dict[i]:
                        temp_metric_dict[i] = ''
                    else:
                        temp_metric_dict[i] = round(metric_dict[i][label], 4)
            features.append(Feature(region, temp_metric_dict,
                                    field_infos=field_infos))
        metric_dataset.append(features)
        metric_dataset.close()


def save_metric_dict_to_attribute_table_sr(metric_dict, out_data, out_data_name):
    # 输入指标的字典，将指标写入数据集的属性字段
    if out_data is not None:
        if out_data_name is None:
            out_data_name = 'default_metric'

        ds = get_output_datasource(out_data)
        adjust_name = True
        if not ds.is_available_dataset_name(out_data_name) and adjust_name:
            out_name = ds.get_available_dataset_name(out_data_name)

        metric_dataset = ds.create_vector_dataset(out_data_name, DatasetType.TABULAR, adjust_name=adjust_name)

        field_infos = []
        region = None

        for i in metric_dict:
            locals()['type_metric' + str(i)] = FieldInfo(i, FieldType.TEXT, max_length=50)
            metric_dataset.create_field(locals()['type_metric' + str(i)])
            field_infos.append(locals()['type_metric' + str(i)])

        features = []
        features.append(Feature(region, metric_dict,field_infos=field_infos))
        metric_dataset.append(features)
        metric_dataset.close()
