# !/usr/bin/env python3
# coding=utf-8

import os
import xml.etree.ElementTree as ET
from multiprocessing import Pool

import numpy as np
import yaml
from dotmap import DotMap


def bbox_overlaps(bboxes1, bboxes2, mode='iou', eps=1e-6):
    """Calculate the ious between each bbox of bboxes1 and bboxes2.

    Args:
        bboxes1(ndarray): shape (n, 4)
        bboxes2(ndarray): shape (k, 4)
        mode(str): iou (intersection over union) or iof (intersection
            over foreground)

    Returns:
        ious(ndarray): shape (n, k)
    """

    assert mode in ['iou', 'iof']

    bboxes1 = bboxes1.astype(np.float32)
    bboxes2 = bboxes2.astype(np.float32)
    rows = bboxes1.shape[0]
    cols = bboxes2.shape[0]
    ious = np.zeros((rows, cols), dtype=np.float32)
    if rows * cols == 0:
        return ious
    exchange = False
    if bboxes1.shape[0] > bboxes2.shape[0]:
        bboxes1, bboxes2 = bboxes2, bboxes1
        ious = np.zeros((cols, rows), dtype=np.float32)
        exchange = True
    area1 = (bboxes1[:, 2] - bboxes1[:, 0]) * (bboxes1[:, 3] - bboxes1[:, 1])
    area2 = (bboxes2[:, 2] - bboxes2[:, 0]) * (bboxes2[:, 3] - bboxes2[:, 1])
    for i in range(bboxes1.shape[0]):
        x_start = np.maximum(bboxes1[i, 0], bboxes2[:, 0])
        y_start = np.maximum(bboxes1[i, 1], bboxes2[:, 1])
        x_end = np.minimum(bboxes1[i, 2], bboxes2[:, 2])
        y_end = np.minimum(bboxes1[i, 3], bboxes2[:, 3])
        overlap = np.maximum(x_end - x_start, 0) * np.maximum(
            y_end - y_start, 0)
        if mode == 'iou':
            union = area1[i] + area2 - overlap
        else:
            union = area1[i] if not exchange else area2
        union = np.maximum(union, eps)
        ious[i, :] = overlap / union
    if exchange:
        ious = ious.T
    return ious
#
#
# def _get_classe_names_from_model(model_config):
#     """
#     通过模型配置文件sdm获取类别列表
#
#     :param str model_config:
#     :rtype: list
#     """
#     with open(model_config) as f:
#         config_dict = yaml.load(f, Loader=yaml.FullLoader)
#     config = DotMap(config_dict)
#     # config.get("model").get("categorys").remove("__background__")
#     class_names = config.get("model").get("categorys")
#
#     return class_names
#
#
# def _get_classe_names_from_sda(sda_config):
#     """
#      通过数据配置文件sda获取类别列表
#
#      :param str sda_config:
#      :rtype: list
#      """
#     with open(sda_config) as f:
#         config_dict = yaml.load(f, Loader=yaml.FullLoader)
#     config = DotMap(config_dict)
#     # config.get("dataset").get("classes").remove("__background__")
#     class_names = config.get("dataset").get("classes")
#
#     return class_names
#
#
# def _get_eval_name_from_txt(eval_name):
#     """
#      通过txt文件读取类别名
#
#      :param str eval_name_path:
#      :rtype: list
#      """
#     eval_name_list = []
#     eval_name = open(eval_name, "r", encoding="utf-8", errors="ignore")
#     while True:
#         mystr = eval_name.readline()  # 表示一次读取一行
#         if not mystr:
#             # 读到数据最后跳出，结束循环。数据的最后也就是读不到数据了，mystr为空的时候
#             break
#         eval_name_list.append(mystr.strip('\n') + '.xml')
#
#     return eval_name_list


def average_precision(recalls, precisions, mode='area'):
    """Calculate average precision (for single or multiple scales).

    Args:
        recalls (ndarray): shape (num_scales, num_dets) or (num_dets, )
        precisions (ndarray): shape (num_scales, num_dets) or (num_dets, )
        mode (str): 'area' or '11points', 'area' means calculating the area
            under precision-recall curve, '11points' means calculating
            the average precision of recalls at [0, 0.1, ..., 1]

    Returns:
        float or ndarray: calculated average precision
    """
    no_scale = False
    if recalls.ndim == 1:
        no_scale = True
        recalls = recalls[np.newaxis, :]
        precisions = precisions[np.newaxis, :]
    assert recalls.shape == precisions.shape and recalls.ndim == 2
    num_scales = recalls.shape[0]
    ap = np.zeros(num_scales, dtype=np.float32)
    if mode == 'area':
        zeros = np.zeros((num_scales, 1), dtype=recalls.dtype)
        ones = np.ones((num_scales, 1), dtype=recalls.dtype)
        mrec = np.hstack((zeros, recalls, ones))
        mpre = np.hstack((zeros, precisions, zeros))
        for i in range(mpre.shape[1] - 1, 0, -1):
            mpre[:, i - 1] = np.maximum(mpre[:, i - 1], mpre[:, i])
        for i in range(num_scales):
            ind = np.where(mrec[i, 1:] != mrec[i, :-1])[0]
            ap[i] = np.sum(
                (mrec[i, ind + 1] - mrec[i, ind]) * mpre[i, ind + 1])
    elif mode == '11points':
        for i in range(num_scales):
            for thr in np.arange(0, 1 + 1e-3, 0.1):
                precs = precisions[i, recalls[i, :] >= thr]
                prec = precs.max() if precs.size > 0 else 0
                ap[i] += prec
            ap /= 11
    else:
        raise ValueError(
            'Unrecognized mode, only "area" and "11points" are supported')
    if no_scale:
        ap = ap[0]
    return ap


# def tpfp_imagenet(det_bboxes,
#                   gt_bboxes,
#                   gt_bboxes_ignore=None,
#                   default_iou_thr=0.5,
#                   area_ranges=None):
#     """Check if detected bboxes are true positive or false positive.
#
#     Args:
#         det_bbox (ndarray): Detected bboxes of this image, of shape (m, 5).
#         gt_bboxes (ndarray): GT bboxes of this image, of shape (n, 4).
#         gt_bboxes_ignore (ndarray): Ignored gt bboxes of this image,
#             of shape (k, 4). Default: None
#         default_iou_thr (float): IoU threshold to be considered as matched for
#             medium and large bboxes (small ones have special rules).
#             Default: 0.5.
#         area_ranges (list[tuple] | None): Range of bbox areas to be evaluated,
#             in the format [(min1, max1), (min2, max2), ...]. Default: None.
#
#     Returns:
#         tuple[np.ndarray]: (tp, fp) whose elements are 0 and 1. The shape of
#             each array is (num_scales, m).
#     """
#     # an indicator of ignored gts
#     gt_ignore_inds = np.concatenate(
#         (np.zeros(gt_bboxes.shape[0], dtype=np.bool),
#          np.ones(gt_bboxes_ignore.shape[0], dtype=np.bool)))
#     # stack gt_bboxes and gt_bboxes_ignore for convenience
#     gt_bboxes = np.vstack((gt_bboxes, gt_bboxes_ignore))
#
#     num_dets = det_bboxes.shape[0]
#     num_gts = gt_bboxes.shape[0]
#     if area_ranges is None:
#         area_ranges = [(None, None)]
#     num_scales = len(area_ranges)
#     # tp and fp are of shape (num_scales, num_gts), each row is tp or fp
#     # of a certain scale.
#     tp = np.zeros((num_scales, num_dets), dtype=np.float32)
#     fp = np.zeros((num_scales, num_dets), dtype=np.float32)
#     if gt_bboxes.shape[0] == 0:
#         if area_ranges == [(None, None)]:
#             fp[...] = 1
#         else:
#             det_areas = (det_bboxes[:, 2] - det_bboxes[:, 0]) * (
#                     det_bboxes[:, 3] - det_bboxes[:, 1])
#             for i, (min_area, max_area) in enumerate(area_ranges):
#                 fp[i, (det_areas >= min_area) & (det_areas < max_area)] = 1
#         return tp, fp
#     ious = bbox_overlaps(det_bboxes, gt_bboxes - 1)
#     gt_w = gt_bboxes[:, 2] - gt_bboxes[:, 0]
#     gt_h = gt_bboxes[:, 3] - gt_bboxes[:, 1]
#     iou_thrs = np.minimum((gt_w * gt_h) / ((gt_w + 10.0) * (gt_h + 10.0)),
#                           default_iou_thr)
#     # sort all detections by scores in descending order
#     sort_inds = np.argsort(-det_bboxes[:, -1])
#     for k, (min_area, max_area) in enumerate(area_ranges):
#         gt_covered = np.zeros(num_gts, dtype=bool)
#         # if no area range is specified, gt_area_ignore is all False
#         if min_area is None:
#             gt_area_ignore = np.zeros_like(gt_ignore_inds, dtype=bool)
#         else:
#             gt_areas = gt_w * gt_h
#             gt_area_ignore = (gt_areas < min_area) | (gt_areas >= max_area)
#         for i in sort_inds:
#             max_iou = -1
#             matched_gt = -1
#             # find best overlapped available gt
#             for j in range(num_gts):
#                 # different from PASCAL VOC: allow finding other gts if the
#                 # best overlaped ones are already matched by other det bboxes
#                 if gt_covered[j]:
#                     continue
#                 elif ious[i, j] >= iou_thrs[j] and ious[i, j] > max_iou:
#                     max_iou = ious[i, j]
#                     matched_gt = j
#             # there are 4 cases for a det bbox:
#             # 1. it matches a gt, tp = 1, fp = 0
#             # 2. it matches an ignored gt, tp = 0, fp = 0
#             # 3. it matches no gt and within area range, tp = 0, fp = 1
#             # 4. it matches no gt but is beyond area range, tp = 0, fp = 0
#             if matched_gt >= 0:
#                 gt_covered[matched_gt] = 1
#                 if not (gt_ignore_inds[matched_gt]
#                         or gt_area_ignore[matched_gt]):
#                     tp[k, i] = 1
#             elif min_area is None:
#                 fp[k, i] = 1
#             else:
#                 bbox = det_bboxes[i, :4]
#                 area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
#                 if area >= min_area and area < max_area:
#                     fp[k, i] = 1
#     return tp, fp


def tpfp_default(det_bboxes,
                 gt_bboxes,
                 gt_bboxes_ignore=None,
                 iou_thr=0.5,
                 area_ranges=None):
    """Check if detected bboxes are true positive or false positive.

    Args:
        det_bbox (ndarray): Detected bboxes of this image, of shape (m, 5).
        gt_bboxes (ndarray): GT bboxes of this image, of shape (n, 4).
        gt_bboxes_ignore (ndarray): Ignored gt bboxes of this image,
            of shape (k, 4). Default: None
        iou_thr (float): IoU threshold to be considered as matched.
            Default: 0.5.
        area_ranges (list[tuple] | None): Range of bbox areas to be evaluated,
            in the format [(min1, max1), (min2, max2), ...]. Default: None.

    Returns:
        tuple[np.ndarray]: (tp, fp) whose elements are 0 and 1. The shape of
            each array is (num_scales, m).
    """
    # an indicator of ignored gts
    gt_ignore_inds = np.concatenate(
        (np.zeros(gt_bboxes.shape[0], dtype=np.bool_),
         np.ones(gt_bboxes_ignore.shape[0], dtype=np.bool_)))
    # stack gt_bboxes and gt_bboxes_ignore for convenience
    gt_bboxes = np.vstack((gt_bboxes, gt_bboxes_ignore))

    num_dets = det_bboxes.shape[0]
    num_gts = gt_bboxes.shape[0]
    if area_ranges is None:
        area_ranges = [(None, None)]
    num_scales = len(area_ranges)
    # tp and fp are of shape (num_scales, num_gts), each row is tp or fp of
    # a certain scale
    tp = np.zeros((num_scales, num_dets), dtype=np.float32)
    fp = np.zeros((num_scales, num_dets), dtype=np.float32)

    # if there is no gt bboxes in this image, then all det bboxes
    # within area range are false positives
    if gt_bboxes.shape[0] == 0:
        if area_ranges == [(None, None)]:
            fp[...] = 1
        else:
            det_areas = (det_bboxes[:, 2] - det_bboxes[:, 0]) * (
                    det_bboxes[:, 3] - det_bboxes[:, 1])
            for i, (min_area, max_area) in enumerate(area_ranges):
                fp[i, (det_areas >= min_area) & (det_areas < max_area)] = 1
        return tp, fp

    ious = bbox_overlaps(det_bboxes, gt_bboxes)
    # for each det, the max iou with all gts
    ious_max = ious.max(axis=1)
    # for each det, which gt overlaps most with it
    ious_argmax = ious.argmax(axis=1)
    # sort all dets in descending order by scores
    sort_inds = np.argsort(-det_bboxes[:, -1])
    for k, (min_area, max_area) in enumerate(area_ranges):
        gt_covered = np.zeros(num_gts, dtype=bool)
        # if no area range is specified, gt_area_ignore is all False
        if min_area is None:
            gt_area_ignore = np.zeros_like(gt_ignore_inds, dtype=bool)
        else:
            gt_areas = (gt_bboxes[:, 2] - gt_bboxes[:, 0]) * (
                    gt_bboxes[:, 3] - gt_bboxes[:, 1])
            gt_area_ignore = (gt_areas < min_area) | (gt_areas >= max_area)
        for i in sort_inds:
            if ious_max[i] >= iou_thr:
                matched_gt = ious_argmax[i]
                if not (gt_ignore_inds[matched_gt]
                        or gt_area_ignore[matched_gt]):
                    if not gt_covered[matched_gt]:
                        gt_covered[matched_gt] = True
                        tp[k, i] = 1
                    else:
                        fp[k, i] = 1
                # otherwise ignore this detected bbox, tp = 0, fp = 0
            elif min_area is None:
                fp[k, i] = 1
            else:
                bbox = det_bboxes[i, :4]
                area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
                if area >= min_area and area < max_area:
                    fp[k, i] = 1
    return tp, fp


def _get_eval_results(inference_array,
                      ground_truth_array,
                      scale_ranges=None,
                      iou_thr=0.5,
                      dataset=None,
                      logger=None,
                      nproc=4):
    """Evaluate mAP of a dataset.

      Args:
          inference_array (list[list]): [[cls1_det, cls2_det, ...], ...].
              The outer list indicates images, and the inner list indicates
              per-class detected bboxes.
          ground_truth_array (list[dict]):  ground_truth_array where each item of
              the list indicates an image. Keys of ground_truth_array are:

              - `bboxes`: numpy array of shape (n, 4)
              - `labels`: numpy array of shape (n, )
              - `bboxes_ignore` (optional): numpy array of shape (k, 4)
              - `labels_ignore` (optional): numpy array of shape (k, )
          scale_ranges (list[tuple] | None): Range of scales to be evaluated,
              in the format [(min1, max1), (min2, max2), ...]. A range of
              (32, 64) means the area range between (32**2, 64**2).
              Default: None.
          iou_thr (float): IoU threshold to be considered as matched.
              Default: 0.5.
          dataset (list[str] | str | None): Dataset name or dataset classes,
              there are minor differences in metrics for different datsets, e.g.
              "voc07", "imagenet_det", etc. Default: None.
          logger (logging.Logger | str | None): The way to print the mAP
              summary. See `mmdet.utils.print_log()` for details. Default: None.
          nproc (int): Processes used for computing TP and FP.
              Default: 4.

      Returns:
          tuple: (mAP, [dict, dict, ...])
      """
    assert len(inference_array) == len(ground_truth_array)

    num_imgs = len(inference_array)
    num_scales = len(scale_ranges) if scale_ranges is not None else 1
    num_classes = len(inference_array[0])  # positive class num
    area_ranges = ([(rg[0] ** 2, rg[1] ** 2) for rg in scale_ranges]
                   if scale_ranges is not None else None)

    pool = Pool(nproc)
    eval_results = []
    for i in range(num_classes):
        # get gt and det bboxes of this class
        cls_dets, cls_gts, cls_gts_ignore = get_cls_results(
            inference_array, ground_truth_array, i)
        # choose proper function according to datasets to compute tp and fp
        # if dataset in ['det', 'vid']:
        #     tpfp_func = tpfp_imagenet
        # else:
        #     tpfp_func = tpfp_default
        tpfp_func = tpfp_default
        # compute tp and fp for each image with multiple processes
        tpfp = pool.starmap(
            tpfp_func,
            zip(cls_dets, cls_gts, cls_gts_ignore,
                [iou_thr for _ in range(num_imgs)],
                [area_ranges for _ in range(num_imgs)]))
        tp, fp = tuple(zip(*tpfp))
        # calculate gt number of each scale
        # ignored gts or gts beyond the specific scale are not counted
        num_gts = np.zeros(num_scales, dtype=int)
        for j, bbox in enumerate(cls_gts):
            if area_ranges is None:
                num_gts[0] += bbox.shape[0]
            else:
                gt_areas = (bbox[:, 2] - bbox[:, 0]) * (
                        bbox[:, 3] - bbox[:, 1])
                for k, (min_area, max_area) in enumerate(area_ranges):
                    num_gts[k] += np.sum((gt_areas >= min_area)
                                         & (gt_areas < max_area))
        # sort all det bboxes by score, also sort tp and fp
        cls_dets = np.vstack(cls_dets)
        num_dets = cls_dets.shape[0]
        sort_inds = np.argsort(-cls_dets[:, -1])
        tp = np.hstack(tp)[:, sort_inds]
        fp = np.hstack(fp)[:, sort_inds]
        # calculate recall and precision with tp and fp
        tp = np.cumsum(tp, axis=1)
        fp = np.cumsum(fp, axis=1)
        eps = np.finfo(np.float32).eps
        recalls = tp / np.maximum(num_gts[:, np.newaxis], eps)
        precisions = tp / np.maximum((tp + fp), eps)
        # calculate AP
        if scale_ranges is None:
            recalls = recalls[0, :]
            precisions = precisions[0, :]
            num_gts = num_gts.item()
        mode = 'area' if dataset != 'voc07' else '11points'
        ap = average_precision(recalls, precisions, mode)
        eval_results.append({
            'num_gts': num_gts,
            'num_dets': num_dets,
            'recall': recalls,
            'precision': precisions,
            'ap': ap
        })
    pool.close()

    return eval_results


def get_cls_results(det_results, annotations, class_id):
    """Get det results and gt information of a certain class.

    Args:
        det_results (list[list]): Same as `eval_map()`.
        annotations (list[dict]): Same as `eval_map()`.
        class_id (int): ID of a specific class.

    Returns:
        tuple[list[np.ndarray]]: detected bboxes, gt bboxes, ignored gt bboxes
    """
    cls_dets = [img_res[class_id] for img_res in det_results]
    cls_gts = []
    cls_gts_ignore = []
    for ann in annotations:
        gt_inds = ann['labels'] == class_id
        cls_gts.append(ann['bboxes'][gt_inds, :])

        if ann.get('labels_ignore', None) is not None:
            ignore_inds = ann['labels_ignore'] == class_id
            cls_gts_ignore.append(ann['bboxes_ignore'][ignore_inds, :])
        else:
            cls_gts_ignore.append(np.empty((0, 4), dtype=np.float32))

    return cls_dets, cls_gts, cls_gts_ignore


def _obj_map(inference_array,
             ground_truth_array,
             class_name,
             scale_ranges=None,
             iou_thr=0.5,
             dataset=None,
             logger=None,
             nproc=4):
    eval_results = _get_eval_results(inference_array,
                                     ground_truth_array,
                                     scale_ranges=scale_ranges,
                                     iou_thr=iou_thr,
                                     dataset=dataset,
                                     logger=logger,
                                     nproc=nproc)
    aps = []
    ap = []
    temp_mAP_dict = {}
    temp_AP_dict = {}
    for cls_result in eval_results:
        ap.append(cls_result['ap'])
        if cls_result['num_gts'] > 0:
            aps.append(cls_result['ap'])
    mAP = np.array(aps).mean().item() if aps else 0.0


    for id, i in enumerate(class_name):
        temp_AP_dict[i] = ap[id]
    temp_mAP_dict['ALL_Classes'] = mAP

    return temp_mAP_dict,temp_AP_dict, eval_results


def _obj_prec_rec(det_results,
                  annotations,
                  class_name,
                  scale_ranges=None,
                  iou_thr=0.5,
                  dataset=None,
                  logger=None,
                  nproc=4):
    eval_results = _get_eval_results(det_results,
                                     annotations,
                                     scale_ranges=scale_ranges,
                                     iou_thr=iou_thr,
                                     dataset=dataset,
                                     logger=logger,
                                     nproc=nproc)
    if isinstance(eval_results[0]['ap'], np.ndarray):
        num_scales = len(eval_results[0]['ap'])
    else:
        num_scales = 1
    num_classes = len(eval_results)
    recalls = np.zeros((num_scales, num_classes), dtype=np.float32)
    precision = np.zeros((num_scales, num_classes), dtype=np.float32)
    num_gts = np.zeros((num_scales, num_classes), dtype=int)
    aps = []
    for i, cls_result in enumerate(eval_results):
        if cls_result['recall'].size > 0:
            recalls[:, i] = np.array(cls_result['recall'], ndmin=2)[:, -1]
        if cls_result['precision'].size > 0:
            precision[:, i] = np.array(cls_result['precision'], ndmin=2)[:, -1]
        if cls_result['num_gts'] > 0:
            aps.append(cls_result['ap'])
        num_gts[:, i] = cls_result['num_gts']
    temp_recalls_dict = {}
    temp_precision_dict = {}
    # temp_recalls_dict['ALL_Classes'] = 0.0
    # temp_precision_dict['ALL_Classes'] = 0.0
    for id, i in enumerate(class_name):
        temp_recalls_dict[i] = recalls[0][id]
        temp_precision_dict[i] = precision[0][id]

    sum_recall = 0
    sum_precision = 0
    for i in temp_recalls_dict:
        sum_recall = temp_recalls_dict[i] + sum_recall
        sum_precision = temp_precision_dict[i] + sum_precision

    num_class = len(aps)
    mean_recall = sum_recall / num_class
    mean_precision = sum_precision / num_class
    temp_recalls_dict['ALL_Classes'] = mean_recall
    temp_precision_dict['ALL_Classes'] = mean_precision

    return temp_recalls_dict, temp_precision_dict, eval_results


def _obj_f1(det_results,
            annotations,
            class_name,
            scale_ranges=None,
            iou_thr=0.5,
            dataset=None,
            logger=None,
            nproc=4):
    eval_results = _get_eval_results(det_results,
                                     annotations,
                                     scale_ranges=scale_ranges,
                                     iou_thr=iou_thr,
                                     dataset=dataset,
                                     logger=logger,
                                     nproc=nproc)
    if isinstance(eval_results[0]['ap'], np.ndarray):
        num_scales = len(eval_results[0]['ap'])
    else:
        num_scales = 1
    num_classes = len(eval_results)
    recalls = np.zeros((num_scales, num_classes), dtype=np.float32)
    precision = np.zeros((num_scales, num_classes), dtype=np.float32)
    num_gts = np.zeros((num_scales, num_classes), dtype=int)
    aps = []
    for i, cls_result in enumerate(eval_results):
        if cls_result['recall'].size > 0:
            recalls[:, i] = np.array(cls_result['recall'], ndmin=2)[:, -1]
        if cls_result['precision'].size > 0:
            precision[:, i] = np.array(cls_result['precision'], ndmin=2)[:, -1]
        if cls_result['num_gts'] > 0:
            aps.append(cls_result['ap'])
        num_gts[:, i] = cls_result['num_gts']
    temp_f1 = {}

    eps = np.finfo(np.float32).eps
    for id, i in enumerate(class_name):
        temp_f1[i] = 2 * recalls[0][id] * precision[0][id] / max((recalls[0][id] + precision[0][id]), eps)

    sum_f1 = 0
    for i in temp_f1:
        sum_f1 = temp_f1[i] + sum_f1

    num_class = len(aps)
    mean_f1 = sum_f1 / num_class
    temp_f1['ALL_Classes'] = mean_f1

    return temp_f1, eval_results


# def _get_pred_array_xml(input_det, list_eval_names, class_name):
#     """
#     通过xml文件构建预测结果数组，用于计算mAP
#     """
#     pred_array = []
#
#     for temp_eval_name in list_eval_names:
#         det_result = []
#
#         det_box_dict = []
#
#         det_file = os.path.join(input_det, temp_eval_name)
#         tree = ET.parse(det_file)
#         rect = {}
#         root = tree.getroot()
#         for name in root.iter('path'):
#             rect['path'] = name.text
#         for ob in root.iter('object'):
#             for name in ob.iter('name'):
#                 rect['name'] = str(name.text)
#             for difficult in ob.iter('difficult'):
#                 rect['difficult'] = str(difficult.text)
#             for score in ob.iter('score'):
#                 rect['score'] = str(score.text)
#             for bndbox in ob.iter('bndbox'):
#                 for xmin in bndbox.iter('xmin'):
#                     rect['xmin'] = xmin.text
#                 for ymin in bndbox.iter('ymin'):
#                     rect['ymin'] = ymin.text
#                 for xmax in bndbox.iter('xmax'):
#                     rect['xmax'] = xmax.text
#                 for ymax in bndbox.iter('ymax'):
#                     rect['ymax'] = ymax.text
#                 det_box_dict.append(
#                     rect['name'] + ' ' + rect['xmin'] + ' ' + rect['ymin'] + ' ' + rect['xmax'] + ' ' + rect[
#                         'ymax'] + ' ' + rect['score'])
#         for id, i in enumerate(class_name):
#             # det_result.append([])
#             temp_ = []
#             for j in det_box_dict:
#                 j_list = j.split(" ")
#                 if str(j.split(" ")[0]) == i:
#                     temp = []
#                     temp.append(float(j_list[1]))
#                     temp.append(float(j_list[2]))
#                     temp.append(float(j_list[3]))
#                     temp.append(float(j_list[4]))
#                     temp.append(float(j_list[5]))
#                     temp_.append(temp)
#             if temp_ == []:
#                 temp_ = np.array(temp_).reshape(0, 5)
#             det_result.append(np.array(temp_))
#         pred_array.append(det_result)
#     return pred_array


def _get_inference_result_dataset_vector(y_pred, predict_field_name, class_name):
    """
    通过DatasetVector构建预测结果numpy数组
    """
    det_result = []
    det_box_dict = []
    recordsets = y_pred.get_features()
    for recordset in recordsets:
        if predict_field_name is None:
            category = "unspecified"
        else:
            category = recordset[predict_field_name]
        score = recordset["scores"]
        xmin = recordset.bounds.left
        ymin = recordset.bounds.bottom
        xmax = recordset.bounds.right
        ymax = recordset.bounds.top
        xmin = str(xmin)
        ymin = str(ymin)
        xmax = str(xmax)
        ymax = str(ymax)
        score = str(score)

        det_box_dict.append(category + ' ' + xmin + ' ' + ymin + ' ' + xmax + ' ' + ymax + ' ' + score)
    for id, i in enumerate(class_name):
        temp_ = []
        for j in det_box_dict:
            j_list = j.split(" ")
            if str(j.split(" ")[0]) == i:
                temp = []
                temp.append(float(j_list[1]))
                temp.append(float(j_list[2]))
                temp.append(float(j_list[3]))
                temp.append(float(j_list[4]))
                if j_list[5] == 'None':
                    j_list[5] = 1
                temp.append(float(j_list[5]))
                temp_.append(temp)
        if temp_ == []:
            temp_ = np.array(temp_).reshape(0, 5)
        det_result.append(np.array(temp_))

    return det_result


# def _get_true_array_xml(input_gt, list_eval_names, class_name):
#     """
#     通过xml文件构建真实矩形框数组，用于计算mAP
#     """
#     true_array = []
#     for temp_eval_name in list_eval_names:
#         bboxes = []
#         labels = []
#         bboxes_ignore = []
#         labels_ignore = []
#         det_file = os.path.join(input_gt, temp_eval_name)
#         tree = ET.parse(det_file)
#         root = tree.getroot()
#         for obj in root.findall('object'):
#             name = obj.find('name').text
#             label = class_name[name]
#             difficult = int(obj.find('difficult').text)
#             bnd_box = obj.find('bndbox')
#             bbox = [
#                 float(bnd_box.find('xmin').text),
#                 float(bnd_box.find('ymin').text),
#                 float(bnd_box.find('xmax').text),
#                 float(bnd_box.find('ymax').text)
#             ]
#             ignore = False
#             w = bbox[2] - bbox[0]
#             h = bbox[3] - bbox[1]
#             if w < 10 or h < 10:
#                 ignore = True
#             if difficult or ignore:
#                 bboxes_ignore.append(bbox)
#                 labels_ignore.append(label)
#             else:
#                 bboxes.append(bbox)
#                 labels.append(label)
#         if not bboxes:
#             bboxes = np.zeros((0, 4))
#             labels = np.zeros((0,))
#         else:
#             bboxes = np.array(bboxes, ndmin=2)
#             labels = np.array(labels)
#         if not bboxes_ignore:
#             bboxes_ignore = np.zeros((0, 4))
#             labels_ignore = np.zeros((0,))
#         else:
#             bboxes_ignore = np.array(bboxes_ignore, ndmin=2)
#             labels_ignore = np.array(labels_ignore)
#         ann = dict(
#             bboxes=bboxes.astype(np.float32),
#             labels=labels.astype(np.int64),
#             bboxes_ignore=bboxes_ignore.astype(np.float32),
#             labels_ignore=labels_ignore.astype(np.int64))
#         true_array.append(ann)
#     return true_array


def _get_ground_truth_dataset_vector(y_true, true_field_name, class_name):
    """
    通过xml文件构建真实矩形框数组，用于计算mAP
    """
    bboxes = []
    labels = []
    bboxes_ignore = []
    labels_ignore = []
    recordsets = y_true.get_features()
    for recordset in recordsets:
        if true_field_name is None:
            category = "unspecified"
        else:
            category = recordset[true_field_name]
        xmin = recordset.bounds.left
        ymin = recordset.bounds.bottom
        xmax = recordset.bounds.right
        ymax = recordset.bounds.top
        xmin = str(xmin)
        ymin = str(ymin)
        xmax = str(xmax)
        ymax = str(ymax)
        name = category
        label = class_name[name]
        difficult = int(0)
        bbox = [
            float(xmin),
            float(ymin),
            float(xmax),
            float(ymax)
        ]
        ignore = False
        if difficult or ignore:
            bboxes_ignore.append(bbox)
            labels_ignore.append(label)
        else:
            bboxes.append(bbox)
            labels.append(label)
    if not bboxes:
        bboxes = np.zeros((0, 4))
        labels = np.zeros((0,))
    else:
        bboxes = np.array(bboxes, ndmin=2)
        labels = np.array(labels)
    if not bboxes_ignore:
        bboxes_ignore = np.zeros((0, 4))
        labels_ignore = np.zeros((0,))
    else:
        bboxes_ignore = np.array(bboxes_ignore, ndmin=2)
        labels_ignore = np.array(labels_ignore)
    ann = dict(
        bboxes=bboxes.astype(np.float32),
        labels=labels.astype(np.int64),
        bboxes_ignore=bboxes_ignore.astype(np.float32),
        labels_ignore=labels_ignore.astype(np.int64))

    return ann


# def _build_numpy_array_xml(y_true, y_pred, class_name, eval_name):
#     """
#     读取xml中的数据，计算真实标签矩形框以及预测结果矩形框数组
#
#     :param str y_true: 真实标签数据
#     :param str y_pred: 预测标签数据
#     :param list or str class_name: 类别名称
#     :param list or str eval_name: 文件名列表
#     :return: pred_array, true_array
#     """
#     if eval_name is None:
#         # get eval_name from det_path_list
#         list_eval_names = os.listdir(y_pred)
#         list_eval_name_gt = os.listdir(y_true)
#         assert len(list_eval_name_gt) == len(list_eval_names)
#         pred_array = _get_pred_array_xml(y_pred, list_eval_names, class_name)
#         true_array = _get_true_array_xml(y_true, list_eval_names, class_name)
#     else:
#         list_eval_names = _get_eval_name_from_txt(eval_name)
#         pred_array = _get_pred_array_xml(y_pred, list_eval_names, class_name)
#         true_array = _get_true_array_xml(y_true, list_eval_names, class_name)
#
#     return pred_array, true_array


def _build_numpy_array_dataset(inference_data, ground_truth_data, class_name, ground_truth_class_value_field,
                               inference_class_value_field):
    """
    读取datasetVector中的矢量数据，计算真实标签矩形框以及预测结果矩形框numpy数组

    :param inference_data: 必选参数。推理结果数据集，输入的矢量面数据集来自于模型推理object_detect_infer
    :type inference_data: str or DatasetVector
    :param ground_truth_data: 必选参数。真实标签数据集，输入的矢量面数据集来自于真实的标签数据集
    :type ground_truth_data: str or DatasetVector
    :param inference_class_value_field: 可选参数。推理结果数据包含类别字段名。如果指定的字段不存在或者为None，则所有记录都被认定为是同一个类。
    :type inference_class_value_field: str or None
    :param ground_truth_class_value_field: 可选参数。真实数据类别字段名。如果指定的字段不存在或者为None，则所有记录都被认定为是同一个类。
    :type ground_truth_class_value_field: str or None
    :param input_data_format: 可选参数。用于支持多种推理结果的数据集。默认为None，为None时候为矢量面数据集的格式
    :type input_data_format: str or None
    :return: inference_data, ground_truth_data
    """
    # 目标检测+对象提取计算ground_truth_data与inference_data的bound之间的交集
    bounds = ground_truth_data.bounds.intersect(inference_data.bounds)
    ground_truth_data = ground_truth_data.query_with_bounds(bounds)
    inference_data = inference_data.query_with_bounds(bounds)

    inference_array = []
    inference_result = _get_inference_result_dataset_vector(inference_data, inference_class_value_field, class_name)
    inference_array.append(inference_result)
    ground_truth_array = []
    if ground_truth_class_value_field is None:
        true_result = _get_ground_truth_dataset_vector(ground_truth_data, ground_truth_class_value_field, class_name)
        ground_truth_array.append(true_result)
    else:
        true_result = _get_ground_truth_dataset_vector(ground_truth_data, ground_truth_class_value_field, class_name)
        ground_truth_array.append(true_result)

    return inference_array, ground_truth_array
